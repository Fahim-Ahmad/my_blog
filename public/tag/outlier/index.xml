<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>outlier | Fahim Ahmad</title>
    <link>/tag/outlier/</link>
      <atom:link href="/tag/outlier/index.xml" rel="self" type="application/rss+xml" />
    <description>outlier</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Fahim Ahmad (2020)</copyright><lastBuildDate>Sun, 10 Feb 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png</url>
      <title>outlier</title>
      <link>/tag/outlier/</link>
    </image>
    
    <item>
      <title>Bayesian robust correlations with brms (and why you should love Student&#39;s $t$)</title>
      <link>/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/</guid>
      <description>
&lt;script src=&#34;/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;[edited Apr 21, 2021]&lt;/p&gt;
&lt;p&gt;In this post, we’ll show how Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution can produce better correlation estimates when your data have outliers. As is often the case, we’ll do so as Bayesians.&lt;/p&gt;
&lt;p&gt;This post is a direct consequence of Adrian Baez-Ortega’s great blog, “&lt;a href=&#34;https://baezortega.github.io/2018/05/28/robust-correlation/&#34;&gt;Bayesian robust correlation with Stan in R (and why you should use Bayesian methods)&lt;/a&gt;”. Baez-Ortega worked out the approach and code for direct use with &lt;a href=&#34;http://mc-stan.org&#34;&gt;Stan&lt;/a&gt; computational environment. That solution is great because Stan is free, open source, and very flexible. However, Stan’s interface might be prohibitively technical for non-statistician users. Happily, the &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms&lt;/a&gt; package allows users to access the computational power of Stan through a simpler interface. In this post, we show how to extend Baez-Ortega’s method to brms. To pay respects where they’re due, the synthetic data, priors, and other model settings are largely the same as those Baez-Ortega used in his blog.&lt;/p&gt;
&lt;div id=&#34;i-make-assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I make assumptions&lt;/h2&gt;
&lt;p&gt;For this post, I’m presuming you are vaguely familiar with linear regression, know about the basic differences between frequentist and Bayesian approaches to fitting models, and have a sense that the issue of outlier values is a pickle worth contending with. All code in is &lt;a href=&#34;https://www.r-bloggers.com/why-use-r-five-reasons/&#34;&gt;R&lt;/a&gt;, with a heavy use of the &lt;a href=&#34;http://style.tidyverse.org&#34;&gt;tidyverse&lt;/a&gt;–which you might learn a lot about &lt;a href=&#34;http://r4ds.had.co.nzhttp://r4ds.had.co.nz&#34;&gt;here, especially chapter 5&lt;/a&gt;–, and, of course, Bürkner’s &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you’d like a warmup, consider checking out my related post, &lt;a href=&#34;https://solomonkurz.netlify.com/post/robust-linear-regression-with-the-robust-student-s-t-distribution/&#34;&gt;Robust Linear Regression with Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-Distribution&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;whats-the-deal&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What’s the deal?&lt;/h2&gt;
&lt;p&gt;Pearson’s correlations are designed to quantify the linear relationship between two normally distributed variables. The normal distribution and its multivariate generalization, the multivariate normal distribution, are sensitive to outliers. When you have well-behaved synthetic data, this isn’t an issue. But if you work real-world data, this can be a problem. One can have data for which the vast majority of cases are well-characterized by a nice liner relationship, but have a few odd cases for which that relationship does not hold. And if those odd cases happen to be overly influential–sometimes called leverage points–the resulting Pearson’s correlation coefficient might look off.&lt;/p&gt;
&lt;p&gt;Recall that the normal distribution is a special case of Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution with the &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter (i.e., &lt;em&gt;nu&lt;/em&gt;, degree of freedom) set to infinity. As it turns out, when &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; is small, Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution is more robust to multivariate outliers. It’s less influenced by them. I’m not going to cover why in any detail. For that you’ve got &lt;a href=&#34;https://baezortega.github.io/2018/05/28/robust-correlation/&#34;&gt;Baez-Ortega’s blog&lt;/a&gt;, an even earlier blog from &lt;a href=&#34;http://www.sumsar.net/blog/2013/08/bayesian-estimation-of-correlation/&#34;&gt;Rasmus Bååth&lt;/a&gt;, and textbook treatments on the topic by &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/arm/&#34;&gt;Gelman &amp;amp; Hill (2007, chapter 6)&lt;/a&gt; and &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;Kruschke (2015, chapter 16)&lt;/a&gt;. Here we’ll get a quick sense of how vulnerable Pearson’s correlations–with their reliance on the Gaussian–are to outliers, we’ll demonstrate how fitting correlations within the Bayesian paradigm using the conventional Gaussian likelihood is similarly vulnerable to distortion, and then see how Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution can save the day. And importantly, we’ll do the bulk of this with the brms package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;we-need-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;We need data&lt;/h2&gt;
&lt;p&gt;To start off, we’ll make a multivariate normal simulated data set using the same steps Baez-Ortega’s used.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mvtnorm)
library(tidyverse)

sigma &amp;lt;- c(20, 40)  # the variances
rho   &amp;lt;- -.95       # the desired correlation

# here&amp;#39;s the variance/covariance matrix
cov.mat &amp;lt;- 
  matrix(c(sigma[1] ^ 2,
           sigma[1] * sigma[2] * rho,
           sigma[1] * sigma[2] * rho,
           sigma[2] ^ 2),
         nrow = 2, byrow = T)

# after setting our seed, we&amp;#39;re ready to simulate with `rmvnorm()`
set.seed(210191)
x.clean &amp;lt;- 
  rmvnorm(n = 40, sigma = cov.mat) %&amp;gt;% 
  as_tibble() %&amp;gt;% 
  rename(x = V1,
         y = V2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we make our second data set, &lt;code&gt;x.noisy&lt;/code&gt;, which is identical to our well-behaved &lt;code&gt;x.clean&lt;/code&gt; data, but with the first three cases transformed to outlier values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x.noisy &amp;lt;- x.clean

x.noisy[1:3,] &amp;lt;-
  matrix(c(-40, -60,
           20, 100,
           40, 40),
         nrow = 3, byrow = T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we’ll add an &lt;code&gt;outlier&lt;/code&gt; index to the data sets, which will help us with plotting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x.clean &amp;lt;-
  x.clean %&amp;gt;% 
  mutate(outlier = factor(0))

x.noisy &amp;lt;- 
  x.noisy %&amp;gt;% 
  mutate(outlier = c(rep(1, 3), rep(0, 37)) %&amp;gt;% as.factor(.))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The plot below shows what the &lt;code&gt;x.clean&lt;/code&gt; data look like. I’m a fan of &lt;a href=&#34;http://fivethirtyeight.com&#34;&gt;FiveThirtyEight&lt;/a&gt;, so we’ll use a few convenience functions from the handy &lt;a href=&#34;https://github.com/jrnold/ggthemes&#34;&gt;ggthemes package&lt;/a&gt; to give our plots a FiveThirtyEight-like feel.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggthemes)

x.clean %&amp;gt;% 
  ggplot(aes(x = x, y = y, color = outlier, fill = outlier)) +
  geom_point() +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, alpha = .15, size = .15, level = .5) +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, alpha = .15, size = .15, level = .95) +
  scale_color_fivethirtyeight() +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = c(-50, 50),
                  ylim = c(-100, 100)) +
  theme_fivethirtyeight() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;312&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And here are the &lt;code&gt;x.noisy&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x.noisy %&amp;gt;% 
  ggplot(aes(x = x, y = y, color = outlier, fill = outlier)) +
  geom_point() +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, alpha = .15, size = .15, level = .5) +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, alpha = .15, size = .15, level = .95) +
  scale_color_fivethirtyeight() +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = c(-50, 50),
                  ylim = c(-100, 100)) +
  theme_fivethirtyeight() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;312&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The three outliers are in red. Even in their presence, the old interocular trauma test suggests there is a pronounced overall trend in the data. I would like a correlation procedure that’s capable of capturing that overall trend. Let’s examine some candidates.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-does-old-pearson-hold-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How does old Pearson hold up?&lt;/h2&gt;
&lt;p&gt;A quick way to get a Pearson’s correlation coefficient in R is with the &lt;code&gt;cor()&lt;/code&gt; function, which does a nice job recovering the correlation we simulated the &lt;code&gt;x.clean&lt;/code&gt; data with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(x.clean$x, x.clean$y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.959702&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, things fall apart if you use &lt;code&gt;cor()&lt;/code&gt; on the &lt;code&gt;x.noisy&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(x.noisy$x, x.noisy$y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.6365649&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So even though most of the &lt;code&gt;x.noisy&lt;/code&gt; data continue to show a clear strong relation, three outlier values reduced the Pearson’s correlation a third of the way toward zero. Let’s see what happens when we go Bayesian.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-correlations-in-brms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bayesian correlations in brms&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/paulbuerkner&#34;&gt;Bürkner&lt;/a&gt;’s brms is a general purpose interface for fitting all manner of Bayesian regression models with &lt;a href=&#34;https://mc-stan.org&#34;&gt;Stan&lt;/a&gt; as the engine under the hood. It has popular &lt;a href=&#34;https://cran.r-project.org/web/packages/lme4/index.html&#34;&gt;lme4&lt;/a&gt;-like syntax and offers a variety of convenience functions for post processing. Let’s load it up.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;first-with-the-gaussian-likelihood.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;First with the Gaussian likelihood.&lt;/h3&gt;
&lt;p&gt;I’m not going to spend a lot of time walking through the syntax in the main brms function, &lt;code&gt;brm()&lt;/code&gt;. You can learn all about that &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;here&lt;/a&gt; or with my ebook &lt;a href=&#34;https://bookdown.org/content/3890/&#34;&gt;&lt;em&gt;Statistical Rethinking with brms, ggplot2, and the tidyverse&lt;/em&gt;&lt;/a&gt;. But our particular use of &lt;code&gt;brm()&lt;/code&gt; requires we make a few fine points.&lt;/p&gt;
&lt;p&gt;One doesn’t always think about bivariate correlations within the regression paradigm. But they work just fine. Within brms, you would typically specify the conventional Gaussian likelihood (i.e., &lt;code&gt;family = gaussian&lt;/code&gt;), use the &lt;code&gt;mvbind()&lt;/code&gt; syntax to set up a &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/vignettes/brms_multivariate.html&#34;&gt;multivariate model&lt;/a&gt;, and fit that model without predictors. For each variable specified in &lt;code&gt;cbind()&lt;/code&gt;, you’ll estimate an intercept (i.e., mean, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and sigma (i.e., &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, often called a residual variance). Since there are no predictors in the model, the residual variance is just the variance and the brms default for multivariate models is to allow the residual variances to covary. But since variances are parameterized in the standard deviation metric in brms, the residual variances and their covariance are &lt;em&gt;SD&lt;/em&gt;s and their correlation, respectively.&lt;/p&gt;
&lt;p&gt;Here’s what it looks like in practice.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f0 &amp;lt;- 
  brm(data = x.clean, 
      family = gaussian,
      bf(mvbind(x, y) ~ 1) + set_rescor(TRUE),
      prior = c(prior(normal(0, 100), class = Intercept, resp = x),
                prior(normal(0, 100), class = Intercept, resp = y),
                prior(normal(0, 100), class = sigma, resp = x),
                prior(normal(0, 100), class = sigma, resp = y),
                prior(lkj(1), class = rescor)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In a typical Bayesian workflow, you’d examine the quality of the chains with trace plots. The easy way to do that in brms is with &lt;code&gt;plot()&lt;/code&gt;. E.g., to get the trace plots for our first model, you’d code &lt;code&gt;plot(f0)&lt;/code&gt;. Happily, the trace plots look fine for all models in this post. For the sake of space, I’ll leave their inspection as exercises for interested readers.&lt;/p&gt;
&lt;p&gt;Our priors and such mirror those in Baez-Ortega’s blog. Here are the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: x ~ 1 
##          y ~ 1 
##    Data: x.clean (Number of observations: 40) 
## Samples: 4 chains, each with iter = 2000; warmup = 500; thin = 1;
##          total post-warmup samples = 6000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## x_Intercept    -2.85      3.40    -9.28     3.81 1.00     2449     2471
## y_Intercept     3.69      6.80    -9.80    16.64 1.00     2428     2368
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_x    21.49      2.60    17.25    27.39 1.00     2051     2251
## sigma_y    43.01      5.18    34.59    54.89 1.00     2102     2226
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(x,y)    -0.95      0.02    -0.98    -0.92 1.00     2146     2715
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Way down there in the last line in the ‘Family Specific Parameters’ section we have &lt;code&gt;rescor(x,y)&lt;/code&gt;, which is our correlation. And indeed, our Gaussian intercept-only multivariate model did a great job recovering the correlation we used to simulate the &lt;code&gt;x.clean&lt;/code&gt; data with. Look at what happens when we try this approach with &lt;code&gt;x.noisy&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f1 &amp;lt;-
  update(f0,
         newdata = x.noisy,
         iter = 2000, warmup = 500, chains = 4, cores = 4, seed = 210191)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: x ~ 1 
##          y ~ 1 
##    Data: x.noisy (Number of observations: 40) 
## Samples: 4 chains, each with iter = 2000; warmup = 500; thin = 1;
##          total post-warmup samples = 6000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## x_Intercept    -3.05      3.84   -10.60     4.44 1.00     4935     4170
## y_Intercept     6.71      7.59    -8.26    21.54 1.00     4832     4362
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_x    23.64      2.76    19.01    29.78 1.00     3699     3844
## sigma_y    47.17      5.54    37.86    59.66 1.00     4058     3752
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(x,y)    -0.61      0.10    -0.78    -0.39 1.00     3682     4159
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the correlation estimate is -.61. As it turns out, &lt;code&gt;data = x.noisy&lt;/code&gt; + &lt;code&gt;family = gaussian&lt;/code&gt; in &lt;code&gt;brm()&lt;/code&gt; failed us just like Pearson’s correlation failed us. Time to leave failure behind.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;now-with-students-t-distribution.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Now with Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution.&lt;/h3&gt;
&lt;p&gt;Before we jump into using &lt;code&gt;family = student&lt;/code&gt;, we should talk a bit about &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;. This is our new parameter which is silently fixed to infinity when we use the Gaussian likelihood. The &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter is bound at zero but, as discussed in Baez-Ortega’s blog, is somewhat nonsensical for values below 1. As it turns out, &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; is constrained to be equal to or greater than 1 in brms. So nothing for us to worry about, there. The &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;Stan team currently recommends the gamma(2, 0.1) prior for &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;&lt;/a&gt;, which is also the current brms default. This is what that distribution looks like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(x = seq(from = 1, to = 120, by = .5)) %&amp;gt;% 
  ggplot(aes(x = x, fill = factor(0))) +
  geom_ribbon(aes(ymin = 0, 
                  ymax = dgamma(x, 2, 0.1))) +
  scale_y_continuous(NULL, breaks = NULL) +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = c(0, 100)) +
  ggtitle(&amp;quot;gamma(2, 0.1)&amp;quot;) +
  theme_fivethirtyeight() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So gamma(2, 0.1) should gently push the &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; posterior toward low values, but it’s slowly-sloping right tail will allow higher values to emerge.&lt;/p&gt;
&lt;p&gt;Following the Stan team’s recommendation, the brms default and Baez-Ortega’s blog, here’s our robust Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; model for the &lt;code&gt;x.noisy&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f2 &amp;lt;- 
  brm(data = x.noisy, 
      family = student,
      bf(mvbind(x, y) ~ 1) + set_rescor(TRUE),
      prior = c(prior(gamma(2, .1), class = nu),
                prior(normal(0, 100), class = Intercept, resp = x),
                prior(normal(0, 100), class = Intercept, resp = y),
                prior(normal(0, 100), class = sigma, resp = x),
                prior(normal(0, 100), class = sigma, resp = y),
                prior(lkj(1), class = rescor)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(student, student) 
##   Links: mu = identity; sigma = identity; nu = identity
##          mu = identity; sigma = identity; nu = identity 
## Formula: x ~ 1 
##          y ~ 1 
##    Data: x.noisy (Number of observations: 40) 
## Samples: 4 chains, each with iter = 2000; warmup = 500; thin = 1;
##          total post-warmup samples = 6000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## x_Intercept    -2.07      3.59    -9.49     4.72 1.00     2412     2651
## y_Intercept     1.93      7.20   -11.31    16.81 1.00     2454     2815
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_x    18.35      2.99    13.12    24.76 1.00     2313     2816
## sigma_y    36.52      5.90    26.13    49.49 1.00     2216     3225
## nu          2.65      0.99     1.36     4.99 1.00     3500     2710
## nu_x        1.00      0.00     1.00     1.00 1.00     6000     6000
## nu_y        1.00      0.00     1.00     1.00 1.00     6000     6000
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(x,y)    -0.93      0.03    -0.97    -0.85 1.00     2974     3366
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Whoa, look at that correlation, &lt;code&gt;rescore(x,y)&lt;/code&gt;! It’s right about what we’d hope for. Sure, it’s not a perfect -.95, but that’s way better than -.61.&lt;/p&gt;
&lt;p&gt;While we’re at it, we may as well see what happens when we fit a Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; model when we have perfectly multivariate normal data. Here it is with the &lt;code&gt;x.clean&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f3 &amp;lt;- 
  update(f2,
         newdata = x.clean, 
         iter = 2000, warmup = 500, chains = 4, cores = 4, seed = 210191)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(student, student) 
##   Links: mu = identity; sigma = identity; nu = identity
##          mu = identity; sigma = identity; nu = identity 
## Formula: x ~ 1 
##          y ~ 1 
##    Data: x.clean (Number of observations: 40) 
## Samples: 4 chains, each with iter = 2000; warmup = 500; thin = 1;
##          total post-warmup samples = 6000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## x_Intercept    -2.31      3.45    -9.10     4.41 1.00     2819     3208
## y_Intercept     2.63      6.85   -10.82    16.16 1.00     2813     2882
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_x    20.75      2.59    16.29    26.28 1.00     2504     3202
## sigma_y    41.29      5.19    32.31    52.36 1.00     2596     3424
## nu         22.63     14.11     5.42    58.63 1.00     4002     3228
## nu_x        1.00      0.00     1.00     1.00 1.00     6000     6000
## nu_y        1.00      0.00     1.00     1.00 1.00     6000     6000
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(x,y)    -0.96      0.01    -0.98    -0.92 1.00     3147     3684
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So when you don’t need Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, it yields the right answer anyways. That’s a nice feature.&lt;/p&gt;
&lt;p&gt;We should probably compare the posteriors of the correlations across the four models. First we’ll collect the posterior samples into a tibble.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posts &amp;lt;-
  tibble(model = str_c(&amp;quot;f&amp;quot;, 0:3)) %&amp;gt;% 
  mutate(fit = map(model, get)) %&amp;gt;% 
  mutate(post = map(fit, posterior_samples)) %&amp;gt;% 
  unnest(post)

head(posts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 11
##   model fit       b_x_Intercept b_y_Intercept sigma_x sigma_y rescor__x__y  lp__
##   &amp;lt;chr&amp;gt; &amp;lt;list&amp;gt;            &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 f0    &amp;lt;brmsfit&amp;gt;         -6.60        14.2      21.6    46.9       -0.968 -355.
## 2 f0    &amp;lt;brmsfit&amp;gt;         -4.85         8.20     19.5    42.5       -0.941 -353.
## 3 f0    &amp;lt;brmsfit&amp;gt;         -1.35        -0.678    19.8    37.9       -0.955 -352.
## 4 f0    &amp;lt;brmsfit&amp;gt;         -6.02         9.94     22.9    46.0       -0.963 -352.
## 5 f0    &amp;lt;brmsfit&amp;gt;         -9.25        13.8      24.9    45.6       -0.966 -355.
## 6 f0    &amp;lt;brmsfit&amp;gt;         -5.31         6.55     23.3    43.0       -0.955 -353.
## # … with 3 more variables: nu &amp;lt;dbl&amp;gt;, nu_x &amp;lt;dbl&amp;gt;, nu_y &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the posterior draws in hand, we just need to wrangle a bit before showing the correlation posteriors in a coefficient plot. To make things easier, we’ll do so with a couple convenience functions from the &lt;a href=&#34;https://github.com/mjskay/tidybayes&#34;&gt;tidybayes&lt;/a&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidybayes)

# wrangle
posts %&amp;gt;% 
  group_by(model) %&amp;gt;% 
  median_qi(rescor__x__y, .width = c(.5, .95)) %&amp;gt;% 
  mutate(key = recode(model, 
                      f0 = &amp;quot;Gaussian likelihood with clean data&amp;quot;,
                      f1 = &amp;quot;Gaussian likelihood with noisy data&amp;quot;,
                      f2 = &amp;quot;Student likelihood with noisy data&amp;quot;,
                      f3 = &amp;quot;Student likelihood with clean data&amp;quot;),
         clean = ifelse(model %in% c(&amp;quot;f0&amp;quot;, &amp;quot;f3&amp;quot;), &amp;quot;0&amp;quot;, &amp;quot;1&amp;quot;)) %&amp;gt;%
  
  # plot
  ggplot(aes(x = rescor__x__y, xmin = .lower, xmax = .upper, y = key, 
             color = clean)) +
  geom_pointinterval() +
  scale_color_fivethirtyeight() +
  scale_x_continuous(breaks = -5:0 / 5, limits = -1:0, expand = expansion(mult = c(0, 0.05))) +
  labs(subtitle = expression(paste(&amp;quot;The posterior for &amp;quot;, rho, &amp;quot; depends on the likelihood. Why not go robust and use Student&amp;#39;s &amp;quot;, italic(t), &amp;quot;?&amp;quot;))) +
  theme_fivethirtyeight() +
  theme(axis.text.y = element_text(hjust = 0),
        legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/index_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From our &lt;code&gt;tidybayes::median_qi()&lt;/code&gt; code, the dots are the posterior medians, the thick inner lines the 50% intervals, and the thinner outer lines the 95% intervals. The posteriors for the &lt;code&gt;x.noisy&lt;/code&gt; data are in red and those for the &lt;code&gt;x.clean&lt;/code&gt; data are in blue. If the data are clean multivariate normal Gaussian or if they’re dirty but fit with robust Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, everything is pretty much alright. But whoa, if you fit a correlation with a combination of &lt;code&gt;family = gaussian&lt;/code&gt; and noisy outlier-laden data, man that’s just a mess.&lt;/p&gt;
&lt;p&gt;Don’t let a few overly-influential outliers make a mess of your analyses. Try the robust Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.3.1 brms_2.15.0     Rcpp_1.0.6      ggthemes_4.2.4 
##  [5] forcats_0.5.1   stringr_1.4.0   dplyr_1.0.5     purrr_0.3.4    
##  [9] readr_1.4.0     tidyr_1.1.3     tibble_3.1.0    ggplot2_3.3.3  
## [13] tidyverse_1.3.0 mvtnorm_1.1-1  
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      Hmisc_4.4-2         
##   [4] plyr_1.8.6           igraph_1.2.6         svUnit_1.0.3        
##   [7] splines_4.0.4        crosstalk_1.1.0.1    TH.data_1.0-10      
##  [10] rstantools_2.1.1     inline_0.3.17        digest_0.6.27       
##  [13] htmltools_0.5.1.1    rsconnect_0.8.16     gdata_2.18.0        
##  [16] fansi_0.4.2          checkmate_2.0.0      magrittr_2.0.1      
##  [19] cluster_2.1.0        modelr_0.1.8         RcppParallel_5.0.2  
##  [22] matrixStats_0.57.0   xts_0.12.1           sandwich_3.0-0      
##  [25] prettyunits_1.1.1    jpeg_0.1-8.1         colorspace_2.0-0    
##  [28] rvest_0.3.6          ggdist_2.4.0.9000    haven_2.3.1         
##  [31] xfun_0.22            callr_3.5.1          crayon_1.4.1        
##  [34] jsonlite_1.7.2       lme4_1.1-25          survival_3.2-10     
##  [37] zoo_1.8-8            glue_1.4.2           gtable_0.3.0        
##  [40] emmeans_1.5.2-1      V8_3.4.0             distributional_0.2.2
##  [43] weights_1.0.1        pkgbuild_1.2.0       rstan_2.21.2        
##  [46] abind_1.4-5          scales_1.1.1         DBI_1.1.0           
##  [49] miniUI_0.1.1.1       htmlTable_2.1.0      xtable_1.8-4        
##  [52] foreign_0.8-81       Formula_1.2-4        stats4_4.0.4        
##  [55] StanHeaders_2.21.0-7 DT_0.16              htmlwidgets_1.5.2   
##  [58] httr_1.4.2           threejs_0.3.3        arrayhelpers_1.1-0  
##  [61] RColorBrewer_1.1-2   ellipsis_0.3.1       mice_3.13.0         
##  [64] pkgconfig_2.0.3      loo_2.4.1            farver_2.0.3        
##  [67] nnet_7.3-15          dbplyr_2.0.0         utf8_1.1.4          
##  [70] tidyselect_1.1.0     labeling_0.4.2       rlang_0.4.10        
##  [73] reshape2_1.4.4       later_1.1.0.1        munsell_0.5.0       
##  [76] cellranger_1.1.0     tools_4.0.4          cli_2.3.1           
##  [79] generics_0.1.0       broom_0.7.5          ggridges_0.5.2      
##  [82] evaluate_0.14        fastmap_1.0.1        yaml_2.2.1          
##  [85] processx_3.4.5       knitr_1.31           fs_1.5.0            
##  [88] nlme_3.1-152         mime_0.10            projpred_2.0.2      
##  [91] xml2_1.3.2           compiler_4.0.4       bayesplot_1.8.0     
##  [94] shinythemes_1.1.2    rstudioapi_0.13      png_0.1-7           
##  [97] gamm4_0.2-6          curl_4.3             reprex_0.3.0        
## [100] statmod_1.4.35       stringi_1.5.3        highr_0.8           
## [103] ps_1.6.0             blogdown_1.3         Brobdingnag_1.2-6   
## [106] lattice_0.20-41      Matrix_1.3-2         nloptr_1.2.2.2      
## [109] markdown_1.1         shinyjs_2.0.0        vctrs_0.3.6         
## [112] pillar_1.5.1         lifecycle_1.0.0      bridgesampling_1.0-0
## [115] estimability_1.3     data.table_1.14.0    httpuv_1.5.4        
## [118] latticeExtra_0.6-29  R6_2.5.0             bookdown_0.21       
## [121] promises_1.1.1       gridExtra_2.3        codetools_0.2-18    
## [124] boot_1.3-26          colourpicker_1.1.0   MASS_7.3-53         
## [127] gtools_3.8.2         assertthat_0.2.1     withr_2.4.1         
## [130] shinystan_2.5.0      multcomp_1.4-16      mgcv_1.8-33         
## [133] parallel_4.0.4       hms_0.5.3            rpart_4.1-15        
## [136] grid_4.0.4           coda_0.19-4          minqa_1.2.4         
## [139] rmarkdown_2.7        shiny_1.5.0          lubridate_1.7.9.2   
## [142] base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Robust Linear Regression with Student’s $t$-Distribution</title>
      <link>/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/</link>
      <pubDate>Sat, 02 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/</guid>
      <description>
&lt;script src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;[edited Nov 30, 2020]&lt;/p&gt;
&lt;p&gt;The purpose of this post is to demonstrate the advantages of the Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution for regression with outliers, particularly within a &lt;a href=&#34;https://www.youtube.com/channel/UCNJK6_DZvcMqNSzQdEkzvzA/playlists&#34;&gt;Bayesian framework&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;i-make-assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I make assumptions&lt;/h2&gt;
&lt;p&gt;I’m presuming you are familiar with linear regression, familiar with the basic differences between frequentist and Bayesian approaches to fitting regression models, and have a sense that the issue of outlier values is a pickle worth contending with. All code in is &lt;a href=&#34;https://www.r-bloggers.com/why-use-r-five-reasons/&#34;&gt;&lt;strong&gt;R&lt;/strong&gt;&lt;/a&gt;, with a heavy use of the &lt;a href=&#34;https://style.tidyverse.org/&#34;&gt;&lt;strong&gt;tidyverse&lt;/strong&gt;&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-tidyverse&#34; role=&#34;doc-biblioref&#34;&gt;Wickham, 2019&lt;/a&gt;; &lt;a href=&#34;#ref-wickhamWelcomeTidyverse2019&#34; role=&#34;doc-biblioref&#34;&gt;Wickham et al., 2019&lt;/a&gt;)&lt;/span&gt;, about which you might learn a lot more from &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-grolemundDataScience2017&#34; role=&#34;doc-biblioref&#34;&gt;Grolemund &amp;amp; Wickham&lt;/a&gt; (&lt;a href=&#34;#ref-grolemundDataScience2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;, especially &lt;a href=&#34;https://r4ds.had.co.nz/transform.html&#34;&gt;chapter 5&lt;/a&gt;. The Bayesian models are fit with &lt;a href=&#34;https://twitter.com/paulbuerkner&#34;&gt;Paul Bürkner&lt;/a&gt;’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-burknerBrmsPackageBayesian2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;, &lt;a href=&#34;#ref-burknerAdvancedBayesianMultilevel2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;, &lt;a href=&#34;#ref-R-brms&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;&lt;strong&gt;brms&lt;/strong&gt; package&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;Simple regression models typically use the Gaussian likelihood. Say you have some criterion variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, which you can reasonably describe with a mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Further, you’d like to describe &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; with a predictor &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. Using the Gaussian likelihood, we can describe the model as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_i &amp;amp; \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i &amp;amp; = \beta_0 + \beta_1 x_i.
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;With this formulation, we use &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; to model the mean of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. The &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; parameter is the intercept of the regression model and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is its slope with respect to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. After accounting for &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;’s relation with &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, the leftover variability in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is described by &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, often called error or residual variance. The reason we describe the model in terms of &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is because those are the two parameters by which we define the Normal distribution, the Gaussian likelihood.&lt;/p&gt;
&lt;p&gt;The Gaussian is a sensible default choice for many data types. You might say it works unreasonably well. Unfortunately, the normal (i.e., Gaussian) distribution is sensitive to outliers.&lt;/p&gt;
&lt;p&gt;The normal distribution is a special case of Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution with the &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter (i.e., the degree of freedom) set to infinity. However, when &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; is small, Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution is more robust to multivariate outliers. See Gelman &amp;amp; Hill &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-gelmanDataAnalysisUsing2006&#34; role=&#34;doc-biblioref&#34;&gt;2006, Chapter 6&lt;/a&gt;)&lt;/span&gt;, Kruschke &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;2015, Chapter 16&lt;/a&gt;)&lt;/span&gt;, or McElreath &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;2020, Chapter 7&lt;/a&gt;)&lt;/span&gt; for textbook treatments on the topic.&lt;/p&gt;
&lt;p&gt;In this post, we demonstrate how vulnerable the Gaussian likelihood is to outliers and then compare it to different ways of using Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-likelihood for the same data.&lt;/p&gt;
&lt;p&gt;First, we’ll get a sense of the distributions with a plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

tibble(x = seq(from = -6, to = 6, by = .01)) %&amp;gt;% 
  expand(x, nu = c(1, 2.5, 5, 10, Inf)) %&amp;gt;% 
  mutate(density = dt(x = x, df = nu),
         nu      = factor(nu, levels = c(&amp;quot;Inf&amp;quot;, &amp;quot;10&amp;quot;, &amp;quot;5&amp;quot;, &amp;quot;2.5&amp;quot;, &amp;quot;1&amp;quot;))) %&amp;gt;% 
  
  ggplot(aes(x = x, y = density, group = nu, color = nu)) +
  geom_line() +
  scale_color_viridis_d(expression(nu),
                        direction = 1, option = &amp;quot;C&amp;quot;, end = .85) +
  scale_y_continuous(NULL, breaks = NULL) +
  coord_cartesian(xlim = c(-5, 5)) +
  xlab(NULL) +
  theme(panel.grid = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;528&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So the difference is that a Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution with a low &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; will have notably heavier tails than the conventional Gaussian distribution. It’s easiest to see the difference when &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; approaches 1. Even then, the difference can be subtle when looking at a plot. Another way is to compare how probable relatively extreme values are in a Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution relative to the Gaussian. For the sake of demonstration, here we’ll compare Gauss with Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; with a &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; of 5. In the plot above, they are clearly different, but not shockingly so. However, that difference is very notable in the tails.&lt;/p&gt;
&lt;p&gt;Let’s look more closely with a table. Below, we compare the probability of a given &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;-score or lower within the Gaussian and a &lt;span class=&#34;math inline&#34;&gt;\(\nu = 5\)&lt;/span&gt; Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. In the rightmost column, we compare the probabilities in a ratio.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# here we pic our nu
nu &amp;lt;- 5

tibble(z_score               = 0:-5,
       p_Gauss               = pnorm(z_score, mean = 0, sd = 1),
       p_Student_t           = pt(z_score, df = nu),
       `Student/Gauss ratio` = p_Student_t/p_Gauss) %&amp;gt;%
  mutate_if(is.double, round, digits = 5) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;z_score&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p_Gauss&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p_Student_t&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Student/Gauss ratio&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.50000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.50000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.15866&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.18161&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.14468&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.02275&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.05097&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.24042&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00135&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.01505&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.14871&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00003&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00516&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;162.97775&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00205&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7159.76534&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note how low &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;-scores are more probable in this Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; than in the Gaussian. This is most apparent in the &lt;code&gt;Student/Gauss ratio&lt;/code&gt; column on the right. A consequence of this is that extreme scores are less influential to your solutions when you use a small-&lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution in place of the Gaussian. That is, the small-&lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; is more robust than the Gaussian to unusual and otherwise influential observations.&lt;/p&gt;
&lt;p&gt;In order to demonstrate, let’s simulate our own. We’ll start by creating multivariate normal data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-create-our-initial-tibble-of-well-behaved-data-d&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let’s create our initial &lt;a href=&#34;https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html&#34;&gt;tibble&lt;/a&gt; of well-behaved data, &lt;code&gt;d&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;First, we’ll need to define our variance/covariance matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s &amp;lt;- matrix(c(1, .6, 
              .6, 1), 
             nrow = 2, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By the two &lt;code&gt;.6&lt;/code&gt;s on the off-diagonal positions, we indicated we’d like our two variables to have a correlation of .6.&lt;/p&gt;
&lt;p&gt;Second, our variables also need means, which we’ll define with a mean vector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m &amp;lt;- c(0, 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With means of &lt;code&gt;0&lt;/code&gt; and variances of &lt;code&gt;1&lt;/code&gt;, our data are in a standardized metric.&lt;/p&gt;
&lt;p&gt;Third, we’ll use the &lt;code&gt;mvrnorm()&lt;/code&gt; function from the &lt;a href=&#34;https://CRAN.R-project.org/package=MASS&#34;&gt;&lt;strong&gt;MASS&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-MASS&#34; role=&#34;doc-biblioref&#34;&gt;Ripley, 2019&lt;/a&gt;)&lt;/span&gt; to simulate our data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(3)

d &amp;lt;- MASS::mvrnorm(n = 100, mu = m, Sigma = s) %&amp;gt;%
  as_tibble() %&amp;gt;%
  rename(y = V1, x = V2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first few rows look like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##         y      x
##     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 -1.14   -0.584
## 2 -0.0805 -0.443
## 3 -0.239   0.702
## 4 -1.30   -0.761
## 5 -0.280   0.630
## 6 -0.245   0.299&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an aside, check out &lt;a href=&#34;https://www.r-bloggers.com/creating-sample-datasets-exercises/&#34;&gt;this nice r-bloggers post&lt;/a&gt; for more information on simulating data with this method.&lt;/p&gt;
&lt;p&gt;Anyway, this line reorders our data by &lt;code&gt;x&lt;/code&gt;, placing the smallest values on top.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;-
  d %&amp;gt;%
  arrange(x)

head(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##        y     x
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 -2.21  -1.84
## 2 -1.27  -1.71
## 3 -0.168 -1.60
## 4 -0.292 -1.46
## 5 -0.785 -1.40
## 6 -0.157 -1.37&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-create-our-outlier-tibble-o&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let’s create our outlier tibble, &lt;code&gt;o&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Here we’ll make two outlying and unduly influential values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;o &amp;lt;- d
o[c(1:2), 1] &amp;lt;- c(5, 4.5)

head(o)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##        y     x
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1  5     -1.84
## 2  4.5   -1.71
## 3 -0.168 -1.60
## 4 -0.292 -1.46
## 5 -0.785 -1.40
## 6 -0.157 -1.37&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the code, above, we replaced the first two values of our first variable, &lt;code&gt;y&lt;/code&gt;. They both started out quite negative. Now they are positive values of a large magnitude within the standardized metric.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;frequentist-ols-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Frequentist &lt;a href=&#34;https://en.wikipedia.org/wiki/Ordinary_least_squares&#34;&gt;OLS&lt;/a&gt; models&lt;/h2&gt;
&lt;p&gt;To get a quick sense of what we’ve done, we’ll first fit two models with OLS regression via the &lt;code&gt;lm()&lt;/code&gt; function. The first model, &lt;code&gt;ols0&lt;/code&gt;, is of the multivariate normal data, &lt;code&gt;d&lt;/code&gt;. The second model, &lt;code&gt;ols1&lt;/code&gt;, is on the otherwise identical data with the two odd and influential values, &lt;code&gt;o&lt;/code&gt;. Here is our model code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ols0 &amp;lt;- lm(data = d, y ~ 1 + x)
ols1 &amp;lt;- lm(data = o, y ~ 1 + x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll use the &lt;a href=&#34;https://cran.r-project.org/web/packages/broom/index.html&#34;&gt;&lt;strong&gt;broom&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-broom&#34; role=&#34;doc-biblioref&#34;&gt;Robinson &amp;amp; Hayes, 2020&lt;/a&gt;)&lt;/span&gt; to assist with model summaries and other things. Here are the parameter estimates for the first model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(broom)

tidy(ols0) %&amp;gt;% mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 5
##   term        estimate std.error statistic p.value
##   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 (Intercept)    -0.01      0.09     -0.08    0.94
## 2 x               0.45      0.1       4.55    0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now the parameters for the second model, the one based on the &lt;code&gt;o&lt;/code&gt; outlier data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(ols1) %&amp;gt;% mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 5
##   term        estimate std.error statistic p.value
##   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 (Intercept)     0.13      0.11      1.15    0.25
## 2 x               0.14      0.13      1.1     0.27&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just two odd and influential values dramatically changed the model parameters, particularly the slope. Let’s plot the data and the models to get a visual sense of what happened.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the well-behaved data
p1 &amp;lt;-
  ggplot(data = d, aes(x = x, y = y)) +
  stat_smooth(method = &amp;quot;lm&amp;quot;, color = &amp;quot;grey92&amp;quot;, fill = &amp;quot;grey67&amp;quot;, alpha = 1, fullrange = T) +
  geom_point(size = 1, alpha = 3/4) +
  scale_x_continuous(limits = c(-4, 4)) +
  coord_cartesian(xlim = c(-3, 3), 
                  ylim = c(-3, 5)) +
  labs(title = &amp;quot;No Outliers&amp;quot;) +
  theme(panel.grid = element_blank())

# the data with two outliers
p2 &amp;lt;-
  ggplot(data = o, aes(x = x, y = y, color = y &amp;gt; 3)) +
  stat_smooth(method = &amp;quot;lm&amp;quot;, color = &amp;quot;grey92&amp;quot;, fill = &amp;quot;grey67&amp;quot;, alpha = 1, fullrange = T) +
  geom_point(size = 1, alpha = 3/4) +
  scale_color_viridis_d(option = &amp;quot;A&amp;quot;, end = 4/7) +
  scale_x_continuous(limits = c(-4, 4)) +
  coord_cartesian(xlim = c(-3, 3), 
                  ylim = c(-3, 5)) +
  labs(title = &amp;quot;Two Outliers&amp;quot;) +
  theme(panel.grid = element_blank(),
        legend.position = &amp;quot;none&amp;quot;)

# combine the ggplots with patchwork syntax
library(patchwork)

p1 + p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;648&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The two outliers were quite influential on the slope. It went from a nice clear diagonal to almost horizontal. You’ll also note how the 95% intervals (i.e., the bowtie shapes) were a bit wider when based on the &lt;code&gt;o&lt;/code&gt; data.&lt;/p&gt;
&lt;p&gt;One of the popular ways to quantify outlier status is with Mahalanobis’ distance. However, the Mahalanobis distance is primarily valid for multivariate normal data. Though the data in this example are indeed multivariate normal–or at least they were before we injected two outlying values into them–I am going to resist relying on Mahalanobis’ distance. There are other more general approaches that will be of greater use when you need to explore other variants of the generalized linear model. The &lt;code&gt;broom::augment()&lt;/code&gt; function will give us access to one.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;aug0 &amp;lt;- augment(ols0)
aug1 &amp;lt;- augment(ols1)

glimpse(aug1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 100
## Columns: 8
## $ y          &amp;lt;dbl&amp;gt; 5.00000000, 4.50000000, -0.16783167, -0.29164105, -0.784918…
## $ x          &amp;lt;dbl&amp;gt; -1.8439208, -1.7071418, -1.5996509, -1.4601550, -1.3954395,…
## $ .fitted    &amp;lt;dbl&amp;gt; -0.129991947, -0.110805943, -0.095728191, -0.076161086, -0.…
## $ .resid     &amp;lt;dbl&amp;gt; 5.12999195, 4.61080594, -0.07210348, -0.21547996, -0.717835…
## $ .hat       &amp;lt;dbl&amp;gt; 0.05521164, 0.04881414, 0.04412882, 0.03849763, 0.03605748,…
## $ .sigma     &amp;lt;dbl&amp;gt; 0.9887858, 1.0170749, 1.1246348, 1.1244384, 1.1222070, 1.12…
## $ .cooksd    &amp;lt;dbl&amp;gt; 6.500952e-01, 4.580898e-01, 1.002809e-04, 7.721988e-04, 7.9…
## $ .std.resid &amp;lt;dbl&amp;gt; 4.71688666, 4.22522826, -0.06591171, -0.19639831, -0.653439…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we can compare the observations with Cook’s distance, &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; (i.e., &lt;code&gt;.cooksd&lt;/code&gt;). Cook’s &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; is a measure of the influence of a given observation on the model. To compute &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt;, the model is fit once for each &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; case, after first dropping that case. Then the difference in the model with all observations and the model with all observations but the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;th observation, as defined by the Euclidean distance between the estimators. Fahrmeir et al &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-fahrmeirRegressionModelsMethods2013&#34; role=&#34;doc-biblioref&#34;&gt;2013, p. 166&lt;/a&gt;)&lt;/span&gt; suggest that within the OLS framework “as a rule of thumb, observations with &lt;span class=&#34;math inline&#34;&gt;\(D_i &amp;gt; 0.5\)&lt;/span&gt; are worthy of attention, and observations with &lt;span class=&#34;math inline&#34;&gt;\(D_i &amp;gt; 1\)&lt;/span&gt; should always be examined.” Here we plot &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; against our observation index, &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, for both models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  aug0 %&amp;gt;% mutate(i = 1:n()),  # the well-behaved data
  aug1 %&amp;gt;% mutate(i = 1:n())   # the data with two outliers
) %&amp;gt;%
  mutate(fit = rep(c(&amp;quot;fit b0&amp;quot;, &amp;quot;fit b1&amp;quot;), each = n()/2)) %&amp;gt;%
  ggplot(aes(x = i, y = .cooksd)) +
  geom_hline(yintercept = .5, color = &amp;quot;white&amp;quot;) +
  geom_point(alpha = .5) +
  geom_text(data = tibble(i = 46, 
                          .cooksd = .53,
                          fit = &amp;quot;fit b0&amp;quot;),
            label = &amp;quot;Fahrmeir et al said we might worry around here&amp;quot;,
            color = &amp;quot;grey50&amp;quot;) +
  coord_cartesian(ylim = c(0, .7)) +
  theme(panel.grid = element_blank(),
        axis.title.x = element_text(face = &amp;quot;italic&amp;quot;, family = &amp;quot;Times&amp;quot;)) +
    facet_wrap(~ fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the model of the well-behaved data, &lt;code&gt;ols0&lt;/code&gt;, we have &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; values all hovering near zero. However, the plot for &lt;code&gt;ols1&lt;/code&gt; shows one &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; value well above the 0.5 level and another not quite that high but deviant relative to the rest. Our two outlier values look quite influential for the results of &lt;code&gt;ols1&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;switch-to-a-bayesian-framework&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Switch to a Bayesian framework&lt;/h2&gt;
&lt;p&gt;It’s time to fire up &lt;strong&gt;brms&lt;/strong&gt;, the package with which we’ll be fitting our Bayesian models. As with all Bayesian models, we’ll need to us use priors. To keep things simple, we’ll use weakly-regularizing priors of the sort &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;discussed by the Stan team&lt;/a&gt;. For more thoughts on how to set priors, check out Kruschke’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; text or either edition of McElreath’s text &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;, &lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;stick-with-gauss.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Stick with Gauss.&lt;/h3&gt;
&lt;p&gt;For our first two Bayesian models, &lt;code&gt;b0&lt;/code&gt; and &lt;code&gt;b1&lt;/code&gt;, we’ll use the conventional Gaussian likelihood (i.e., &lt;code&gt;family = gaussian&lt;/code&gt; in the &lt;code&gt;brm()&lt;/code&gt; function). Like with &lt;code&gt;ols0&lt;/code&gt;, above, the first model is based on the nice &lt;code&gt;d&lt;/code&gt; data. The second, &lt;code&gt;b1&lt;/code&gt;, is based on the more-difficult &lt;code&gt;o&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b0 &amp;lt;- 
  brm(data = d, 
      family = gaussian,
      y ~ 1 + x,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(cauchy(0, 1),  class = sigma)),
      seed = 1)
b1 &amp;lt;- 
  update(b0, 
         newdata = o,
         seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the model summaries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_summary(b0)[1:3, ] %&amp;gt;% round(digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate Est.Error  Q2.5 Q97.5
## b_Intercept    -0.01      0.09 -0.18  0.16
## b_x             0.44      0.10  0.25  0.64
## sigma           0.86      0.06  0.75  0.99&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_summary(b1)[1:3, ] %&amp;gt;% round(digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate Est.Error  Q2.5 Q97.5
## b_Intercept     0.13      0.11 -0.09  0.35
## b_x             0.14      0.13 -0.11  0.40
## sigma           1.13      0.08  0.98  1.29&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We summarized our model parameters with &lt;code&gt;brms::posterior_summary()&lt;/code&gt; rather than &lt;code&gt;broom::tid()&lt;/code&gt;. Otherwise, these should look familiar. They’re very much like the results from the OLS models. Hopefully this isn’t surprising. Our priors were quite weak, so there’s no reason to suspect the results would differ much.&lt;/p&gt;
&lt;div id=&#34;the-loo-and-other-goodies-help-with-diagnostics.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;The LOO and other goodies help with diagnostics.&lt;/h4&gt;
&lt;p&gt;With the &lt;code&gt;loo()&lt;/code&gt; function, we’ll extract loo objects, which contain some handy output.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_b0 &amp;lt;- loo(b0)
loo_b1 &amp;lt;- loo(b1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll use &lt;code&gt;str()&lt;/code&gt; to get a sense of what’s all in there, using &lt;code&gt;loo_b1&lt;/code&gt; as an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(loo_b1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 10
##  $ estimates  : num [1:3, 1:2] -157.41 6.65 314.81 15.76 3.75 ...
##   ..- attr(*, &amp;quot;dimnames&amp;quot;)=List of 2
##   .. ..$ : chr [1:3] &amp;quot;elpd_loo&amp;quot; &amp;quot;p_loo&amp;quot; &amp;quot;looic&amp;quot;
##   .. ..$ : chr [1:2] &amp;quot;Estimate&amp;quot; &amp;quot;SE&amp;quot;
##  $ pointwise  : num [1:100, 1:5] -13.47 -10.79 -1.06 -1.08 -1.27 ...
##   ..- attr(*, &amp;quot;dimnames&amp;quot;)=List of 2
##   .. ..$ : NULL
##   .. ..$ : chr [1:5] &amp;quot;elpd_loo&amp;quot; &amp;quot;mcse_elpd_loo&amp;quot; &amp;quot;p_loo&amp;quot; &amp;quot;looic&amp;quot; ...
##  $ diagnostics:List of 2
##   ..$ pareto_k: num [1:100] 0.8171 0.6003 0.0139 -0.0705 -0.0817 ...
##   ..$ n_eff   : num [1:100] 71.1 186.8 2553.2 2795.7 3845.7 ...
##  $ psis_object: NULL
##  $ elpd_loo   : num -157
##  $ p_loo      : num 6.65
##  $ looic      : num 315
##  $ se_elpd_loo: num 15.8
##  $ se_p_loo   : num 3.75
##  $ se_looic   : num 31.5
##  - attr(*, &amp;quot;dims&amp;quot;)= int [1:2] 4000 100
##  - attr(*, &amp;quot;class&amp;quot;)= chr [1:3] &amp;quot;psis_loo&amp;quot; &amp;quot;importance_sampling_loo&amp;quot; &amp;quot;loo&amp;quot;
##  - attr(*, &amp;quot;yhash&amp;quot;)= chr &amp;quot;b52ef230de67f0bebc3480da360987ee2c0f4de8&amp;quot;
##  - attr(*, &amp;quot;model_name&amp;quot;)= chr &amp;quot;b1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For a detailed explanation of all those elements, see the &lt;a href=&#34;https://CRAN.R-project.org/package=loo/loo.pdf&#34;&gt;&lt;strong&gt;loo&lt;/strong&gt; reference manual&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-loo2020RM&#34; role=&#34;doc-biblioref&#34;&gt;Vehtari et al., 2020&lt;/a&gt;)&lt;/span&gt;. For our purposes, we’ll focus on the &lt;code&gt;pareto_k&lt;/code&gt;. Here’s a glimpse of what it contains for the &lt;code&gt;b1&lt;/code&gt; model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_b1$diagnostics$pareto_k %&amp;gt;% as_tibble()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 100 x 1
##       value
##       &amp;lt;dbl&amp;gt;
##  1  0.817  
##  2  0.600  
##  3  0.0139 
##  4 -0.0705 
##  5 -0.0817 
##  6 -0.00611
##  7  0.0431 
##  8  0.00514
##  9  0.111  
## 10  0.0629 
## # … with 90 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ve got us a numeric vector of as many values as our data had observations–100 in this case. The &lt;code&gt;pareto_k&lt;/code&gt; values can be used to examine overly-influential cases. See, for example &lt;a href=&#34;https://stackoverflow.com/questions/39578834/linear-model-diagnostics-for-bayesian-models-using-rstan/39595436&#34;&gt;this discussion on stackoverflow.com&lt;/a&gt; in which several members of the &lt;a href=&#34;http://mc-stan.org&#34;&gt;Stan team&lt;/a&gt; weighed in. The issue is also discussed in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-vehtariPracticalBayesianModel2017&#34; role=&#34;doc-biblioref&#34;&gt;Vehtari et al.&lt;/a&gt; (&lt;a href=&#34;#ref-vehtariPracticalBayesianModel2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;, in the &lt;a href=&#34;https://CRAN.R-project.org/package=loo/loo.pdf&#34;&gt;&lt;strong&gt;loo&lt;/strong&gt; reference manual&lt;/a&gt;, and in &lt;a href=&#34;https://www.youtube.com/watch?v=FUROJM3u5HQ&amp;amp;feature=youtu.be&amp;amp;a=&#34;&gt;this presentation by Aki Vehtari&lt;/a&gt;, himself. If we explicitly open the &lt;a href=&#34;https://CRAN.R-project.org/package=loo&#34;&gt;&lt;strong&gt;loo&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-loo&#34; role=&#34;doc-biblioref&#34;&gt;Vehtari et al., 2019&lt;/a&gt;)&lt;/span&gt;, we can use a few convenience functions to leverage &lt;code&gt;pareto_k&lt;/code&gt; for diagnostic purposes. The &lt;code&gt;pareto_k_table()&lt;/code&gt; function will categorize the &lt;code&gt;pareto_k&lt;/code&gt; values and give us a sense of how many values are in problematic ranges.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(loo)

pareto_k_table(loo_b1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     98    98.0%   2439      
##  (0.5, 0.7]   (ok)        1     1.0%   187       
##    (0.7, 1]   (bad)       1     1.0%   71        
##    (1, Inf)   (very bad)  0     0.0%   &amp;lt;NA&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Happily, most of our cases were in the “good” range. One pesky case was in the “bad” range [can you guess which one?] and another case was only “ok” [and can you guess that one, too?]. The &lt;code&gt;pareto_k_ids()&lt;/code&gt; function will tell exactly us which cases we’ll want to look at.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pareto_k_ids(loo_b1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Those numbers correspond to the row numbers in the data, &lt;code&gt;o&lt;/code&gt;. These are exactly the cases that plagued our second OLS model, &lt;code&gt;fit1&lt;/code&gt;, and are also the ones we hand coded to be outliers. With the simple &lt;code&gt;plot()&lt;/code&gt; function, we can get a diagnostic plot for the &lt;code&gt;pareto_k&lt;/code&gt; values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(loo_b1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There they are, cases 1 and 2, lurking in the “bad” and “[just] ok” ranges. We can also make a similar plot with &lt;strong&gt;ggplot2&lt;/strong&gt;. Though it takes a little more work, &lt;strong&gt;ggplot2&lt;/strong&gt; makes it easy to compare &lt;code&gt;pareto_k&lt;/code&gt; plots across models with a little faceting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# for the annotation
text &amp;lt;-
  tibble(i     = 1, 
         k     = c(.45, .65, .95),
         label = c(&amp;quot;good&amp;quot;, &amp;quot;[just] ok&amp;quot;, &amp;quot;bad&amp;quot;),
         fit   = &amp;quot;fit b0&amp;quot;)

# extract the diagnostics
tibble(k   = c(loo_b0$diagnostics$pareto_k, loo_b1$diagnostics$pareto_k),
       i   = rep(1:100, times = 2),
       fit = rep(str_c(&amp;quot;fit b&amp;quot;, 0:1), each = 100)) %&amp;gt;%
  
  # plot!
  ggplot(aes(x = i, y = k)) +
  geom_hline(yintercept = c(.5, .7, 1), color = &amp;quot;white&amp;quot;) +
  geom_point(alpha = .5) +
  geom_text(data = text,
            aes(label = label),
            color = &amp;quot;grey50&amp;quot;, hjust = 0) +
  scale_y_continuous(expression(Pareto~italic(k)), breaks = c(0, .5, .7, 1)) +
  theme(panel.grid = element_blank(),
        axis.title.x = element_text(face = &amp;quot;italic&amp;quot;, family = &amp;quot;Times&amp;quot;)) +
  facet_wrap(~ fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So with &lt;code&gt;b0&lt;/code&gt;–the model based on the well-behaved multivariate normal data, &lt;code&gt;d&lt;/code&gt;–, all the &lt;code&gt;pareto_k&lt;/code&gt; values hovered around zero in the “good” range. Things got concerning with model &lt;code&gt;b1&lt;/code&gt;. But we know all that. Let’s move forward.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-do-we-do-with-those-overly-influential-outlying-values&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;What do we do with those overly-influential outlying values?&lt;/h4&gt;
&lt;p&gt;A typical way to handle outlying values is to delete them based on some criterion, such as the Mahalanobis distance, Cook’s &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt;, or our new friend the &lt;code&gt;pareto_k&lt;/code&gt;. In our next two models, we’ll do that. In our &lt;code&gt;data&lt;/code&gt; arguments, we can use the &lt;code&gt;slice()&lt;/code&gt; function to omit cases. In model &lt;code&gt;b1.1&lt;/code&gt;, we simply omit the first and most influential case. In model &lt;code&gt;b1.2&lt;/code&gt;, we omitted both unduly-influential cases, the values from rows 1 and 2.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b1.1 &amp;lt;- 
  update(b1, 
         newdata = o %&amp;gt;% slice(2:100),
         seed = 1)
b1.2 &amp;lt;- 
  update(b1, 
         newdata = o %&amp;gt;% slice(3:100),
         seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the summaries for our models based on the &lt;code&gt;slice[d]&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_summary(b1.1)[1:3, ] %&amp;gt;% round(digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate Est.Error  Q2.5 Q97.5
## b_Intercept     0.07      0.10 -0.12  0.27
## b_x             0.27      0.12  0.04  0.50
## sigma           1.00      0.07  0.87  1.15&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_summary(b1.2)[1:3, ] %&amp;gt;% round(digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate Est.Error  Q2.5 Q97.5
## b_Intercept     0.01      0.09 -0.16  0.19
## b_x             0.39      0.10  0.19  0.59
## sigma           0.86      0.06  0.75  0.99&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;They are closer to the true data generating model (i.e., the code we used to make &lt;code&gt;d&lt;/code&gt;), especially &lt;code&gt;b1.2&lt;/code&gt;. However, there are other ways to handle the influential cases without dropping them. Finally, we’re ready to switch to Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;time-to-leave-gauss-for-the-more-general-students-t&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Time to leave Gauss for the more general Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Recall that the normal distribution is equivalent to a Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; with the degrees of freedom parameter, &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;, set to infinity. That is, &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; is fixed. Here we’ll relax that assumption and estimate &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; from the data just like we estimate &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; with the linear model and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; as the residual spread. Since &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;’s now a parameter, we’ll have to give it a prior. For our first Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; model, we’ll estimate &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; with the &lt;strong&gt;brms&lt;/strong&gt; default &lt;code&gt;gamma(2, 0.1)&lt;/code&gt; prior.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b2 &amp;lt;- 
  brm(data = o, family = student,
      y ~ 1 + x,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(gamma(2, 0.1), class = nu),
                prior(cauchy(0, 1),  class = sigma)),
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the next model, we’ll switch out that weak &lt;code&gt;gamma(2, 0.1)&lt;/code&gt; for a stronger &lt;code&gt;gamma(4, 1)&lt;/code&gt;. In some disciplines, the gamma distribution is something of an exotic bird. So before fitting the model, it might be useful to take a peek at what these gamma priors looks like. In the plot, below, the orange density in the background is the default &lt;code&gt;gamma(2, 0.1)&lt;/code&gt; and the purple density in the foreground is the stronger &lt;code&gt;gamma(4, 1)&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# data
tibble(x = seq(from = 0, to = 60, by = .1)) %&amp;gt;% 
  expand(x, nesting(alpha = c(2, 4), 
                    beta  = c(0.1, 1))) %&amp;gt;% 
  mutate(density = dgamma(x, alpha, beta),
         group   = rep(letters[1:2], times = n() / 2)) %&amp;gt;% 
  
  # plot
  ggplot(aes(x = x, ymin = 0, ymax = density, 
             group = group, fill = group)) +
  geom_ribbon(size = 0, alpha = 3/4) +
  scale_fill_viridis_d(option = &amp;quot;B&amp;quot;, direction = -1, 
                       begin = 1/3, end = 2/3) +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05))) +
  scale_y_continuous(NULL, breaks = NULL) +
  coord_cartesian(xlim = c(0, 50)) +
  theme(panel.grid = element_blank(),
        legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So the default prior is centered around values in the 2 to 30 range, but has a long gentle-sloping tail, allowing the model to yield much larger values for &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;, as needed. The prior we use below is almost entirely concentrated in the single-digit range. In this case, that will preference Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; likelihoods with very small &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameters and correspondingly thick tails–easily allowing for extreme values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b3 &amp;lt;- 
  update(b2,
         prior = c(prior(normal(0, 10), class = Intercept),
                   prior(normal(0, 10), class = b),
                   prior(gamma(4, 1),   class = nu),
                   prior(cauchy(0, 1),  class = sigma)),
         seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For our final model, we’ll fix the &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter in a &lt;code&gt;bf()&lt;/code&gt; statement.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b4 &amp;lt;-
  brm(data = o, family = student,
      bf(y ~ 1 + x, nu = 4),
      prior = c(prior(normal(0, 100), class = Intercept),
                prior(normal(0, 10),  class = b),
                prior(cauchy(0, 1),   class = sigma)),
         seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we’ve got all those models, we can gather their results into a single tibble.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b_estimates &amp;lt;-
  tibble(model = c(&amp;quot;b0&amp;quot;, &amp;quot;b1&amp;quot;, &amp;quot;b1.1&amp;quot;, &amp;quot;b1.2&amp;quot;, &amp;quot;b2&amp;quot;, &amp;quot;b3&amp;quot;, &amp;quot;b4&amp;quot;)) %&amp;gt;% 
  mutate(fit = map(model, get)) %&amp;gt;% 
  mutate(posterior_summary = map(fit, ~posterior_summary(.) %&amp;gt;% 
                                   data.frame() %&amp;gt;% 
                                   rownames_to_column(&amp;quot;term&amp;quot;))) %&amp;gt;% 
  unnest(posterior_summary) %&amp;gt;% 
  select(-fit) %&amp;gt;% 
  filter(term %in% c(&amp;quot;b_Intercept&amp;quot;, &amp;quot;b_x&amp;quot;)) %&amp;gt;%
  arrange(term)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get a sense of what we’ve done, let’s take a peek at our models tibble.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b_estimates %&amp;gt;%
  mutate_if(is.double, round, digits = 2)  # this is just to round the numbers&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 14 x 6
##    model term        Estimate Est.Error  Q2.5 Q97.5
##    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 b0    b_Intercept    -0.01      0.09 -0.18 0.16 
##  2 b1    b_Intercept     0.13      0.11 -0.09 0.35 
##  3 b1.1  b_Intercept     0.07      0.1  -0.12 0.27 
##  4 b1.2  b_Intercept     0.01      0.09 -0.16 0.19 
##  5 b2    b_Intercept     0.04      0.09 -0.14 0.23 
##  6 b3    b_Intercept     0.04      0.09 -0.14 0.22 
##  7 b4    b_Intercept     0.04      0.09 -0.14 0.22 
##  8 b0    b_x             0.44      0.1   0.25 0.64 
##  9 b1    b_x             0.14      0.13 -0.11 0.4  
## 10 b1.1  b_x             0.27      0.12  0.04 0.5  
## 11 b1.2  b_x             0.39      0.1   0.19 0.59 
## 12 b2    b_x             0.36      0.11  0.15 0.56 
## 13 b3    b_x             0.36      0.1   0.16 0.56 
## 14 b4    b_x             0.37      0.11  0.16 0.580&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The models differ by their intercepts, slopes, sigmas, and &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;s. For the sake of this post, we’ll focus on the slopes. Here we compare the different Bayesian models’ slopes by their posterior means and 95% intervals in a coefficient plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b_estimates %&amp;gt;%
  filter(term == &amp;quot;b_x&amp;quot;) %&amp;gt;% # b_Intercept b_x
  
  ggplot(aes(x = model)) +
  geom_pointrange(aes(y    = Estimate,
                      ymin = Q2.5,
                      ymax = Q97.5),
                  shape = 20) +
  coord_flip(ylim = c(-.2, 1)) +
  labs(title    = &amp;quot;The x slope, varying by model&amp;quot;,
       subtitle = &amp;quot;The dots are the posterior means and the lines the percentile-based 95% intervals.&amp;quot;,
       x        = NULL,
       y        = NULL) +
  theme(panel.grid   = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y  = element_text(hjust = 0))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You might think of the &lt;code&gt;b0&lt;/code&gt; slope as the “true” slope. That’s the one estimated from the well-behaved multivariate normal data, &lt;code&gt;d&lt;/code&gt;. That estimate’s just where we’d want it to be. The &lt;code&gt;b1&lt;/code&gt; slope is a disaster–way lower than the others. The slopes for &lt;code&gt;b1.1&lt;/code&gt; and &lt;code&gt;b1.2&lt;/code&gt; get better, but at the expense of deleting data. All three of our Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; models produced slopes that were pretty close to the &lt;code&gt;b0&lt;/code&gt; slope. They weren’t perfect, but, all in all, Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution did pretty okay.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;we-need-more-loo-and-more-pareto_k.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;We need more LOO and more &lt;code&gt;pareto_k&lt;/code&gt;.&lt;/h3&gt;
&lt;p&gt;We already have loo objects for our first two models, &lt;code&gt;b0&lt;/code&gt; and &lt;code&gt;b1&lt;/code&gt;. Let’s get some for models &lt;code&gt;b2&lt;/code&gt; through &lt;code&gt;b4&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_b2 &amp;lt;- loo(b2)
loo_b3 &amp;lt;- loo(b3)
loo_b4 &amp;lt;- loo(b4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a little data wrangling, we can compare our models by how they look in our custom &lt;code&gt;pareto_k&lt;/code&gt; diagnostic plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# make a custom function to work with the loo objects in bulk
get_pareto_k &amp;lt;- function(l) {
  l$diagnostics$pareto_k %&amp;gt;% 
    as_tibble() %&amp;gt;%
    mutate(i = 1:n()) %&amp;gt;% 
    rename(pareto_k = value)
}

# wrangle
tibble(name = str_c(&amp;quot;loo_b&amp;quot;, 1:4)) %&amp;gt;% 
  mutate(loo_object = map(name, get)) %&amp;gt;% 
  mutate(pareto_k = map(loo_object, get_pareto_k)) %&amp;gt;% 
  unnest(pareto_k) %&amp;gt;% 
  mutate(fit = rep(c(&amp;quot;fit b1&amp;quot;, &amp;quot;fit b2&amp;quot;, &amp;quot;fit b3&amp;quot;, &amp;quot;fit b4&amp;quot;), each = n() / 4)) %&amp;gt;%
  
  # plot
  ggplot(aes(x = i, y = pareto_k)) +
  geom_hline(yintercept = c(.5, .7),
             color = &amp;quot;white&amp;quot;) +
  geom_point(alpha = .5) +
  scale_y_continuous(expression(Pareto~italic(k)), breaks = c(0, .5, .7)) +
  theme(panel.grid = element_blank(),
        axis.title.x = element_text(face = &amp;quot;italic&amp;quot;, family = &amp;quot;Times&amp;quot;)) +
    facet_wrap(~ fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Oh man, those Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; models worked sweet! In a succession from &lt;code&gt;b2&lt;/code&gt; through &lt;code&gt;b4&lt;/code&gt;, each model looked better by &lt;code&gt;pareto_k&lt;/code&gt;. All were way better than the typical Gaussian model, &lt;code&gt;b1&lt;/code&gt;. While we’re at it, we might compare those by their LOO values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_compare(loo_b1, loo_b2, loo_b3, loo_b4) %&amp;gt;% print(simplify = F)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    elpd_diff se_diff elpd_loo se_elpd_loo p_loo  se_p_loo looic  se_looic
## b4    0.0       0.0  -143.5     10.3         2.7    0.3    287.1   20.7  
## b3   -0.8       0.4  -144.4     10.7         3.6    0.8    288.8   21.4  
## b2   -1.9       1.8  -145.5     11.7         4.6    1.5    291.0   23.4  
## b1  -13.9       7.6  -157.4     15.8         6.7    3.7    314.8   31.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In terms of the LOO, &lt;code&gt;b2&lt;/code&gt; through &lt;code&gt;b4&lt;/code&gt; were about the same, but all looked better than &lt;code&gt;b1&lt;/code&gt;. In fairness, though, the standard errors for the difference scores were a bit on the wide side.
If you’re new to using information criteria to compare models, you might sit down and soak in &lt;a href=&#34;https://www.youtube.com/watch?v=t0pRuy1_190&amp;amp;list=PLDcUM9US4XdM9_N6XUUFrhghGJ4K25bFc&amp;amp;index=8&#34;&gt;one of McElreath’s lectures on the topic&lt;/a&gt; or the &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-vehtariUsingLooPackage2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; vignette by Vehtari and Gabry, &lt;a href=&#34;https://cran.r-project.org/web/packages/loo/vignettes/loo2-example.html#plotting-pareto-k-diagnostics&#34;&gt;&lt;em&gt;Using the loo package (version &amp;gt;= 2.0.0)&lt;/em&gt;&lt;/a&gt;. For a more technical introduction, you might check out the references in the &lt;strong&gt;loo&lt;/strong&gt; package’s &lt;a href=&#34;https://CRAN.R-project.org/package=loo&#34;&gt;reference manual&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For one final LOO-related comparison, we can use the &lt;code&gt;brms::model_weights()&lt;/code&gt; function to see how much relative weight we might put on each of those four models if we were to use a model averaging approach. Here we use the default method, which is model averaging via posterior predictive stacking.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_weights(b1, b2, b3, b4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           b1           b2           b3           b4 
## 3.310561e-07 8.617446e-07 1.808979e-06 9.999970e-01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you’re not a fan of scientific notation, just tack on &lt;code&gt;round(digits = 2)&lt;/code&gt;. The stacking method suggests that we should place virtually all the weight on &lt;code&gt;b4&lt;/code&gt;, the model in which we fixed our Student-&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter at 4. To learn more about model stacking, check out Yao, Vehtari, Simpson, and Gelman’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-yaoUsingStackingAverage2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; paper, &lt;a href=&#34;https://projecteuclid.org/euclid.ba/1516093227&#34;&gt;&lt;em&gt;Using stacking to average Bayesian predictive distributions&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-compare-a-few-bayesian-models.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Let’s compare a few Bayesian models.&lt;/h3&gt;
&lt;p&gt;That’s enough with coefficients, &lt;code&gt;pareto_k&lt;/code&gt;, and the LOO. Let’s get a sense of the implications of the models by comparing a few in plots. Here we use convenience functions from &lt;a href=&#34;https://twitter.com/mjskay&#34;&gt;Matthew Kay&lt;/a&gt;’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-tidybayes&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;http://mjskay.github.io/tidybayes&#34;&gt;&lt;strong&gt;tidybayes&lt;/strong&gt; package&lt;/a&gt; to streamline the data wrangling and plotting. The method came from a &lt;a href=&#34;https://twitter.com/mjskay/status/1091926564101599232&#34;&gt;kind twitter suggesion from Kay&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidybayes)

# these are the values of x we&amp;#39;d like model-implied summaries for
nd &amp;lt;- tibble(x = seq(from = -4, to = 4, length.out = 50))

# here&amp;#39;s another way to arrange the models
list(b0 = b0, b1 = b1, b3 = b3) %&amp;gt;% 
  # with help from `tidybayes::add_fitted_draws()`, here we use `fitted()` in bulk
  map_dfr(add_fitted_draws, newdata = nd, .id = &amp;quot;model&amp;quot;) %&amp;gt;% 
  
  # plot
  ggplot(aes(x = x)) +
  stat_lineribbon(aes(y = .value),
                  .width = .95,
                  color = &amp;quot;grey92&amp;quot;, fill = &amp;quot;grey67&amp;quot;) +
  geom_point(data = d %&amp;gt;%
               bind_rows(o, o) %&amp;gt;%
               mutate(model = rep(c(&amp;quot;b0&amp;quot;, &amp;quot;b1&amp;quot;, &amp;quot;b3&amp;quot;), each = 100)), 
             aes(y = y, color = y &amp;gt; 3),
             size = 1, alpha = 3/4) +
  scale_color_viridis_d(option = &amp;quot;A&amp;quot;, end = 4/7) +
  coord_cartesian(xlim = c(-3, 3), 
                  ylim = c(-3, 5)) +
  ylab(NULL) +
  theme(panel.grid = element_blank(),
        legend.position = &amp;quot;none&amp;quot;) +
  facet_wrap(~ model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-31-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For each subplot, the gray band is the 95% interval band and the overlapping light gray line is the posterior mean. Model &lt;code&gt;b0&lt;/code&gt;, recall, is our baseline comparison model. This is of the well-behaved no-outlier data, &lt;code&gt;d&lt;/code&gt;, using the good old Gaussian likelihood. Model &lt;code&gt;b1&lt;/code&gt; is of the outlier data, &lt;code&gt;o&lt;/code&gt;, but still using the non-robust Gaussian likelihood. Model &lt;code&gt;b3&lt;/code&gt; uses a robust Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; likelihood with &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; estimated with the fairly narrow &lt;code&gt;gamma(4, 1)&lt;/code&gt; prior. For my money, &lt;code&gt;b3&lt;/code&gt; did a pretty good job.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.3.1 loo_2.4.1       brms_2.15.0     Rcpp_1.0.6     
##  [5] patchwork_1.1.1 broom_0.7.5     forcats_0.5.1   stringr_1.4.0  
##  [9] dplyr_1.0.5     purrr_0.3.4     readr_1.4.0     tidyr_1.1.3    
## [13] tibble_3.1.0    ggplot2_3.3.3   tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6          
##   [4] igraph_1.2.6         svUnit_1.0.3         splines_4.0.4       
##   [7] crosstalk_1.1.0.1    TH.data_1.0-10       rstantools_2.1.1    
##  [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.1.1   
##  [13] rsconnect_0.8.16     fansi_0.4.2          checkmate_2.0.0     
##  [16] magrittr_2.0.1       modelr_0.1.8         RcppParallel_5.0.2  
##  [19] matrixStats_0.57.0   xts_0.12.1           sandwich_3.0-0      
##  [22] prettyunits_1.1.1    colorspace_2.0-0     rvest_0.3.6         
##  [25] ggdist_2.4.0.9000    haven_2.3.1          xfun_0.22           
##  [28] callr_3.5.1          crayon_1.4.1         jsonlite_1.7.2      
##  [31] lme4_1.1-25          survival_3.2-10      zoo_1.8-8           
##  [34] glue_1.4.2           gtable_0.3.0         emmeans_1.5.2-1     
##  [37] V8_3.4.0             distributional_0.2.2 pkgbuild_1.2.0      
##  [40] rstan_2.21.2         abind_1.4-5          scales_1.1.1        
##  [43] mvtnorm_1.1-1        DBI_1.1.0            miniUI_0.1.1.1      
##  [46] viridisLite_0.3.0    xtable_1.8-4         stats4_4.0.4        
##  [49] StanHeaders_2.21.0-7 DT_0.16              htmlwidgets_1.5.2   
##  [52] httr_1.4.2           threejs_0.3.3        arrayhelpers_1.1-0  
##  [55] ellipsis_0.3.1       pkgconfig_2.0.3      farver_2.0.3        
##  [58] dbplyr_2.0.0         utf8_1.1.4           tidyselect_1.1.0    
##  [61] labeling_0.4.2       rlang_0.4.10         reshape2_1.4.4      
##  [64] later_1.1.0.1        munsell_0.5.0        cellranger_1.1.0    
##  [67] tools_4.0.4          cli_2.3.1            generics_0.1.0      
##  [70] ggridges_0.5.2       evaluate_0.14        fastmap_1.0.1       
##  [73] yaml_2.2.1           processx_3.4.5       knitr_1.31          
##  [76] fs_1.5.0             nlme_3.1-152         mime_0.10           
##  [79] projpred_2.0.2       xml2_1.3.2           compiler_4.0.4      
##  [82] bayesplot_1.8.0      shinythemes_1.1.2    rstudioapi_0.13     
##  [85] gamm4_0.2-6          curl_4.3             reprex_0.3.0        
##  [88] statmod_1.4.35       stringi_1.5.3        highr_0.8           
##  [91] ps_1.6.0             blogdown_1.3         Brobdingnag_1.2-6   
##  [94] lattice_0.20-41      Matrix_1.3-2         nloptr_1.2.2.2      
##  [97] markdown_1.1         shinyjs_2.0.0        vctrs_0.3.6         
## [100] pillar_1.5.1         lifecycle_1.0.0      bridgesampling_1.0-0
## [103] estimability_1.3     httpuv_1.5.4         R6_2.5.0            
## [106] bookdown_0.21        promises_1.1.1       gridExtra_2.3       
## [109] codetools_0.2-18     boot_1.3-26          colourpicker_1.1.0  
## [112] MASS_7.3-53          gtools_3.8.2         assertthat_0.2.1    
## [115] withr_2.4.1          shinystan_2.5.0      multcomp_1.4-16     
## [118] mgcv_1.8-33          parallel_4.0.4       hms_0.5.3           
## [121] grid_4.0.4           coda_0.19-4          minqa_1.2.4         
## [124] rmarkdown_2.7        shiny_1.5.0          lubridate_1.7.9.2   
## [127] base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-burknerBrmsPackageBayesian2017&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2017). &lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;An R&lt;/span&gt; package for &lt;span&gt;Bayesian&lt;/span&gt; multilevel models using &lt;span&gt;Stan&lt;/span&gt;. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;80&lt;/em&gt;(1), 1–28. &lt;a href=&#34;https://doi.org/10.18637/jss.v080.i01&#34;&gt;https://doi.org/10.18637/jss.v080.i01&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerAdvancedBayesianMultilevel2018&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2018). Advanced &lt;span&gt;Bayesian&lt;/span&gt; multilevel modeling with the &lt;span&gt;R&lt;/span&gt; package brms. &lt;em&gt;The R Journal&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(1), 395–411. &lt;a href=&#34;https://doi.org/10.32614/RJ-2018-017&#34;&gt;https://doi.org/10.32614/RJ-2018-017&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-brms&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;Bayesian&lt;/span&gt; regression models using ’&lt;span&gt;Stan&lt;/span&gt;’&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=brms&#34;&gt;https://CRAN.R-project.org/package=brms&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-fahrmeirRegressionModelsMethods2013&#34; class=&#34;csl-entry&#34;&gt;
Fahrmeir, L., Kneib, T., Lang, S., &amp;amp; Marx, B. (2013). &lt;em&gt;Regression: &lt;span&gt;Models&lt;/span&gt;, methods and applications&lt;/em&gt;. &lt;span&gt;Springer-Verlag&lt;/span&gt;. &lt;a href=&#34;https://doi.org/10.1007/978-3-642-34333-9&#34;&gt;https://doi.org/10.1007/978-3-642-34333-9&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelmanDataAnalysisUsing2006&#34; class=&#34;csl-entry&#34;&gt;
Gelman, A., &amp;amp; Hill, J. (2006). &lt;em&gt;Data analysis using regression and multilevel/hierarchical models&lt;/em&gt;. &lt;span&gt;Cambridge University Press&lt;/span&gt;. &lt;a href=&#34;https://doi.org/10.1017/CBO9780511790942&#34;&gt;https://doi.org/10.1017/CBO9780511790942&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-grolemundDataScience2017&#34; class=&#34;csl-entry&#34;&gt;
Grolemund, G., &amp;amp; Wickham, H. (2017). &lt;em&gt;R for data science&lt;/em&gt;. &lt;span&gt;O’Reilly&lt;/span&gt;. &lt;a href=&#34;https://r4ds.had.co.nz&#34;&gt;https://r4ds.had.co.nz&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-tidybayes&#34; class=&#34;csl-entry&#34;&gt;
Kay, M. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;tidybayes&lt;/span&gt;: &lt;span&gt;Tidy&lt;/span&gt; data and ’geoms’ for &lt;span&gt;Bayesian&lt;/span&gt; models&lt;/em&gt;. &lt;a href=&#34;https://mjskay.github.io/tidybayes/&#34;&gt;https://mjskay.github.io/tidybayes/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kruschkeDoingBayesianData2015&#34; class=&#34;csl-entry&#34;&gt;
Kruschke, J. K. (2015). &lt;em&gt;Doing &lt;span&gt;Bayesian&lt;/span&gt; data analysis: &lt;span&gt;A&lt;/span&gt; tutorial with &lt;span&gt;R&lt;/span&gt;, &lt;span&gt;JAGS&lt;/span&gt;, and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;Academic Press&lt;/span&gt;. &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;https://sites.google.com/site/doingbayesiandataanalysis/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2020&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2020). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt; (Second Edition). &lt;span&gt;CRC Press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2015&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2015). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-MASS&#34; class=&#34;csl-entry&#34;&gt;
Ripley, B. (2019). &lt;em&gt;&lt;span&gt;MASS&lt;/span&gt;: &lt;span&gt;Support&lt;/span&gt; functions and datasets for venables and ripley’s &lt;span&gt;MASS&lt;/span&gt;&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=MASS&#34;&gt;https://CRAN.R-project.org/package=MASS&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-broom&#34; class=&#34;csl-entry&#34;&gt;
Robinson, D., &amp;amp; Hayes, A. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;broom&lt;/span&gt;: &lt;span&gt;Convert&lt;/span&gt; statistical analysis objects into tidy tibbles&lt;/em&gt; [Manual]. &lt;a href=&#34;https://CRAN.R-project.org/package=broom&#34;&gt;https://CRAN.R-project.org/package=broom&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vehtariUsingLooPackage2020&#34; class=&#34;csl-entry&#34;&gt;
Vehtari, A., &amp;amp; Gabry, J. (2020). &lt;em&gt;Using the loo package (version &lt;span&gt;&lt;span class=&#34;math inline&#34;&gt;\(&amp;gt;\)&lt;/span&gt;&lt;/span&gt;= 2.0.0)&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=loo/vignettes/loo2-example.html&#34;&gt;https://CRAN.R-project.org/package=loo/vignettes/loo2-example.html&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-loo2020RM&#34; class=&#34;csl-entry&#34;&gt;
Vehtari, A., Gabry, J., Magnusson, M., Yao, Y., Bürkner, P.-C., Paananen, T., &amp;amp; Gelman, A. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;loo&lt;/span&gt; reference manual, &lt;span&gt;Version&lt;/span&gt; 2.3.1&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=loo/loo.pdf&#34;&gt;https://CRAN.R-project.org/package=loo/loo.pdf&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-loo&#34; class=&#34;csl-entry&#34;&gt;
Vehtari, A., Gabry, J., Magnusson, M., Yao, Y., &amp;amp; Gelman, A. (2019). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;loo&lt;/span&gt;: &lt;span&gt;Efficient&lt;/span&gt; leave-one-out cross-validation and &lt;span&gt;WAIC&lt;/span&gt; for bayesian models&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=loo/&#34;&gt;https://CRAN.R-project.org/package=loo/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vehtariPracticalBayesianModel2017&#34; class=&#34;csl-entry&#34;&gt;
Vehtari, A., Gelman, A., &amp;amp; Gabry, J. (2017). Practical &lt;span&gt;Bayesian&lt;/span&gt; model evaluation using leave-one-out cross-validation and &lt;span&gt;WAIC&lt;/span&gt;. &lt;em&gt;Statistics and Computing&lt;/em&gt;, &lt;em&gt;27&lt;/em&gt;(5), 1413–1432. &lt;a href=&#34;https://doi.org/10.1007/s11222-016-9696-4&#34;&gt;https://doi.org/10.1007/s11222-016-9696-4&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-tidyverse&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H. (2019). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;tidyverse&lt;/span&gt;: &lt;span&gt;Easily&lt;/span&gt; install and load the ’tidyverse’&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=tidyverse&#34;&gt;https://CRAN.R-project.org/package=tidyverse&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wickhamWelcomeTidyverse2019&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. &lt;em&gt;Journal of Open Source Software&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(43), 1686. &lt;a href=&#34;https://doi.org/10.21105/joss.01686&#34;&gt;https://doi.org/10.21105/joss.01686&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-yaoUsingStackingAverage2018&#34; class=&#34;csl-entry&#34;&gt;
Yao, Y., Vehtari, A., Simpson, D., &amp;amp; Gelman, A. (2018). Using stacking to average &lt;span&gt;Bayesian&lt;/span&gt; predictive distributions (with discussion). &lt;em&gt;Bayesian Analysis&lt;/em&gt;, &lt;em&gt;13&lt;/em&gt;(3), 917–1007. &lt;a href=&#34;https://doi.org/10.1214/17-BA1091&#34;&gt;https://doi.org/10.1214/17-BA1091&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
