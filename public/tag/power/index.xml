<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>power | Fahim Ahmad</title>
    <link>/tag/power/</link>
      <atom:link href="/tag/power/index.xml" rel="self" type="application/rss+xml" />
    <description>power</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>¬© Fahim Ahmad (2020)</copyright><lastBuildDate>Fri, 02 Jul 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png</url>
      <title>power</title>
      <link>/tag/power/</link>
    </image>
    
    <item>
      <title>Example power analysis report</title>
      <link>/post/2021-07-02-example-power-analysis-report/</link>
      <pubDate>Fri, 02 Jul 2021 00:00:00 +0000</pubDate>
      <guid>/post/2021-07-02-example-power-analysis-report/</guid>
      <description>
&lt;script src=&#34;/post/2021-07-02-example-power-analysis-report/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;context&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Context&lt;/h2&gt;
&lt;p&gt;In one of my recent Twitter posts, I got pissy and complained about a vague power-analysis statement I saw while reviewing a manuscript submitted to a scientific journal.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;If you submit a manuscript for publication that involves HLMs and SEMs of longitudinal data and you vaguely summarize your power analysis in one sentence, I, as your friendly neighborhood Reviewer #2, am requesting a full power-analysis write-up as a supplementary material.&lt;/p&gt;&amp;mdash; Solomon Kurz (@SolomonKurz) &lt;a href=&#34;https://twitter.com/SolomonKurz/status/1409626961161371648?ref_src=twsrc%5Etfw&#34;&gt;June 28, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;It wasn‚Äôt my best moment and I ended up apologizing for my tone.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Okay, I apologize for getting a little pissy with the tweet. Yet the issue is real and it leads to a natural question: What would go into a good power analysis report? I‚Äôve done a few for work and I promise to morph one into a blog post, by the end of the week.&lt;/p&gt;&amp;mdash; Solomon Kurz (@SolomonKurz) &lt;a href=&#34;https://twitter.com/SolomonKurz/status/1409634560485199876?ref_src=twsrc%5Etfw&#34;&gt;June 28, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;However, the broader issue remains. If you plan to analyze your data with anything more complicated than a &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-test, the power analysis phase gets tricky. The manuscript I was complaining about used a complicated multilevel model as its primary analysis. I‚Äôm willing to bet that most applied researchers (including the authors of that manuscript) have never done a power analysis for a multilevel model and probably have never seen what one might look like, either. The purpose of this post is to give a real-world example of just such an analysis.&lt;/p&gt;
&lt;p&gt;Over the past couple years, I‚Äôve done a few multilevel power analyses as part of my day job. In this post, I will reproduce one of them. For the sake of confidentiality, some of the original content will be omitted or slightly altered. But the overall workflow will be about 90% faithful to the original report I submitted to my boss. To understand this report, you should know:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;my boss has some experience fitting multilevel models, but they‚Äôre not a stats jock;&lt;/li&gt;
&lt;li&gt;we had pilot data from two different sources, each with its strengths and weaknesses; and&lt;/li&gt;
&lt;li&gt;this document was meant for internal purposes only, though I believe some of its contents did make it into other materials.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At the end, I‚Äôll wrap this post up with a few comments. Here‚Äôs the report:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;executive-summary&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Executive summary&lt;/h2&gt;
&lt;p&gt;A total sample size of &lt;strong&gt;164&lt;/strong&gt; is the minimum number to detect an effect size similar to that in the pilot data (i.e., Cohen‚Äôs &lt;span class=&#34;math inline&#34;&gt;\(d = 0.3\)&lt;/span&gt;). This recommendation assumes&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a study design of three time points,&lt;/li&gt;
&lt;li&gt;random assignment of participants into two equal groups, and&lt;/li&gt;
&lt;li&gt;20% dropout on the second time point and another 20% dropout by the third time point.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we presume a more conservative effect size of &lt;span class=&#34;math inline&#34;&gt;\(0.2\)&lt;/span&gt; and a larger dropout rate of 30% the second and third time points, the minimum recommended total sample size is &lt;strong&gt;486&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The remainder of this report details how I came to these conclusions. For full transparency, I will supplement prose with figures, tables, and the statistical code used used for all computations. By default, the code is hidden is this document. However, if you are interested in the code, you should be able to make it appear by selecting ‚ÄúShow All Code‚Äù in the dropdown menu from the ‚ÄúCode‚Äù button on the upper-right corner.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cohens-d&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cohen‚Äôs &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;In this report, Cohen‚Äôs &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is meant to indicate a standardized mean difference. The &lt;span class=&#34;math inline&#34;&gt;\(d = 0.3\)&lt;/span&gt; from above is based on the &lt;code&gt;some_file.docx&lt;/code&gt; file you shared with me last week. In Table 1, you provided the following summary information for the intervention group:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

tibble(summary = c(&amp;quot;mean&amp;quot;, &amp;quot;sd&amp;quot;),
       baseline = c(1.29, 1.13),
       followup = c(0.95, 1.09)) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;summary&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;baseline&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;followup&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mean&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sd&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.09&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;With that information, we can compute a within-subject‚Äôs &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; by hand. With this formula, we will be using the pooled standard deviation in the denominator.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;- (1.29 - .95) / sqrt((1.13^2 + 1.09^2) / 2)
d&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3062566&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, 0.306 is just a point estimate. We can express the uncertainty in that point estimate with 95% confidence intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ci &amp;lt;-
  MBESS::ci.smd(smd = d,
                n.1 = 50, 
                n.2 = 26)

ci %&amp;gt;% 
  data.frame() %&amp;gt;% 
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 1
## Columns: 3
## $ Lower.Conf.Limit.smd &amp;lt;dbl&amp;gt; -0.1712149
## $ smd                  &amp;lt;dbl&amp;gt; 0.3062566
## $ Upper.Conf.Limit.smd &amp;lt;dbl&amp;gt; 0.7816834&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this output, &lt;code&gt;smd&lt;/code&gt; refers to ‚Äústandardized mean difference,‚Äù what what we have been referring to as Cohen‚Äôs &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;. The output indicates the effect size for the experimental group from the pilot study was &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; of 0.31 [-0.17, .78]. The data look promising for a small/moderate effect. But those confidence intervals swing from small negative to large.&lt;/p&gt;
&lt;p&gt;For reference, here are the 50% intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MBESS::ci.smd(smd = d,
              n.1 = 50, 
              n.2 = 26,
              conf.level = .5) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 1
## Columns: 3
## $ Lower.Conf.Limit.smd &amp;lt;dbl&amp;gt; 0.1412595
## $ smd                  &amp;lt;dbl&amp;gt; 0.3062566
## $ Upper.Conf.Limit.smd &amp;lt;dbl&amp;gt; 0.4691839&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The 50% CIs range from 0.14 to 0.47.&lt;/p&gt;
&lt;div id=&#34;power-analyses-can-be-tailor-made.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Power analyses can be tailor made.&lt;/h3&gt;
&lt;p&gt;Whenever possible, it is preferable to tailor a power analysis to the statistical models researchers plan to use to analyze the data they intend to collect. Based on your previous analyses, I suspect you intend to fit a series of hierarchical models. I would have done the same thing with those data and I further recommend you analyze the data you intend to collect within a hierarchical growth model paradigm. With that in mind, the power analyses in the report are all based on the following model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
y_{ij} &amp;amp; = \beta_{0i} + \beta_{1i} \text{time}_{ij} + \epsilon_{ij} \\
\beta_{0i} &amp;amp; = \gamma_{00} + \gamma_{01} \text{treatment}_i +  u_{0i} \\
\beta_{1i} &amp;amp; = \gamma_{10} + \gamma_{11} \text{treatment}_i +  u_{1i}, 
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is the dependent variable of interest, which varies across &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; participants and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; measurement occasions. The model is linear with an intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_{0i}\)&lt;/span&gt; and slope &lt;span class=&#34;math inline&#34;&gt;\(\beta_{1i}\)&lt;/span&gt;. As indicated by the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; subscripts, both intercepts and slopes vary across participants with grand means &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{00}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{10}\)&lt;/span&gt;, respectively, and participant-specific deviations around those means &lt;span class=&#34;math inline&#34;&gt;\(u_{0i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(u_{1i}\)&lt;/span&gt;, respectively. There is a focal between-participant predictor in the model, &lt;span class=&#34;math inline&#34;&gt;\(\text{treatment}_i\)&lt;/span&gt;, which is coded 0 = &lt;em&gt;control&lt;/em&gt; 1 = &lt;em&gt;treatment&lt;/em&gt;. Rearranging the the formulas into the composite form will make it clear this is an interaction model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
y_{ij} &amp;amp; = \gamma_{00} + \gamma_{01} \text{treatment}_i \\
       &amp;amp; \;\;\; + \gamma_{10} \text{time}_{ij} + \gamma_{11} \text{treatment}_i \times \text{time}_{ij} \\
       &amp;amp; \;\;\; + u_{0i} +  u_{1i} \text{time}_{ij} + \epsilon_{ij},
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the parameter of primary interest for the study is &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{11} \text{treatment}_i \times \text{time}_{ij}\)&lt;/span&gt;, the difference between the two &lt;span class=&#34;math inline&#34;&gt;\(\text{treatment}\)&lt;/span&gt; conditions in their change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; over &lt;span class=&#34;math inline&#34;&gt;\(\text{time}\)&lt;/span&gt;. As such, the focus of the power analyses reported above are on the power to reject the null hypothesis the &lt;span class=&#34;math inline&#34;&gt;\(\text{treatment}\)&lt;/span&gt; conditions do not differ in their change over &lt;span class=&#34;math inline&#34;&gt;\(\text{time}\)&lt;/span&gt;,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0: \gamma_{11} = 0.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To finish out the equations, this approach makes the typical assumptions the within-participant residual term, &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ij}\)&lt;/span&gt;, is normally distributed around zero,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\epsilon_{ij} \sim \operatorname{Normal} (0, \sigma_\epsilon^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and the between-participant variances &lt;span class=&#34;math inline&#34;&gt;\(u_{0i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(u_{1i}\)&lt;/span&gt; have a multivariate normal distribution with a mean vector of zeros,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{bmatrix} u_{0i} \\ u_{1i} \end{bmatrix} \sim \operatorname{Normal} \Bigg ( \begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} \sigma_0^2 &amp;amp; \sigma_{01} \\ \sigma_{01} &amp;amp; \sigma_1^2 \end{bmatrix} \Bigg ).\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Following convention, the within-participant residuals &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ij}\)&lt;/span&gt; are orthogonal to the between-participant variances &lt;span class=&#34;math inline&#34;&gt;\(u_{0i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(u_{1i}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;For simplicity, another assumption of this model that the control condition will remain constant over time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;main-results-power-curves.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Main results: Power curves.&lt;/h3&gt;
&lt;p&gt;I computed a series of power curves to examine the necessary sample size given different assumptions. Due to the uncertainty in the effect size from the pilot data, &lt;span class=&#34;math inline&#34;&gt;\(d = 0.31 [-0.17, .78]\)&lt;/span&gt;, varied the effect size from 0.1 to 0.3. I also examined different levels of missing data via dropout. These followed four patterns of dropout and were extensions of the missing data pattern described in the &lt;code&gt;some_other_file.docx&lt;/code&gt; file. They were:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(`dropout rate` = str_c(c(0, 10, 20, 30), &amp;quot;%&amp;quot;),
       baseline = &amp;quot;100%&amp;quot;,
       `1st followup` = str_c(c(100, 90, 80, 70), &amp;quot;%&amp;quot;),
       `2nd followup` = str_c(c(100, 80, 60, 40), &amp;quot;%&amp;quot;)) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;dropout rate&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;baseline&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;1st followup&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;2nd followup&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;0%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;10%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;90%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;20%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;60%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;30%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;70%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;40%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The row with the 20% dropout rate, for example, corresponds directly to the dropout rate entertained in the &lt;code&gt;some_other_file.docx&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;The power simulations of this kind required two more bits of information. The first was that we specify an expected intraclass correlation coefficient (ICC). I used ICC = .9, which is the ICC value you reported in your previous work (p.¬†41).&lt;/p&gt;
&lt;p&gt;The second value needed is the ratio of &lt;span class=&#34;math inline&#34;&gt;\(u_{1i}/ \epsilon_{ij}\)&lt;/span&gt;, sometimes called the ‚Äúvariance ratio.‚Äù I was not able to determine that value from the &lt;code&gt;some_file.docx&lt;/code&gt; or the &lt;code&gt;some_other_file.docx&lt;/code&gt;. However, I was able to compute one based on data from a different project on participants from a similar population. The data are from several hundred participants in a longitudinal survey study. The data do not include your primary variable of interest. Instead, I took the &lt;span class=&#34;math inline&#34;&gt;\(u_{1i}/ \epsilon_{ij}\)&lt;/span&gt; from recent hierarchical analyses of two related measures. These left me with two values: 0.018 on the low end and 0.281 on the high end. Thus, I performed the power curves using both.&lt;/p&gt;
&lt;p&gt;Here is the code for the simulations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(powerlmm)

t &amp;lt;- 3
n &amp;lt;- 100

# variance ratio 0.018
icc0.9_vr_0.018_d0.1 &amp;lt;-
  study_parameters(n1 = t,
                 n2 = n,
                 icc_pre_subject = 0.9,
                  var_ratio = 0.018,
                  effect_size = cohend(-0.2, 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;),
                 dropout = dropout_manual(0, 0.1, 0.2)) %&amp;gt;% 
  get_power_table(n2 = 25:500,
                  effect_size = cohend(c(.1, .15, .2, .25, .3), 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;))

icc0.9_vr_0.018_d0.2 &amp;lt;-
  study_parameters(n1 = t,
                 n2 = n,
                 icc_pre_subject = 0.9,
                  var_ratio = 0.018,
                  effect_size = cohend(-0.2, 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;),
                 dropout = dropout_manual(0, 0.2, 0.4)) %&amp;gt;% 
  get_power_table(n2 = 25:500,
                  effect_size = cohend(c(.1, .15, .2, .25, .3), 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;))

icc0.9_vr_0.018_d0.3 &amp;lt;-
  study_parameters(n1 = t,
                 n2 = n,
                 icc_pre_subject = 0.9,
                  var_ratio = 0.018,
                  effect_size = cohend(-0.2, 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;),
                 dropout = dropout_manual(0, 0.3, 0.6)) %&amp;gt;% 
  get_power_table(n2 = 25:500,
                  effect_size = cohend(c(.1, .15, .2, .25, .3), 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;))

# variance ratio 0.281
icc0.9_vr_0.281_d0.1 &amp;lt;-
  study_parameters(n1 = t,
                 n2 = n,
                 icc_pre_subject = 0.9,
                  var_ratio = 0.281,
                  effect_size = cohend(-0.2, 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;),
                 dropout = dropout_manual(0, 0.1, 0.2)) %&amp;gt;% 
  get_power_table(n2 = 25:500,
                  effect_size = cohend(c(.1, .15, .2, .25, .3), 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;))

icc0.9_vr_0.281_d0.2 &amp;lt;-
  study_parameters(n1 = t,
                 n2 = n,
                 icc_pre_subject = 0.9,
                  var_ratio = 0.281,
                  effect_size = cohend(-0.2, 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;),
                 dropout = dropout_manual(0, 0.2, 0.4)) %&amp;gt;% 
  get_power_table(n2 = 25:500,
                  effect_size = cohend(c(.1, .15, .2, .25, .3), 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;))

icc0.9_vr_0.281_d0.3 &amp;lt;-
  study_parameters(n1 = t,
                 n2 = n,
                 icc_pre_subject = 0.9,
                  var_ratio = 0.281,
                  effect_size = cohend(-0.2, 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;),
                 dropout = dropout_manual(0, 0.3, 0.6)) %&amp;gt;% 
  get_power_table(n2 = 25:500,
                  effect_size = cohend(c(.1, .15, .2, .25, .3), 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the power curve plots, beginning with the plot for the smaller variance ratio of 0.018.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  icc0.9_vr_0.018_d0.1 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.018_d0.2 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.018_d0.3
) %&amp;gt;% 
  mutate(missing = c(rep(str_c(c(10, 20, 30, 00), &amp;quot;% missing per time point after baseline&amp;quot;), each = n() / 4))) %&amp;gt;% 
  
  mutate(d = factor(effect_size,
                    levels = c(&amp;quot;0.1&amp;quot;, &amp;quot;0.15&amp;quot;, &amp;quot;0.2&amp;quot;, &amp;quot;0.25&amp;quot;, &amp;quot;0.3&amp;quot;),
                    labels = c(&amp;quot;.10&amp;quot;, &amp;quot;.15&amp;quot;, &amp;quot;.20&amp;quot;, &amp;quot;.25&amp;quot;, &amp;quot;.30&amp;quot;))) %&amp;gt;% 
  mutate(d = fct_rev(d)) %&amp;gt;% 
  
  ggplot(aes(x = tot_n, y = power, color = d)) +
  geom_vline(xintercept = 500, color = &amp;quot;white&amp;quot;, size = 1) +
  geom_hline(yintercept = .8, color = &amp;quot;white&amp;quot;, size = 1) +
  geom_line(size = 1.5) +
  scale_color_viridis_d(expression(paste(&amp;quot;Cohen&amp;#39;s &amp;quot;, italic(d))),
                        option = &amp;quot;A&amp;quot;, end = .67, direction = -1) +
  scale_x_continuous(expression(paste(italic(N), &amp;quot; (i.e., the total sample size)&amp;quot;)), 
                     breaks = seq(from = 0, to = 1000, by = 100), limits = c(0, 1000)) +
  scale_y_continuous(breaks = c(0, .2, .4, .6, .8, 1), limits = c(0, 1)) +
  ggtitle(&amp;quot;Power curves based on a variance ratio of 0.018&amp;quot;) +
  theme(panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()) +
  facet_wrap(~missing)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-07-02-example-power-analysis-report/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;816&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here is the power curve plot for the larger variance ratio of 0.281.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  icc0.9_vr_0.281_d0.1 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.281_d0.2 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.281_d0.3
) %&amp;gt;% 
  mutate(missing = c(rep(str_c(c(10, 20, 30, 00), &amp;quot;% missing per time point after baseline&amp;quot;), each = n() / 4))) %&amp;gt;% 
  
  mutate(d = factor(effect_size,
                    levels = c(&amp;quot;0.1&amp;quot;, &amp;quot;0.15&amp;quot;, &amp;quot;0.2&amp;quot;, &amp;quot;0.25&amp;quot;, &amp;quot;0.3&amp;quot;),
                    labels = c(&amp;quot;.10&amp;quot;, &amp;quot;.15&amp;quot;, &amp;quot;.20&amp;quot;, &amp;quot;.25&amp;quot;, &amp;quot;.30&amp;quot;))) %&amp;gt;% 
  mutate(d = fct_rev(d)) %&amp;gt;% 
  
  ggplot(aes(x = tot_n, y = power, color = d)) +
  geom_vline(xintercept = 500, color = &amp;quot;white&amp;quot;, size = 1) +
  geom_hline(yintercept = .8, color = &amp;quot;white&amp;quot;, size = 1) +
  geom_line(size = 1.5) +
  scale_color_viridis_d(expression(paste(&amp;quot;Cohen&amp;#39;s &amp;quot;, italic(d))),
                        option = &amp;quot;A&amp;quot;, end = .67, direction = -1) +
  scale_x_continuous(expression(paste(italic(N), &amp;quot; (i.e., the total sample size)&amp;quot;)), 
                     breaks = seq(from = 0, to = 1000, by = 100), limits = c(0, 1000)) +
  scale_y_continuous(breaks = c(0, .2, .4, .6, .8, 1), limits = c(0, 1)) +
  ggtitle(&amp;quot;Power curves based on a variance ratio of 0.281&amp;quot;) +
  theme(panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()) +
  facet_wrap(~missing)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-07-02-example-power-analysis-report/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;816&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The upshot of the variance ratio issue is that a higher variance ratio led to lower power. To be on the safe side, &lt;em&gt;I recommend leaning on the more conservative power curve estimates from the simulations based on the larger variance ratio&lt;/em&gt;, &lt;strong&gt;0.281&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;A more succinct way to summarize the information in the power curves in with two tables. Here is the minimum total sample size required to reach a power of .8 based on the smaller evidence ratio of 0.018 and the various combinations of Cohen‚Äôs &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and dropout:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  icc0.9_vr_0.018_d0.1 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.018_d0.2 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.018_d0.3
) %&amp;gt;% 
  mutate(missing = c(rep(c(10, 20, 30, 00), each = n() / 4))) %&amp;gt;% 

  filter(power &amp;gt; .8) %&amp;gt;% 
  group_by(missing, effect_size) %&amp;gt;% 
  top_n(-1, power) %&amp;gt;% 
  select(-n2, -power, -dropout) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(`Cohen&amp;#39;s d` = effect_size) %&amp;gt;% 
  
  ggplot(aes(x = `Cohen&amp;#39;s d`, y = missing)) +
  geom_tile(aes(fill = tot_n),
            show.legend = F) +
  geom_text(aes(label = tot_n, color = tot_n &amp;lt; 700),
            show.legend = F) +
  scale_fill_viridis_c(option = &amp;quot;B&amp;quot;, begin = .1, end = .70 ,limits = c(0, 1000)) +
  scale_color_manual(values = c(&amp;quot;black&amp;quot;, &amp;quot;white&amp;quot;)) +
  labs(title = expression(paste(&amp;quot;Total &amp;quot;, italic(N), &amp;quot; required for .8 power, based on a variance ratio of 0.018&amp;quot;)),
       subtitle = expression(paste(&amp;quot;The power simulations only considered up to &amp;quot;, italic(N), &amp;quot; = 1,000.&amp;quot;)),
       x = expression(paste(&amp;quot;Cohen&amp;#39;s &amp;quot;, italic(d))),
       y = &amp;quot;% missing\nper follow-up&amp;quot;) +
  theme(axis.ticks = element_blank(),
        panel.grid = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-07-02-example-power-analysis-report/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;624&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here is an alternative version of that plot, this time based on the more conservative variance ratio of 0.281.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  icc0.9_vr_0.281_d0.1 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.281_d0.2 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.281_d0.3
) %&amp;gt;% 
  mutate(missing = c(rep(c(10, 20, 30, 00), each = n() / 4))) %&amp;gt;% 

  filter(power &amp;gt; .8) %&amp;gt;% 
  group_by(missing, effect_size) %&amp;gt;% 
  top_n(-1, power) %&amp;gt;% 
  select(-n2, -power, -dropout) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(`Cohen&amp;#39;s d` = effect_size) %&amp;gt;% 
  
  ggplot(aes(x = `Cohen&amp;#39;s d`, y = missing)) +
  geom_tile(aes(fill = tot_n),
            show.legend = F) +
  geom_text(aes(label = tot_n, color = tot_n &amp;lt; 700),
            show.legend = F) +
  scale_fill_viridis_c(option = &amp;quot;B&amp;quot;, begin = .1, end = .70 ,limits = c(0, 1000)) +
  scale_color_manual(values = c(&amp;quot;black&amp;quot;, &amp;quot;white&amp;quot;)) +
  labs(title = expression(paste(&amp;quot;Total &amp;quot;, italic(N), &amp;quot; required for .8 power, based on variance ratio of 0.281&amp;quot;)),
       subtitle = expression(paste(&amp;quot;The power simulations only considered up to &amp;quot;, italic(N), &amp;quot; = 1,000.&amp;quot;)),
       x = expression(paste(&amp;quot;Cohen&amp;#39;s &amp;quot;, italic(d))),
       y = &amp;quot;% missing\nper follow-up&amp;quot;) +
  theme(axis.ticks = element_blank(),
        panel.grid = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-07-02-example-power-analysis-report/index_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;624&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Again, I recommend playing it safe and relying on the power estimates based on the larger variance ratio of 0.281. Those power curves indicate that even with rather large dropout (i.e., 30% at the second time point and another 30% at the final time point), &lt;span class=&#34;math inline&#34;&gt;\(N = 486\)&lt;/span&gt; is sufficient to detect a small effect size (i.e., &lt;span class=&#34;math inline&#34;&gt;\(d = 0.2\)&lt;/span&gt;) at the conventional .8 power threshold. Note that because we cut off the power simulations at &lt;span class=&#34;math inline&#34;&gt;\(N = 1{,}000\)&lt;/span&gt;, we never reached .8 power in the conditions where &lt;span class=&#34;math inline&#34;&gt;\(d = 0.1\)&lt;/span&gt; and there was missingness at or greater than 0% dropout at each follow-up time point.&lt;/p&gt;
&lt;p&gt;To clarify, &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; in each cell is the total sample size presuming both the control and experimental conditions have equal numbers in each. Thus, &lt;span class=&#34;math inline&#34;&gt;\(n_\text{control} = n_\text{experimental} = N/2\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;wrap-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Wrap up&lt;/h2&gt;
&lt;p&gt;I presented the original report with an HTML document, which used the R Markdown &lt;a href=&#34;https://community.rstudio.com/t/notebook-with-code-folding-hide-by-default/55845&#34;&gt;code folding&lt;/a&gt; option, which hid my code, by default. Since I‚Äôm not aware of a good way to use code folding with &lt;strong&gt;blogdown&lt;/strong&gt; blog posts, here you see the code in all its glory.&lt;/p&gt;
&lt;p&gt;All you Bayesian freaks may have noticed that this was a conventional frequentist power analysis. I‚Äôm not always a Bayesian. ü§∑ When you intend to analyze experimental RCT-like data with frequentist software, the &lt;a href=&#34;https://github.com/rpsychologist/powerlmm&#34;&gt;&lt;strong&gt;powerlmm&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-powerlmm&#34; role=&#34;doc-biblioref&#34;&gt;Magnusson, 2018&lt;/a&gt;)&lt;/span&gt; can come in really handy.&lt;/p&gt;
&lt;p&gt;Had I intended to share a report like this for a broader audience, possibly as supplemental material for a paper, I might have explained the &lt;strong&gt;powerlmm&lt;/strong&gt; code a bit more. Since this was originally meant for internal use, my main goal was to present the results with an extra bit of transparency for the sake of building trust with a new collaborator. It worked, by the way. This person‚Äôs grant money now pays for part of my salary.&lt;/p&gt;
&lt;p&gt;If this was supplementary material, I would have also spent more time explicitly showing where I got the Cohen‚Äôs &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, ICC, and variance ratio values.&lt;/p&gt;
&lt;p&gt;If you didn‚Äôt notice, the context for this power analysis wasn‚Äôt ideal. Even though I pulled information from two different data sources, neither was ideal and their combination wasn‚Äôt, either. Though my collaborator‚Äôs pilot data let me compute the Cohen‚Äôs &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and the ICC, I didn‚Äôt have access to the raw data, themselves. Without that, I had no good way to compute the variance ratio. As it turns out, that was a big deal. Though I was able to compute variance ratios from different data from a similar population, it wasn‚Äôt on the same criterion variable. The best place to be in is if you have pilot data from the same population and on the same criterion variable. Outside of that, you‚Äôre making assumptions about model parameters you might not have spent a lot of time pondering, before. Welcome to the world of multilevel power analyses, friends. Keep your chins up. It‚Äôs rough, out there.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] forcats_0.5.1   stringr_1.4.0   dplyr_1.0.6     purrr_0.3.4    
## [5] readr_1.4.0     tidyr_1.1.3     tibble_3.1.2    ggplot2_3.3.3  
## [9] tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##  [1] tidyselect_1.1.1  xfun_0.23         bslib_0.2.4       haven_2.3.1      
##  [5] colorspace_2.0-0  vctrs_0.3.8       generics_0.1.0    viridisLite_0.4.0
##  [9] htmltools_0.5.1.1 emo_0.0.0.9000    yaml_2.2.1        utf8_1.2.1       
## [13] rlang_0.4.11      jquerylib_0.1.4   pillar_1.6.1      withr_2.4.2      
## [17] glue_1.4.2        DBI_1.1.0         dbplyr_2.0.0      modelr_0.1.8     
## [21] readxl_1.3.1      lifecycle_1.0.0   munsell_0.5.0     blogdown_1.3     
## [25] gtable_0.3.0      cellranger_1.1.0  rvest_0.3.6       evaluate_0.14    
## [29] labeling_0.4.2    knitr_1.33        MBESS_4.8.0       fansi_0.4.2      
## [33] highr_0.9         broom_0.7.6       Rcpp_1.0.6        backports_1.2.1  
## [37] scales_1.1.1      jsonlite_1.7.2    farver_2.1.0      fs_1.5.0         
## [41] hms_0.5.3         digest_0.6.27     stringi_1.6.2     bookdown_0.22    
## [45] grid_4.0.4        cli_2.5.0         tools_4.0.4       magrittr_2.0.1   
## [49] sass_0.3.1        crayon_1.4.1      pkgconfig_2.0.3   ellipsis_0.3.2   
## [53] xml2_1.3.2        reprex_0.3.0      lubridate_1.7.9.2 rstudioapi_0.13  
## [57] assertthat_0.2.1  rmarkdown_2.8     httr_1.4.2        R6_2.5.0         
## [61] compiler_4.0.4&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-R-powerlmm&#34; class=&#34;csl-entry&#34;&gt;
Magnusson, K. (2018). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;powerlmm&lt;/span&gt;: &lt;span&gt;Power&lt;/span&gt; analysis for longitudinal multilevel models&lt;/em&gt; [Manual]. &lt;a href=&#34;https://github.com/rpsychologist/powerlmm&#34;&gt;https://github.com/rpsychologist/powerlmm&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian power analysis: Part III.b. What about 0/1 data?</title>
      <link>/post/bayesian-power-analysis-part-iii-b/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      <guid>/post/bayesian-power-analysis-part-iii-b/</guid>
      <description>
&lt;script src=&#34;/post/bayesian-power-analysis-part-iii-b/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;version-1.1.0&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Version 1.1.0&lt;/h2&gt;
&lt;p&gt;Edited on April 21, 2021, to fix a few code breaks and add a Reference section.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;orientation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Orientation&lt;/h2&gt;
&lt;p&gt;In the &lt;a href=&#34;https://solomonkurz.netlify.com/post/bayesian-power-analysis-part-iii-a/&#34;&gt;last post&lt;/a&gt;, we covered how the Poisson distribution is handy for modeling count data. Binary data are even weirder than counts. They typically only take on two values: 0 and 1. Sometimes 0 is a stand-in for ‚Äúno‚Äù and 1 for ‚Äúyes‚Äù (e.g., &lt;em&gt;Are you an expert in Bayesian power analysis?&lt;/em&gt; For me that would be &lt;code&gt;0&lt;/code&gt;). You can also have data of this kind if you asked people whether they‚Äôd like to choose option A or B. With those kinds of data, you might arbitrarily code A as 0 and B as 1. Binary data also often stand in for trials where 0 = ‚Äúfail‚Äù and 1 = ‚Äúsuccess.‚Äù For example, if you answered ‚ÄúYes‚Äù to the question &lt;em&gt;Are all data normally distributed?&lt;/em&gt; we‚Äôd mark your answer down as a &lt;code&gt;0&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Though 0‚Äôs and 1‚Äôs are popular, sometimes binary data appear in their aggregated form. Let‚Äôs say I gave you 10 algebra questions and you got 7 of them right. Here‚Äôs one way to encode those data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 10
z &amp;lt;- 7

rep(0:1, times = c(n - z, z))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 0 0 0 1 1 1 1 1 1 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In that example, &lt;code&gt;n&lt;/code&gt; stood for the total number of trials and &lt;code&gt;z&lt;/code&gt; was the number you got correct (i.e., the number of times we encoded your response as a 1). A more compact way to encode that data is with two columns, one for &lt;code&gt;z&lt;/code&gt; and the other for &lt;code&gt;n&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

tibble(z = z,
       n = n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 √ó 2
##       z     n
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     7    10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So then if you gave those same 10 questions to four of your friends, we could encode the results like this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(3)

tibble(id = letters[1:5],
       z  = rpois(n = 5, lambda = 5),
       n  = n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 √ó 3
##   id        z     n
##   &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
## 1 a         3    10
## 2 b         7    10
## 3 c         4    10
## 4 d         4    10
## 5 e         5    10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you were &lt;code&gt;b&lt;/code&gt;, you‚Äôd be the smart one in the group.&lt;/p&gt;
&lt;p&gt;Anyway, whether working with binary or aggregated binary data, we‚Äôre interested in the probability a given trial will be 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;logistic-regression-with-unaggregated-binary-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Logistic regression with unaggregated binary data&lt;/h2&gt;
&lt;p&gt;Taking unaggregated binary data as a starting point, given &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; data that includes a variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; where the value in the &lt;span class=&#34;math inline&#34;&gt;\(i^\text{th}\)&lt;/span&gt; row is a 0 or a 1, we‚Äôd like to know the probability a given trial would be 1, given &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; [i.e., &lt;span class=&#34;math inline&#34;&gt;\(p(y_i = 1 | d)\)&lt;/span&gt;]. The binomial distribution will help us get that estimate for &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;. We‚Äôll do so within the context of a logistic regression model following the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_i                        &amp;amp; \sim \text{Binomial} (n = 1, p_i) \\
\operatorname{logit} (p_i) &amp;amp; = \beta_0,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;were the logit function is defined as the log odds&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\operatorname{logit} (p_i) = \log \left (\frac{p_i}{1 - p_i} \right ),
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which also means that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\log \left (\frac{p_i}{1 - p_i} \right ) = \beta_0.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In those formulas, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the intercept. In a binomial model with no predictors&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, the intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is just the estimate for &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;, but in the log-odds metric. So yes, similar to the Poisson models from the last post, we typically use a link function with our binomial models. Instead of the log link, we use the logit because it constrains the posterior for &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; to values between 0 and 1. Just as the null value for a probability is .5, the null value for the parameters within a logistic regression model is typically 0.&lt;/p&gt;
&lt;p&gt;As with the Poisson, I‚Äôm not going to go into a full-blown tutorial on the binomial distribution or on logistic regression. For more thorough introductions, check out chapters 9 through 10 in McElreath‚Äôs &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;&lt;em&gt;Statistical rethinking&lt;/em&gt;&lt;/a&gt; or Agresti‚Äôs &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-agrestiFoundationsLinearGeneralized2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&#34;&gt;&lt;em&gt;Foundations of linear and generalized linear models&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;we-need-data.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;We need data.&lt;/h3&gt;
&lt;p&gt;Time to simulate some data. Let‚Äôs say we‚Äôd like to estimate the probability someone will hit a ball in a baseball game. Nowadays, batting averages for professional baseball players tend around .25 (see &lt;a href=&#34;http://www.baseball-almanac.com/hitting/hibavg4.shtml&#34;&gt;here&lt;/a&gt;). So if we wanted to simulate 50 at-bats, we might do so like this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(3)

d &amp;lt;- tibble(y = rbinom(n = 50, size = 1, prob = .25))

str(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## tibble [50 √ó 1] (S3: tbl_df/tbl/data.frame)
##  $ y: int [1:50] 0 1 0 0 0 0 0 0 0 0 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are what those data look like in a bar plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_set(theme_gray() + theme(panel.grid = element_blank()))

d %&amp;gt;% 
  mutate(y = factor(y)) %&amp;gt;% 
  
  ggplot(aes(x = y)) +
  geom_bar()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-b/index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;288&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;time-to-model.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Time to model.&lt;/h3&gt;
&lt;p&gt;To practice modeling those data, we‚Äôll want to fire up the &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;&lt;strong&gt;brms&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-burknerBrmsPackageBayesian2017&#34; role=&#34;doc-biblioref&#34;&gt;B√ºrkner, 2017&lt;/a&gt;, &lt;a href=&#34;#ref-burknerAdvancedBayesianMultilevel2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;, &lt;a href=&#34;#ref-R-brms&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can use the &lt;code&gt;get_prior()&lt;/code&gt; function to get the &lt;strong&gt;brms&lt;/strong&gt; default for our intercept-only logistic regression model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_prior(data = d, 
          family = binomial,
          y | trials(1) ~ 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Intercept ~ student_t(3, 0, 2.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As it turns out, that‚Äôs a really liberal prior. We might step up a bit and put a more skeptical &lt;code&gt;normal(0, 2)&lt;/code&gt; prior on that intercept. With the context of our logit link, that still puts a 95% probability that the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is between .02 and .98, which is almost the entire parameter space. Here‚Äôs how to fit the model with the &lt;code&gt;brm()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit1 &amp;lt;-
  brm(data = d, 
      family = binomial,
      y | trials(1) ~ 1,
      prior(normal(0, 2), class = Intercept),
      seed = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the &lt;code&gt;brm()&lt;/code&gt; formula syntax, including a &lt;code&gt;|&lt;/code&gt; bar on the left side of a formula indicates we have extra supplementary information about our criterion variable. In this case, that information is that each &lt;code&gt;y&lt;/code&gt; value corresponds to a single trial [i.e., &lt;code&gt;trials(1)&lt;/code&gt;], which itself corresponds to the &lt;span class=&#34;math inline&#34;&gt;\(n = 1\)&lt;/span&gt; portion of the statistical formula, above. Here are the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(fit1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: binomial 
##   Links: mu = logit 
## Formula: y | trials(1) ~ 1 
##    Data: d (Number of observations: 50) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -1.39      0.36    -2.12    -0.71 1.00     1622     1434
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Remember that that intercept is on the scale of the logit link, the log odds. We can transform it with the &lt;code&gt;brms::inv_logit_scaled()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(fit1)[&amp;quot;Intercept&amp;quot;, 1] %&amp;gt;% 
  inv_logit_scaled()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1995929&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we‚Äôd like to view the full posterior distribution, we‚Äôll need to work with the posterior draws themselves. Then we‚Äôll plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract the posterior draws
posterior_samples(fit1) %&amp;gt;% 
  # transform from the log-odds to a probability metric
  transmute(p = inv_logit_scaled(b_Intercept)) %&amp;gt;% 
  
  # plot!
  ggplot(aes(x = p)) +
  geom_density(fill = &amp;quot;grey25&amp;quot;, size = 0) +
  scale_x_continuous(&amp;quot;probability of a hit&amp;quot;, limits = c(0, 1)) +
  scale_y_continuous(NULL, breaks = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Method &amp;#39;posterior_samples&amp;#39; is deprecated. Please see ?as_draws for
## recommended alternatives.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-b/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks like the null hypothesis of &lt;span class=&#34;math inline&#34;&gt;\(p = .5\)&lt;/span&gt; is not credible for this simulation. If we‚Äôd like the posterior median and percentile-based 95% intervals, we might use the &lt;code&gt;median_qi()&lt;/code&gt; function from the handy &lt;a href=&#34;https://mjskay.github.io/tidybayes/&#34;&gt;&lt;strong&gt;tidybayes&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-tidybayes&#34; role=&#34;doc-biblioref&#34;&gt;Kay, 2020&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidybayes)

posterior_samples(fit1) %&amp;gt;% 
  transmute(p = inv_logit_scaled(b_Intercept)) %&amp;gt;% 
  median_qi()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 √ó 6
##       p .lower .upper .width .point .interval
##   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;    
## 1 0.201  0.108  0.330   0.95 median qi&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yep, .5 was not within those intervals.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;but-what-about-power&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;But what about power?&lt;/h3&gt;
&lt;p&gt;That‚Äôs enough preliminary work. Let‚Äôs see what happens when we do a mini power analysis with 100 iterations. First we set up our simulation function using the same methods we introduced in earlier blog posts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_data_fit &amp;lt;- function(seed, n_player) {
  
  n_trials &amp;lt;- 1
  prob_hit &amp;lt;- .25
  
  set.seed(seed)
  
  d &amp;lt;- tibble(y = rbinom(n    = n_player, 
                         size = n_trials, 
                         prob = prob_hit))
  
  update(fit1,
         newdata = d,
         seed = seed) %&amp;gt;% 
  posterior_samples() %&amp;gt;% 
  transmute(p = inv_logit_scaled(b_Intercept)) %&amp;gt;% 
  median_qi() %&amp;gt;% 
    select(.lower:.upper)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Simulate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim1 &amp;lt;-
  tibble(seed = 1:100) %&amp;gt;% 
  mutate(ci = map(seed, sim_data_fit, n_player = 50)) %&amp;gt;% 
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You might plot the intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim1 %&amp;gt;% 
  ggplot(aes(x = seed, ymin = .lower, ymax = .upper)) +
  geom_hline(yintercept = c(.25, .5), color = &amp;quot;white&amp;quot;) +
  geom_linerange() +
  xlab(&amp;quot;seed (i.e., simulation index)&amp;quot;) +
  scale_y_continuous(&amp;quot;probability of hitting the ball&amp;quot;, limits = c(0, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-b/index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Like one of my old coworkers used to say: &lt;em&gt;Purtier ‚Äôn a hog!&lt;/em&gt; Here we‚Äôll summarize the results both in terms of their conventional power, their mean width, and the proportion of widths more narrow than .25. &lt;em&gt;Why .25?&lt;/em&gt; I don‚Äôt know. Without a substantively-informed alternative, it‚Äôs as good a criterion as any.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim1 %&amp;gt;% 
  mutate(width = .upper - .lower) %&amp;gt;% 
  summarise(`conventional power` = mean(.upper &amp;lt; .5),
            `mean width`         = mean(width),
            `width below .25`    = mean(width &amp;lt; .25))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 √ó 3
##   `conventional power` `mean width` `width below .25`
##                  &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;             &amp;lt;dbl&amp;gt;
## 1                 0.95        0.231              0.78&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Depending on your study needs, you‚Äôd adjust your sample size accordingly, do a mini simulation or two first, and then follow up with a proper power simulation with 1000+ iterations.&lt;/p&gt;
&lt;p&gt;I should point out that whereas in the last post we evaluated the power of the Poisson model with the parameters on the scale of the link function, here we evaluated the power for our logistic regression model after transforming the intercept back into the probability metric. Both methods are fine. I recommend you run your power simulation based on how you want to interpret and report your results.&lt;/p&gt;
&lt;p&gt;We should also acknowledge that this was our first example of a power simulation that wasn‚Äôt based on some group comparison. Comparing groups is fine and normal and important. And it‚Äôs also the case that we can care about power and/or parameter precision for more than group-based analyses. Our simulation-based approach is fine for both.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;aggregated-binomial-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Aggregated binomial regression&lt;/h2&gt;
&lt;p&gt;It‚Äôs no more difficult to simulate and work with aggregated binomial data. But since the mechanics for &lt;code&gt;brms::brm()&lt;/code&gt; and thus the down-the-road simulation setup are a little different, we should practice. With our new setup, we‚Äôll consider a new example. Since .25 is the typical batting average, it might better sense to define the null hypothesis like this:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0 \text{: } p = .25.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Consider a case where we had some intervention where we expected a new batting average of .35. How many trials would we need, then, to either reject &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; or perhaps estimate &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; with a satisfactory degree of precision? Here‚Äôs what the statistical formula for the implied aggregated binomial model might look like:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_i                        &amp;amp; \sim \text{Binomial} (n, p_i) \\
\operatorname{logit} (p_i) &amp;amp; = \beta_0.
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The big change is we no longer defined &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; as 1. Let‚Äôs say we wanted our aggregated binomial data set to contain the summary statistics for &lt;span class=&#34;math inline&#34;&gt;\(n = 100\)&lt;/span&gt; trials. Here‚Äôs what that might look like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_trials &amp;lt;- 100
prob_hit &amp;lt;- .35

set.seed(3)

d &amp;lt;- tibble(n_trials = n_trials,
            y = rbinom(n    = 1, 
                       size = n_trials, 
                       prob = prob_hit))

d&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 √ó 2
##   n_trials     y
##      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1      100    32&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have two columns. The first, &lt;code&gt;n_trials&lt;/code&gt;, indicates how many cases or trials we‚Äôre summarizing. The second, &lt;code&gt;y&lt;/code&gt;, indicates how many successes/1‚Äôs/hits we might expect given &lt;span class=&#34;math inline&#34;&gt;\(p = .35\)&lt;/span&gt;. This is the aggregated binomial equivalent of if we had a 100-row vector composed of 32 1s and 68 0s.&lt;/p&gt;
&lt;p&gt;Now, before we discuss fitting the model with &lt;strong&gt;brms&lt;/strong&gt;, let‚Äôs talk priors. Since we‚Äôve updated our definition of &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;, it might make sense to update the prior for &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;. As it turns out, setting that prior to &lt;code&gt;normal(-1, 0.5)&lt;/code&gt; puts the posterior mode at about .25 on the probability space, but with fairly wide 95% intervals ranging from about .12 to .5. Though centered on our updated null value, this prior is still quite permissive given our hypothesized &lt;span class=&#34;math inline&#34;&gt;\(p = .35\)&lt;/span&gt;. Let‚Äôs give it a whirl.&lt;/p&gt;
&lt;p&gt;To fit an aggregated binomial model with the &lt;code&gt;brm()&lt;/code&gt; function, we augment the &lt;code&gt;&amp;lt;criterion&amp;gt; | trials()&lt;/code&gt; syntax where the value that goes in &lt;code&gt;trials()&lt;/code&gt; is either a fixed number or variable in the data indexing &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. Our approach will be the latter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit2 &amp;lt;-
  brm(data = d, 
      family = binomial,
      y | trials(n_trials) ~ 1,
      prior(normal(-1, 0.5), class = Intercept),
      seed = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Inspect the summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(fit2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: binomial 
##   Links: mu = logit 
## Formula: y | trials(n_trials) ~ 1 
##    Data: d (Number of observations: 1) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -0.80      0.20    -1.19    -0.42 1.00     1524     1697
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After a transformation, here‚Äôs what that looks like in a plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(fit2) %&amp;gt;% 
  transmute(p = inv_logit_scaled(b_Intercept)) %&amp;gt;% 
  
  ggplot(aes(x = p, y = 0)) +
  stat_halfeye(.width = c(.5, .95)) +
  scale_x_continuous(&amp;quot;probability of a hit&amp;quot;, limits = c(0, 1)) +
  scale_y_continuous(NULL, breaks = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Method &amp;#39;posterior_samples&amp;#39; is deprecated. Please see ?as_draws for
## recommended alternatives.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-b/index_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Based on a single simulation, it looks like &lt;span class=&#34;math inline&#34;&gt;\(n = 100\)&lt;/span&gt; won‚Äôt quite be enough to reject &lt;span class=&#34;math inline&#34;&gt;\(H_0 \text{: } p = .25\)&lt;/span&gt; with a conventional 2-sided 95% interval. But it does look like we‚Äôre in the ballpark and that our basic data + model setup will work for a larger-scale simulation. Here‚Äôs an example of how you might update our custom simulation function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_data_fit &amp;lt;- function(seed, n_trials) {
  
  prob_hit &amp;lt;- .35
  
  set.seed(seed)
  
  d &amp;lt;- tibble(y = rbinom(n    = 1, 
                         size = n_trials, 
                         prob = prob_hit),
              n_trials = n_trials)
  
  update(fit2,
         newdata = d,
         seed = seed) %&amp;gt;% 
  posterior_samples() %&amp;gt;% 
  transmute(p = inv_logit_scaled(b_Intercept)) %&amp;gt;% 
  median_qi() %&amp;gt;% 
    select(.lower:.upper)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Simulate, this time trying out &lt;span class=&#34;math inline&#34;&gt;\(n = 120\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim2 &amp;lt;-
  tibble(seed = 1:100) %&amp;gt;% 
  mutate(ci = map(seed, sim_data_fit, n_trials = 120)) %&amp;gt;% 
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Plot the intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim2 %&amp;gt;% 
  ggplot(aes(x = seed, ymin = .lower, ymax = .upper)) +
  geom_hline(yintercept = c(.25, .35), color = &amp;quot;white&amp;quot;) +
  geom_linerange() +
  xlab(&amp;quot;seed (i.e., simulation index)&amp;quot;) +
  scale_y_continuous(&amp;quot;probability of hitting the ball&amp;quot;,
                     limits = c(0, 1), breaks = c(0, .25, .35, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-b/index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Overall, those intervals look pretty good. They‚Äôre fairly narrow and are hovering around the data generating &lt;span class=&#34;math inline&#34;&gt;\(p = .35\)&lt;/span&gt;. But many are still crossing the .25 threshold. Let‚Äôs see the results of a formal summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim2 %&amp;gt;% 
  mutate(width = .upper - .lower) %&amp;gt;% 
  summarise(`conventional power` = mean(.lower &amp;gt; .25),
            `mean width`         = mean(width),
            `width below .2`     = mean(width &amp;lt; .2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 √ó 3
##   `conventional power` `mean width` `width below .2`
##                  &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;
## 1                 0.54        0.155                1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All widths were narrower than .2 and the mean width was about .16. In the abstract that might seem reasonably precise. But we‚Äôre still not precise enough to reject &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; with a conventional power level. Depending on your needs, adjust the &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; accordingly and simulate again.&lt;/p&gt;
&lt;p&gt;Now you‚Äôve got a sense of how to work with the binomial likelihood for (aggregated)binary data, next time we‚Äôll play with Likert-type data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.1.1 (2021-08-10)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_3.0.1 brms_2.16.2     Rcpp_1.0.7      forcats_0.5.1  
##  [5] stringr_1.4.0   dplyr_1.0.7     purrr_0.3.4     readr_2.0.1    
##  [9] tidyr_1.1.3     tibble_3.1.4    ggplot2_3.3.5   tidyverse_1.3.1
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6          
##   [4] igraph_1.2.6         svUnit_1.0.6         splines_4.1.1       
##   [7] crosstalk_1.1.1      TH.data_1.0-10       rstantools_2.1.1    
##  [10] inline_0.3.19        digest_0.6.27        htmltools_0.5.2     
##  [13] rsconnect_0.8.24     fansi_0.5.0          magrittr_2.0.1      
##  [16] checkmate_2.0.0      tzdb_0.1.2           modelr_0.1.8        
##  [19] RcppParallel_5.1.4   matrixStats_0.60.1   sandwich_3.0-1      
##  [22] xts_0.12.1           prettyunits_1.1.1    colorspace_2.0-2    
##  [25] rvest_1.0.1          ggdist_3.0.0         haven_2.4.3         
##  [28] xfun_0.25            callr_3.7.0          crayon_1.4.1        
##  [31] jsonlite_1.7.2       lme4_1.1-27.1        survival_3.2-11     
##  [34] zoo_1.8-9            glue_1.4.2           gtable_0.3.0        
##  [37] emmeans_1.6.3        V8_3.4.2             distributional_0.2.2
##  [40] pkgbuild_1.2.0       rstan_2.26.3         abind_1.4-5         
##  [43] scales_1.1.1         mvtnorm_1.1-2        DBI_1.1.1           
##  [46] miniUI_0.1.1.1       xtable_1.8-4         stats4_4.1.1        
##  [49] StanHeaders_2.26.3   DT_0.19              htmlwidgets_1.5.3   
##  [52] httr_1.4.2           threejs_0.3.3        arrayhelpers_1.1-0  
##  [55] posterior_1.0.1      ellipsis_0.3.2       pkgconfig_2.0.3     
##  [58] loo_2.4.1            farver_2.1.0         sass_0.4.0          
##  [61] dbplyr_2.1.1         utf8_1.2.2           tidyselect_1.1.1    
##  [64] labeling_0.4.2       rlang_0.4.11         reshape2_1.4.4      
##  [67] later_1.3.0          munsell_0.5.0        cellranger_1.1.0    
##  [70] tools_4.1.1          cli_3.0.1            generics_0.1.0      
##  [73] broom_0.7.9          ggridges_0.5.3       evaluate_0.14       
##  [76] fastmap_1.1.0        yaml_2.2.1           processx_3.5.2      
##  [79] knitr_1.33           fs_1.5.0             nlme_3.1-152        
##  [82] mime_0.11            projpred_2.0.2       xml2_1.3.2          
##  [85] compiler_4.1.1       bayesplot_1.8.1      shinythemes_1.2.0   
##  [88] rstudioapi_0.13      gamm4_0.2-6          curl_4.3.2          
##  [91] reprex_2.0.1         bslib_0.3.0          stringi_1.7.4       
##  [94] highr_0.9            ps_1.6.0             blogdown_1.5        
##  [97] Brobdingnag_1.2-6    lattice_0.20-44      Matrix_1.3-4        
## [100] nloptr_1.2.2.2       markdown_1.1         shinyjs_2.0.0       
## [103] tensorA_0.36.2       vctrs_0.3.8          pillar_1.6.2        
## [106] lifecycle_1.0.0      jquerylib_0.1.4      bridgesampling_1.1-2
## [109] estimability_1.3     httpuv_1.6.2         R6_2.5.1            
## [112] bookdown_0.23        promises_1.2.0.1     gridExtra_2.3       
## [115] codetools_0.2-18     boot_1.3-28          colourpicker_1.1.0  
## [118] MASS_7.3-54          gtools_3.9.2         assertthat_0.2.1    
## [121] withr_2.4.2          shinystan_2.5.0      multcomp_1.4-17     
## [124] mgcv_1.8-36          parallel_4.1.1       hms_1.1.0           
## [127] grid_4.1.1           coda_0.19-4          minqa_1.2.4         
## [130] rmarkdown_2.10       shiny_1.6.0          lubridate_1.7.10    
## [133] base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-agrestiFoundationsLinearGeneralized2015&#34; class=&#34;csl-entry&#34;&gt;
Agresti, A. (2015). &lt;em&gt;Foundations of linear and generalized linear models&lt;/em&gt;. &lt;span&gt;John Wiley &amp;amp; Sons&lt;/span&gt;. &lt;a href=&#34;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&#34;&gt;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerBrmsPackageBayesian2017&#34; class=&#34;csl-entry&#34;&gt;
B√ºrkner, P.-C. (2017). &lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;An R&lt;/span&gt; package for &lt;span&gt;Bayesian&lt;/span&gt; multilevel models using &lt;span&gt;Stan&lt;/span&gt;. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;80&lt;/em&gt;(1), 1‚Äì28. &lt;a href=&#34;https://doi.org/10.18637/jss.v080.i01&#34;&gt;https://doi.org/10.18637/jss.v080.i01&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerAdvancedBayesianMultilevel2018&#34; class=&#34;csl-entry&#34;&gt;
B√ºrkner, P.-C. (2018). Advanced &lt;span&gt;Bayesian&lt;/span&gt; multilevel modeling with the &lt;span&gt;R&lt;/span&gt; package brms. &lt;em&gt;The R Journal&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(1), 395‚Äì411. &lt;a href=&#34;https://doi.org/10.32614/RJ-2018-017&#34;&gt;https://doi.org/10.32614/RJ-2018-017&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-brms&#34; class=&#34;csl-entry&#34;&gt;
B√ºrkner, P.-C. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;Bayesian&lt;/span&gt; regression models using ‚Äô&lt;span&gt;Stan&lt;/span&gt;‚Äô&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=brms&#34;&gt;https://CRAN.R-project.org/package=brms&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-tidybayes&#34; class=&#34;csl-entry&#34;&gt;
Kay, M. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;tidybayes&lt;/span&gt;: &lt;span&gt;Tidy&lt;/span&gt; data and ‚Äôgeoms‚Äô for &lt;span&gt;Bayesian&lt;/span&gt; models&lt;/em&gt;. &lt;a href=&#34;https://mjskay.github.io/tidybayes/&#34;&gt;https://mjskay.github.io/tidybayes/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2015&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2015). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;In case this is all new to you and you and you had the question in your mind: Yes, you can add predictors to the logistic regression model. Say we had a model with two predictors, &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;. Our statistical model would then follow the form &lt;span class=&#34;math inline&#34;&gt;\(\operatorname{logit} (p_i) = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i}\)&lt;/span&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;‚Ü©Ô∏é&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian power analysis: Part III.a. Counts are special.</title>
      <link>/post/bayesian-power-analysis-part-iii-a/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      <guid>/post/bayesian-power-analysis-part-iii-a/</guid>
      <description>
&lt;script src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;version-1.1.0&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Version 1.1.0&lt;/h2&gt;
&lt;p&gt;Edited on April 21, 2021, to remove the &lt;code&gt;broom::tidy()&lt;/code&gt; portion of the workflow.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;orientation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Orientation&lt;/h2&gt;
&lt;p&gt;So far we‚Äôve covered Bayesian power simulations from both a null hypothesis orientation (see &lt;a href=&#34;https://solomonkurz.netlify.com/post/bayesian-power-analysis-part-i/&#34;&gt;part I&lt;/a&gt;) and a parameter width perspective (see &lt;a href=&#34;https://solomonkurz.netlify.com/post/bayesian-power-analysis-part-ii/&#34;&gt;part II&lt;/a&gt;). In both instances, we kept things simple and stayed with Gaussian (i.e., normally distributed) data. But not all data follow that form, so it might do us well to expand our skill set a bit. In the next few posts, we‚Äôll cover how we might perform power simulations with other kinds of data. In this post, we‚Äôll focus on how to use the Poisson likelihood to model counts. In follow-up posts, we‚Äôll explore how to model binary and Likert-type data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-poisson-distribution-is-handy-for-counts.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Poisson distribution is handy for counts.&lt;/h2&gt;
&lt;p&gt;In the social sciences, count data arise when we ask questions like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How many sexual partners have you had?&lt;/li&gt;
&lt;li&gt;How many pets do you have at home?&lt;/li&gt;
&lt;li&gt;How many cigarettes did you smoke, yesterday?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The values these data will take are discrete&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; in that you‚Äôve either slept with 9 or 10 people, but definitely not 9.5. The values cannot go below zero in that even if you quit smoking cold turkey 15 years ago and have been a health nut since, you still could not have smoked -3 cigarettes, yesterday. Zero is as low as it goes.&lt;/p&gt;
&lt;p&gt;The canonical distribution for data of this type‚Äìnon-negative integers‚Äìis the Poisson. It‚Äôs named after the French mathematician Sim√©on Denis Poisson, &lt;a href=&#34;https://upload.wikimedia.org/wikipedia/commons/e/e8/E._Marcellot_Sim√©on-Denis_Poisson_1804.jpg&#34;&gt;who had quite the confident stare in his youth&lt;/a&gt;. The Poisson distribution has one parameter, &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;, which controls both its mean and variance. Although the numbers the Poisson describes are counts, the &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; parameter does not need to be an integer. For example, here‚Äôs the plot of 1,000 draws from a Poisson for which &lt;span class=&#34;math inline&#34;&gt;\(\lambda = 3.2\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

theme_set(theme_gray() + theme(panel.grid = element_blank()))

tibble(x = rpois(n = 1e3, lambda = 3.2)) %&amp;gt;% 
  mutate(x = factor(x)) %&amp;gt;% 
  
  ggplot(aes(x = x)) +
  geom_bar()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In case you missed it, the key function for generating those data was &lt;code&gt;rpois()&lt;/code&gt; (see &lt;code&gt;?rpois&lt;/code&gt;). I‚Äôm not going to go into a full-blown tutorial on the Poisson distribution or on count regression. For more thorough introductions, check out Atkins et al‚Äôs &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-atkinsTutorialOnCount2013&#34; role=&#34;doc-biblioref&#34;&gt;2013&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3513584/pdf/nihms396181.pdf&#34;&gt;&lt;em&gt;A tutorial on count regression and zero-altered count models for longitudinal substance use data&lt;/em&gt;&lt;/a&gt;, chapters 9 through 11 in McElreath‚Äôs &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;&lt;em&gt;Statistical Rethinking&lt;/em&gt;&lt;/a&gt;, or, if you really want to dive in, Agresti‚Äôs &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-agrestiFoundationsLinearGeneralized2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&#34;&gt;&lt;em&gt;Foundations of linear and generalized linear models&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For our power example, let‚Äôs say you were interested in drinking. Using data from &lt;a href=&#34;https://pubs.niaaa.nih.gov/publications/AA70/AA70.htm&#34;&gt;the National Epidemiologic Survey on Alcohol and Related Conditions&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-niaaaNationalEpidemiologicSurvey2006&#34; role=&#34;doc-biblioref&#34;&gt;{{National Institute on Alcohol Abuse and Alcoholism}}, 2006&lt;/a&gt;)&lt;/span&gt;, Christopher Ingraham &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-ingrahamThinkYouDrink2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt; presented &lt;a href=&#34;https://www.washingtonpost.com/news/wonk/wp/2014/09/25/think-you-drink-a-lot-this-chart-will-tell-you/?utm_term=.b81599bbbe25&#34;&gt;a data visualization&lt;/a&gt; of the average number of alcoholic drinks American adults consume, per week. By decile, the numbers were:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;0.00&lt;/li&gt;
&lt;li&gt;0.00&lt;/li&gt;
&lt;li&gt;0.00&lt;/li&gt;
&lt;li&gt;0.02&lt;/li&gt;
&lt;li&gt;0.14&lt;/li&gt;
&lt;li&gt;0.63&lt;/li&gt;
&lt;li&gt;2.17&lt;/li&gt;
&lt;li&gt;6.25&lt;/li&gt;
&lt;li&gt;15.28&lt;/li&gt;
&lt;li&gt;73.85&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let‚Äôs say you wanted to run a study where you planned on comparing two demographic groups by their weekly drinking levels. Let‚Äôs further say you suspected one of those groups drank like the American adults in the 7&lt;sup&gt;th&lt;/sup&gt; decile and the other drank like American adults in the 8&lt;sup&gt;th&lt;/sup&gt;. We‚Äôll call them low and high drinkers, respectively. For convenience, let‚Äôs further presume you‚Äôll be able to recruit equal numbers of participants from both groups. The objective for our power analysis‚Äìor sample size analysis if you prefer to avoid the language of &lt;em&gt;power&lt;/em&gt;‚Äìis to determine how many you‚Äôd need per group to detect reliable differences. Using &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt; as a starting point, here‚Äôs what the data for our hypothetical groups might look like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mu_7 &amp;lt;- 2.17
mu_8 &amp;lt;- 6.25

n &amp;lt;- 50

set.seed(3)

d &amp;lt;-
  tibble(low  = rpois(n = n, lambda = mu_7),
         high = rpois(n = n, lambda = mu_8)) %&amp;gt;% 
  gather(group, count) 

d %&amp;gt;%
  mutate(count = factor(count)) %&amp;gt;% 
  
  ggplot(aes(x = count)) +
  geom_bar() +
  facet_wrap(~group, ncol = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This will be our primary data type. Our next step is to determine how to express our research question as a regression model. Like with our two-group Gaussian models, we can predict counts in terms of an intercept (i.e., standing for the expected value on the reference group) and slope (i.e., standing for the expected difference between the reference group and the comparison group). If we coded our two groups by a &lt;code&gt;high&lt;/code&gt; variable for which 0 stood for low drinkers and 1 stood for high drinkers, the basic model would follow the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\text{drinks_per_week}_i         &amp;amp; \sim \operatorname{Poisson}(\lambda_i) \\
\log(\lambda_i)   &amp;amp; = \beta_0 + \beta_1 \text{high}_i.
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here‚Äôs how to set the data up for that model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;-
  d %&amp;gt;% 
  mutate(high = ifelse(group == &amp;quot;low&amp;quot;, 0, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you were attending closely to our model formula, you noticed we ran into a detail. Count regression, such as with the Poisson likelihood, tends to use the log link. &lt;em&gt;Why?&lt;/em&gt; you ask. Recall that counts need to be 0 and above. Same deal for our &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; parameter. In order to make sure our models don‚Äôt yield silly estimates for &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;, like -2 or something, we typically use the log link. You don‚Äôt have to, of course. The world is your playground. But this is the method most of your colleagues are likely to use and it‚Äôs the one I suggest you use until you have compelling reasons to do otherwise.&lt;/p&gt;
&lt;p&gt;So then since we‚Äôre now fitting a model with a log link, it might seem challenging to pick good priors. As a place to start, we can use the &lt;code&gt;brms::get_prior()&lt;/code&gt; function to see the &lt;strong&gt;brms&lt;/strong&gt; defaults.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)

get_prior(data = d,
          family = poisson,
          count ~ 0 + Intercept + high)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   prior class      coef group resp dpar nlpar bound       source
##  (flat)     b                                            default
##  (flat)     b      high                             (vectorized)
##  (flat)     b Intercept                             (vectorized)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hopefully two things popped out. First, there‚Äôs no prior of &lt;code&gt;class = sigma&lt;/code&gt;. Since the Poisson distribution only has one parameter &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;, we don‚Äôt need to set a prior for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Our model won‚Äôt have one. Second, because we‚Äôre continuing to use the &lt;code&gt;0 + Intercept&lt;/code&gt; syntax for our model intercept, both our intercept and slope are of prior &lt;code&gt;class = b&lt;/code&gt; and those currently have default flat priors with &lt;strong&gt;brms&lt;/strong&gt;. To be sure, flat priors aren‚Äôt the best. But maybe if this was your first time playing around with a Poisson model, default flat priors might seem like a safe place to start. &lt;a href=&#34;https://xkcd.com/386/&#34;&gt;Feel free to disagree&lt;/a&gt;. In the meantime, here‚Äôs how to fit that default Poisson model with &lt;code&gt;brms::brm()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit1 &amp;lt;-
  brm(data = d,
      family = poisson,
      count ~ 0 + Intercept + high,
      seed = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(fit1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: poisson 
##   Links: mu = log 
## Formula: count ~ 0 + Intercept + high 
##    Data: d (Number of observations: 100) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.59      0.11     0.38     0.79 1.01      917     1133
## high          1.27      0.12     1.03     1.51 1.01      935     1182
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since we used the log link, our model results are in the log metric, too. If you‚Äôd like them in the metric of the data, you‚Äôd work directly with the poster samples and exponentiate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post &amp;lt;- 
  posterior_samples(fit1) %&amp;gt;% 
  mutate(`beta_0 (i.e., low)`                       = exp(b_Intercept),
         `beta_1 (i.e., difference score for high)` = exp(b_high))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then just summarize our parameters of interest.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post %&amp;gt;% 
  select(starts_with(&amp;quot;beta_&amp;quot;)) %&amp;gt;% 
  gather() %&amp;gt;% 
  group_by(key) %&amp;gt;% 
  summarise(mean  = mean(value),
            lower = quantile(value, prob = .025),
            upper = quantile(value, prob = .975))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 4
##   key                                       mean lower upper
##   &amp;lt;chr&amp;gt;                                    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 beta_0 (i.e., low)                        1.81  1.46  2.21
## 2 beta_1 (i.e., difference score for high)  3.58  2.81  4.53&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the sake of simulation, it‚Äôll be easier if we press on with evaluating the parameters on the log metric, though. If you‚Äôre working within a null-hypothesis oriented power paradigm, you‚Äôll be happy to know zero is still the number to beat for evaluating our 95% intervals for &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;, even when that parameter is in the log metric. Here it is, again.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(fit1)[&amp;quot;high&amp;quot;, ]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Estimate Est.Error      Q2.5     Q97.5 
## 1.2690437 0.1211455 1.0330613 1.5108894&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So our first fit suggests we‚Äôre on good footing to run a quick power simulation holding &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt;. As in the prior blog posts, our lives will be simpler if we set up a custom simulation function. Since we‚Äôll be using it to simulate the data and fit the model in one step, let‚Äôs call it &lt;code&gt;sim_data_fit()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_data_fit &amp;lt;- function(seed, n) {
  
  # define our mus in the function
  mu_7 &amp;lt;- 2.17
  mu_8 &amp;lt;- 6.25

  # make your results reproducible
  set.seed(seed)
  
  # simulate the data
  d &amp;lt;-
    tibble(high  = rep(0:1, each = n),
           count = c(rpois(n = n, lambda = mu_7),
                     rpois(n = n, lambda = mu_8)))
  
  # fit and summarize
  update(fit1,
         newdata = d,
         seed = seed) %&amp;gt;% 
    fixef() %&amp;gt;% 
    data.frame() %&amp;gt;% 
    rownames_to_column(&amp;quot;parameter&amp;quot;) %&amp;gt;% 
    filter(parameter == &amp;quot;high&amp;quot;) %&amp;gt;% 
    select(Q2.5:Q97.5 )
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here‚Äôs the simulation for a simple 100 iterations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim1 &amp;lt;-
  tibble(seed = 1:100) %&amp;gt;% 
  mutate(ci = map(seed, sim_data_fit, n = 50)) %&amp;gt;% 
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That went quick‚Äìjust a little over a minute on my laptop. Here‚Äôs what those 100 &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; intervals look like in bulk.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim1 %&amp;gt;% 
  ggplot(aes(x = seed, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = 0, color = &amp;quot;white&amp;quot;) +
  geom_linerange() +
  labs(x = &amp;quot;seed (i.e., simulation index)&amp;quot;,
       y = expression(beta[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;None of them are anywhere near the null value 0. So it appears we‚Äôre well above .8 power to reject the typical &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt;. Switching to the precision orientation, here‚Äôs the distribution of their widths.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim1 %&amp;gt;% 
  mutate(width = Q97.5 - Q2.5) %&amp;gt;% 
  
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = 0.01) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What if we wanted a mean width of 0.25 on the log scale? We might try the simulation with &lt;span class=&#34;math inline&#34;&gt;\(n = 150\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim2 &amp;lt;-
  tibble(seed = 1:100) %&amp;gt;% 
  mutate(ci = map(seed, sim_data_fit, n = 150)) %&amp;gt;% 
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we‚Äôll summarize the widths both in terms of their mean and what proportion were smaller than 0.25.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim2 %&amp;gt;% 
  mutate(width = Q97.5 - Q2.5) %&amp;gt;% 
  summarise(`mean width` = mean(width),
            `below 0.25` = mean(width &amp;lt; 0.25))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   `mean width` `below 0.25`
##          &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1        0.252         0.43&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we wanted to focus on the mean, we did pretty good. Perhaps set the &lt;span class=&#34;math inline&#34;&gt;\(n = 155\)&lt;/span&gt; and simulate a full 1,000+ iterations for a serious power analysis. But if we wanted to make the stricter criteria of all below 0.25, we‚Äôd need to up the &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; quite a bit more. And of course, once you have a little experience working with Poisson models, you might do the power simulations with more ambitious priors. For example, if your count values are lower than like 1,000, there‚Äôs a good chance a &lt;code&gt;normal(0, 6)&lt;/code&gt; prior on your &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; parameters will be nearly flat within the reasonable neighborhoods of the parameter space.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;but-logs-are-hard.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;But logs are hard.&lt;/h2&gt;
&lt;p&gt;If we approach our Bayesian power analysis from a precision perspective, it can be difficult to settle on a reasonable interval width when they‚Äôre on the log scale. So let‚Äôs modify our simulation flow so it converts the width summaries back into the natural metric. Before we go big, let‚Äôs practice with a single iteration.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seed &amp;lt;- 0
set.seed(seed)

# simulate the data
d &amp;lt;-
  tibble(high  = rep(0:1, each = n),
         count = c(rpois(n = n, lambda = mu_7),
                   rpois(n = n, lambda = mu_8)))

# fit the model
fit2 &amp;lt;-
  update(fit1,
         newdata = d,
         seed = seed) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now summarize.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidybayes)

fit2 %&amp;gt;% 
  posterior_samples() %&amp;gt;% 
  transmute(`beta_1` = exp(b_high)) %&amp;gt;% 
  mean_qi()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     beta_1  .lower   .upper .width .point .interval
## 1 2.705404 2.16512 3.341729   0.95   mean        qi&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we used the &lt;code&gt;fixef()&lt;/code&gt; function to extract our intervals, which took the &lt;strong&gt;brms&lt;/strong&gt; fit object as input. Here we took a different approach. Because we are transforming &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;, we used the &lt;code&gt;posterior_samples()&lt;/code&gt; function to work directly with the posterior draws. We then exponentiated within &lt;code&gt;transmute()&lt;/code&gt;, which returned a single-column tibble, not a &lt;strong&gt;brms&lt;/strong&gt; fit object. So instead of &lt;code&gt;fixef()&lt;/code&gt;, it‚Äôs easier to get our summary statistics with the &lt;code&gt;tidybayes::mean_qi()&lt;/code&gt; function. Do note that now our lower and upper levels are named &lt;code&gt;.lower&lt;/code&gt; and &lt;code&gt;.upper&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;p&gt;Now we‚Äôve practiced with the new flow, let‚Äôs redefine our simulation function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_data_fit &amp;lt;- function(seed, n) {
  
  # define our mus in the function
  mu_7 &amp;lt;- 2.17
  mu_8 &amp;lt;- 6.25

  # make your results reproducible
  set.seed(seed)
  
  # simulate the data
  d &amp;lt;-
    tibble(high  = rep(0:1, each = n),
           count = c(rpois(n = n, lambda = mu_7),
                     rpois(n = n, lambda = mu_8)))
  
  # fit and summarize
  update(fit1,
         newdata = d,
         seed = seed) %&amp;gt;% 
  posterior_samples() %&amp;gt;% 
  transmute(`beta_1` = exp(b_high)) %&amp;gt;% 
  mean_qi()
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Simulate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim3 &amp;lt;-
  tibble(seed = 1:100) %&amp;gt;% 
  mutate(ci = map(seed, sim_data_fit, n = 50)) %&amp;gt;% 
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here‚Äôs what those 100 &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; intervals look like in bulk.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim3 %&amp;gt;% 
  ggplot(aes(x = seed, y = beta_1, ymin = .lower, ymax = .upper)) +
  geom_hline(yintercept = 0, color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1) +
  labs(x = &amp;quot;seed (i.e., simulation index)&amp;quot;,
       y = expression(beta[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Inspect the distribution of their widths.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim3 %&amp;gt;% 
  mutate(width = .upper - .lower) %&amp;gt;% 
  
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = 0.05) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What if we wanted a mean 95% interval width of 1? Let‚Äôs run the simulation again, this time with &lt;span class=&#34;math inline&#34;&gt;\(n = 100\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim4 &amp;lt;-
  tibble(seed = 1:100) %&amp;gt;% 
  mutate(ci = map(seed, sim_data_fit, n = 100)) %&amp;gt;% 
  unnest() %&amp;gt;% 
  mutate(width = .upper - .lower)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here‚Äôs the new width distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim4 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = 0.05) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And the mean width is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim4 %&amp;gt;% 
  summarise(mean_width = mean(width))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   mean_width
##        &amp;lt;dbl&amp;gt;
## 1      0.913&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nice! If we want a mean width of 1, it looks like we‚Äôre a little &lt;em&gt;overpowered&lt;/em&gt; with &lt;span class=&#34;math inline&#34;&gt;\(n = 100\)&lt;/span&gt;. The next step would be to up your iterations to 1,000 or so to do a proper simulation.&lt;/p&gt;
&lt;p&gt;Now you‚Äôve got a sense of how to work with the Poisson likelihood, &lt;a href=&#34;https://solomonkurz.netlify.app/post/bayesian-power-analysis-part-iii-b/&#34;&gt;next time&lt;/a&gt; we‚Äôll play with binary data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.3.1 brms_2.15.0     Rcpp_1.0.6      forcats_0.5.1  
##  [5] stringr_1.4.0   dplyr_1.0.6     purrr_0.3.4     readr_1.4.0    
##  [9] tidyr_1.1.3     tibble_3.1.2    ggplot2_3.3.3   tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6          
##   [4] igraph_1.2.6         svUnit_1.0.3         splines_4.0.4       
##   [7] crosstalk_1.1.0.1    TH.data_1.0-10       rstantools_2.1.1    
##  [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.1.1   
##  [13] rsconnect_0.8.16     fansi_0.4.2          magrittr_2.0.1      
##  [16] modelr_0.1.8         RcppParallel_5.0.2   matrixStats_0.57.0  
##  [19] xts_0.12.1           sandwich_3.0-0       prettyunits_1.1.1   
##  [22] colorspace_2.0-0     rvest_0.3.6          ggdist_2.4.0.9000   
##  [25] haven_2.3.1          xfun_0.23            callr_3.7.0         
##  [28] crayon_1.4.1         jsonlite_1.7.2       lme4_1.1-25         
##  [31] survival_3.2-10      zoo_1.8-8            glue_1.4.2          
##  [34] gtable_0.3.0         emmeans_1.5.2-1      V8_3.4.0            
##  [37] distributional_0.2.2 pkgbuild_1.2.0       rstan_2.21.2        
##  [40] abind_1.4-5          scales_1.1.1         mvtnorm_1.1-1       
##  [43] DBI_1.1.0            miniUI_0.1.1.1       xtable_1.8-4        
##  [46] stats4_4.0.4         StanHeaders_2.21.0-7 DT_0.16             
##  [49] htmlwidgets_1.5.3    httr_1.4.2           threejs_0.3.3       
##  [52] arrayhelpers_1.1-0   ellipsis_0.3.2       pkgconfig_2.0.3     
##  [55] loo_2.4.1            farver_2.1.0         sass_0.3.1          
##  [58] dbplyr_2.0.0         utf8_1.2.1           tidyselect_1.1.1    
##  [61] labeling_0.4.2       rlang_0.4.11         reshape2_1.4.4      
##  [64] later_1.2.0          munsell_0.5.0        cellranger_1.1.0    
##  [67] tools_4.0.4          cli_2.5.0            generics_0.1.0      
##  [70] broom_0.7.6          ggridges_0.5.3       evaluate_0.14       
##  [73] fastmap_1.1.0        yaml_2.2.1           processx_3.5.2      
##  [76] knitr_1.33           fs_1.5.0             nlme_3.1-152        
##  [79] mime_0.10            projpred_2.0.2       xml2_1.3.2          
##  [82] compiler_4.0.4       bayesplot_1.8.0      shinythemes_1.1.2   
##  [85] rstudioapi_0.13      gamm4_0.2-6          curl_4.3            
##  [88] reprex_0.3.0         statmod_1.4.35       bslib_0.2.4         
##  [91] stringi_1.6.2        highr_0.9            ps_1.6.0            
##  [94] blogdown_1.3         Brobdingnag_1.2-6    lattice_0.20-41     
##  [97] Matrix_1.3-2         nloptr_1.2.2.2       markdown_1.1        
## [100] shinyjs_2.0.0        vctrs_0.3.8          pillar_1.6.1        
## [103] lifecycle_1.0.0      jquerylib_0.1.4      bridgesampling_1.0-0
## [106] estimability_1.3     httpuv_1.6.0         R6_2.5.0            
## [109] bookdown_0.22        promises_1.2.0.1     gridExtra_2.3       
## [112] codetools_0.2-18     boot_1.3-26          colourpicker_1.1.0  
## [115] MASS_7.3-53          gtools_3.8.2         assertthat_0.2.1    
## [118] withr_2.4.2          shinystan_2.5.0      multcomp_1.4-16     
## [121] mgcv_1.8-33          parallel_4.0.4       hms_0.5.3           
## [124] grid_4.0.4           coda_0.19-4          minqa_1.2.4         
## [127] rmarkdown_2.8        shiny_1.6.0          lubridate_1.7.9.2   
## [130] base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-agrestiFoundationsLinearGeneralized2015&#34; class=&#34;csl-entry&#34;&gt;
Agresti, A. (2015). &lt;em&gt;Foundations of linear and generalized linear models&lt;/em&gt;. &lt;span&gt;John Wiley &amp;amp; Sons&lt;/span&gt;. &lt;a href=&#34;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&#34;&gt;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-atkinsTutorialOnCount2013&#34; class=&#34;csl-entry&#34;&gt;
Atkins, D. C., Baldwin, S. A., Zheng, C., Gallop, R. J., &amp;amp; Neighbors, C. (2013). A tutorial on count regression and zero-altered count models for longitudinal substance use data. &lt;em&gt;Psychology of Addictive Behaviors&lt;/em&gt;, &lt;em&gt;27&lt;/em&gt;(1), 166. &lt;a href=&#34;https://doi.org/10.1037/a0029508&#34;&gt;https://doi.org/10.1037/a0029508&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-ingrahamThinkYouDrink2014&#34; class=&#34;csl-entry&#34;&gt;
Ingraham, C. (2014). Think you drink a lot? &lt;span&gt;This&lt;/span&gt; chart will tell you. &lt;em&gt;Wonkblog. The Washington Post&lt;/em&gt;. &lt;a href=&#34;https://www.washingtonpost.com/news/wonk/wp/2014/09/25/think-you-drink-a-lot-this-chart-will-tell-you/?utm_term=.b81599bbbe25&#34;&gt;https://www.washingtonpost.com/news/wonk/wp/2014/09/25/think-you-drink-a-lot-this-chart-will-tell-you/?utm_term=.b81599bbbe25&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2015&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2015). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-niaaaNationalEpidemiologicSurvey2006&#34; class=&#34;csl-entry&#34;&gt;
{{National Institute on Alcohol Abuse and Alcoholism}}. (2006). &lt;em&gt;National epidemiologic survey on alcohol and related conditions&lt;/em&gt;. &lt;a href=&#34;https://pubs.niaaa.nih.gov/publications/AA70/AA70.htm&#34;&gt;https://pubs.niaaa.nih.gov/publications/AA70/AA70.htm&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Yes, one can smoke half a cigarette or drink 1/3 of a drink. Ideally, we‚Äôd have the exact amount of nicotine in your blood at a given moment and over time and the same for the amount of alcohol in your system relative to your blood volume and such. But in practice, substance use researchers just don‚Äôt tend to have access to data of that quality. Instead, we‚Äôre typically stuck with simple counts. And I look forward to the day the right team of engineers, computer scientists, and substance use researchers (and whoever else I forgot to mention) release the cheap, non-invasive technology we need to passively measure these things. Until then: &lt;em&gt;How many standard servings of alcohol did you drink, last night?&lt;/em&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;‚Ü©Ô∏é&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian power analysis: Part II. Some might prefer precision to power</title>
      <link>/post/bayesian-power-analysis-part-ii/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/post/bayesian-power-analysis-part-ii/</guid>
      <description>
&lt;script src=&#34;/post/bayesian-power-analysis-part-ii/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;version-1.1.0&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Version 1.1.0&lt;/h2&gt;
&lt;p&gt;Edited on April 21, 2021, to remove the &lt;code&gt;broom::tidy()&lt;/code&gt; portion of the workflow.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tldr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;When researchers decide on a sample size for an upcoming project, there are more things to consider than null-hypothesis-oriented power. Bayesian researchers might like to frame their concerns in terms of precision. Stick around to learn what and how.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;are-bayesians-doomed-to-refer-to-h_0-1-with-sample-size-planning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Are Bayesians doomed to refer to &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; with sample-size planning?&lt;/h2&gt;
&lt;p&gt;If you read the first post in this series (click &lt;a href=&#34;https://solomonkurz.netlify.app/post/bayesian-power-analysis-part-i/&#34;&gt;here&lt;/a&gt; for a refresher), you may have found yourself thinking: &lt;em&gt;Sure, last time you avoided computing &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values with your 95% Bayesian credible intervals. But weren‚Äôt you still operating like a NHSTesting frequentist with all that &lt;span class=&#34;math inline&#34;&gt;\(H_0 / H_1\)&lt;/span&gt; talk?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Solid criticism. We didn‚Äôt even bother discussing all the type-I versus type-II error details. Yet they too were lurking in the background the way we just chose the typical .8 power benchmark. That‚Äôs not to say that a &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value oriented approach isn‚Äôt legitimate. It‚Äôs certainly congruent with what most reviewers would expect.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; But this all seems at odds with a model-oriented Bayesian approach, which is what I generally prefer. Happily, we have other options to explore.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-just-pick-up-where-we-left-off.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let‚Äôs just pick up where we left off.&lt;/h2&gt;
&lt;p&gt;Load our primary statistical packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a recap, here‚Äôs how we performed the last simulation-based Bayesian power analysis from part I. First, we simulated a single data set and fit an initial model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define the means
mu_c &amp;lt;- 0
mu_t &amp;lt;- 0.5

# determine the group size
n &amp;lt;- 50

# simulate the data
set.seed(1)
d &amp;lt;-
  tibble(group     = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
  mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
         y         = ifelse(group == &amp;quot;control&amp;quot;, 
                            rnorm(n, mean = mu_c, sd = 1),
                            rnorm(n, mean = mu_t, sd = 1)))
# fit the model
fit &amp;lt;-
  brm(data = d,
      family = gaussian,
      y ~ 0 + intercept + treatment,
      prior = c(prior(normal(0, 2), class = b),
                prior(student_t(3, 1, 1), class = sigma)),
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we made a custom function that both simulated data sets and used the &lt;code&gt;update()&lt;/code&gt; function to update that initial fit in order to avoid additional compilation time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_d_and_fit &amp;lt;- function(seed, n) {
  
  mu_c &amp;lt;- 0
  mu_t &amp;lt;- 0.5
  
  set.seed(seed)
  
  d &amp;lt;-
    tibble(group = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
    mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
           y         = ifelse(group == &amp;quot;control&amp;quot;, 
                              rnorm(n, mean = mu_c, sd = 1),
                              rnorm(n, mean = mu_t, sd = 1)))
  
  update(fit,
         newdata = d, 
         seed = seed) %&amp;gt;% 
    fixef() %&amp;gt;% 
    data.frame() %&amp;gt;% 
    rownames_to_column(&amp;quot;parameter&amp;quot;) %&amp;gt;% 
    filter(parameter == &amp;quot;treatment&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we finally iterated over &lt;code&gt;n_sim &amp;lt;- 100&lt;/code&gt; times.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_sim &amp;lt;- 100

s3 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 50)) %&amp;gt;% 
  unnest(b1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results looked like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_set(theme_grey() +
            theme(panel.grid = element_blank()))

s3 %&amp;gt;% 
  ggplot(aes(x = seed, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1/2) +
  labs(x = &amp;quot;seed (i.e., simulation index)&amp;quot;,
       y = expression(beta[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It‚Äôs time to build on the foundation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;we-might-evaluate-power-by-widths.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;We might evaluate ‚Äúpower‚Äù by widths.&lt;/h2&gt;
&lt;p&gt;Instead of just ordering the point-ranges by their &lt;code&gt;seed&lt;/code&gt; values, we might instead arrange them by the &lt;code&gt;lower&lt;/code&gt; levels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 %&amp;gt;%
  ggplot(aes(x = reorder(seed, Q2.5), y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1/2) +
  scale_x_discrete(&amp;quot;reordered by the lower level of the 95% intervals&amp;quot;, breaks = NULL) +
  ylab(expression(beta[1])) +
  coord_cartesian(ylim = c(-.5, 1.3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice how this arrangement highlights the differences in widths among the intervals. The wider the interval, the less precise the estimate. Some intervals were wider than others, but all tended to hover in a similar range. We might quantify those ranges by computing a &lt;code&gt;width&lt;/code&gt; variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 &amp;lt;-
  s3 %&amp;gt;% 
  mutate(width = Q97.5 - Q2.5)

head(s3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##    seed parameter Estimate Est.Error    Q2.5 Q97.5 width
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1 treatment    0.514     0.185  0.159  0.898 0.739
## 2     2 treatment    0.307     0.239 -0.143  0.782 0.925
## 3     3 treatment    0.643     0.171  0.310  0.975 0.666
## 4     4 treatment    0.224     0.182 -0.128  0.574 0.702
## 5     5 treatment    0.429     0.189  0.0596 0.792 0.733
## 6     6 treatment    0.304     0.208 -0.114  0.711 0.825&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here‚Äôs the &lt;code&gt;width&lt;/code&gt; distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .01)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The widths of our 95% intervals range from 0.6 to 0.95, with the bulk sitting around 0.8. Let‚Äôs focus a bit and take a random sample from one of the simulation iterations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)

s3 %&amp;gt;% 
  sample_n(1) %&amp;gt;% 
  mutate(seed = seed %&amp;gt;% as.character()) %&amp;gt;% 

  ggplot(aes(x = Estimate, xmin = Q2.5, xmax = Q97.5, y = seed)) +
  geom_vline(xintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange() +
  labs(x = expression(beta[1]),
       y = &amp;quot;seed #&amp;quot;) +
  xlim(0, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Though the posterior mean suggests the most probable value for &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is about 0.6, the intervals suggest values from about 0.2 to almost 1 are within the 95% probability range. That‚Äôs a wide spread. Within psychology, a standardized mean difference of 0.2 would typically be considered small, whereas a difference of 1 would be large enough to raise a skeptical eyebrow or two.&lt;/p&gt;
&lt;p&gt;So instead of focusing on rejecting a null hypothesis like &lt;span class=&#34;math inline&#34;&gt;\(\mu_\text{control} = \mu_\text{treatment}\)&lt;/span&gt;, we might instead use our simulation skills to determine the sample size we need to have most of our 95% intervals come in at a certain level of precision. This has been termed the accuracy in parameter estimation [AIPE; &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-maxwellSampleSizePlanning2008&#34; role=&#34;doc-biblioref&#34;&gt;Maxwell et al.&lt;/a&gt; (&lt;a href=&#34;#ref-maxwellSampleSizePlanning2008&#34; role=&#34;doc-biblioref&#34;&gt;2008&lt;/a&gt;)&lt;/span&gt;; see also &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;Kruschke&lt;/a&gt; (&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;] approach to sample size planning.&lt;/p&gt;
&lt;p&gt;Thinking in terms of AIPE, in terms of precision, let‚Äôs say we wanted widths of 0.7 or smaller. Here‚Äôs how we did with &lt;code&gt;s3&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 %&amp;gt;% 
  mutate(check = ifelse(width &amp;lt; .7, 1, 0)) %&amp;gt;% 
  summarise(`width power` = mean(check))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   `width power`
##           &amp;lt;dbl&amp;gt;
## 1           0.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We did terrible. I‚Äôm not sure the term ‚Äúwidth power‚Äù is even a thing. But hopefully you get the point. Our baby 100-iteration simulation suggests we have about a .08 probability of achieving 95% CI widths of 0.7 or smaller with &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt; per group. Though we‚Äôre pretty good at excluding zero, we don‚Äôt tend to do so with precision above that.&lt;/p&gt;
&lt;p&gt;That last bit about excluding zero brings up an important point. Once we‚Äôre concerned about width size, about precision, the null hypothesis is no longer of direct relevance. And since we‚Äôre no longer wed to thinking in terms of the null hypothesis, there‚Äôs no real need to stick with a .8 threshold for evaluating width power (okay, I‚Äôll stop using that term). Now if we wanted to stick with .8, we could. Though a little nonsensical, the .8 criterion would give our AIPE analyses a sense of familiarity with traditional power analyses, which some reviewers might appreciate. But in his text, Kruschke mentioned several other alternatives. One would be to set maximum value for our CI widths and simulate to find the &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; necessary so all our simulations pass that criterion. Another would follow Joseph, Wolfson, and du Berger &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-josephSampleSizeCalculations1995&#34; role=&#34;doc-biblioref&#34;&gt;1995a&lt;/a&gt;, &lt;a href=&#34;#ref-josephCommentsBayesianSample1995&#34; role=&#34;doc-biblioref&#34;&gt;1995b&lt;/a&gt;)&lt;/span&gt;, who suggested we shoot for an &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; that produces widths that pass that criterion on average. Here‚Äôs how we did based on the average-width criterion.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 %&amp;gt;% 
  summarise(`average width` = mean(width))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   `average width`
##             &amp;lt;dbl&amp;gt;
## 1           0.783&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Close. Let‚Äôs see how increasing our sample size to 75 per group effects these metrics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s4 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 75)) %&amp;gt;% 
  unnest(b1) %&amp;gt;%
  mutate(width = Q97.5 - Q2.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here‚Äôs what our new batch of 95% intervals looks like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s4 %&amp;gt;% 
  ggplot(aes(x = reorder(seed, Q2.5), y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1/2) +
  scale_x_discrete(&amp;quot;reordered by the lower level of the 95% intervals&amp;quot;, breaks = NULL) +
  ylab(expression(beta[1])) +
  # this kept the scale on the y-axis the same as the simulation with n = 50
  coord_cartesian(ylim = c(-.5, 1.3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Some of the intervals are still more precise than others, but they all now hover more tightly around their true data-generating value of 0.5. Here‚Äôs our updated ‚Äúpower‚Äù for producing interval widths smaller than 0.7.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s4 %&amp;gt;% 
  mutate(check = ifelse(width &amp;lt; .7, 1, 0)) %&amp;gt;% 
  summarise(`proportion below 0.7` = mean(check),
            `average width`        = mean(width))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   `proportion below 0.7` `average width`
##                    &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt;
## 1                   0.94           0.639&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we hold to the NHST-oriented .8 threshold, we did great and are even ‚Äúoverpowered.‚Äù We didn‚Äôt quite meet Kruschke‚Äôs strict limiting-worst-precision threshold, but we got close enough we‚Äôd have a good sense of what range of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; values we might evaluate over next. As far as the mean-precision criterion, we did great by that one and even beat it.&lt;/p&gt;
&lt;p&gt;Here‚Äôs a look at how this batch of widths is distributed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s4 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .02) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let‚Äôs see if we can nail down the &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;s for our three AIPE criteria. Since we‚Äôre so close to fulfilling Kruschke‚Äôs limiting-worst-precision criterion, we‚Äôll start there. I‚Äôm thinking &lt;span class=&#34;math inline&#34;&gt;\(n = 85\)&lt;/span&gt; should just about do it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s5 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 85)) %&amp;gt;% 
  unnest(b1) %&amp;gt;%
  mutate(width = Q97.5 - Q2.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Did we pass?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s5 %&amp;gt;% 
  mutate(check = ifelse(width &amp;lt; .7, 1, 0)) %&amp;gt;% 
  summarise(`proportion below 0.7` = mean(check))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   `proportion below 0.7`
##                    &amp;lt;dbl&amp;gt;
## 1                      1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Success! We might look at how they‚Äôre distributed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s5 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .01) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A few of our simulated widths were approaching the 0.7 boundary. If we were to do a proper simulation with 1,000+ iterations, I‚Äôd worry one or two would creep over that boundary. So perhaps &lt;span class=&#34;math inline&#34;&gt;\(n = 90\)&lt;/span&gt; would be a better candidate for a large-scale simulation.&lt;/p&gt;
&lt;p&gt;If we just wanted to meet the mean-precision criterion, we might look at something like &lt;span class=&#34;math inline&#34;&gt;\(n = 65\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s6 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 65)) %&amp;gt;% 
  unnest(b1) %&amp;gt;%
  mutate(width = Q97.5 - Q2.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Did we pass the mean-precision criterion?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s6 %&amp;gt;% 
  summarise(`average width` = mean(width))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   `average width`
##             &amp;lt;dbl&amp;gt;
## 1           0.688&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We got it! It looks like something like &lt;span class=&#34;math inline&#34;&gt;\(n = 65\)&lt;/span&gt; would be a good candidate for a larger-scale simulation. Here‚Äôs the distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s6 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .02) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For our final possible criterion, just get .8 of the widths below the threshold, we‚Äôll want an &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; somewhere between 65 and 85. 70, perhaps?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s7 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 70)) %&amp;gt;% 
  unnest(b1) %&amp;gt;%
  mutate(width = Q97.5 - Q2.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Did we pass the .8-threshold criterion?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s7 %&amp;gt;% 
  mutate(check = ifelse(width &amp;lt; .7, 1, 0)) %&amp;gt;% 
  summarise(`proportion below 0.7` = mean(check))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   `proportion below 0.7`
##                    &amp;lt;dbl&amp;gt;
## 1                   0.82&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yep. Here‚Äôs the distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s7 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .02) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-are-we-defining-our-widths&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How are we defining our widths?&lt;/h2&gt;
&lt;p&gt;In frequentist analyses, we typically work with 95% confidence intervals because of their close connection to the conventional &lt;span class=&#34;math inline&#34;&gt;\(p &amp;lt; .05\)&lt;/span&gt; threshold. Another consequence of dropping our focus on rejecting &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; is that it no longer seems necessary to evaluate our posteriors with 95% intervals. And as it turns out, some Bayesians aren‚Äôt fans of the 95% interval. McElreath, for example, defiantly used 89% intervals in both editions of his &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;, &lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;http://xcelab.net/rm/statistical-rethinking/&#34;&gt;text&lt;/a&gt;. In contrast, Gelman has &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2016/11/05/why-i-prefer-50-to-95-intervals/&#34;&gt;blogged&lt;/a&gt; on his fondness for 50% intervals. Just for kicks, let‚Äôs follow Gelman‚Äôs lead and practice evaluating an &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; based on 50% intervals. This will require us to update our &lt;code&gt;sim_d_and_fit()&lt;/code&gt; function to allow us to change the &lt;code&gt;probs&lt;/code&gt; setting in the &lt;code&gt;fixef()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_d_and_fit &amp;lt;- function(seed, n, probs = c(.25, .75)) {
  
  mu_c &amp;lt;- 0
  mu_t &amp;lt;- 0.5
  
  set.seed(seed)
  
  d &amp;lt;-
    tibble(group = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
    mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
           y         = ifelse(group == &amp;quot;control&amp;quot;, 
                              rnorm(n, mean = mu_c, sd = 1),
                              rnorm(n, mean = mu_t, sd = 1)))
  
  update(fit,
         newdata = d, 
         seed = seed) %&amp;gt;% 
    fixef(probs = probs) %&amp;gt;% 
    data.frame() %&amp;gt;% 
    rownames_to_column(&amp;quot;parameter&amp;quot;) %&amp;gt;% 
    filter(parameter == &amp;quot;treatment&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To make things simple, we just set the default &lt;code&gt;probs&lt;/code&gt; settings to return 50% intervals. Now we simulate to examine those 50% intervals. We‚Äôll start with the original &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_sim &amp;lt;- 100

s8 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 50)) %&amp;gt;% 
  unnest(b1) %&amp;gt;% 
  # notice the change to this line of code
  mutate(width = Q75 - Q25)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is the distribution of our 50% interval widths.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s8 %&amp;gt;% 
  mutate(width = Q75 - Q25) %&amp;gt;% 
  
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .01) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Since we‚Äôve gone from 95% to 50% intervals, it should be no surprise that their widths are narrower. Accordingly, we should evaluate then with a higher standard. Perhaps it‚Äôs more reasonable to ask for an average width of 0.1. Let‚Äôs see how close &lt;span class=&#34;math inline&#34;&gt;\(n = 150\)&lt;/span&gt; gets us.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s9 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 150)) %&amp;gt;% 
  unnest(b1) %&amp;gt;% 
  mutate(width = Q75 - Q25)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Look at the distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s9 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .0025) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Nope, we‚Äôre not there yet. Perhaps &lt;span class=&#34;math inline&#34;&gt;\(n = 200\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(250\)&lt;/span&gt; is the ticket. This is an iterative process. Anyway, once we‚Äôre talking that AIPE/precision/interval-width talk, we can get all kinds of creative with which intervals we‚Äôre even interested in. As far as I can tell, the topic is wide open for fights and collaborations between statisticians, methodologists, and substantive researchers to find sensible ways forward.&lt;/p&gt;
&lt;p&gt;Maybe you should write a dissertation on it.&lt;/p&gt;
&lt;p&gt;Regardless, get ready for &lt;a href=&#34;https://solomonkurz.netlify.app/post/bayesian-power-analysis-part-iii-a/&#34;&gt;part III&lt;/a&gt; where we‚Äôll liberate ourselves from the tyranny of the Gauss.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] brms_2.15.0     Rcpp_1.0.6      forcats_0.5.1   stringr_1.4.0  
##  [5] dplyr_1.0.5     purrr_0.3.4     readr_1.4.0     tidyr_1.1.3    
##  [9] tibble_3.1.0    ggplot2_3.3.3   tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6          
##   [4] igraph_1.2.6         splines_4.0.4        crosstalk_1.1.0.1   
##   [7] TH.data_1.0-10       rstantools_2.1.1     inline_0.3.17       
##  [10] digest_0.6.27        htmltools_0.5.1.1    rsconnect_0.8.16    
##  [13] fansi_0.4.2          magrittr_2.0.1       modelr_0.1.8        
##  [16] RcppParallel_5.0.2   matrixStats_0.57.0   xts_0.12.1          
##  [19] sandwich_3.0-0       prettyunits_1.1.1    colorspace_2.0-0    
##  [22] rvest_0.3.6          haven_2.3.1          xfun_0.22           
##  [25] callr_3.5.1          crayon_1.4.1         jsonlite_1.7.2      
##  [28] lme4_1.1-25          survival_3.2-10      zoo_1.8-8           
##  [31] glue_1.4.2           gtable_0.3.0         emmeans_1.5.2-1     
##  [34] V8_3.4.0             pkgbuild_1.2.0       rstan_2.21.2        
##  [37] abind_1.4-5          scales_1.1.1         mvtnorm_1.1-1       
##  [40] DBI_1.1.0            miniUI_0.1.1.1       xtable_1.8-4        
##  [43] stats4_4.0.4         StanHeaders_2.21.0-7 DT_0.16             
##  [46] htmlwidgets_1.5.2    httr_1.4.2           threejs_0.3.3       
##  [49] ellipsis_0.3.1       pkgconfig_2.0.3      loo_2.4.1           
##  [52] farver_2.0.3         dbplyr_2.0.0         utf8_1.1.4          
##  [55] tidyselect_1.1.0     labeling_0.4.2       rlang_0.4.10        
##  [58] reshape2_1.4.4       later_1.1.0.1        munsell_0.5.0       
##  [61] cellranger_1.1.0     tools_4.0.4          cli_2.3.1           
##  [64] generics_0.1.0       broom_0.7.5          ggridges_0.5.2      
##  [67] evaluate_0.14        fastmap_1.0.1        yaml_2.2.1          
##  [70] processx_3.4.5       knitr_1.31           fs_1.5.0            
##  [73] nlme_3.1-152         mime_0.10            projpred_2.0.2      
##  [76] xml2_1.3.2           compiler_4.0.4       bayesplot_1.8.0     
##  [79] shinythemes_1.1.2    rstudioapi_0.13      gamm4_0.2-6         
##  [82] curl_4.3             reprex_0.3.0         statmod_1.4.35      
##  [85] stringi_1.5.3        highr_0.8            ps_1.6.0            
##  [88] blogdown_1.3         Brobdingnag_1.2-6    lattice_0.20-41     
##  [91] Matrix_1.3-2         nloptr_1.2.2.2       markdown_1.1        
##  [94] shinyjs_2.0.0        vctrs_0.3.6          pillar_1.5.1        
##  [97] lifecycle_1.0.0      bridgesampling_1.0-0 estimability_1.3    
## [100] httpuv_1.5.4         R6_2.5.0             bookdown_0.21       
## [103] promises_1.1.1       gridExtra_2.3        codetools_0.2-18    
## [106] boot_1.3-26          colourpicker_1.1.0   MASS_7.3-53         
## [109] gtools_3.8.2         assertthat_0.2.1     withr_2.4.1         
## [112] shinystan_2.5.0      multcomp_1.4-16      mgcv_1.8-33         
## [115] parallel_4.0.4       hms_0.5.3            grid_4.0.4          
## [118] coda_0.19-4          minqa_1.2.4          rmarkdown_2.7       
## [121] shiny_1.5.0          lubridate_1.7.9.2    base64enc_0.1-3     
## [124] dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-josephSampleSizeCalculations1995&#34; class=&#34;csl-entry&#34;&gt;
Joseph, L., Wolfson, D. B., &amp;amp; Berger, R. D. (1995a). Sample size calculations for binomial proportions via highest posterior density intervals. &lt;em&gt;Journal of the Royal Statistical Society: Series D (The Statistician)&lt;/em&gt;, &lt;em&gt;44&lt;/em&gt;(2), 143‚Äì154. &lt;a href=&#34;https://doi.org/10.2307/2348439&#34;&gt;https://doi.org/10.2307/2348439&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-josephCommentsBayesianSample1995&#34; class=&#34;csl-entry&#34;&gt;
Joseph, L., Wolfson, D. B., &amp;amp; Berger, R. D. (1995b). Some comments on &lt;span&gt;Bayesian&lt;/span&gt; sample size determination. &lt;em&gt;Journal of the Royal Statistical Society: Series D (The Statistician)&lt;/em&gt;, &lt;em&gt;44&lt;/em&gt;(2), 167‚Äì171. &lt;a href=&#34;https://doi.org/10.2307/2348442&#34;&gt;https://doi.org/10.2307/2348442&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kruschkeDoingBayesianData2015&#34; class=&#34;csl-entry&#34;&gt;
Kruschke, J. K. (2015). &lt;em&gt;Doing &lt;span&gt;Bayesian&lt;/span&gt; data analysis: &lt;span&gt;A&lt;/span&gt; tutorial with &lt;span&gt;R&lt;/span&gt;, &lt;span&gt;JAGS&lt;/span&gt;, and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;Academic Press&lt;/span&gt;. &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;https://sites.google.com/site/doingbayesiandataanalysis/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-maxwellSampleSizePlanning2008&#34; class=&#34;csl-entry&#34;&gt;
Maxwell, S. E., Kelley, K., &amp;amp; Rausch, J. R. (2008). Sample size planning for statistical power and accuracy in parameter estimation. &lt;em&gt;Annual Review of Psychology&lt;/em&gt;, &lt;em&gt;59&lt;/em&gt;(1), 537‚Äì563. &lt;a href=&#34;https://doi.org/10.1146/annurev.psych.59.103006.093735&#34;&gt;https://doi.org/10.1146/annurev.psych.59.103006.093735&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2020&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2020). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt; (Second Edition). &lt;span&gt;CRC Press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2015&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2015). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-moreyBayesFactorApproaches2011&#34; class=&#34;csl-entry&#34;&gt;
Morey, R. D., &amp;amp; Rouder, J. N. (2011). Bayes factor approaches for testing interval null hypotheses. &lt;em&gt;Psychological Methods&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;(4), 406‚Äì419. &lt;a href=&#34;https://doi.org/10.1037/a0024377&#34;&gt;https://doi.org/10.1037/a0024377&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rouderBayesianTestsAccepting2009&#34; class=&#34;csl-entry&#34;&gt;
Rouder, J. N., Speckman, P. L., Sun, D., Morey, R. D., &amp;amp; Iverson, G. (2009). Bayesian t tests for accepting and rejecting the null hypothesis. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;(2), 225‚Äì237. &lt;a href=&#34;https://doi.org/10.3758/PBR.16.2.225&#34;&gt;https://doi.org/10.3758/PBR.16.2.225&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wassersteinMovingWorld052019&#34; class=&#34;csl-entry&#34;&gt;
Wasserstein, R. L., Schirm, A. L., &amp;amp; Lazar, N. A. (2019). Moving to a &lt;span&gt;World Beyond&lt;/span&gt; &lt;span&gt;‚Äúp &lt;span&gt;&lt;span class=&#34;math inline&#34;&gt;\(&amp;lt;\)&lt;/span&gt;&lt;/span&gt; 0.05.‚Äù&lt;/span&gt; &lt;em&gt;The American Statistician&lt;/em&gt;, &lt;em&gt;73&lt;/em&gt;(sup1), 1‚Äì19. &lt;a href=&#34;https://doi.org/10.1080/00031305.2019.1583913&#34;&gt;https://doi.org/10.1080/00031305.2019.1583913&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;To be clear, one can consider the null hypothesis within the Bayesian paradigm. I don‚Äôt tend to take this approach, but it‚Äôd be unfair not to at least mention some resources. Kurschke covered the topic in chapters 11 and 12 in his &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; text, &lt;a href=&#34;http://www.indiana.edu/~kruschke/DoingBayesianDataAnalysis/&#34;&gt;&lt;em&gt;Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan&lt;/em&gt;&lt;/a&gt;. You might also check out &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-rouderBayesianTestsAccepting2009&#34; role=&#34;doc-biblioref&#34;&gt;Rouder et al.&lt;/a&gt; (&lt;a href=&#34;#ref-rouderBayesianTestsAccepting2009&#34; role=&#34;doc-biblioref&#34;&gt;2009&lt;/a&gt;)&lt;/span&gt;, &lt;a href=&#34;https://link.springer.com/content/pdf/10.3758/PBR.16.2.225.pdf&#34;&gt;&lt;em&gt;Bayesian t tests for accepting and rejecting the null hypothesis&lt;/em&gt;&lt;/a&gt;, or &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-moreyBayesFactorApproaches2011&#34; role=&#34;doc-biblioref&#34;&gt;Morey &amp;amp; Rouder&lt;/a&gt; (&lt;a href=&#34;#ref-moreyBayesFactorApproaches2011&#34; role=&#34;doc-biblioref&#34;&gt;2011&lt;/a&gt;)&lt;/span&gt;, &lt;a href=&#34;https://d1wqtxts1xzle7.cloudfront.net/45416179/Bayes_Factor_Approaches_for_Testing_Inte20160506-23207-1t89l96.pdf?1462571611=&amp;amp;response-content-disposition=inline%3B+filename%3DBayes_factor_approaches_for_testing_inte.pdf&amp;amp;Expires=1597530412&amp;amp;Signature=QAJQOISIvwxUlHd2uTfzgOMzf2TRcuWTcfwgki7JL4AIoYDziVCAfmDFOgUDi-h1mMEViTKFhOLTJF0-9u2IEyF2lR7-yhM67CYdKhqs8EEJOnhT9iK9MaaM2FBwZM8QoVtOXkOUaOXRHIt7C76UV5dbErTUx0r5Y1yym4a~-hDClb0696a6EB~dj0arYeDdylP7a3tfczmSxbIvrH8pOE4kQeHwsZXoANSh-eKXKYIYf6VD1yed~CSVPRkqlhMq6udOjg4INPZ33QBv3QQqYCk2esRC2DxxNmDF~rRVrIp0ebr6VMZkuMflVaj2~I2BFz7WS32Lb2hGFHT3jHskDA__&amp;amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA&#34;&gt;&lt;em&gt;Bayes factor approaches for testing interval null hypotheses&lt;/em&gt;&lt;/a&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;‚Ü©Ô∏é&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;For a contemporary discussion of the uses and misuses of &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values, see &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-wassersteinMovingWorld052019&#34; role=&#34;doc-biblioref&#34;&gt;Wasserstein et al.&lt;/a&gt; (&lt;a href=&#34;#ref-wassersteinMovingWorld052019&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; and the other articles contained in that &lt;a href=&#34;https://www.tandfonline.com/toc/utas20/73/sup1?nav=tocList&#34;&gt;special issue of &lt;em&gt;The American Statistician&lt;/em&gt;&lt;/a&gt;.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;‚Ü©Ô∏é&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian power analysis: Part I. Prepare to reject $H_0$ with simulation.</title>
      <link>/post/bayesian-power-analysis-part-i/</link>
      <pubDate>Thu, 18 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/post/bayesian-power-analysis-part-i/</guid>
      <description>
&lt;script src=&#34;/post/bayesian-power-analysis-part-i/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;version-1.1.0&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Version 1.1.0&lt;/h2&gt;
&lt;p&gt;Edited on April 21, 2021, to remove the &lt;code&gt;broom::tidy()&lt;/code&gt; portion of the workflow.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tldr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;If you‚Äôd like to learn how to do Bayesian power calculations using &lt;strong&gt;brms&lt;/strong&gt;, stick around for this multi-part blog series. Here with part I, we‚Äôll set the foundation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;power-is-hard-especially-for-bayesians.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Power is hard, especially for Bayesians.&lt;/h2&gt;
&lt;p&gt;Many journals, funding agencies, and dissertation committees require power calculations for your primary analyses. Frequentists have a variety of tools available to perform these calculations (e.g., &lt;a href=&#34;https://rpsychologist.com/analytical-and-simulation-based-power-analyses-for-mixed-design-anovas&#34;&gt;here&lt;/a&gt;). Bayesians, however, have a more difficult time of it. Most of our research questions and data issues are sufficiently complicated that we cannot solve the problems by hand. We need Markov chain Monte Carlo methods to iteratively sample from the posterior to summarize the parameters from our models. Same deal for power. If you‚Äôd like to compute the power for a given combination of &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;, likelihood &lt;span class=&#34;math inline&#34;&gt;\(p(\text{data} | \theta)\)&lt;/span&gt;, and set of priors &lt;span class=&#34;math inline&#34;&gt;\(p (\theta)\)&lt;/span&gt;, you‚Äôll need to simulate.&lt;/p&gt;
&lt;p&gt;It‚Äôs been one of my recent career goals to learn how to do this. You know how they say: &lt;em&gt;The best way to learn is to teach&lt;/em&gt;. This series of blog posts is the evidence of me learning by teaching. It will be an exploration of what a Bayesian power simulation workflow might look like. The overall statistical framework will be within &lt;strong&gt;R&lt;/strong&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-base&#34; role=&#34;doc-biblioref&#34;&gt;R Core Team, 2020&lt;/a&gt;)&lt;/span&gt;, with an emphasis on code style based on the &lt;a href=&#34;https://www.tidyverse.org&#34;&gt;&lt;strong&gt;tidyverse&lt;/strong&gt;&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-tidyverse&#34; role=&#34;doc-biblioref&#34;&gt;Wickham, 2019&lt;/a&gt;; &lt;a href=&#34;#ref-wickhamWelcomeTidyverse2019&#34; role=&#34;doc-biblioref&#34;&gt;Wickham et al., 2019&lt;/a&gt;)&lt;/span&gt;. We‚Äôll be fitting our Bayesian models with B√ºrkner‚Äôs &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;&lt;strong&gt;brms&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-burknerBrmsPackageBayesian2017&#34; role=&#34;doc-biblioref&#34;&gt;B√ºrkner, 2017&lt;/a&gt;, &lt;a href=&#34;#ref-burknerAdvancedBayesianMultilevel2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;, &lt;a href=&#34;#ref-R-brms&#34; role=&#34;doc-biblioref&#34;&gt;2020a&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;What this series is not, however, is an introduction to statistical power itself. Keep reading if you‚Äôre ready to roll up your sleeves, put on your applied hat, and learn how to get things done. If you‚Äôre more interested in introductions to power, see the references in the next section.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;i-make-assumptions.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I make assumptions.&lt;/h2&gt;
&lt;p&gt;For this series, I‚Äôm presuming you are familiar with linear regression, familiar with the basic differences between frequentist and Bayesian approaches to statistics, and have a basic sense of what we mean by statistical power. Here are some resources if you‚Äôd like to shore up.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you‚Äôre unfamiliar with statistical power, Kruschke covered it in chapter 13 of his &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;http://www.indiana.edu/~kruschke/DoingBayesianDataAnalysis/&#34;&gt;text&lt;/a&gt;. You might also check out the &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-maxwellSampleSizePlanning2008&#34; role=&#34;doc-biblioref&#34;&gt;2008&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://www3.nd.edu/~kkelley/publications/articles/Maxwell_Kelley_Rausch_2008.pdf&#34;&gt;review paper&lt;/a&gt; by Maxwell, Kelley, and Rausch. There‚Äôs always, of course, the original work by Cohen &lt;span class=&#34;citation&#34;&gt;(e.g., &lt;a href=&#34;#ref-cohenStatisticalPowerAnalysis1988a&#34; role=&#34;doc-biblioref&#34;&gt;Cohen, 1988&lt;/a&gt;)&lt;/span&gt;. You might also like this &lt;a href=&#34;https://www.khanacademy.org/math/ap-statistics/tests-significance-ap/error-probabilities-power/v/introduction-to-power-in-significance-tests&#34;&gt;Khan Academy video&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;To learn about Bayesian regression, I recommend the introductory text books by either McElreath &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;, &lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; or &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;Kruschke&lt;/a&gt; (&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;. Both authors host blogs (&lt;a href=&#34;http://doingbayesiandataanalysis.blogspot.com&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://elevanth.org/blog/&#34;&gt;here&lt;/a&gt;, respectively). If you go with McElreath, do check out his &lt;a href=&#34;https://www.youtube.com/channel/UCNJK6_DZvcMqNSzQdEkzvzA/playlists&#34;&gt;online lectures&lt;/a&gt; and my &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kurzStatisticalRethinkingBrms2020&#34; role=&#34;doc-biblioref&#34;&gt;2020a&lt;/a&gt;, &lt;a href=&#34;#ref-kurzStatisticalRethinkingSecondEd2020&#34; role=&#34;doc-biblioref&#34;&gt;2020c&lt;/a&gt;)&lt;/span&gt; ebooks translating his text to &lt;strong&gt;brms&lt;/strong&gt; and &lt;strong&gt;tidyverse&lt;/strong&gt; code. I have an ebook for Kruschke‚Äôs text &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kurzDoingBayesianData2020&#34; role=&#34;doc-biblioref&#34;&gt;Kurz, 2020b&lt;/a&gt;)&lt;/span&gt;, too.&lt;/li&gt;
&lt;li&gt;For even more &lt;strong&gt;brms&lt;/strong&gt;-related resources, you can find vignettes and documentation at &lt;a href=&#34;https://cran.r-project.org/package=brms/index.html&#34;&gt;https://cran.r-project.org/package=brms/index.html&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For &lt;strong&gt;tidyverse&lt;/strong&gt; introductions, your best bets are Grolemund and Wickham‚Äôs &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-grolemundDataScience2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://r4ds.had.co.nz&#34;&gt;&lt;em&gt;R for data science&lt;/em&gt;&lt;/a&gt; and Wickham‚Äôs &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-wickhamTidyverseStyleGuide2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://style.tidyverse.org&#34;&gt;&lt;em&gt;The tidyverse style guide&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;We‚Äôll be simulating data. If that‚Äôs new to you, both Kruschke and McElreath cover that a little in their texts. You can find nice online tutorials &lt;a href=&#34;https://debruine.github.io/tutorials/sim-data.html&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://aosmith.rbind.io/2018/08/29/getting-started-simulating-data/&#34;&gt;here&lt;/a&gt;, too.&lt;/li&gt;
&lt;li&gt;We‚Äôll also be making a couple custom functions. If that‚Äôs new, you might check out &lt;a href=&#34;https://r4ds.had.co.nz/functions.html&#34;&gt;&lt;em&gt;R4DS&lt;/em&gt;, chapter 19&lt;/a&gt; or &lt;a href=&#34;https://bookdown.org/rdpeng/rprogdatascience/functions.html&#34;&gt;chapter 14&lt;/a&gt; of Roger Peng‚Äôs &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-pengProgrammingDataScience2019&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; &lt;em&gt;R Programming for Data Science&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;we-need-to-warm-up-before-jumping-into-power.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;We need to warm up before jumping into power.&lt;/h2&gt;
&lt;p&gt;Let‚Äôs load our primary packages. The &lt;strong&gt;tidyverse&lt;/strong&gt; helps organize data and we model with &lt;strong&gt;brms&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Consider a case where you have some dependent variable &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; that you‚Äôd like to compare between two groups, which we‚Äôll call treatment and control. Here we presume &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is continuous and, for the sake of simplicity, is in a standardized metric for the control condition. Letting &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; stand for control and &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; index the data row for a given case, we might write that as &lt;span class=&#34;math inline&#34;&gt;\(y_{i, c} \sim \operatorname{Normal} (0, 1)\)&lt;/span&gt;. The mean for our treatment condition is 0.5, with the standard deviation still in the standardized metric. In the social sciences a standardized mean difference of 0.5 would typically be considered a medium effect size. Here‚Äôs what that‚Äôd look like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set our theme because, though I love the default ggplot theme, I hate gridlines
theme_set(theme_grey() +
            theme(panel.grid = element_blank()))

# define the means
mu_c &amp;lt;- 0
mu_t &amp;lt;- 0.5

# set up the data
tibble(x = seq(from = -4, to = 5, by = .01)) %&amp;gt;%
  mutate(c = dnorm(x, mean = mu_c, sd = 1),
         t = dnorm(x, mean = mu_t, sd = 1)) %&amp;gt;% 
  
  # plot
  ggplot(aes(x = x)) +
  geom_area(aes(y = c),
            size = 0, alpha = 1/3, fill = &amp;quot;grey25&amp;quot;) +
  geom_area(aes(y = t),
            size = 0, alpha = 1/3, fill = &amp;quot;blue2&amp;quot;) +
 annotate(geom = &amp;quot;text&amp;quot;,
           x = c(-.5, 1), y = .385,
           label = c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;),
           hjust = 1:0,
           size = 5) +
  scale_x_continuous(NULL, breaks = -4:5) +
  scale_y_continuous(NULL, breaks = NULL) +
  scale_color_manual(values = c(&amp;quot;grey25&amp;quot;, &amp;quot;blue2&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Sure, those distributions have a lot of overlap. But their means are clearly different and we‚Äôd like to make sure we plan on collecting enough data to do a good job showing that. A power analysis will help.&lt;/p&gt;
&lt;p&gt;Within the conventional frequentist paradigm, power is the probability of rejecting the null hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; in favor of the alternative hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;, given the alternative hypothesis is ‚Äútrue.‚Äù In this case, the typical null hypothesis is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0\text{: } \mu_c = \mu_t,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or put differently,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
H_0\text{: } \mu_t - \mu_c = 0.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And the alternative hypothesis is often just&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_1\text{: } \mu_c \neq \mu_t,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or otherwise put,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
H_1\text{: } \mu_t - \mu_c \neq 0.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Within the regression framework, we‚Äôll be comparing &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;s using the formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_i &amp;amp; \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i &amp;amp; = \beta_0 + \beta_1 \text{treatment}_i,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\text{treatment}\)&lt;/span&gt; is a dummy variable coded 0 = control 1 = treatment and varies across cases indexed by &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;. In this setup, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the estimate for &lt;span class=&#34;math inline&#34;&gt;\(\mu_c\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is the estimate of the difference between condition means, &lt;span class=&#34;math inline&#34;&gt;\(\mu_t - \mu_c\)&lt;/span&gt;. Thus our focal parameter, the one we care about the most in our power analysis, will be &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Within the frequentist paradigm, we typically compare these hypotheses using a &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value for &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; with the critical value, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, set to .05. Thus, power is the probability we‚Äôll have &lt;span class=&#34;math inline&#34;&gt;\(p &amp;lt; .05\)&lt;/span&gt; when it is indeed the case that &lt;span class=&#34;math inline&#34;&gt;\(\mu_c \neq \mu_t\)&lt;/span&gt;. We won‚Äôt be computing &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values in this project, but we will use 95% intervals. Recall that the result of a Bayesian analysis, the posterior distribution, is the probability of the parameters, given the data &lt;span class=&#34;math inline&#34;&gt;\(p (\theta | \text{data})\)&lt;/span&gt;. With our 95% Bayesian credible intervals, we‚Äôll be able to describe the parameter space over which our estimate of &lt;span class=&#34;math inline&#34;&gt;\(\mu_t - \mu_c\)&lt;/span&gt; is 95% probable. That is, for our power analysis, we‚Äôre interested in the probability our 95% credible intervals for &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; contain zero within their bounds when we know a priori &lt;span class=&#34;math inline&#34;&gt;\(\mu_c \neq \mu_t\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The reason we know &lt;span class=&#34;math inline&#34;&gt;\(\mu_c \neq \mu_t\)&lt;/span&gt; is because we‚Äôll be simulating the data that way. What our power analysis will help us determine is how many cases we‚Äôll need to achieve a predetermined level of power. The conventional threshold is .8.&lt;/p&gt;
&lt;div id=&#34;dry-run-number-1.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Dry run number 1.&lt;/h3&gt;
&lt;p&gt;To make this all concrete, let‚Äôs start with a simple example. We‚Äôll simulate a single set of data, fit a Bayesian regression model, and examine the results for the critical parameter &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;. For the sake of simplicity, let‚Äôs keep our two groups, treatment and control, the same size. We‚Äôll start with &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt; for each.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 50&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We already decided above that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{i, c} &amp;amp; \sim \operatorname{Normal}(0, 1) \text{ and} \\
y_{i, t} &amp;amp; \sim \operatorname{Normal}(0.5, 1).
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here‚Äôs how we might simulate data along those lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)

d &amp;lt;-
  tibble(group = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
  mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
         y         = ifelse(group == &amp;quot;control&amp;quot;, 
                            rnorm(n, mean = mu_c, sd = 1),
                            rnorm(n, mean = mu_t, sd = 1)))

glimpse(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 100
## Columns: 3
## $ group     &amp;lt;chr&amp;gt; &amp;quot;control&amp;quot;, &amp;quot;control&amp;quot;, &amp;quot;control&amp;quot;, &amp;quot;control&amp;quot;, &amp;quot;control&amp;quot;, &amp;quot;cont‚Ä¶
## $ treatment &amp;lt;dbl&amp;gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ‚Ä¶
## $ y         &amp;lt;dbl&amp;gt; -0.62645381, 0.18364332, -0.83562861, 1.59528080, 0.32950777‚Ä¶&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In case it wasn‚Äôt clear, the two variables &lt;code&gt;group&lt;/code&gt; and &lt;code&gt;treatment&lt;/code&gt; are redundant. Whereas the former is composed of names, the latter is the dummy-variable equivalent (i.e., control = 0, treatment = 1). The main event was how we used the &lt;code&gt;rnorm()&lt;/code&gt; function to simulate the normally-distributed values for &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Before we fit our model, we need to decide on priors. To give us ideas, here are the &lt;strong&gt;brms&lt;/strong&gt; defaults for our model and data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_prior(data = d,
          family = gaussian,
          y ~ 0 + Intercept + treatment)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                 prior class      coef group resp dpar nlpar bound       source
##                (flat)     b                                            default
##                (flat)     b Intercept                             (vectorized)
##                (flat)     b treatment                             (vectorized)
##  student_t(3, 0, 2.5) sigma                                            default&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A few things: Notice that here we‚Äôre using the &lt;code&gt;0 + Intercept&lt;/code&gt; syntax. This is because &lt;strong&gt;brms&lt;/strong&gt; handles the priors for the default intercept under the presumption you‚Äôve mean-centered all your predictor variables. However, since our &lt;code&gt;treatment&lt;/code&gt; variable is a dummy, that assumption won‚Äôt fly. The &lt;code&gt;0 + Intercept&lt;/code&gt; allows us to treat the model intercept as just another &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; parameter, which makes no assumptions about centering. Along those lines, you‚Äôll notice &lt;strong&gt;brms&lt;/strong&gt; currently defaults to flat priors for the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; parameters (i.e., those for which &lt;code&gt;class = b&lt;/code&gt;). And finally, the default prior on &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is moderately wide &lt;code&gt;student_t(3, 0, 2.5)&lt;/code&gt;. By default, &lt;strong&gt;brms&lt;/strong&gt; also sets the left bounds for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; parameters at zero, making that a folded-&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; distribution. If you‚Äôre confused by these details, spend some time with the &lt;a href=&#34;https://cran.r-project.org/package=brms/brms.pdf&#34;&gt;&lt;strong&gt;brms&lt;/strong&gt; reference manual&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-brms2020RM&#34; role=&#34;doc-biblioref&#34;&gt;B√ºrkner, 2020b&lt;/a&gt;)&lt;/span&gt;, particularly the &lt;code&gt;brm&lt;/code&gt; and &lt;code&gt;brmsformula&lt;/code&gt; sections.&lt;/p&gt;
&lt;p&gt;In this project, we‚Äôll be primarily using two kinds of priors: default flat priors and weakly-regularizing priors. Hopefully flat priors are self-explanatory. They let the likelihood (data) dominate the posterior and tend to produce results similar to those from frequentist estimators.&lt;/p&gt;
&lt;p&gt;As for weakly-regularizing priors, McElreath covered them in his text. They‚Äôre mentioned a bit in the &lt;strong&gt;Stan&lt;/strong&gt; team‚Äôs &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;&lt;em&gt;Prior Choice Recommendations&lt;/em&gt;&lt;/a&gt; wiki, and you can learn even more from Gelman, Simpson, and Betancourt‚Äôs &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-gelmanPriorCanOften2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/published/entropy-19-00555-v2.pdf&#34;&gt;&lt;em&gt;The prior can only be understood in the context of the likelihood&lt;/em&gt;&lt;/a&gt;. These priors aren‚Äôt strongly informative and aren‚Äôt really representative of our research hypotheses. But they‚Äôre not as absurd as flat priors, either. Rather, with just a little bit of knowledge about the data, these priors are set to keep the MCMC chains on target. Since our &lt;code&gt;y&lt;/code&gt; variable has a mean near zero and a standard deviation near one and since our sole predictor, &lt;code&gt;treatment&lt;/code&gt; is a dummy, setting &lt;span class=&#34;math inline&#34;&gt;\(\operatorname{Normal}(0, 2)\)&lt;/span&gt; as the prior for both &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; parameters might be a good place to start. The prior is permissive enough that it will let likelihood dominate the posterior, but it also rules out ridiculous parts of the parameter space (e.g., a standardized mean difference of 20, an intercept of -93). And since we know the data are on the unit scale, we might just center our folded-Student-&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; prior on one and add a gentle scale setting of one.&lt;/p&gt;
&lt;p&gt;Feel free to disagree and use your own priors. The great thing about priors is that they can be proposed, defended, criticized and improved. The point is to settle on the priors you can defend with written reasons. Select ones you‚Äôd feel comfortable defending to a skeptical reviewer.&lt;/p&gt;
&lt;p&gt;Here‚Äôs how we might fit the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit &amp;lt;-
  brm(data = d,
      family = gaussian,
      y ~ 0 + Intercept + treatment,
      prior = c(prior(normal(0, 2), class = b),
                prior(student_t(3, 1, 1), class = sigma)),
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we look at the summary, we might check the chains in a trace plot. We‚Äôre looking for ‚Äústuck‚Äù chains that don‚Äôt appear to come from a normal distribution (the chains are a profile-like view rather than histogram, allowing for inspection of dependence between samples).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Yep, the chains all look good. Here‚Äôs the parameter summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y ~ 0 + Intercept + treatment 
##    Data: d (Number of observations: 100) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.10      0.13    -0.16     0.36 1.00     2094     2048
## treatment     0.51      0.18     0.16     0.90 1.00     2079     1989
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.92      0.07     0.80     1.06 1.00     2684     2122
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The 95% credible intervals for our &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; parameter, termed &lt;code&gt;treatment&lt;/code&gt; in the output, are well above zero.&lt;/p&gt;
&lt;p&gt;Another way to look at the parameter summary is with the &lt;code&gt;brms::fixef()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            Estimate Est.Error       Q2.5     Q97.5
## Intercept 0.1033326 0.1312632 -0.1556192 0.3640170
## treatment 0.5142275 0.1847559  0.1587896 0.8976941&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;you-can-reuse-a-fit.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;You can reuse a fit.&lt;/h3&gt;
&lt;p&gt;Especially with simple models like this, a lot of the time we spend waiting for &lt;code&gt;brms::brm()&lt;/code&gt; to return the model is wrapped up in compilation. This is because &lt;strong&gt;brms&lt;/strong&gt; is a collection of user-friendly functions designed to fit models with &lt;a href=&#34;https://mc-stan.org&#34;&gt;&lt;strong&gt;Stan&lt;/strong&gt;&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-standevelopmentteamRStanInterfaceStan2020&#34; role=&#34;doc-biblioref&#34;&gt;Stan Development Team, 2020&lt;/a&gt;, &lt;a href=&#34;#ref-standevelopmentteamStanReferenceManual2021&#34; role=&#34;doc-biblioref&#34;&gt;2021a&lt;/a&gt;, &lt;a href=&#34;#ref-standevelopmentteamStanUserGuide2021&#34; role=&#34;doc-biblioref&#34;&gt;2021b&lt;/a&gt;)&lt;/span&gt;. With each new model, &lt;code&gt;brm()&lt;/code&gt; translates your model into &lt;strong&gt;Stan&lt;/strong&gt; code, which then gets translated to C++ and is compiled afterwards (see &lt;a href=&#34;https://cran.r-project.org/package=brms/vignettes/brms_overview.pdf&#34;&gt;here&lt;/a&gt; or &lt;a href=&#34;https://cran.r-project.org/package=brms/brms.pdf&#34;&gt;here&lt;/a&gt;). However, we can use the &lt;code&gt;update()&lt;/code&gt; function to update a previously-compiled fit object with new data. This cuts out the compilation time and allows us to get directly to sampling. Here‚Äôs how to do it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set a new seed
set.seed(2)

# simulate new data based on that new seed
d &amp;lt;-
  tibble(group = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
  mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
         y         = ifelse(group == &amp;quot;control&amp;quot;, 
                            rnorm(n, mean = mu_c, sd = 1),
                            rnorm(n, mean = mu_t, sd = 1)))

updated_fit &amp;lt;-
  update(fit,
         newdata = d,
         seed = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Behold the &lt;code&gt;fixef()&lt;/code&gt; parameter summary for our updated model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(updated_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate Est.Error       Q2.5     Q97.5
## Intercept 0.06410605 0.1692172 -0.2700568 0.3995847
## treatment 0.30654690 0.2387028 -0.1434469 0.7815116&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well how about that? In this case, our 95% credible intervals for the &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; &lt;code&gt;treatment&lt;/code&gt; coefficient did include zero within their bounds. Though the posterior mean, 0.30, is still well away from zero, here we‚Äôd fail to reject &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; at the conventional level. This is why we simulate.&lt;/p&gt;
&lt;p&gt;To recap, we‚Äôve&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;determined our primary data type,&lt;/li&gt;
&lt;li&gt;cast our research question in terms of a regression model,&lt;/li&gt;
&lt;li&gt;identified the parameter of interest,&lt;/li&gt;
&lt;li&gt;settled on defensible priors,&lt;/li&gt;
&lt;li&gt;picked an initial sample size,&lt;/li&gt;
&lt;li&gt;fit an initial model with a single simulated data set, and&lt;/li&gt;
&lt;li&gt;practiced reusing that fit with &lt;code&gt;update()&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We‚Äôre more than half way there! It‚Äôs time to do our first power simulation.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;simulate-to-determine-power.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulate to determine power.&lt;/h2&gt;
&lt;p&gt;In this post, we‚Äôll play with three ways to do a Bayesian power simulation. They‚Äôll all be similar, but hopefully you‚Äôll learn a bit as we transition from one to the next. Though if you‚Äôre impatient and all this seems remedial, you could probably just skip down to the final example, &lt;a href=&#34;#version-3-still-talking-about-memory-we-can-be-even-stingier.&#34;&gt;Version 3&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;version-1-lets-introduce-making-a-custom-model-fitting-function.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Version 1: Let‚Äôs introduce making a custom model-fitting function.&lt;/h3&gt;
&lt;p&gt;For our power analysis, we‚Äôll need to simulate a large number of data sets, each of which we‚Äôll fit a model to. Here we‚Äôll make a custom function, &lt;code&gt;sim_d()&lt;/code&gt;, that will simulate new data sets just like before. Our function will have two parameters: we‚Äôll set our seeds with &lt;code&gt;seed&lt;/code&gt; and determine how many cases we‚Äôd like per group with &lt;code&gt;n&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_d &amp;lt;- function(seed, n) {
  
  mu_t &amp;lt;- .5
  mu_c &amp;lt;- 0

  set.seed(seed)
  
  tibble(group = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
  mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
         y         = ifelse(group == &amp;quot;control&amp;quot;, 
                            rnorm(n, mean = mu_c, sd = 1),
                            rnorm(n, mean = mu_t, sd = 1)))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here‚Äôs a quick example of how our function works.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_d(seed = 123, n = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 3
##   group     treatment      y
##   &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 control           0 -0.560
## 2 control           0 -0.230
## 3 treatment         1  2.06 
## 4 treatment         1  0.571&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we‚Äôre ready to get down to business. We‚Äôre going to be saving our simulation results in a nested data frame, &lt;code&gt;s&lt;/code&gt;. Initially, &lt;code&gt;s&lt;/code&gt; will have one column of &lt;code&gt;seed&lt;/code&gt; values. These will serve a dual function. First, they are the values we‚Äôll be feeding into the &lt;code&gt;seed&lt;/code&gt; argument of our custom data-generating function, &lt;code&gt;sim_d()&lt;/code&gt;. Second, since the &lt;code&gt;seed&lt;/code&gt; values serially increase, they also stand in as iteration indexes.&lt;/p&gt;
&lt;p&gt;For our second step, we add the data simulations and save them in a nested column, &lt;code&gt;d&lt;/code&gt;. In the first argument of the &lt;code&gt;purrr::map()&lt;/code&gt; function, we indicate we want to iterate over the values in &lt;code&gt;seed&lt;/code&gt;. In the second argument, we indicate we want to serially plug those &lt;code&gt;seed&lt;/code&gt; values into the first argument within the &lt;code&gt;sim_d()&lt;/code&gt; function. That argument, recall, is the well-named &lt;code&gt;seed&lt;/code&gt; argument. With the final argument in &lt;code&gt;map()&lt;/code&gt;, &lt;code&gt;n = 50&lt;/code&gt;, we hard code 50 into the &lt;code&gt;n&lt;/code&gt; argument of &lt;code&gt;sim_d()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For the third step, we expand our &lt;code&gt;purrr::map()&lt;/code&gt; skills from above to &lt;code&gt;purrr::map2()&lt;/code&gt;, which allows us to iteratively insert two arguments into a function. Within this paradigm, the two arguments are generically termed &lt;code&gt;.x&lt;/code&gt; and &lt;code&gt;.y&lt;/code&gt;. Thus our approach will be &lt;code&gt;.x = d, .y = seed&lt;/code&gt;. For our function, we specify &lt;code&gt;~update(fit, newdata = .x, seed = .y)&lt;/code&gt;. Thus we‚Äôll be iteratively inserting our simulated &lt;code&gt;d&lt;/code&gt; data into the &lt;code&gt;newdata&lt;/code&gt; argument and will be simultaneously inserting our &lt;code&gt;seed&lt;/code&gt; values into the &lt;code&gt;seed&lt;/code&gt; argument.&lt;/p&gt;
&lt;p&gt;Also notice that the number of iterations we‚Äôll be working with is determined by the number of rows in the &lt;code&gt;seed&lt;/code&gt; column. We are defining that number as &lt;code&gt;n_sim&lt;/code&gt;. Since this is just a blog post, I‚Äôm going to take it easy and use 100. But if this was a real power analysis for one of your projects, something like 1,000 would be better.&lt;/p&gt;
&lt;p&gt;Finally, you don‚Äôt have to do this, but I‚Äôm timing my simulation by saving &lt;code&gt;Sys.time()&lt;/code&gt; values at the beginning and end of the simulation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# how many simulations would you like?
n_sim &amp;lt;- 100

# this will help us track time
t1 &amp;lt;- Sys.time()

# here&amp;#39;s the main event!
s &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(d = map(seed, sim_d, n = 50)) %&amp;gt;% 
  mutate(fit = map2(d, seed, ~update(fit, newdata = .x, seed = .y)))

t2 &amp;lt;- Sys.time()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The entire simulation took just about a minute on my &lt;a href=&#34;https://twitter.com/SolomonKurz/status/1250193047096299520&#34;&gt;new laptop&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t2 - t1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 44.20048 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Your mileage may vary.&lt;/p&gt;
&lt;p&gt;Let‚Äôs take a look at what we‚Äôve done.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(s)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##    seed d                  fit      
##   &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;   
## 1     1 &amp;lt;tibble [100 √ó 3]&amp;gt; &amp;lt;brmsfit&amp;gt;
## 2     2 &amp;lt;tibble [100 √ó 3]&amp;gt; &amp;lt;brmsfit&amp;gt;
## 3     3 &amp;lt;tibble [100 √ó 3]&amp;gt; &amp;lt;brmsfit&amp;gt;
## 4     4 &amp;lt;tibble [100 √ó 3]&amp;gt; &amp;lt;brmsfit&amp;gt;
## 5     5 &amp;lt;tibble [100 √ó 3]&amp;gt; &amp;lt;brmsfit&amp;gt;
## 6     6 &amp;lt;tibble [100 √ó 3]&amp;gt; &amp;lt;brmsfit&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In our 100-row nested tibble, we have all our simulated data sets in the &lt;code&gt;d&lt;/code&gt; column and all of our &lt;strong&gt;brms&lt;/strong&gt; fit objects nested in the &lt;code&gt;fit&lt;/code&gt; column. Next we‚Äôll use &lt;code&gt;fixef()&lt;/code&gt; and a little wrangling to extract the parameter of interest, &lt;code&gt;treatment&lt;/code&gt; (i.e., &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;), from each simulation. We‚Äôll save the results as &lt;code&gt;parameters&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;parameters &amp;lt;-
  s %&amp;gt;% 
  mutate(treatment = map(fit, ~ fixef(.) %&amp;gt;% 
                           data.frame() %&amp;gt;% 
                           rownames_to_column(&amp;quot;parameter&amp;quot;))) %&amp;gt;% 
  unnest(treatment)

parameters %&amp;gt;% 
  select(-d, -fit) %&amp;gt;% 
  filter(parameter == &amp;quot;treatment&amp;quot;) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
##    seed parameter Estimate Est.Error    Q2.5 Q97.5
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1 treatment    0.514     0.185  0.159  0.898
## 2     2 treatment    0.307     0.239 -0.143  0.782
## 3     3 treatment    0.643     0.171  0.310  0.975
## 4     4 treatment    0.224     0.182 -0.128  0.574
## 5     5 treatment    0.429     0.189  0.0596 0.792
## 6     6 treatment    0.304     0.208 -0.114  0.711&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an aside, I know I‚Äôm moving kinda fast with all this wacky &lt;code&gt;purrr::map()&lt;/code&gt;/&lt;code&gt;purrr::map2()&lt;/code&gt; stuff. If you‚Äôre new to using the &lt;strong&gt;tidyverse&lt;/strong&gt; for iterating and saving the results in nested data structures, I recommend fixing an adult beverage and cozying up with Hadley Wickham‚Äôs presentation, &lt;a href=&#34;https://www.youtube.com/watch?v=rz3_FDVt9eg&#34;&gt;&lt;em&gt;Managing many models&lt;/em&gt;&lt;/a&gt;. And if you really hate it, both Kruschke and McElreath texts contain many examples of how to iterate in a more base &lt;strong&gt;R&lt;/strong&gt; sort of way.&lt;/p&gt;
&lt;p&gt;Anyway, here‚Äôs what those 100 &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; summaries look like in bulk.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;parameters %&amp;gt;% 
  filter(parameter == &amp;quot;treatment&amp;quot;) %&amp;gt;% 
  
  ggplot(aes(x = seed, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1/2) +
  labs(x = &amp;quot;seed (i.e., simulation index)&amp;quot;,
       y = expression(beta[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The horizontal lines show the idealized effect size (0.5) and the null hypothesis (0). Already, it‚Äôs apparent that most of our intervals indicate there‚Äôs more than a 95% probability the null hypothesis is not credible. Several do. Here‚Äôs how to quantify that.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;parameters %&amp;gt;% 
  filter(parameter == &amp;quot;treatment&amp;quot;) %&amp;gt;% 
  mutate(check = ifelse(Q2.5 &amp;gt; 0, 1, 0)) %&amp;gt;% 
  summarise(power = mean(check))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   power
##   &amp;lt;dbl&amp;gt;
## 1  0.66&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the second &lt;code&gt;mutate()&lt;/code&gt; line, we used a logical statement within &lt;code&gt;ifelse()&lt;/code&gt; to code all instances where the lower limit of the 95% interval (&lt;code&gt;Q2.5&lt;/code&gt;) was greater than 0 as a 1, with the rest as 0. That left us with a vector of 1‚Äôs and 0‚Äôs, which we saved as &lt;code&gt;check&lt;/code&gt;. In the &lt;code&gt;summarise()&lt;/code&gt; line, we took the mean of that column, which returned our Bayesian power estimate.&lt;/p&gt;
&lt;p&gt;That is, in 66 of our 100 simulations, an &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt; per group was enough to produce a 95% Bayesian credible interval that did not straddle 0.&lt;/p&gt;
&lt;p&gt;I should probably point out that a 95% interval for which &lt;code&gt;Q97.5 &amp;lt; 0&lt;/code&gt; would have also been consistent with the alternative hypothesis of &lt;span class=&#34;math inline&#34;&gt;\(\mu_c \neq \mu_t\)&lt;/span&gt;. However, I didn‚Äôt bother to work that option into the definition of our &lt;code&gt;check&lt;/code&gt; variable because I knew from the outset that that would be a highly unlikely result. But if you‚Äôd like to work more rigor into your checks, by all means do.&lt;/p&gt;
&lt;p&gt;And if you‚Äôve gotten this far and have been following along with code of your own, congratulations! You did it! You‚Äôve estimated the power of a Bayesian model with a given &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. Now let‚Äôs refine our approach.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;version-2-we-might-should-be-more-careful-with-memory.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Version 2: We might should be more careful with memory.&lt;/h3&gt;
&lt;p&gt;I really like it that our &lt;code&gt;s&lt;/code&gt; object contains all our &lt;code&gt;brm()&lt;/code&gt; fits. It makes it really handy to do global diagnostics like making sure our &lt;span class=&#34;math inline&#34;&gt;\(\widehat R\)&lt;/span&gt; values are all within a respectable range.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s %&amp;gt;% 
  mutate(rhat = map(fit, rhat)) %&amp;gt;% 
  unnest(rhat) %&amp;gt;% 
  
  ggplot(aes(x = rhat)) +
  geom_histogram(bins = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;288&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Man those &lt;span class=&#34;math inline&#34;&gt;\(\widehat R\)&lt;/span&gt; values look sweet. It‚Äôs great to have a workflow that lets you check them. But holding on to all those fits can take up a lot of memory. If the only thing you‚Äôre interested in are the parameter summaries, a better approach might be to do the model refitting and parameter extraction in one step. That way you only save the parameter summaries. Here‚Äôs how you might do that.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t3 &amp;lt;- Sys.time()

s2 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(d = map(seed, sim_d, n = 50)) %&amp;gt;% 
  # here&amp;#39;s the new part
  mutate(b1 = map2(d, seed, ~update(fit, newdata = .x, seed = .y) %&amp;gt;% 
                     fixef() %&amp;gt;% 
                     data.frame() %&amp;gt;% 
                     rownames_to_column(&amp;quot;parameter&amp;quot;) %&amp;gt;% 
                     filter(parameter == &amp;quot;treatment&amp;quot;)))

t4 &amp;lt;- Sys.time()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Like before, this only about a minute.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t4 - t3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 48.12622 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a point of comparison, here are the sizes of the results from our first approach to those from the second.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;object.size(s)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 79822320 bytes&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;object.size(s2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 503120 bytes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That‚Äôs a big difference. Hopefully you get the idea. With more complicated models and 10+ times the number of simulations, size will eventually matter.&lt;/p&gt;
&lt;p&gt;Anyway, here are the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s2 %&amp;gt;% 
  unnest(b1) %&amp;gt;% 

  ggplot(aes(x = seed, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1/2) +
  labs(x = &amp;quot;seed (i.e., simulation index)&amp;quot;,
       y = expression(beta[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Same parameter summaries, lower memory burden.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;version-3-still-talking-about-memory-we-can-be-even-stingier.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Version 3: Still talking about memory, we can be even stingier.&lt;/h3&gt;
&lt;p&gt;So far, both of our simulation attempts resulted in our saving the simulated data sets. It‚Äôs a really nice option if you ever want to go back and take a look at those simulated data. For example, you might want to inspect a random subset of the data simulations with box plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)

s2 %&amp;gt;% 
  sample_n(12) %&amp;gt;% 
  unnest(d) %&amp;gt;% 
  
  ggplot(aes(x = group, y = y)) +
  geom_boxplot(aes(fill = group), 
               alpha = 2/3, show.legend = F) +
  scale_fill_manual(values = c(&amp;quot;grey25&amp;quot;, &amp;quot;blue2&amp;quot;)) +
  xlab(NULL) +
  facet_wrap(~ seed)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this case, it‚Äôs no big deal if we keep the data around or not. The data sets are fairly small and we‚Äôre only simulating 100 of them. But in cases where the data are larger and you‚Äôre doing thousands of simulations, keeping the data could become a memory drain.&lt;/p&gt;
&lt;p&gt;If you‚Äôre willing to forgo the luxury of inspecting your data simulations, it might make sense to run our power analysis in a way that avoids saving them. One way to do so would be to just wrap the data simulation and model fitting all in one function. We‚Äôll call it &lt;code&gt;sim_d_and_fit()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_d_and_fit &amp;lt;- function(seed, n) {
  
  mu_t &amp;lt;- .5
  mu_c &amp;lt;- 0
  
  set.seed(seed)
  
  d &amp;lt;-
    tibble(group     = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
    mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
           y         = ifelse(group == &amp;quot;control&amp;quot;, 
                              rnorm(n, mean = mu_c, sd = 1),
                              rnorm(n, mean = mu_t, sd = 1)))
  
  update(fit,
         newdata = d, 
         seed = seed) %&amp;gt;% 
    fixef() %&amp;gt;% 
    data.frame() %&amp;gt;% 
    rownames_to_column(&amp;quot;parameter&amp;quot;) %&amp;gt;% 
    filter(parameter == &amp;quot;treatment&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now iterate 100 times once more.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t5 &amp;lt;- Sys.time()

s3 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 50)) %&amp;gt;% 
  unnest(b1)

t6 &amp;lt;- Sys.time()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That was pretty quick.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t6 - t5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 48.48654 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here‚Äôs what it returned.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(s3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
##    seed parameter Estimate Est.Error    Q2.5 Q97.5
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1 treatment    0.514     0.185  0.159  0.898
## 2     2 treatment    0.307     0.239 -0.143  0.782
## 3     3 treatment    0.643     0.171  0.310  0.975
## 4     4 treatment    0.224     0.182 -0.128  0.574
## 5     5 treatment    0.429     0.189  0.0596 0.792
## 6     6 treatment    0.304     0.208 -0.114  0.711&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By wrapping our data simulation, model fitting, and parameter extraction steps all in one function, we simplified the output such that we‚Äôre no longer holding on to the data simulations or the &lt;strong&gt;brms&lt;/strong&gt; fit objects. We just have the parameter summaries and the &lt;code&gt;seed&lt;/code&gt;, making the product even smaller.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(object = c(&amp;quot;s&amp;quot;, &amp;quot;s2&amp;quot;, &amp;quot;s3&amp;quot;)) %&amp;gt;% 
  mutate(bytes = map_dbl(object, ~get(.) %&amp;gt;% object.size()))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##   object    bytes
##   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 s      79822320
## 2 s2       503120
## 3 s3         5952&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But the primary results are the same.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 %&amp;gt;% 
  ggplot(aes(x = seed, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1/2) +
  labs(x = &amp;quot;seed (i.e., simulation index)&amp;quot;,
       y = expression(beta[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We still get the same power estimate, too.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 %&amp;gt;% 
  mutate(check = ifelse(Q2.5 &amp;gt; 0, 1, 0)) %&amp;gt;% 
  summarise(power = mean(check))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   power
##   &amp;lt;dbl&amp;gt;
## 1  0.66&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;next-steps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Next steps&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;But my goal was to figure out what &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; will get me power of .8 or more!&lt;/em&gt;, you say. Fair enough. Try increasing &lt;code&gt;n&lt;/code&gt; to 65 or something.&lt;/p&gt;
&lt;p&gt;If that seems unsatisfying, welcome to the world of simulation. Since our Bayesian models are complicated, we don‚Äôt have the luxury of plugging a few values into some quick power formula. Just as simulation is an iterative process, determining on the right values to simulate over might well be an iterative process, too.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;wrap-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Wrap-up&lt;/h2&gt;
&lt;p&gt;Anyway, that‚Äôs the essence of the &lt;strong&gt;brms/tidyverse&lt;/strong&gt; workflow for Bayesian power analysis. You follow these steps:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Determine your primary data type.&lt;/li&gt;
&lt;li&gt;Determine your primary regression model and parameter(s) of interest.&lt;/li&gt;
&lt;li&gt;Pick defensible priors for all parameters‚Äìthe kinds of priors you intend to use once you have the real data in hand.&lt;/li&gt;
&lt;li&gt;Select a sample size.&lt;/li&gt;
&lt;li&gt;Fit an initial model and save the fit object.&lt;/li&gt;
&lt;li&gt;Simulate some large number of data sets all following your prechosen form and use the &lt;code&gt;update()&lt;/code&gt; function to iteratively fit the models.&lt;/li&gt;
&lt;li&gt;Extract the parameter(s) of interest.&lt;/li&gt;
&lt;li&gt;Summarize.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In addition, we played with a few approaches based on logistical concerns like memory. In the next post, &lt;a href=&#34;https://solomonkurz.netlify.app/post/bayesian-power-analysis-part-ii/&#34;&gt;part II&lt;/a&gt;, we‚Äôll see how the precision-oriented approach to sample-size planning is a viable alternative to power focused on rejecting null hypotheses.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;i-had-help.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I had help.&lt;/h2&gt;
&lt;p&gt;Special thanks to Christopher Peters (&lt;a href=&#34;https://github.com/statwonk&#34;&gt;@statwonk&lt;/a&gt;) for the helpful edits and suggestions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] brms_2.15.0     Rcpp_1.0.6      forcats_0.5.1   stringr_1.4.0  
##  [5] dplyr_1.0.5     purrr_0.3.4     readr_1.4.0     tidyr_1.1.3    
##  [9] tibble_3.1.0    ggplot2_3.3.3   tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6          
##   [4] igraph_1.2.6         splines_4.0.4        crosstalk_1.1.0.1   
##   [7] TH.data_1.0-10       rstantools_2.1.1     inline_0.3.17       
##  [10] digest_0.6.27        htmltools_0.5.1.1    rsconnect_0.8.16    
##  [13] fansi_0.4.2          magrittr_2.0.1       modelr_0.1.8        
##  [16] RcppParallel_5.0.2   matrixStats_0.57.0   xts_0.12.1          
##  [19] sandwich_3.0-0       prettyunits_1.1.1    colorspace_2.0-0    
##  [22] rvest_0.3.6          haven_2.3.1          xfun_0.22           
##  [25] callr_3.5.1          crayon_1.4.1         jsonlite_1.7.2      
##  [28] lme4_1.1-25          survival_3.2-10      zoo_1.8-8           
##  [31] glue_1.4.2           gtable_0.3.0         emmeans_1.5.2-1     
##  [34] V8_3.4.0             pkgbuild_1.2.0       rstan_2.21.2        
##  [37] abind_1.4-5          scales_1.1.1         mvtnorm_1.1-1       
##  [40] DBI_1.1.0            miniUI_0.1.1.1       xtable_1.8-4        
##  [43] stats4_4.0.4         StanHeaders_2.21.0-7 DT_0.16             
##  [46] htmlwidgets_1.5.2    httr_1.4.2           threejs_0.3.3       
##  [49] ellipsis_0.3.1       pkgconfig_2.0.3      loo_2.4.1           
##  [52] farver_2.0.3         dbplyr_2.0.0         utf8_1.1.4          
##  [55] tidyselect_1.1.0     labeling_0.4.2       rlang_0.4.10        
##  [58] reshape2_1.4.4       later_1.1.0.1        munsell_0.5.0       
##  [61] cellranger_1.1.0     tools_4.0.4          cli_2.3.1           
##  [64] generics_0.1.0       broom_0.7.5          ggridges_0.5.2      
##  [67] evaluate_0.14        fastmap_1.0.1        yaml_2.2.1          
##  [70] processx_3.4.5       knitr_1.31           fs_1.5.0            
##  [73] nlme_3.1-152         mime_0.10            projpred_2.0.2      
##  [76] xml2_1.3.2           compiler_4.0.4       bayesplot_1.8.0     
##  [79] shinythemes_1.1.2    rstudioapi_0.13      gamm4_0.2-6         
##  [82] curl_4.3             reprex_0.3.0         statmod_1.4.35      
##  [85] stringi_1.5.3        highr_0.8            ps_1.6.0            
##  [88] blogdown_1.3         Brobdingnag_1.2-6    lattice_0.20-41     
##  [91] Matrix_1.3-2         nloptr_1.2.2.2       markdown_1.1        
##  [94] shinyjs_2.0.0        vctrs_0.3.6          pillar_1.5.1        
##  [97] lifecycle_1.0.0      bridgesampling_1.0-0 estimability_1.3    
## [100] httpuv_1.5.4         R6_2.5.0             bookdown_0.21       
## [103] promises_1.1.1       gridExtra_2.3        codetools_0.2-18    
## [106] boot_1.3-26          colourpicker_1.1.0   MASS_7.3-53         
## [109] gtools_3.8.2         assertthat_0.2.1     withr_2.4.1         
## [112] shinystan_2.5.0      multcomp_1.4-16      mgcv_1.8-33         
## [115] parallel_4.0.4       hms_0.5.3            grid_4.0.4          
## [118] coda_0.19-4          minqa_1.2.4          rmarkdown_2.7       
## [121] shiny_1.5.0          lubridate_1.7.9.2    base64enc_0.1-3     
## [124] dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# for the hard-core scrollers:
# if you increase n to 65, the power becomes about .85
n_sim &amp;lt;- 100

t7 &amp;lt;- Sys.time()

s4 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 65))

t8 &amp;lt;- Sys.time()

t8 - t7

object.size(s4)

s4 %&amp;gt;% 
  unnest(b1) %&amp;gt;% 
  mutate(check = ifelse(Q2.5 &amp;gt; 0, 1, 0)) %&amp;gt;% 
  summarise(power = mean(check))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-burknerBrmsPackageBayesian2017&#34; class=&#34;csl-entry&#34;&gt;
B√ºrkner, P.-C. (2017). &lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;An R&lt;/span&gt; package for &lt;span&gt;Bayesian&lt;/span&gt; multilevel models using &lt;span&gt;Stan&lt;/span&gt;. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;80&lt;/em&gt;(1), 1‚Äì28. &lt;a href=&#34;https://doi.org/10.18637/jss.v080.i01&#34;&gt;https://doi.org/10.18637/jss.v080.i01&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerAdvancedBayesianMultilevel2018&#34; class=&#34;csl-entry&#34;&gt;
B√ºrkner, P.-C. (2018). Advanced &lt;span&gt;Bayesian&lt;/span&gt; multilevel modeling with the &lt;span&gt;R&lt;/span&gt; package brms. &lt;em&gt;The R Journal&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(1), 395‚Äì411. &lt;a href=&#34;https://doi.org/10.32614/RJ-2018-017&#34;&gt;https://doi.org/10.32614/RJ-2018-017&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-brms&#34; class=&#34;csl-entry&#34;&gt;
B√ºrkner, P.-C. (2020a). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;Bayesian&lt;/span&gt; regression models using ‚Äô&lt;span&gt;Stan&lt;/span&gt;‚Äô&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=brms&#34;&gt;https://CRAN.R-project.org/package=brms&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-brms2020RM&#34; class=&#34;csl-entry&#34;&gt;
B√ºrkner, P.-C. (2020b). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt; reference manual, &lt;span&gt;Version&lt;/span&gt; 2.14.4&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=brms/brms.pdf&#34;&gt;https://CRAN.R-project.org/package=brms/brms.pdf&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-cohenStatisticalPowerAnalysis1988a&#34; class=&#34;csl-entry&#34;&gt;
Cohen, J. (1988). &lt;em&gt;Statistical power analysis for the behavioral sciences&lt;/em&gt;. &lt;span&gt;L. Erlbaum Associates&lt;/span&gt;. &lt;a href=&#34;https://www.worldcat.org/title/statistical-power-analysis-for-the-behavioral-sciences/oclc/17877467&#34;&gt;https://www.worldcat.org/title/statistical-power-analysis-for-the-behavioral-sciences/oclc/17877467&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelmanPriorCanOften2017&#34; class=&#34;csl-entry&#34;&gt;
Gelman, A., Simpson, D., &amp;amp; Betancourt, M. (2017). The prior can often only be understood in the context of the likelihood. &lt;em&gt;Entropy&lt;/em&gt;, &lt;em&gt;19&lt;/em&gt;(10), 555. &lt;a href=&#34;https://doi.org/10.3390/e19100555&#34;&gt;https://doi.org/10.3390/e19100555&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-grolemundDataScience2017&#34; class=&#34;csl-entry&#34;&gt;
Grolemund, G., &amp;amp; Wickham, H. (2017). &lt;em&gt;R for data science&lt;/em&gt;. &lt;span&gt;O‚ÄôReilly&lt;/span&gt;. &lt;a href=&#34;https://r4ds.had.co.nz&#34;&gt;https://r4ds.had.co.nz&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kruschkeDoingBayesianData2015&#34; class=&#34;csl-entry&#34;&gt;
Kruschke, J. K. (2015). &lt;em&gt;Doing &lt;span&gt;Bayesian&lt;/span&gt; data analysis: &lt;span&gt;A&lt;/span&gt; tutorial with &lt;span&gt;R&lt;/span&gt;, &lt;span&gt;JAGS&lt;/span&gt;, and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;Academic Press&lt;/span&gt;. &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;https://sites.google.com/site/doingbayesiandataanalysis/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kurzStatisticalRethinkingBrms2020&#34; class=&#34;csl-entry&#34;&gt;
Kurz, A. S. (2020a). &lt;em&gt;Statistical rethinking with brms, &lt;span class=&#34;nocase&#34;&gt;ggplot2&lt;/span&gt;, and the tidyverse&lt;/em&gt; (version 1.2.0). &lt;a href=&#34;https://doi.org/10.5281/zenodo.3693202&#34;&gt;https://doi.org/10.5281/zenodo.3693202&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kurzDoingBayesianData2020&#34; class=&#34;csl-entry&#34;&gt;
Kurz, A. S. (2020b). &lt;em&gt;Doing &lt;span&gt;Bayesian&lt;/span&gt; data analysis in brms and the tidyverse&lt;/em&gt; (version 0.3.0). &lt;a href=&#34;https://bookdown.org/content/3686/&#34;&gt;https://bookdown.org/content/3686/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kurzStatisticalRethinkingSecondEd2020&#34; class=&#34;csl-entry&#34;&gt;
Kurz, A. S. (2020c). &lt;em&gt;Statistical rethinking with brms, Ggplot2, and the tidyverse: &lt;span&gt;Second&lt;/span&gt; edition&lt;/em&gt; (version 0.1.1). &lt;a href=&#34;https://bookdown.org/content/4857/&#34;&gt;https://bookdown.org/content/4857/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-maxwellSampleSizePlanning2008&#34; class=&#34;csl-entry&#34;&gt;
Maxwell, S. E., Kelley, K., &amp;amp; Rausch, J. R. (2008). Sample size planning for statistical power and accuracy in parameter estimation. &lt;em&gt;Annual Review of Psychology&lt;/em&gt;, &lt;em&gt;59&lt;/em&gt;(1), 537‚Äì563. &lt;a href=&#34;https://doi.org/10.1146/annurev.psych.59.103006.093735&#34;&gt;https://doi.org/10.1146/annurev.psych.59.103006.093735&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2020&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2020). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt; (Second Edition). &lt;span&gt;CRC Press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2015&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2015). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-pengProgrammingDataScience2019&#34; class=&#34;csl-entry&#34;&gt;
Peng, R. D. (2019). &lt;em&gt;R programming for data science&lt;/em&gt;. &lt;a href=&#34;https://bookdown.org/rdpeng/rprogdatascience/&#34;&gt;https://bookdown.org/rdpeng/rprogdatascience/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-base&#34; class=&#34;csl-entry&#34;&gt;
R Core Team. (2020). &lt;em&gt;R: &lt;span&gt;A&lt;/span&gt; language and environment for statistical computing&lt;/em&gt;. &lt;span&gt;R Foundation for Statistical Computing&lt;/span&gt;. &lt;a href=&#34;https://www.R-project.org/&#34;&gt;https://www.R-project.org/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-standevelopmentteamRStanInterfaceStan2020&#34; class=&#34;csl-entry&#34;&gt;
Stan Development Team. (2020). &lt;em&gt;&lt;span&gt;RStan&lt;/span&gt;: The &lt;span&gt;R&lt;/span&gt; interface to &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;a href=&#34;https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html&#34;&gt;https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-standevelopmentteamStanReferenceManual2021&#34; class=&#34;csl-entry&#34;&gt;
Stan Development Team. (2021a). &lt;em&gt;Stan reference manual, &lt;span&gt;Version&lt;/span&gt; 2.26&lt;/em&gt;. &lt;a href=&#34;https://mc-stan.org/docs/2_26/reference-manual/&#34;&gt;https://mc-stan.org/docs/2_26/reference-manual/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-standevelopmentteamStanUserGuide2021&#34; class=&#34;csl-entry&#34;&gt;
Stan Development Team. (2021b). &lt;em&gt;Stan user‚Äôs guide, &lt;span&gt;Version&lt;/span&gt; 2.26&lt;/em&gt;. &lt;a href=&#34;https://mc-stan.org/docs/2_26/stan-users-guide/index.html&#34;&gt;https://mc-stan.org/docs/2_26/stan-users-guide/index.html&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-tidyverse&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H. (2019). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;tidyverse&lt;/span&gt;: &lt;span&gt;Easily&lt;/span&gt; install and load the ‚Äôtidyverse‚Äô&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=tidyverse&#34;&gt;https://CRAN.R-project.org/package=tidyverse&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wickhamTidyverseStyleGuide2020&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H. (2020). &lt;em&gt;The tidyverse style guide&lt;/em&gt;. &lt;a href=&#34;https://style.tidyverse.org/&#34;&gt;https://style.tidyverse.org/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wickhamWelcomeTidyverse2019&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., Fran√ßois, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., M√ºller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., ‚Ä¶ Yutani, H. (2019). Welcome to the tidyverse. &lt;em&gt;Journal of Open Source Software&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(43), 1686. &lt;a href=&#34;https://doi.org/10.21105/joss.01686&#34;&gt;https://doi.org/10.21105/joss.01686&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
