<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>power | Fahim Ahmad</title>
    <link>/tag/power/</link>
      <atom:link href="/tag/power/index.xml" rel="self" type="application/rss+xml" />
    <description>power</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Fahim Ahmad (2020)</copyright><lastBuildDate>Fri, 02 Jul 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png</url>
      <title>power</title>
      <link>/tag/power/</link>
    </image>
    
    <item>
      <title>Example power analysis report</title>
      <link>/post/2021-07-02-example-power-analysis-report/</link>
      <pubDate>Fri, 02 Jul 2021 00:00:00 +0000</pubDate>
      <guid>/post/2021-07-02-example-power-analysis-report/</guid>
      <description>
&lt;script src=&#34;/post/2021-07-02-example-power-analysis-report/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;context&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Context&lt;/h2&gt;
&lt;p&gt;In one of my recent Twitter posts, I got pissy and complained about a vague power-analysis statement I saw while reviewing a manuscript submitted to a scientific journal.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;If you submit a manuscript for publication that involves HLMs and SEMs of longitudinal data and you vaguely summarize your power analysis in one sentence, I, as your friendly neighborhood Reviewer #2, am requesting a full power-analysis write-up as a supplementary material.&lt;/p&gt;&amp;mdash; Solomon Kurz (@SolomonKurz) &lt;a href=&#34;https://twitter.com/SolomonKurz/status/1409626961161371648?ref_src=twsrc%5Etfw&#34;&gt;June 28, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;It wasn’t my best moment and I ended up apologizing for my tone.&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Okay, I apologize for getting a little pissy with the tweet. Yet the issue is real and it leads to a natural question: What would go into a good power analysis report? I’ve done a few for work and I promise to morph one into a blog post, by the end of the week.&lt;/p&gt;&amp;mdash; Solomon Kurz (@SolomonKurz) &lt;a href=&#34;https://twitter.com/SolomonKurz/status/1409634560485199876?ref_src=twsrc%5Etfw&#34;&gt;June 28, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;However, the broader issue remains. If you plan to analyze your data with anything more complicated than a &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-test, the power analysis phase gets tricky. The manuscript I was complaining about used a complicated multilevel model as its primary analysis. I’m willing to bet that most applied researchers (including the authors of that manuscript) have never done a power analysis for a multilevel model and probably have never seen what one might look like, either. The purpose of this post is to give a real-world example of just such an analysis.&lt;/p&gt;
&lt;p&gt;Over the past couple years, I’ve done a few multilevel power analyses as part of my day job. In this post, I will reproduce one of them. For the sake of confidentiality, some of the original content will be omitted or slightly altered. But the overall workflow will be about 90% faithful to the original report I submitted to my boss. To understand this report, you should know:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;my boss has some experience fitting multilevel models, but they’re not a stats jock;&lt;/li&gt;
&lt;li&gt;we had pilot data from two different sources, each with its strengths and weaknesses; and&lt;/li&gt;
&lt;li&gt;this document was meant for internal purposes only, though I believe some of its contents did make it into other materials.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;At the end, I’ll wrap this post up with a few comments. Here’s the report:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;executive-summary&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Executive summary&lt;/h2&gt;
&lt;p&gt;A total sample size of &lt;strong&gt;164&lt;/strong&gt; is the minimum number to detect an effect size similar to that in the pilot data (i.e., Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d = 0.3\)&lt;/span&gt;). This recommendation assumes&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;a study design of three time points,&lt;/li&gt;
&lt;li&gt;random assignment of participants into two equal groups, and&lt;/li&gt;
&lt;li&gt;20% dropout on the second time point and another 20% dropout by the third time point.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If we presume a more conservative effect size of &lt;span class=&#34;math inline&#34;&gt;\(0.2\)&lt;/span&gt; and a larger dropout rate of 30% the second and third time points, the minimum recommended total sample size is &lt;strong&gt;486&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The remainder of this report details how I came to these conclusions. For full transparency, I will supplement prose with figures, tables, and the statistical code used used for all computations. By default, the code is hidden is this document. However, if you are interested in the code, you should be able to make it appear by selecting “Show All Code” in the dropdown menu from the “Code” button on the upper-right corner.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cohens-d&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;In this report, Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; is meant to indicate a standardized mean difference. The &lt;span class=&#34;math inline&#34;&gt;\(d = 0.3\)&lt;/span&gt; from above is based on the &lt;code&gt;some_file.docx&lt;/code&gt; file you shared with me last week. In Table 1, you provided the following summary information for the intervention group:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

tibble(summary = c(&amp;quot;mean&amp;quot;, &amp;quot;sd&amp;quot;),
       baseline = c(1.29, 1.13),
       followup = c(0.95, 1.09)) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;summary&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;baseline&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;followup&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mean&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.29&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.95&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;sd&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.13&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.09&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;With that information, we can compute a within-subject’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; by hand. With this formula, we will be using the pooled standard deviation in the denominator.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;- (1.29 - .95) / sqrt((1.13^2 + 1.09^2) / 2)
d&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.3062566&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, 0.306 is just a point estimate. We can express the uncertainty in that point estimate with 95% confidence intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ci &amp;lt;-
  MBESS::ci.smd(smd = d,
                n.1 = 50, 
                n.2 = 26)

ci %&amp;gt;% 
  data.frame() %&amp;gt;% 
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 1
## Columns: 3
## $ Lower.Conf.Limit.smd &amp;lt;dbl&amp;gt; -0.1712149
## $ smd                  &amp;lt;dbl&amp;gt; 0.3062566
## $ Upper.Conf.Limit.smd &amp;lt;dbl&amp;gt; 0.7816834&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this output, &lt;code&gt;smd&lt;/code&gt; refers to “standardized mean difference,” what what we have been referring to as Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;. The output indicates the effect size for the experimental group from the pilot study was &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; of 0.31 [-0.17, .78]. The data look promising for a small/moderate effect. But those confidence intervals swing from small negative to large.&lt;/p&gt;
&lt;p&gt;For reference, here are the 50% intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;MBESS::ci.smd(smd = d,
              n.1 = 50, 
              n.2 = 26,
              conf.level = .5) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 1
## Columns: 3
## $ Lower.Conf.Limit.smd &amp;lt;dbl&amp;gt; 0.1412595
## $ smd                  &amp;lt;dbl&amp;gt; 0.3062566
## $ Upper.Conf.Limit.smd &amp;lt;dbl&amp;gt; 0.4691839&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The 50% CIs range from 0.14 to 0.47.&lt;/p&gt;
&lt;div id=&#34;power-analyses-can-be-tailor-made.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Power analyses can be tailor made.&lt;/h3&gt;
&lt;p&gt;Whenever possible, it is preferable to tailor a power analysis to the statistical models researchers plan to use to analyze the data they intend to collect. Based on your previous analyses, I suspect you intend to fit a series of hierarchical models. I would have done the same thing with those data and I further recommend you analyze the data you intend to collect within a hierarchical growth model paradigm. With that in mind, the power analyses in the report are all based on the following model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
y_{ij} &amp;amp; = \beta_{0i} + \beta_{1i} \text{time}_{ij} + \epsilon_{ij} \\
\beta_{0i} &amp;amp; = \gamma_{00} + \gamma_{01} \text{treatment}_i +  u_{0i} \\
\beta_{1i} &amp;amp; = \gamma_{10} + \gamma_{11} \text{treatment}_i +  u_{1i}, 
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is the dependent variable of interest, which varies across &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; participants and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; measurement occasions. The model is linear with an intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_{0i}\)&lt;/span&gt; and slope &lt;span class=&#34;math inline&#34;&gt;\(\beta_{1i}\)&lt;/span&gt;. As indicated by the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; subscripts, both intercepts and slopes vary across participants with grand means &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{00}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{10}\)&lt;/span&gt;, respectively, and participant-specific deviations around those means &lt;span class=&#34;math inline&#34;&gt;\(u_{0i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(u_{1i}\)&lt;/span&gt;, respectively. There is a focal between-participant predictor in the model, &lt;span class=&#34;math inline&#34;&gt;\(\text{treatment}_i\)&lt;/span&gt;, which is coded 0 = &lt;em&gt;control&lt;/em&gt; 1 = &lt;em&gt;treatment&lt;/em&gt;. Rearranging the the formulas into the composite form will make it clear this is an interaction model:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
y_{ij} &amp;amp; = \gamma_{00} + \gamma_{01} \text{treatment}_i \\
       &amp;amp; \;\;\; + \gamma_{10} \text{time}_{ij} + \gamma_{11} \text{treatment}_i \times \text{time}_{ij} \\
       &amp;amp; \;\;\; + u_{0i} +  u_{1i} \text{time}_{ij} + \epsilon_{ij},
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the parameter of primary interest for the study is &lt;span class=&#34;math inline&#34;&gt;\(\gamma_{11} \text{treatment}_i \times \text{time}_{ij}\)&lt;/span&gt;, the difference between the two &lt;span class=&#34;math inline&#34;&gt;\(\text{treatment}\)&lt;/span&gt; conditions in their change in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; over &lt;span class=&#34;math inline&#34;&gt;\(\text{time}\)&lt;/span&gt;. As such, the focus of the power analyses reported above are on the power to reject the null hypothesis the &lt;span class=&#34;math inline&#34;&gt;\(\text{treatment}\)&lt;/span&gt; conditions do not differ in their change over &lt;span class=&#34;math inline&#34;&gt;\(\text{time}\)&lt;/span&gt;,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0: \gamma_{11} = 0.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To finish out the equations, this approach makes the typical assumptions the within-participant residual term, &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ij}\)&lt;/span&gt;, is normally distributed around zero,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\epsilon_{ij} \sim \operatorname{Normal} (0, \sigma_\epsilon^2),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;and the between-participant variances &lt;span class=&#34;math inline&#34;&gt;\(u_{0i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(u_{1i}\)&lt;/span&gt; have a multivariate normal distribution with a mean vector of zeros,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{bmatrix} u_{0i} \\ u_{1i} \end{bmatrix} \sim \operatorname{Normal} \Bigg ( \begin{bmatrix} 0 \\ 0 \end{bmatrix}, \begin{bmatrix} \sigma_0^2 &amp;amp; \sigma_{01} \\ \sigma_{01} &amp;amp; \sigma_1^2 \end{bmatrix} \Bigg ).\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Following convention, the within-participant residuals &lt;span class=&#34;math inline&#34;&gt;\(\epsilon_{ij}\)&lt;/span&gt; are orthogonal to the between-participant variances &lt;span class=&#34;math inline&#34;&gt;\(u_{0i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(u_{1i}\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;For simplicity, another assumption of this model that the control condition will remain constant over time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;main-results-power-curves.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Main results: Power curves.&lt;/h3&gt;
&lt;p&gt;I computed a series of power curves to examine the necessary sample size given different assumptions. Due to the uncertainty in the effect size from the pilot data, &lt;span class=&#34;math inline&#34;&gt;\(d = 0.31 [-0.17, .78]\)&lt;/span&gt;, varied the effect size from 0.1 to 0.3. I also examined different levels of missing data via dropout. These followed four patterns of dropout and were extensions of the missing data pattern described in the &lt;code&gt;some_other_file.docx&lt;/code&gt; file. They were:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(`dropout rate` = str_c(c(0, 10, 20, 30), &amp;quot;%&amp;quot;),
       baseline = &amp;quot;100%&amp;quot;,
       `1st followup` = str_c(c(100, 90, 80, 70), &amp;quot;%&amp;quot;),
       `2nd followup` = str_c(c(100, 80, 60, 40), &amp;quot;%&amp;quot;)) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;dropout rate&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;baseline&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;1st followup&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;2nd followup&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;0%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;10%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;90%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;20%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;80%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;60%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;30%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;100%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;70%&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;40%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The row with the 20% dropout rate, for example, corresponds directly to the dropout rate entertained in the &lt;code&gt;some_other_file.docx&lt;/code&gt; file.&lt;/p&gt;
&lt;p&gt;The power simulations of this kind required two more bits of information. The first was that we specify an expected intraclass correlation coefficient (ICC). I used ICC = .9, which is the ICC value you reported in your previous work (p. 41).&lt;/p&gt;
&lt;p&gt;The second value needed is the ratio of &lt;span class=&#34;math inline&#34;&gt;\(u_{1i}/ \epsilon_{ij}\)&lt;/span&gt;, sometimes called the “variance ratio.” I was not able to determine that value from the &lt;code&gt;some_file.docx&lt;/code&gt; or the &lt;code&gt;some_other_file.docx&lt;/code&gt;. However, I was able to compute one based on data from a different project on participants from a similar population. The data are from several hundred participants in a longitudinal survey study. The data do not include your primary variable of interest. Instead, I took the &lt;span class=&#34;math inline&#34;&gt;\(u_{1i}/ \epsilon_{ij}\)&lt;/span&gt; from recent hierarchical analyses of two related measures. These left me with two values: 0.018 on the low end and 0.281 on the high end. Thus, I performed the power curves using both.&lt;/p&gt;
&lt;p&gt;Here is the code for the simulations:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(powerlmm)

t &amp;lt;- 3
n &amp;lt;- 100

# variance ratio 0.018
icc0.9_vr_0.018_d0.1 &amp;lt;-
  study_parameters(n1 = t,
                 n2 = n,
                 icc_pre_subject = 0.9,
                  var_ratio = 0.018,
                  effect_size = cohend(-0.2, 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;),
                 dropout = dropout_manual(0, 0.1, 0.2)) %&amp;gt;% 
  get_power_table(n2 = 25:500,
                  effect_size = cohend(c(.1, .15, .2, .25, .3), 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;))

icc0.9_vr_0.018_d0.2 &amp;lt;-
  study_parameters(n1 = t,
                 n2 = n,
                 icc_pre_subject = 0.9,
                  var_ratio = 0.018,
                  effect_size = cohend(-0.2, 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;),
                 dropout = dropout_manual(0, 0.2, 0.4)) %&amp;gt;% 
  get_power_table(n2 = 25:500,
                  effect_size = cohend(c(.1, .15, .2, .25, .3), 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;))

icc0.9_vr_0.018_d0.3 &amp;lt;-
  study_parameters(n1 = t,
                 n2 = n,
                 icc_pre_subject = 0.9,
                  var_ratio = 0.018,
                  effect_size = cohend(-0.2, 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;),
                 dropout = dropout_manual(0, 0.3, 0.6)) %&amp;gt;% 
  get_power_table(n2 = 25:500,
                  effect_size = cohend(c(.1, .15, .2, .25, .3), 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;))

# variance ratio 0.281
icc0.9_vr_0.281_d0.1 &amp;lt;-
  study_parameters(n1 = t,
                 n2 = n,
                 icc_pre_subject = 0.9,
                  var_ratio = 0.281,
                  effect_size = cohend(-0.2, 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;),
                 dropout = dropout_manual(0, 0.1, 0.2)) %&amp;gt;% 
  get_power_table(n2 = 25:500,
                  effect_size = cohend(c(.1, .15, .2, .25, .3), 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;))

icc0.9_vr_0.281_d0.2 &amp;lt;-
  study_parameters(n1 = t,
                 n2 = n,
                 icc_pre_subject = 0.9,
                  var_ratio = 0.281,
                  effect_size = cohend(-0.2, 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;),
                 dropout = dropout_manual(0, 0.2, 0.4)) %&amp;gt;% 
  get_power_table(n2 = 25:500,
                  effect_size = cohend(c(.1, .15, .2, .25, .3), 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;))

icc0.9_vr_0.281_d0.3 &amp;lt;-
  study_parameters(n1 = t,
                 n2 = n,
                 icc_pre_subject = 0.9,
                  var_ratio = 0.281,
                  effect_size = cohend(-0.2, 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;),
                 dropout = dropout_manual(0, 0.3, 0.6)) %&amp;gt;% 
  get_power_table(n2 = 25:500,
                  effect_size = cohend(c(.1, .15, .2, .25, .3), 
                                       standardizer = &amp;quot;pretest_SD&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the power curve plots, beginning with the plot for the smaller variance ratio of 0.018.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  icc0.9_vr_0.018_d0.1 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.018_d0.2 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.018_d0.3
) %&amp;gt;% 
  mutate(missing = c(rep(str_c(c(10, 20, 30, 00), &amp;quot;% missing per time point after baseline&amp;quot;), each = n() / 4))) %&amp;gt;% 
  
  mutate(d = factor(effect_size,
                    levels = c(&amp;quot;0.1&amp;quot;, &amp;quot;0.15&amp;quot;, &amp;quot;0.2&amp;quot;, &amp;quot;0.25&amp;quot;, &amp;quot;0.3&amp;quot;),
                    labels = c(&amp;quot;.10&amp;quot;, &amp;quot;.15&amp;quot;, &amp;quot;.20&amp;quot;, &amp;quot;.25&amp;quot;, &amp;quot;.30&amp;quot;))) %&amp;gt;% 
  mutate(d = fct_rev(d)) %&amp;gt;% 
  
  ggplot(aes(x = tot_n, y = power, color = d)) +
  geom_vline(xintercept = 500, color = &amp;quot;white&amp;quot;, size = 1) +
  geom_hline(yintercept = .8, color = &amp;quot;white&amp;quot;, size = 1) +
  geom_line(size = 1.5) +
  scale_color_viridis_d(expression(paste(&amp;quot;Cohen&amp;#39;s &amp;quot;, italic(d))),
                        option = &amp;quot;A&amp;quot;, end = .67, direction = -1) +
  scale_x_continuous(expression(paste(italic(N), &amp;quot; (i.e., the total sample size)&amp;quot;)), 
                     breaks = seq(from = 0, to = 1000, by = 100), limits = c(0, 1000)) +
  scale_y_continuous(breaks = c(0, .2, .4, .6, .8, 1), limits = c(0, 1)) +
  ggtitle(&amp;quot;Power curves based on a variance ratio of 0.018&amp;quot;) +
  theme(panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()) +
  facet_wrap(~missing)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-07-02-example-power-analysis-report/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;816&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here is the power curve plot for the larger variance ratio of 0.281.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  icc0.9_vr_0.281_d0.1 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.281_d0.2 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.281_d0.3
) %&amp;gt;% 
  mutate(missing = c(rep(str_c(c(10, 20, 30, 00), &amp;quot;% missing per time point after baseline&amp;quot;), each = n() / 4))) %&amp;gt;% 
  
  mutate(d = factor(effect_size,
                    levels = c(&amp;quot;0.1&amp;quot;, &amp;quot;0.15&amp;quot;, &amp;quot;0.2&amp;quot;, &amp;quot;0.25&amp;quot;, &amp;quot;0.3&amp;quot;),
                    labels = c(&amp;quot;.10&amp;quot;, &amp;quot;.15&amp;quot;, &amp;quot;.20&amp;quot;, &amp;quot;.25&amp;quot;, &amp;quot;.30&amp;quot;))) %&amp;gt;% 
  mutate(d = fct_rev(d)) %&amp;gt;% 
  
  ggplot(aes(x = tot_n, y = power, color = d)) +
  geom_vline(xintercept = 500, color = &amp;quot;white&amp;quot;, size = 1) +
  geom_hline(yintercept = .8, color = &amp;quot;white&amp;quot;, size = 1) +
  geom_line(size = 1.5) +
  scale_color_viridis_d(expression(paste(&amp;quot;Cohen&amp;#39;s &amp;quot;, italic(d))),
                        option = &amp;quot;A&amp;quot;, end = .67, direction = -1) +
  scale_x_continuous(expression(paste(italic(N), &amp;quot; (i.e., the total sample size)&amp;quot;)), 
                     breaks = seq(from = 0, to = 1000, by = 100), limits = c(0, 1000)) +
  scale_y_continuous(breaks = c(0, .2, .4, .6, .8, 1), limits = c(0, 1)) +
  ggtitle(&amp;quot;Power curves based on a variance ratio of 0.281&amp;quot;) +
  theme(panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank()) +
  facet_wrap(~missing)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-07-02-example-power-analysis-report/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;816&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The upshot of the variance ratio issue is that a higher variance ratio led to lower power. To be on the safe side, &lt;em&gt;I recommend leaning on the more conservative power curve estimates from the simulations based on the larger variance ratio&lt;/em&gt;, &lt;strong&gt;0.281&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;A more succinct way to summarize the information in the power curves in with two tables. Here is the minimum total sample size required to reach a power of .8 based on the smaller evidence ratio of 0.018 and the various combinations of Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and dropout:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  icc0.9_vr_0.018_d0.1 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.018_d0.2 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.018_d0.3
) %&amp;gt;% 
  mutate(missing = c(rep(c(10, 20, 30, 00), each = n() / 4))) %&amp;gt;% 

  filter(power &amp;gt; .8) %&amp;gt;% 
  group_by(missing, effect_size) %&amp;gt;% 
  top_n(-1, power) %&amp;gt;% 
  select(-n2, -power, -dropout) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(`Cohen&amp;#39;s d` = effect_size) %&amp;gt;% 
  
  ggplot(aes(x = `Cohen&amp;#39;s d`, y = missing)) +
  geom_tile(aes(fill = tot_n),
            show.legend = F) +
  geom_text(aes(label = tot_n, color = tot_n &amp;lt; 700),
            show.legend = F) +
  scale_fill_viridis_c(option = &amp;quot;B&amp;quot;, begin = .1, end = .70 ,limits = c(0, 1000)) +
  scale_color_manual(values = c(&amp;quot;black&amp;quot;, &amp;quot;white&amp;quot;)) +
  labs(title = expression(paste(&amp;quot;Total &amp;quot;, italic(N), &amp;quot; required for .8 power, based on a variance ratio of 0.018&amp;quot;)),
       subtitle = expression(paste(&amp;quot;The power simulations only considered up to &amp;quot;, italic(N), &amp;quot; = 1,000.&amp;quot;)),
       x = expression(paste(&amp;quot;Cohen&amp;#39;s &amp;quot;, italic(d))),
       y = &amp;quot;% missing\nper follow-up&amp;quot;) +
  theme(axis.ticks = element_blank(),
        panel.grid = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-07-02-example-power-analysis-report/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;624&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here is an alternative version of that plot, this time based on the more conservative variance ratio of 0.281.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  icc0.9_vr_0.281_d0.1 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.281_d0.2 %&amp;gt;% filter(dropout == &amp;quot;with missing&amp;quot;),
  icc0.9_vr_0.281_d0.3
) %&amp;gt;% 
  mutate(missing = c(rep(c(10, 20, 30, 00), each = n() / 4))) %&amp;gt;% 

  filter(power &amp;gt; .8) %&amp;gt;% 
  group_by(missing, effect_size) %&amp;gt;% 
  top_n(-1, power) %&amp;gt;% 
  select(-n2, -power, -dropout) %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(`Cohen&amp;#39;s d` = effect_size) %&amp;gt;% 
  
  ggplot(aes(x = `Cohen&amp;#39;s d`, y = missing)) +
  geom_tile(aes(fill = tot_n),
            show.legend = F) +
  geom_text(aes(label = tot_n, color = tot_n &amp;lt; 700),
            show.legend = F) +
  scale_fill_viridis_c(option = &amp;quot;B&amp;quot;, begin = .1, end = .70 ,limits = c(0, 1000)) +
  scale_color_manual(values = c(&amp;quot;black&amp;quot;, &amp;quot;white&amp;quot;)) +
  labs(title = expression(paste(&amp;quot;Total &amp;quot;, italic(N), &amp;quot; required for .8 power, based on variance ratio of 0.281&amp;quot;)),
       subtitle = expression(paste(&amp;quot;The power simulations only considered up to &amp;quot;, italic(N), &amp;quot; = 1,000.&amp;quot;)),
       x = expression(paste(&amp;quot;Cohen&amp;#39;s &amp;quot;, italic(d))),
       y = &amp;quot;% missing\nper follow-up&amp;quot;) +
  theme(axis.ticks = element_blank(),
        panel.grid = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-07-02-example-power-analysis-report/index_files/figure-html/unnamed-chunk-13-1.png&#34; width=&#34;624&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Again, I recommend playing it safe and relying on the power estimates based on the larger variance ratio of 0.281. Those power curves indicate that even with rather large dropout (i.e., 30% at the second time point and another 30% at the final time point), &lt;span class=&#34;math inline&#34;&gt;\(N = 486\)&lt;/span&gt; is sufficient to detect a small effect size (i.e., &lt;span class=&#34;math inline&#34;&gt;\(d = 0.2\)&lt;/span&gt;) at the conventional .8 power threshold. Note that because we cut off the power simulations at &lt;span class=&#34;math inline&#34;&gt;\(N = 1{,}000\)&lt;/span&gt;, we never reached .8 power in the conditions where &lt;span class=&#34;math inline&#34;&gt;\(d = 0.1\)&lt;/span&gt; and there was missingness at or greater than 0% dropout at each follow-up time point.&lt;/p&gt;
&lt;p&gt;To clarify, &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt; in each cell is the total sample size presuming both the control and experimental conditions have equal numbers in each. Thus, &lt;span class=&#34;math inline&#34;&gt;\(n_\text{control} = n_\text{experimental} = N/2\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;wrap-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Wrap up&lt;/h2&gt;
&lt;p&gt;I presented the original report with an HTML document, which used the R Markdown &lt;a href=&#34;https://community.rstudio.com/t/notebook-with-code-folding-hide-by-default/55845&#34;&gt;code folding&lt;/a&gt; option, which hid my code, by default. Since I’m not aware of a good way to use code folding with &lt;strong&gt;blogdown&lt;/strong&gt; blog posts, here you see the code in all its glory.&lt;/p&gt;
&lt;p&gt;All you Bayesian freaks may have noticed that this was a conventional frequentist power analysis. I’m not always a Bayesian. 🤷 When you intend to analyze experimental RCT-like data with frequentist software, the &lt;a href=&#34;https://github.com/rpsychologist/powerlmm&#34;&gt;&lt;strong&gt;powerlmm&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-powerlmm&#34; role=&#34;doc-biblioref&#34;&gt;Magnusson, 2018&lt;/a&gt;)&lt;/span&gt; can come in really handy.&lt;/p&gt;
&lt;p&gt;Had I intended to share a report like this for a broader audience, possibly as supplemental material for a paper, I might have explained the &lt;strong&gt;powerlmm&lt;/strong&gt; code a bit more. Since this was originally meant for internal use, my main goal was to present the results with an extra bit of transparency for the sake of building trust with a new collaborator. It worked, by the way. This person’s grant money now pays for part of my salary.&lt;/p&gt;
&lt;p&gt;If this was supplementary material, I would have also spent more time explicitly showing where I got the Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt;, ICC, and variance ratio values.&lt;/p&gt;
&lt;p&gt;If you didn’t notice, the context for this power analysis wasn’t ideal. Even though I pulled information from two different data sources, neither was ideal and their combination wasn’t, either. Though my collaborator’s pilot data let me compute the Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; and the ICC, I didn’t have access to the raw data, themselves. Without that, I had no good way to compute the variance ratio. As it turns out, that was a big deal. Though I was able to compute variance ratios from different data from a similar population, it wasn’t on the same criterion variable. The best place to be in is if you have pilot data from the same population and on the same criterion variable. Outside of that, you’re making assumptions about model parameters you might not have spent a lot of time pondering, before. Welcome to the world of multilevel power analyses, friends. Keep your chins up. It’s rough, out there.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] forcats_0.5.1   stringr_1.4.0   dplyr_1.0.6     purrr_0.3.4    
## [5] readr_1.4.0     tidyr_1.1.3     tibble_3.1.2    ggplot2_3.3.3  
## [9] tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##  [1] tidyselect_1.1.1  xfun_0.23         bslib_0.2.4       haven_2.3.1      
##  [5] colorspace_2.0-0  vctrs_0.3.8       generics_0.1.0    viridisLite_0.4.0
##  [9] htmltools_0.5.1.1 emo_0.0.0.9000    yaml_2.2.1        utf8_1.2.1       
## [13] rlang_0.4.11      jquerylib_0.1.4   pillar_1.6.1      withr_2.4.2      
## [17] glue_1.4.2        DBI_1.1.0         dbplyr_2.0.0      modelr_0.1.8     
## [21] readxl_1.3.1      lifecycle_1.0.0   munsell_0.5.0     blogdown_1.3     
## [25] gtable_0.3.0      cellranger_1.1.0  rvest_0.3.6       evaluate_0.14    
## [29] labeling_0.4.2    knitr_1.33        MBESS_4.8.0       fansi_0.4.2      
## [33] highr_0.9         broom_0.7.6       Rcpp_1.0.6        backports_1.2.1  
## [37] scales_1.1.1      jsonlite_1.7.2    farver_2.1.0      fs_1.5.0         
## [41] hms_0.5.3         digest_0.6.27     stringi_1.6.2     bookdown_0.22    
## [45] grid_4.0.4        cli_2.5.0         tools_4.0.4       magrittr_2.0.1   
## [49] sass_0.3.1        crayon_1.4.1      pkgconfig_2.0.3   ellipsis_0.3.2   
## [53] xml2_1.3.2        reprex_0.3.0      lubridate_1.7.9.2 rstudioapi_0.13  
## [57] assertthat_0.2.1  rmarkdown_2.8     httr_1.4.2        R6_2.5.0         
## [61] compiler_4.0.4&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-R-powerlmm&#34; class=&#34;csl-entry&#34;&gt;
Magnusson, K. (2018). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;powerlmm&lt;/span&gt;: &lt;span&gt;Power&lt;/span&gt; analysis for longitudinal multilevel models&lt;/em&gt; [Manual]. &lt;a href=&#34;https://github.com/rpsychologist/powerlmm&#34;&gt;https://github.com/rpsychologist/powerlmm&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian power analysis: Part III.b. What about 0/1 data?</title>
      <link>/post/bayesian-power-analysis-part-iii-b/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      <guid>/post/bayesian-power-analysis-part-iii-b/</guid>
      <description>
&lt;script src=&#34;/post/bayesian-power-analysis-part-iii-b/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;version-1.1.0&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Version 1.1.0&lt;/h2&gt;
&lt;p&gt;Edited on April 21, 2021, to fix a few code breaks and add a Reference section.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;orientation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Orientation&lt;/h2&gt;
&lt;p&gt;In the &lt;a href=&#34;https://solomonkurz.netlify.com/post/bayesian-power-analysis-part-iii-a/&#34;&gt;last post&lt;/a&gt;, we covered how the Poisson distribution is handy for modeling count data. Binary data are even weirder than counts. They typically only take on two values: 0 and 1. Sometimes 0 is a stand-in for “no” and 1 for “yes” (e.g., &lt;em&gt;Are you an expert in Bayesian power analysis?&lt;/em&gt; For me that would be &lt;code&gt;0&lt;/code&gt;). You can also have data of this kind if you asked people whether they’d like to choose option A or B. With those kinds of data, you might arbitrarily code A as 0 and B as 1. Binary data also often stand in for trials where 0 = “fail” and 1 = “success.” For example, if you answered “Yes” to the question &lt;em&gt;Are all data normally distributed?&lt;/em&gt; we’d mark your answer down as a &lt;code&gt;0&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Though 0’s and 1’s are popular, sometimes binary data appear in their aggregated form. Let’s say I gave you 10 algebra questions and you got 7 of them right. Here’s one way to encode those data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 10
z &amp;lt;- 7

rep(0:1, times = c(n - z, z))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  [1] 0 0 0 1 1 1 1 1 1 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In that example, &lt;code&gt;n&lt;/code&gt; stood for the total number of trials and &lt;code&gt;z&lt;/code&gt; was the number you got correct (i.e., the number of times we encoded your response as a 1). A more compact way to encode that data is with two columns, one for &lt;code&gt;z&lt;/code&gt; and the other for &lt;code&gt;n&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

tibble(z = z,
       n = n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 2
##       z     n
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     7    10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So then if you gave those same 10 questions to four of your friends, we could encode the results like this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(3)

tibble(id = letters[1:5],
       z  = rpois(n = 5, lambda = 5),
       n  = n)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 × 3
##   id        z     n
##   &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt;
## 1 a         3    10
## 2 b         7    10
## 3 c         4    10
## 4 d         4    10
## 5 e         5    10&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you were &lt;code&gt;b&lt;/code&gt;, you’d be the smart one in the group.&lt;/p&gt;
&lt;p&gt;Anyway, whether working with binary or aggregated binary data, we’re interested in the probability a given trial will be 1.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;logistic-regression-with-unaggregated-binary-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Logistic regression with unaggregated binary data&lt;/h2&gt;
&lt;p&gt;Taking unaggregated binary data as a starting point, given &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; data that includes a variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; where the value in the &lt;span class=&#34;math inline&#34;&gt;\(i^\text{th}\)&lt;/span&gt; row is a 0 or a 1, we’d like to know the probability a given trial would be 1, given &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; [i.e., &lt;span class=&#34;math inline&#34;&gt;\(p(y_i = 1 | d)\)&lt;/span&gt;]. The binomial distribution will help us get that estimate for &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;. We’ll do so within the context of a logistic regression model following the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_i                        &amp;amp; \sim \text{Binomial} (n = 1, p_i) \\
\operatorname{logit} (p_i) &amp;amp; = \beta_0,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;were the logit function is defined as the log odds&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\operatorname{logit} (p_i) = \log \left (\frac{p_i}{1 - p_i} \right ),
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which also means that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\log \left (\frac{p_i}{1 - p_i} \right ) = \beta_0.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;In those formulas, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the intercept. In a binomial model with no predictors&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, the intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is just the estimate for &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;, but in the log-odds metric. So yes, similar to the Poisson models from the last post, we typically use a link function with our binomial models. Instead of the log link, we use the logit because it constrains the posterior for &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; to values between 0 and 1. Just as the null value for a probability is .5, the null value for the parameters within a logistic regression model is typically 0.&lt;/p&gt;
&lt;p&gt;As with the Poisson, I’m not going to go into a full-blown tutorial on the binomial distribution or on logistic regression. For more thorough introductions, check out chapters 9 through 10 in McElreath’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;&lt;em&gt;Statistical rethinking&lt;/em&gt;&lt;/a&gt; or Agresti’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-agrestiFoundationsLinearGeneralized2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&#34;&gt;&lt;em&gt;Foundations of linear and generalized linear models&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;we-need-data.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;We need data.&lt;/h3&gt;
&lt;p&gt;Time to simulate some data. Let’s say we’d like to estimate the probability someone will hit a ball in a baseball game. Nowadays, batting averages for professional baseball players tend around .25 (see &lt;a href=&#34;http://www.baseball-almanac.com/hitting/hibavg4.shtml&#34;&gt;here&lt;/a&gt;). So if we wanted to simulate 50 at-bats, we might do so like this.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(3)

d &amp;lt;- tibble(y = rbinom(n = 50, size = 1, prob = .25))

str(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## tibble [50 × 1] (S3: tbl_df/tbl/data.frame)
##  $ y: int [1:50] 0 1 0 0 0 0 0 0 0 0 ...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are what those data look like in a bar plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_set(theme_gray() + theme(panel.grid = element_blank()))

d %&amp;gt;% 
  mutate(y = factor(y)) %&amp;gt;% 
  
  ggplot(aes(x = y)) +
  geom_bar()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-b/index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;288&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;time-to-model.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Time to model.&lt;/h3&gt;
&lt;p&gt;To practice modeling those data, we’ll want to fire up the &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;&lt;strong&gt;brms&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-burknerBrmsPackageBayesian2017&#34; role=&#34;doc-biblioref&#34;&gt;Bürkner, 2017&lt;/a&gt;, &lt;a href=&#34;#ref-burknerAdvancedBayesianMultilevel2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;, &lt;a href=&#34;#ref-R-brms&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can use the &lt;code&gt;get_prior()&lt;/code&gt; function to get the &lt;strong&gt;brms&lt;/strong&gt; default for our intercept-only logistic regression model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_prior(data = d, 
          family = binomial,
          y | trials(1) ~ 1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Intercept ~ student_t(3, 0, 2.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As it turns out, that’s a really liberal prior. We might step up a bit and put a more skeptical &lt;code&gt;normal(0, 2)&lt;/code&gt; prior on that intercept. With the context of our logit link, that still puts a 95% probability that the &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; is between .02 and .98, which is almost the entire parameter space. Here’s how to fit the model with the &lt;code&gt;brm()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit1 &amp;lt;-
  brm(data = d, 
      family = binomial,
      y | trials(1) ~ 1,
      prior(normal(0, 2), class = Intercept),
      seed = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the &lt;code&gt;brm()&lt;/code&gt; formula syntax, including a &lt;code&gt;|&lt;/code&gt; bar on the left side of a formula indicates we have extra supplementary information about our criterion variable. In this case, that information is that each &lt;code&gt;y&lt;/code&gt; value corresponds to a single trial [i.e., &lt;code&gt;trials(1)&lt;/code&gt;], which itself corresponds to the &lt;span class=&#34;math inline&#34;&gt;\(n = 1\)&lt;/span&gt; portion of the statistical formula, above. Here are the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(fit1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: binomial 
##   Links: mu = logit 
## Formula: y | trials(1) ~ 1 
##    Data: d (Number of observations: 50) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -1.39      0.36    -2.12    -0.71 1.00     1622     1434
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Remember that that intercept is on the scale of the logit link, the log odds. We can transform it with the &lt;code&gt;brms::inv_logit_scaled()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(fit1)[&amp;quot;Intercept&amp;quot;, 1] %&amp;gt;% 
  inv_logit_scaled()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.1995929&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we’d like to view the full posterior distribution, we’ll need to work with the posterior draws themselves. Then we’ll plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# extract the posterior draws
posterior_samples(fit1) %&amp;gt;% 
  # transform from the log-odds to a probability metric
  transmute(p = inv_logit_scaled(b_Intercept)) %&amp;gt;% 
  
  # plot!
  ggplot(aes(x = p)) +
  geom_density(fill = &amp;quot;grey25&amp;quot;, size = 0) +
  scale_x_continuous(&amp;quot;probability of a hit&amp;quot;, limits = c(0, 1)) +
  scale_y_continuous(NULL, breaks = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Method &amp;#39;posterior_samples&amp;#39; is deprecated. Please see ?as_draws for
## recommended alternatives.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-b/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Looks like the null hypothesis of &lt;span class=&#34;math inline&#34;&gt;\(p = .5\)&lt;/span&gt; is not credible for this simulation. If we’d like the posterior median and percentile-based 95% intervals, we might use the &lt;code&gt;median_qi()&lt;/code&gt; function from the handy &lt;a href=&#34;https://mjskay.github.io/tidybayes/&#34;&gt;&lt;strong&gt;tidybayes&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-tidybayes&#34; role=&#34;doc-biblioref&#34;&gt;Kay, 2020&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidybayes)

posterior_samples(fit1) %&amp;gt;% 
  transmute(p = inv_logit_scaled(b_Intercept)) %&amp;gt;% 
  median_qi()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 6
##       p .lower .upper .width .point .interval
##   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;    
## 1 0.201  0.108  0.330   0.95 median qi&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yep, .5 was not within those intervals.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;but-what-about-power&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;But what about power?&lt;/h3&gt;
&lt;p&gt;That’s enough preliminary work. Let’s see what happens when we do a mini power analysis with 100 iterations. First we set up our simulation function using the same methods we introduced in earlier blog posts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_data_fit &amp;lt;- function(seed, n_player) {
  
  n_trials &amp;lt;- 1
  prob_hit &amp;lt;- .25
  
  set.seed(seed)
  
  d &amp;lt;- tibble(y = rbinom(n    = n_player, 
                         size = n_trials, 
                         prob = prob_hit))
  
  update(fit1,
         newdata = d,
         seed = seed) %&amp;gt;% 
  posterior_samples() %&amp;gt;% 
  transmute(p = inv_logit_scaled(b_Intercept)) %&amp;gt;% 
  median_qi() %&amp;gt;% 
    select(.lower:.upper)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Simulate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim1 &amp;lt;-
  tibble(seed = 1:100) %&amp;gt;% 
  mutate(ci = map(seed, sim_data_fit, n_player = 50)) %&amp;gt;% 
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You might plot the intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim1 %&amp;gt;% 
  ggplot(aes(x = seed, ymin = .lower, ymax = .upper)) +
  geom_hline(yintercept = c(.25, .5), color = &amp;quot;white&amp;quot;) +
  geom_linerange() +
  xlab(&amp;quot;seed (i.e., simulation index)&amp;quot;) +
  scale_y_continuous(&amp;quot;probability of hitting the ball&amp;quot;, limits = c(0, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-b/index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Like one of my old coworkers used to say: &lt;em&gt;Purtier ’n a hog!&lt;/em&gt; Here we’ll summarize the results both in terms of their conventional power, their mean width, and the proportion of widths more narrow than .25. &lt;em&gt;Why .25?&lt;/em&gt; I don’t know. Without a substantively-informed alternative, it’s as good a criterion as any.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim1 %&amp;gt;% 
  mutate(width = .upper - .lower) %&amp;gt;% 
  summarise(`conventional power` = mean(.upper &amp;lt; .5),
            `mean width`         = mean(width),
            `width below .25`    = mean(width &amp;lt; .25))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 3
##   `conventional power` `mean width` `width below .25`
##                  &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;             &amp;lt;dbl&amp;gt;
## 1                 0.95        0.231              0.78&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Depending on your study needs, you’d adjust your sample size accordingly, do a mini simulation or two first, and then follow up with a proper power simulation with 1000+ iterations.&lt;/p&gt;
&lt;p&gt;I should point out that whereas in the last post we evaluated the power of the Poisson model with the parameters on the scale of the link function, here we evaluated the power for our logistic regression model after transforming the intercept back into the probability metric. Both methods are fine. I recommend you run your power simulation based on how you want to interpret and report your results.&lt;/p&gt;
&lt;p&gt;We should also acknowledge that this was our first example of a power simulation that wasn’t based on some group comparison. Comparing groups is fine and normal and important. And it’s also the case that we can care about power and/or parameter precision for more than group-based analyses. Our simulation-based approach is fine for both.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;aggregated-binomial-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Aggregated binomial regression&lt;/h2&gt;
&lt;p&gt;It’s no more difficult to simulate and work with aggregated binomial data. But since the mechanics for &lt;code&gt;brms::brm()&lt;/code&gt; and thus the down-the-road simulation setup are a little different, we should practice. With our new setup, we’ll consider a new example. Since .25 is the typical batting average, it might better sense to define the null hypothesis like this:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0 \text{: } p = .25.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Consider a case where we had some intervention where we expected a new batting average of .35. How many trials would we need, then, to either reject &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; or perhaps estimate &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt; with a satisfactory degree of precision? Here’s what the statistical formula for the implied aggregated binomial model might look like:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_i                        &amp;amp; \sim \text{Binomial} (n, p_i) \\
\operatorname{logit} (p_i) &amp;amp; = \beta_0.
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The big change is we no longer defined &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; as 1. Let’s say we wanted our aggregated binomial data set to contain the summary statistics for &lt;span class=&#34;math inline&#34;&gt;\(n = 100\)&lt;/span&gt; trials. Here’s what that might look like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_trials &amp;lt;- 100
prob_hit &amp;lt;- .35

set.seed(3)

d &amp;lt;- tibble(n_trials = n_trials,
            y = rbinom(n    = 1, 
                       size = n_trials, 
                       prob = prob_hit))

d&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 2
##   n_trials     y
##      &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1      100    32&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have two columns. The first, &lt;code&gt;n_trials&lt;/code&gt;, indicates how many cases or trials we’re summarizing. The second, &lt;code&gt;y&lt;/code&gt;, indicates how many successes/1’s/hits we might expect given &lt;span class=&#34;math inline&#34;&gt;\(p = .35\)&lt;/span&gt;. This is the aggregated binomial equivalent of if we had a 100-row vector composed of 32 1s and 68 0s.&lt;/p&gt;
&lt;p&gt;Now, before we discuss fitting the model with &lt;strong&gt;brms&lt;/strong&gt;, let’s talk priors. Since we’ve updated our definition of &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;, it might make sense to update the prior for &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;. As it turns out, setting that prior to &lt;code&gt;normal(-1, 0.5)&lt;/code&gt; puts the posterior mode at about .25 on the probability space, but with fairly wide 95% intervals ranging from about .12 to .5. Though centered on our updated null value, this prior is still quite permissive given our hypothesized &lt;span class=&#34;math inline&#34;&gt;\(p = .35\)&lt;/span&gt;. Let’s give it a whirl.&lt;/p&gt;
&lt;p&gt;To fit an aggregated binomial model with the &lt;code&gt;brm()&lt;/code&gt; function, we augment the &lt;code&gt;&amp;lt;criterion&amp;gt; | trials()&lt;/code&gt; syntax where the value that goes in &lt;code&gt;trials()&lt;/code&gt; is either a fixed number or variable in the data indexing &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. Our approach will be the latter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit2 &amp;lt;-
  brm(data = d, 
      family = binomial,
      y | trials(n_trials) ~ 1,
      prior(normal(-1, 0.5), class = Intercept),
      seed = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Inspect the summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(fit2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: binomial 
##   Links: mu = logit 
## Formula: y | trials(n_trials) ~ 1 
##    Data: d (Number of observations: 1) 
##   Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup draws = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -0.80      0.20    -1.19    -0.42 1.00     1524     1697
## 
## Draws were sampled using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After a transformation, here’s what that looks like in a plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(fit2) %&amp;gt;% 
  transmute(p = inv_logit_scaled(b_Intercept)) %&amp;gt;% 
  
  ggplot(aes(x = p, y = 0)) +
  stat_halfeye(.width = c(.5, .95)) +
  scale_x_continuous(&amp;quot;probability of a hit&amp;quot;, limits = c(0, 1)) +
  scale_y_continuous(NULL, breaks = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Warning: Method &amp;#39;posterior_samples&amp;#39; is deprecated. Please see ?as_draws for
## recommended alternatives.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-b/index_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Based on a single simulation, it looks like &lt;span class=&#34;math inline&#34;&gt;\(n = 100\)&lt;/span&gt; won’t quite be enough to reject &lt;span class=&#34;math inline&#34;&gt;\(H_0 \text{: } p = .25\)&lt;/span&gt; with a conventional 2-sided 95% interval. But it does look like we’re in the ballpark and that our basic data + model setup will work for a larger-scale simulation. Here’s an example of how you might update our custom simulation function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_data_fit &amp;lt;- function(seed, n_trials) {
  
  prob_hit &amp;lt;- .35
  
  set.seed(seed)
  
  d &amp;lt;- tibble(y = rbinom(n    = 1, 
                         size = n_trials, 
                         prob = prob_hit),
              n_trials = n_trials)
  
  update(fit2,
         newdata = d,
         seed = seed) %&amp;gt;% 
  posterior_samples() %&amp;gt;% 
  transmute(p = inv_logit_scaled(b_Intercept)) %&amp;gt;% 
  median_qi() %&amp;gt;% 
    select(.lower:.upper)
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Simulate, this time trying out &lt;span class=&#34;math inline&#34;&gt;\(n = 120\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim2 &amp;lt;-
  tibble(seed = 1:100) %&amp;gt;% 
  mutate(ci = map(seed, sim_data_fit, n_trials = 120)) %&amp;gt;% 
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Plot the intervals.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim2 %&amp;gt;% 
  ggplot(aes(x = seed, ymin = .lower, ymax = .upper)) +
  geom_hline(yintercept = c(.25, .35), color = &amp;quot;white&amp;quot;) +
  geom_linerange() +
  xlab(&amp;quot;seed (i.e., simulation index)&amp;quot;) +
  scale_y_continuous(&amp;quot;probability of hitting the ball&amp;quot;,
                     limits = c(0, 1), breaks = c(0, .25, .35, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-b/index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Overall, those intervals look pretty good. They’re fairly narrow and are hovering around the data generating &lt;span class=&#34;math inline&#34;&gt;\(p = .35\)&lt;/span&gt;. But many are still crossing the .25 threshold. Let’s see the results of a formal summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim2 %&amp;gt;% 
  mutate(width = .upper - .lower) %&amp;gt;% 
  summarise(`conventional power` = mean(.lower &amp;gt; .25),
            `mean width`         = mean(width),
            `width below .2`     = mean(width &amp;lt; .2))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 × 3
##   `conventional power` `mean width` `width below .2`
##                  &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;            &amp;lt;dbl&amp;gt;
## 1                 0.54        0.155                1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All widths were narrower than .2 and the mean width was about .16. In the abstract that might seem reasonably precise. But we’re still not precise enough to reject &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; with a conventional power level. Depending on your needs, adjust the &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; accordingly and simulate again.&lt;/p&gt;
&lt;p&gt;Now you’ve got a sense of how to work with the binomial likelihood for (aggregated)binary data, next time we’ll play with Likert-type data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.1.1 (2021-08-10)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_3.0.1 brms_2.16.2     Rcpp_1.0.7      forcats_0.5.1  
##  [5] stringr_1.4.0   dplyr_1.0.7     purrr_0.3.4     readr_2.0.1    
##  [9] tidyr_1.1.3     tibble_3.1.4    ggplot2_3.3.5   tidyverse_1.3.1
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6          
##   [4] igraph_1.2.6         svUnit_1.0.6         splines_4.1.1       
##   [7] crosstalk_1.1.1      TH.data_1.0-10       rstantools_2.1.1    
##  [10] inline_0.3.19        digest_0.6.27        htmltools_0.5.2     
##  [13] rsconnect_0.8.24     fansi_0.5.0          magrittr_2.0.1      
##  [16] checkmate_2.0.0      tzdb_0.1.2           modelr_0.1.8        
##  [19] RcppParallel_5.1.4   matrixStats_0.60.1   sandwich_3.0-1      
##  [22] xts_0.12.1           prettyunits_1.1.1    colorspace_2.0-2    
##  [25] rvest_1.0.1          ggdist_3.0.0         haven_2.4.3         
##  [28] xfun_0.25            callr_3.7.0          crayon_1.4.1        
##  [31] jsonlite_1.7.2       lme4_1.1-27.1        survival_3.2-11     
##  [34] zoo_1.8-9            glue_1.4.2           gtable_0.3.0        
##  [37] emmeans_1.6.3        V8_3.4.2             distributional_0.2.2
##  [40] pkgbuild_1.2.0       rstan_2.26.3         abind_1.4-5         
##  [43] scales_1.1.1         mvtnorm_1.1-2        DBI_1.1.1           
##  [46] miniUI_0.1.1.1       xtable_1.8-4         stats4_4.1.1        
##  [49] StanHeaders_2.26.3   DT_0.19              htmlwidgets_1.5.3   
##  [52] httr_1.4.2           threejs_0.3.3        arrayhelpers_1.1-0  
##  [55] posterior_1.0.1      ellipsis_0.3.2       pkgconfig_2.0.3     
##  [58] loo_2.4.1            farver_2.1.0         sass_0.4.0          
##  [61] dbplyr_2.1.1         utf8_1.2.2           tidyselect_1.1.1    
##  [64] labeling_0.4.2       rlang_0.4.11         reshape2_1.4.4      
##  [67] later_1.3.0          munsell_0.5.0        cellranger_1.1.0    
##  [70] tools_4.1.1          cli_3.0.1            generics_0.1.0      
##  [73] broom_0.7.9          ggridges_0.5.3       evaluate_0.14       
##  [76] fastmap_1.1.0        yaml_2.2.1           processx_3.5.2      
##  [79] knitr_1.33           fs_1.5.0             nlme_3.1-152        
##  [82] mime_0.11            projpred_2.0.2       xml2_1.3.2          
##  [85] compiler_4.1.1       bayesplot_1.8.1      shinythemes_1.2.0   
##  [88] rstudioapi_0.13      gamm4_0.2-6          curl_4.3.2          
##  [91] reprex_2.0.1         bslib_0.3.0          stringi_1.7.4       
##  [94] highr_0.9            ps_1.6.0             blogdown_1.5        
##  [97] Brobdingnag_1.2-6    lattice_0.20-44      Matrix_1.3-4        
## [100] nloptr_1.2.2.2       markdown_1.1         shinyjs_2.0.0       
## [103] tensorA_0.36.2       vctrs_0.3.8          pillar_1.6.2        
## [106] lifecycle_1.0.0      jquerylib_0.1.4      bridgesampling_1.1-2
## [109] estimability_1.3     httpuv_1.6.2         R6_2.5.1            
## [112] bookdown_0.23        promises_1.2.0.1     gridExtra_2.3       
## [115] codetools_0.2-18     boot_1.3-28          colourpicker_1.1.0  
## [118] MASS_7.3-54          gtools_3.9.2         assertthat_0.2.1    
## [121] withr_2.4.2          shinystan_2.5.0      multcomp_1.4-17     
## [124] mgcv_1.8-36          parallel_4.1.1       hms_1.1.0           
## [127] grid_4.1.1           coda_0.19-4          minqa_1.2.4         
## [130] rmarkdown_2.10       shiny_1.6.0          lubridate_1.7.10    
## [133] base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-agrestiFoundationsLinearGeneralized2015&#34; class=&#34;csl-entry&#34;&gt;
Agresti, A. (2015). &lt;em&gt;Foundations of linear and generalized linear models&lt;/em&gt;. &lt;span&gt;John Wiley &amp;amp; Sons&lt;/span&gt;. &lt;a href=&#34;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&#34;&gt;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerBrmsPackageBayesian2017&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2017). &lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;An R&lt;/span&gt; package for &lt;span&gt;Bayesian&lt;/span&gt; multilevel models using &lt;span&gt;Stan&lt;/span&gt;. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;80&lt;/em&gt;(1), 1–28. &lt;a href=&#34;https://doi.org/10.18637/jss.v080.i01&#34;&gt;https://doi.org/10.18637/jss.v080.i01&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerAdvancedBayesianMultilevel2018&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2018). Advanced &lt;span&gt;Bayesian&lt;/span&gt; multilevel modeling with the &lt;span&gt;R&lt;/span&gt; package brms. &lt;em&gt;The R Journal&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(1), 395–411. &lt;a href=&#34;https://doi.org/10.32614/RJ-2018-017&#34;&gt;https://doi.org/10.32614/RJ-2018-017&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-brms&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;Bayesian&lt;/span&gt; regression models using ’&lt;span&gt;Stan&lt;/span&gt;’&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=brms&#34;&gt;https://CRAN.R-project.org/package=brms&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-tidybayes&#34; class=&#34;csl-entry&#34;&gt;
Kay, M. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;tidybayes&lt;/span&gt;: &lt;span&gt;Tidy&lt;/span&gt; data and ’geoms’ for &lt;span&gt;Bayesian&lt;/span&gt; models&lt;/em&gt;. &lt;a href=&#34;https://mjskay.github.io/tidybayes/&#34;&gt;https://mjskay.github.io/tidybayes/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2015&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2015). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;In case this is all new to you and you and you had the question in your mind: Yes, you can add predictors to the logistic regression model. Say we had a model with two predictors, &lt;span class=&#34;math inline&#34;&gt;\(x_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(x_2\)&lt;/span&gt;. Our statistical model would then follow the form &lt;span class=&#34;math inline&#34;&gt;\(\operatorname{logit} (p_i) = \beta_0 + \beta_1 x_{1i} + \beta_2 x_{2i}\)&lt;/span&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian power analysis: Part III.a. Counts are special.</title>
      <link>/post/bayesian-power-analysis-part-iii-a/</link>
      <pubDate>Sun, 11 Aug 2019 00:00:00 +0000</pubDate>
      <guid>/post/bayesian-power-analysis-part-iii-a/</guid>
      <description>
&lt;script src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;version-1.1.0&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Version 1.1.0&lt;/h2&gt;
&lt;p&gt;Edited on April 21, 2021, to remove the &lt;code&gt;broom::tidy()&lt;/code&gt; portion of the workflow.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;orientation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Orientation&lt;/h2&gt;
&lt;p&gt;So far we’ve covered Bayesian power simulations from both a null hypothesis orientation (see &lt;a href=&#34;https://solomonkurz.netlify.com/post/bayesian-power-analysis-part-i/&#34;&gt;part I&lt;/a&gt;) and a parameter width perspective (see &lt;a href=&#34;https://solomonkurz.netlify.com/post/bayesian-power-analysis-part-ii/&#34;&gt;part II&lt;/a&gt;). In both instances, we kept things simple and stayed with Gaussian (i.e., normally distributed) data. But not all data follow that form, so it might do us well to expand our skill set a bit. In the next few posts, we’ll cover how we might perform power simulations with other kinds of data. In this post, we’ll focus on how to use the Poisson likelihood to model counts. In follow-up posts, we’ll explore how to model binary and Likert-type data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-poisson-distribution-is-handy-for-counts.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The Poisson distribution is handy for counts.&lt;/h2&gt;
&lt;p&gt;In the social sciences, count data arise when we ask questions like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;How many sexual partners have you had?&lt;/li&gt;
&lt;li&gt;How many pets do you have at home?&lt;/li&gt;
&lt;li&gt;How many cigarettes did you smoke, yesterday?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The values these data will take are discrete&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; in that you’ve either slept with 9 or 10 people, but definitely not 9.5. The values cannot go below zero in that even if you quit smoking cold turkey 15 years ago and have been a health nut since, you still could not have smoked -3 cigarettes, yesterday. Zero is as low as it goes.&lt;/p&gt;
&lt;p&gt;The canonical distribution for data of this type–non-negative integers–is the Poisson. It’s named after the French mathematician Siméon Denis Poisson, &lt;a href=&#34;https://upload.wikimedia.org/wikipedia/commons/e/e8/E._Marcellot_Siméon-Denis_Poisson_1804.jpg&#34;&gt;who had quite the confident stare in his youth&lt;/a&gt;. The Poisson distribution has one parameter, &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;, which controls both its mean and variance. Although the numbers the Poisson describes are counts, the &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; parameter does not need to be an integer. For example, here’s the plot of 1,000 draws from a Poisson for which &lt;span class=&#34;math inline&#34;&gt;\(\lambda = 3.2\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

theme_set(theme_gray() + theme(panel.grid = element_blank()))

tibble(x = rpois(n = 1e3, lambda = 3.2)) %&amp;gt;% 
  mutate(x = factor(x)) %&amp;gt;% 
  
  ggplot(aes(x = x)) +
  geom_bar()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In case you missed it, the key function for generating those data was &lt;code&gt;rpois()&lt;/code&gt; (see &lt;code&gt;?rpois&lt;/code&gt;). I’m not going to go into a full-blown tutorial on the Poisson distribution or on count regression. For more thorough introductions, check out Atkins et al’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-atkinsTutorialOnCount2013&#34; role=&#34;doc-biblioref&#34;&gt;2013&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3513584/pdf/nihms396181.pdf&#34;&gt;&lt;em&gt;A tutorial on count regression and zero-altered count models for longitudinal substance use data&lt;/em&gt;&lt;/a&gt;, chapters 9 through 11 in McElreath’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;&lt;em&gt;Statistical Rethinking&lt;/em&gt;&lt;/a&gt;, or, if you really want to dive in, Agresti’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-agrestiFoundationsLinearGeneralized2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&#34;&gt;&lt;em&gt;Foundations of linear and generalized linear models&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For our power example, let’s say you were interested in drinking. Using data from &lt;a href=&#34;https://pubs.niaaa.nih.gov/publications/AA70/AA70.htm&#34;&gt;the National Epidemiologic Survey on Alcohol and Related Conditions&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-niaaaNationalEpidemiologicSurvey2006&#34; role=&#34;doc-biblioref&#34;&gt;{{National Institute on Alcohol Abuse and Alcoholism}}, 2006&lt;/a&gt;)&lt;/span&gt;, Christopher Ingraham &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-ingrahamThinkYouDrink2014&#34; role=&#34;doc-biblioref&#34;&gt;2014&lt;/a&gt;)&lt;/span&gt; presented &lt;a href=&#34;https://www.washingtonpost.com/news/wonk/wp/2014/09/25/think-you-drink-a-lot-this-chart-will-tell-you/?utm_term=.b81599bbbe25&#34;&gt;a data visualization&lt;/a&gt; of the average number of alcoholic drinks American adults consume, per week. By decile, the numbers were:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;0.00&lt;/li&gt;
&lt;li&gt;0.00&lt;/li&gt;
&lt;li&gt;0.00&lt;/li&gt;
&lt;li&gt;0.02&lt;/li&gt;
&lt;li&gt;0.14&lt;/li&gt;
&lt;li&gt;0.63&lt;/li&gt;
&lt;li&gt;2.17&lt;/li&gt;
&lt;li&gt;6.25&lt;/li&gt;
&lt;li&gt;15.28&lt;/li&gt;
&lt;li&gt;73.85&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Let’s say you wanted to run a study where you planned on comparing two demographic groups by their weekly drinking levels. Let’s further say you suspected one of those groups drank like the American adults in the 7&lt;sup&gt;th&lt;/sup&gt; decile and the other drank like American adults in the 8&lt;sup&gt;th&lt;/sup&gt;. We’ll call them low and high drinkers, respectively. For convenience, let’s further presume you’ll be able to recruit equal numbers of participants from both groups. The objective for our power analysis–or sample size analysis if you prefer to avoid the language of &lt;em&gt;power&lt;/em&gt;–is to determine how many you’d need per group to detect reliable differences. Using &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt; as a starting point, here’s what the data for our hypothetical groups might look like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mu_7 &amp;lt;- 2.17
mu_8 &amp;lt;- 6.25

n &amp;lt;- 50

set.seed(3)

d &amp;lt;-
  tibble(low  = rpois(n = n, lambda = mu_7),
         high = rpois(n = n, lambda = mu_8)) %&amp;gt;% 
  gather(group, count) 

d %&amp;gt;%
  mutate(count = factor(count)) %&amp;gt;% 
  
  ggplot(aes(x = count)) +
  geom_bar() +
  facet_wrap(~group, ncol = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This will be our primary data type. Our next step is to determine how to express our research question as a regression model. Like with our two-group Gaussian models, we can predict counts in terms of an intercept (i.e., standing for the expected value on the reference group) and slope (i.e., standing for the expected difference between the reference group and the comparison group). If we coded our two groups by a &lt;code&gt;high&lt;/code&gt; variable for which 0 stood for low drinkers and 1 stood for high drinkers, the basic model would follow the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\text{drinks_per_week}_i         &amp;amp; \sim \operatorname{Poisson}(\lambda_i) \\
\log(\lambda_i)   &amp;amp; = \beta_0 + \beta_1 \text{high}_i.
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here’s how to set the data up for that model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;-
  d %&amp;gt;% 
  mutate(high = ifelse(group == &amp;quot;low&amp;quot;, 0, 1))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you were attending closely to our model formula, you noticed we ran into a detail. Count regression, such as with the Poisson likelihood, tends to use the log link. &lt;em&gt;Why?&lt;/em&gt; you ask. Recall that counts need to be 0 and above. Same deal for our &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt; parameter. In order to make sure our models don’t yield silly estimates for &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;, like -2 or something, we typically use the log link. You don’t have to, of course. The world is your playground. But this is the method most of your colleagues are likely to use and it’s the one I suggest you use until you have compelling reasons to do otherwise.&lt;/p&gt;
&lt;p&gt;So then since we’re now fitting a model with a log link, it might seem challenging to pick good priors. As a place to start, we can use the &lt;code&gt;brms::get_prior()&lt;/code&gt; function to see the &lt;strong&gt;brms&lt;/strong&gt; defaults.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)

get_prior(data = d,
          family = poisson,
          count ~ 0 + Intercept + high)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   prior class      coef group resp dpar nlpar bound       source
##  (flat)     b                                            default
##  (flat)     b      high                             (vectorized)
##  (flat)     b Intercept                             (vectorized)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Hopefully two things popped out. First, there’s no prior of &lt;code&gt;class = sigma&lt;/code&gt;. Since the Poisson distribution only has one parameter &lt;span class=&#34;math inline&#34;&gt;\(\lambda\)&lt;/span&gt;, we don’t need to set a prior for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Our model won’t have one. Second, because we’re continuing to use the &lt;code&gt;0 + Intercept&lt;/code&gt; syntax for our model intercept, both our intercept and slope are of prior &lt;code&gt;class = b&lt;/code&gt; and those currently have default flat priors with &lt;strong&gt;brms&lt;/strong&gt;. To be sure, flat priors aren’t the best. But maybe if this was your first time playing around with a Poisson model, default flat priors might seem like a safe place to start. &lt;a href=&#34;https://xkcd.com/386/&#34;&gt;Feel free to disagree&lt;/a&gt;. In the meantime, here’s how to fit that default Poisson model with &lt;code&gt;brms::brm()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit1 &amp;lt;-
  brm(data = d,
      family = poisson,
      count ~ 0 + Intercept + high,
      seed = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(fit1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: poisson 
##   Links: mu = log 
## Formula: count ~ 0 + Intercept + high 
##    Data: d (Number of observations: 100) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.59      0.11     0.38     0.79 1.01      917     1133
## high          1.27      0.12     1.03     1.51 1.01      935     1182
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since we used the log link, our model results are in the log metric, too. If you’d like them in the metric of the data, you’d work directly with the poster samples and exponentiate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post &amp;lt;- 
  posterior_samples(fit1) %&amp;gt;% 
  mutate(`beta_0 (i.e., low)`                       = exp(b_Intercept),
         `beta_1 (i.e., difference score for high)` = exp(b_high))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can then just summarize our parameters of interest.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post %&amp;gt;% 
  select(starts_with(&amp;quot;beta_&amp;quot;)) %&amp;gt;% 
  gather() %&amp;gt;% 
  group_by(key) %&amp;gt;% 
  summarise(mean  = mean(value),
            lower = quantile(value, prob = .025),
            upper = quantile(value, prob = .975))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 4
##   key                                       mean lower upper
##   &amp;lt;chr&amp;gt;                                    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 beta_0 (i.e., low)                        1.81  1.46  2.21
## 2 beta_1 (i.e., difference score for high)  3.58  2.81  4.53&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the sake of simulation, it’ll be easier if we press on with evaluating the parameters on the log metric, though. If you’re working within a null-hypothesis oriented power paradigm, you’ll be happy to know zero is still the number to beat for evaluating our 95% intervals for &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;, even when that parameter is in the log metric. Here it is, again.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(fit1)[&amp;quot;high&amp;quot;, ]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Estimate Est.Error      Q2.5     Q97.5 
## 1.2690437 0.1211455 1.0330613 1.5108894&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So our first fit suggests we’re on good footing to run a quick power simulation holding &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt;. As in the prior blog posts, our lives will be simpler if we set up a custom simulation function. Since we’ll be using it to simulate the data and fit the model in one step, let’s call it &lt;code&gt;sim_data_fit()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_data_fit &amp;lt;- function(seed, n) {
  
  # define our mus in the function
  mu_7 &amp;lt;- 2.17
  mu_8 &amp;lt;- 6.25

  # make your results reproducible
  set.seed(seed)
  
  # simulate the data
  d &amp;lt;-
    tibble(high  = rep(0:1, each = n),
           count = c(rpois(n = n, lambda = mu_7),
                     rpois(n = n, lambda = mu_8)))
  
  # fit and summarize
  update(fit1,
         newdata = d,
         seed = seed) %&amp;gt;% 
    fixef() %&amp;gt;% 
    data.frame() %&amp;gt;% 
    rownames_to_column(&amp;quot;parameter&amp;quot;) %&amp;gt;% 
    filter(parameter == &amp;quot;high&amp;quot;) %&amp;gt;% 
    select(Q2.5:Q97.5 )
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the simulation for a simple 100 iterations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim1 &amp;lt;-
  tibble(seed = 1:100) %&amp;gt;% 
  mutate(ci = map(seed, sim_data_fit, n = 50)) %&amp;gt;% 
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That went quick–just a little over a minute on my laptop. Here’s what those 100 &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; intervals look like in bulk.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim1 %&amp;gt;% 
  ggplot(aes(x = seed, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = 0, color = &amp;quot;white&amp;quot;) +
  geom_linerange() +
  labs(x = &amp;quot;seed (i.e., simulation index)&amp;quot;,
       y = expression(beta[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;None of them are anywhere near the null value 0. So it appears we’re well above .8 power to reject the typical &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; with &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt;. Switching to the precision orientation, here’s the distribution of their widths.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim1 %&amp;gt;% 
  mutate(width = Q97.5 - Q2.5) %&amp;gt;% 
  
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = 0.01) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What if we wanted a mean width of 0.25 on the log scale? We might try the simulation with &lt;span class=&#34;math inline&#34;&gt;\(n = 150\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim2 &amp;lt;-
  tibble(seed = 1:100) %&amp;gt;% 
  mutate(ci = map(seed, sim_data_fit, n = 150)) %&amp;gt;% 
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we’ll summarize the widths both in terms of their mean and what proportion were smaller than 0.25.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim2 %&amp;gt;% 
  mutate(width = Q97.5 - Q2.5) %&amp;gt;% 
  summarise(`mean width` = mean(width),
            `below 0.25` = mean(width &amp;lt; 0.25))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   `mean width` `below 0.25`
##          &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1        0.252         0.43&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we wanted to focus on the mean, we did pretty good. Perhaps set the &lt;span class=&#34;math inline&#34;&gt;\(n = 155\)&lt;/span&gt; and simulate a full 1,000+ iterations for a serious power analysis. But if we wanted to make the stricter criteria of all below 0.25, we’d need to up the &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; quite a bit more. And of course, once you have a little experience working with Poisson models, you might do the power simulations with more ambitious priors. For example, if your count values are lower than like 1,000, there’s a good chance a &lt;code&gt;normal(0, 6)&lt;/code&gt; prior on your &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; parameters will be nearly flat within the reasonable neighborhoods of the parameter space.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;but-logs-are-hard.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;But logs are hard.&lt;/h2&gt;
&lt;p&gt;If we approach our Bayesian power analysis from a precision perspective, it can be difficult to settle on a reasonable interval width when they’re on the log scale. So let’s modify our simulation flow so it converts the width summaries back into the natural metric. Before we go big, let’s practice with a single iteration.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;seed &amp;lt;- 0
set.seed(seed)

# simulate the data
d &amp;lt;-
  tibble(high  = rep(0:1, each = n),
         count = c(rpois(n = n, lambda = mu_7),
                   rpois(n = n, lambda = mu_8)))

# fit the model
fit2 &amp;lt;-
  update(fit1,
         newdata = d,
         seed = seed) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now summarize.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidybayes)

fit2 %&amp;gt;% 
  posterior_samples() %&amp;gt;% 
  transmute(`beta_1` = exp(b_high)) %&amp;gt;% 
  mean_qi()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##     beta_1  .lower   .upper .width .point .interval
## 1 2.705404 2.16512 3.341729   0.95   mean        qi&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we used the &lt;code&gt;fixef()&lt;/code&gt; function to extract our intervals, which took the &lt;strong&gt;brms&lt;/strong&gt; fit object as input. Here we took a different approach. Because we are transforming &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;, we used the &lt;code&gt;posterior_samples()&lt;/code&gt; function to work directly with the posterior draws. We then exponentiated within &lt;code&gt;transmute()&lt;/code&gt;, which returned a single-column tibble, not a &lt;strong&gt;brms&lt;/strong&gt; fit object. So instead of &lt;code&gt;fixef()&lt;/code&gt;, it’s easier to get our summary statistics with the &lt;code&gt;tidybayes::mean_qi()&lt;/code&gt; function. Do note that now our lower and upper levels are named &lt;code&gt;.lower&lt;/code&gt; and &lt;code&gt;.upper&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;p&gt;Now we’ve practiced with the new flow, let’s redefine our simulation function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_data_fit &amp;lt;- function(seed, n) {
  
  # define our mus in the function
  mu_7 &amp;lt;- 2.17
  mu_8 &amp;lt;- 6.25

  # make your results reproducible
  set.seed(seed)
  
  # simulate the data
  d &amp;lt;-
    tibble(high  = rep(0:1, each = n),
           count = c(rpois(n = n, lambda = mu_7),
                     rpois(n = n, lambda = mu_8)))
  
  # fit and summarize
  update(fit1,
         newdata = d,
         seed = seed) %&amp;gt;% 
  posterior_samples() %&amp;gt;% 
  transmute(`beta_1` = exp(b_high)) %&amp;gt;% 
  mean_qi()
  
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Simulate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim3 &amp;lt;-
  tibble(seed = 1:100) %&amp;gt;% 
  mutate(ci = map(seed, sim_data_fit, n = 50)) %&amp;gt;% 
  unnest()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s what those 100 &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; intervals look like in bulk.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim3 %&amp;gt;% 
  ggplot(aes(x = seed, y = beta_1, ymin = .lower, ymax = .upper)) +
  geom_hline(yintercept = 0, color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1) +
  labs(x = &amp;quot;seed (i.e., simulation index)&amp;quot;,
       y = expression(beta[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Inspect the distribution of their widths.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim3 %&amp;gt;% 
  mutate(width = .upper - .lower) %&amp;gt;% 
  
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = 0.05) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;What if we wanted a mean 95% interval width of 1? Let’s run the simulation again, this time with &lt;span class=&#34;math inline&#34;&gt;\(n = 100\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim4 &amp;lt;-
  tibble(seed = 1:100) %&amp;gt;% 
  mutate(ci = map(seed, sim_data_fit, n = 100)) %&amp;gt;% 
  unnest() %&amp;gt;% 
  mutate(width = .upper - .lower)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the new width distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim4 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = 0.05) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-iii-a/index_files/figure-html/unnamed-chunk-19-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And the mean width is:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim4 %&amp;gt;% 
  summarise(mean_width = mean(width))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   mean_width
##        &amp;lt;dbl&amp;gt;
## 1      0.913&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nice! If we want a mean width of 1, it looks like we’re a little &lt;em&gt;overpowered&lt;/em&gt; with &lt;span class=&#34;math inline&#34;&gt;\(n = 100\)&lt;/span&gt;. The next step would be to up your iterations to 1,000 or so to do a proper simulation.&lt;/p&gt;
&lt;p&gt;Now you’ve got a sense of how to work with the Poisson likelihood, &lt;a href=&#34;https://solomonkurz.netlify.app/post/bayesian-power-analysis-part-iii-b/&#34;&gt;next time&lt;/a&gt; we’ll play with binary data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.3.1 brms_2.15.0     Rcpp_1.0.6      forcats_0.5.1  
##  [5] stringr_1.4.0   dplyr_1.0.6     purrr_0.3.4     readr_1.4.0    
##  [9] tidyr_1.1.3     tibble_3.1.2    ggplot2_3.3.3   tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6          
##   [4] igraph_1.2.6         svUnit_1.0.3         splines_4.0.4       
##   [7] crosstalk_1.1.0.1    TH.data_1.0-10       rstantools_2.1.1    
##  [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.1.1   
##  [13] rsconnect_0.8.16     fansi_0.4.2          magrittr_2.0.1      
##  [16] modelr_0.1.8         RcppParallel_5.0.2   matrixStats_0.57.0  
##  [19] xts_0.12.1           sandwich_3.0-0       prettyunits_1.1.1   
##  [22] colorspace_2.0-0     rvest_0.3.6          ggdist_2.4.0.9000   
##  [25] haven_2.3.1          xfun_0.23            callr_3.7.0         
##  [28] crayon_1.4.1         jsonlite_1.7.2       lme4_1.1-25         
##  [31] survival_3.2-10      zoo_1.8-8            glue_1.4.2          
##  [34] gtable_0.3.0         emmeans_1.5.2-1      V8_3.4.0            
##  [37] distributional_0.2.2 pkgbuild_1.2.0       rstan_2.21.2        
##  [40] abind_1.4-5          scales_1.1.1         mvtnorm_1.1-1       
##  [43] DBI_1.1.0            miniUI_0.1.1.1       xtable_1.8-4        
##  [46] stats4_4.0.4         StanHeaders_2.21.0-7 DT_0.16             
##  [49] htmlwidgets_1.5.3    httr_1.4.2           threejs_0.3.3       
##  [52] arrayhelpers_1.1-0   ellipsis_0.3.2       pkgconfig_2.0.3     
##  [55] loo_2.4.1            farver_2.1.0         sass_0.3.1          
##  [58] dbplyr_2.0.0         utf8_1.2.1           tidyselect_1.1.1    
##  [61] labeling_0.4.2       rlang_0.4.11         reshape2_1.4.4      
##  [64] later_1.2.0          munsell_0.5.0        cellranger_1.1.0    
##  [67] tools_4.0.4          cli_2.5.0            generics_0.1.0      
##  [70] broom_0.7.6          ggridges_0.5.3       evaluate_0.14       
##  [73] fastmap_1.1.0        yaml_2.2.1           processx_3.5.2      
##  [76] knitr_1.33           fs_1.5.0             nlme_3.1-152        
##  [79] mime_0.10            projpred_2.0.2       xml2_1.3.2          
##  [82] compiler_4.0.4       bayesplot_1.8.0      shinythemes_1.1.2   
##  [85] rstudioapi_0.13      gamm4_0.2-6          curl_4.3            
##  [88] reprex_0.3.0         statmod_1.4.35       bslib_0.2.4         
##  [91] stringi_1.6.2        highr_0.9            ps_1.6.0            
##  [94] blogdown_1.3         Brobdingnag_1.2-6    lattice_0.20-41     
##  [97] Matrix_1.3-2         nloptr_1.2.2.2       markdown_1.1        
## [100] shinyjs_2.0.0        vctrs_0.3.8          pillar_1.6.1        
## [103] lifecycle_1.0.0      jquerylib_0.1.4      bridgesampling_1.0-0
## [106] estimability_1.3     httpuv_1.6.0         R6_2.5.0            
## [109] bookdown_0.22        promises_1.2.0.1     gridExtra_2.3       
## [112] codetools_0.2-18     boot_1.3-26          colourpicker_1.1.0  
## [115] MASS_7.3-53          gtools_3.8.2         assertthat_0.2.1    
## [118] withr_2.4.2          shinystan_2.5.0      multcomp_1.4-16     
## [121] mgcv_1.8-33          parallel_4.0.4       hms_0.5.3           
## [124] grid_4.0.4           coda_0.19-4          minqa_1.2.4         
## [127] rmarkdown_2.8        shiny_1.6.0          lubridate_1.7.9.2   
## [130] base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-agrestiFoundationsLinearGeneralized2015&#34; class=&#34;csl-entry&#34;&gt;
Agresti, A. (2015). &lt;em&gt;Foundations of linear and generalized linear models&lt;/em&gt;. &lt;span&gt;John Wiley &amp;amp; Sons&lt;/span&gt;. &lt;a href=&#34;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&#34;&gt;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-atkinsTutorialOnCount2013&#34; class=&#34;csl-entry&#34;&gt;
Atkins, D. C., Baldwin, S. A., Zheng, C., Gallop, R. J., &amp;amp; Neighbors, C. (2013). A tutorial on count regression and zero-altered count models for longitudinal substance use data. &lt;em&gt;Psychology of Addictive Behaviors&lt;/em&gt;, &lt;em&gt;27&lt;/em&gt;(1), 166. &lt;a href=&#34;https://doi.org/10.1037/a0029508&#34;&gt;https://doi.org/10.1037/a0029508&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-ingrahamThinkYouDrink2014&#34; class=&#34;csl-entry&#34;&gt;
Ingraham, C. (2014). Think you drink a lot? &lt;span&gt;This&lt;/span&gt; chart will tell you. &lt;em&gt;Wonkblog. The Washington Post&lt;/em&gt;. &lt;a href=&#34;https://www.washingtonpost.com/news/wonk/wp/2014/09/25/think-you-drink-a-lot-this-chart-will-tell-you/?utm_term=.b81599bbbe25&#34;&gt;https://www.washingtonpost.com/news/wonk/wp/2014/09/25/think-you-drink-a-lot-this-chart-will-tell-you/?utm_term=.b81599bbbe25&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2015&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2015). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-niaaaNationalEpidemiologicSurvey2006&#34; class=&#34;csl-entry&#34;&gt;
{{National Institute on Alcohol Abuse and Alcoholism}}. (2006). &lt;em&gt;National epidemiologic survey on alcohol and related conditions&lt;/em&gt;. &lt;a href=&#34;https://pubs.niaaa.nih.gov/publications/AA70/AA70.htm&#34;&gt;https://pubs.niaaa.nih.gov/publications/AA70/AA70.htm&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Yes, one can smoke half a cigarette or drink 1/3 of a drink. Ideally, we’d have the exact amount of nicotine in your blood at a given moment and over time and the same for the amount of alcohol in your system relative to your blood volume and such. But in practice, substance use researchers just don’t tend to have access to data of that quality. Instead, we’re typically stuck with simple counts. And I look forward to the day the right team of engineers, computer scientists, and substance use researchers (and whoever else I forgot to mention) release the cheap, non-invasive technology we need to passively measure these things. Until then: &lt;em&gt;How many standard servings of alcohol did you drink, last night?&lt;/em&gt;&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian power analysis: Part II. Some might prefer precision to power</title>
      <link>/post/bayesian-power-analysis-part-ii/</link>
      <pubDate>Wed, 24 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/post/bayesian-power-analysis-part-ii/</guid>
      <description>
&lt;script src=&#34;/post/bayesian-power-analysis-part-ii/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;version-1.1.0&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Version 1.1.0&lt;/h2&gt;
&lt;p&gt;Edited on April 21, 2021, to remove the &lt;code&gt;broom::tidy()&lt;/code&gt; portion of the workflow.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tldr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;When researchers decide on a sample size for an upcoming project, there are more things to consider than null-hypothesis-oriented power. Bayesian researchers might like to frame their concerns in terms of precision. Stick around to learn what and how.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;are-bayesians-doomed-to-refer-to-h_0-1-with-sample-size-planning&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Are Bayesians doomed to refer to &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt;&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; with sample-size planning?&lt;/h2&gt;
&lt;p&gt;If you read the first post in this series (click &lt;a href=&#34;https://solomonkurz.netlify.app/post/bayesian-power-analysis-part-i/&#34;&gt;here&lt;/a&gt; for a refresher), you may have found yourself thinking: &lt;em&gt;Sure, last time you avoided computing &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values with your 95% Bayesian credible intervals. But weren’t you still operating like a NHSTesting frequentist with all that &lt;span class=&#34;math inline&#34;&gt;\(H_0 / H_1\)&lt;/span&gt; talk?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Solid criticism. We didn’t even bother discussing all the type-I versus type-II error details. Yet they too were lurking in the background the way we just chose the typical .8 power benchmark. That’s not to say that a &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value oriented approach isn’t legitimate. It’s certainly congruent with what most reviewers would expect.&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; But this all seems at odds with a model-oriented Bayesian approach, which is what I generally prefer. Happily, we have other options to explore.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-just-pick-up-where-we-left-off.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let’s just pick up where we left off.&lt;/h2&gt;
&lt;p&gt;Load our primary statistical packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a recap, here’s how we performed the last simulation-based Bayesian power analysis from part I. First, we simulated a single data set and fit an initial model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define the means
mu_c &amp;lt;- 0
mu_t &amp;lt;- 0.5

# determine the group size
n &amp;lt;- 50

# simulate the data
set.seed(1)
d &amp;lt;-
  tibble(group     = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
  mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
         y         = ifelse(group == &amp;quot;control&amp;quot;, 
                            rnorm(n, mean = mu_c, sd = 1),
                            rnorm(n, mean = mu_t, sd = 1)))
# fit the model
fit &amp;lt;-
  brm(data = d,
      family = gaussian,
      y ~ 0 + intercept + treatment,
      prior = c(prior(normal(0, 2), class = b),
                prior(student_t(3, 1, 1), class = sigma)),
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, we made a custom function that both simulated data sets and used the &lt;code&gt;update()&lt;/code&gt; function to update that initial fit in order to avoid additional compilation time.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_d_and_fit &amp;lt;- function(seed, n) {
  
  mu_c &amp;lt;- 0
  mu_t &amp;lt;- 0.5
  
  set.seed(seed)
  
  d &amp;lt;-
    tibble(group = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
    mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
           y         = ifelse(group == &amp;quot;control&amp;quot;, 
                              rnorm(n, mean = mu_c, sd = 1),
                              rnorm(n, mean = mu_t, sd = 1)))
  
  update(fit,
         newdata = d, 
         seed = seed) %&amp;gt;% 
    fixef() %&amp;gt;% 
    data.frame() %&amp;gt;% 
    rownames_to_column(&amp;quot;parameter&amp;quot;) %&amp;gt;% 
    filter(parameter == &amp;quot;treatment&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then we finally iterated over &lt;code&gt;n_sim &amp;lt;- 100&lt;/code&gt; times.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_sim &amp;lt;- 100

s3 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 50)) %&amp;gt;% 
  unnest(b1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results looked like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;theme_set(theme_grey() +
            theme(panel.grid = element_blank()))

s3 %&amp;gt;% 
  ggplot(aes(x = seed, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1/2) +
  labs(x = &amp;quot;seed (i.e., simulation index)&amp;quot;,
       y = expression(beta[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-3-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;It’s time to build on the foundation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;we-might-evaluate-power-by-widths.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;We might evaluate “power” by widths.&lt;/h2&gt;
&lt;p&gt;Instead of just ordering the point-ranges by their &lt;code&gt;seed&lt;/code&gt; values, we might instead arrange them by the &lt;code&gt;lower&lt;/code&gt; levels.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 %&amp;gt;%
  ggplot(aes(x = reorder(seed, Q2.5), y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1/2) +
  scale_x_discrete(&amp;quot;reordered by the lower level of the 95% intervals&amp;quot;, breaks = NULL) +
  ylab(expression(beta[1])) +
  coord_cartesian(ylim = c(-.5, 1.3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice how this arrangement highlights the differences in widths among the intervals. The wider the interval, the less precise the estimate. Some intervals were wider than others, but all tended to hover in a similar range. We might quantify those ranges by computing a &lt;code&gt;width&lt;/code&gt; variable.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 &amp;lt;-
  s3 %&amp;gt;% 
  mutate(width = Q97.5 - Q2.5)

head(s3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 7
##    seed parameter Estimate Est.Error    Q2.5 Q97.5 width
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1 treatment    0.514     0.185  0.159  0.898 0.739
## 2     2 treatment    0.307     0.239 -0.143  0.782 0.925
## 3     3 treatment    0.643     0.171  0.310  0.975 0.666
## 4     4 treatment    0.224     0.182 -0.128  0.574 0.702
## 5     5 treatment    0.429     0.189  0.0596 0.792 0.733
## 6     6 treatment    0.304     0.208 -0.114  0.711 0.825&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the &lt;code&gt;width&lt;/code&gt; distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .01)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The widths of our 95% intervals range from 0.6 to 0.95, with the bulk sitting around 0.8. Let’s focus a bit and take a random sample from one of the simulation iterations.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)

s3 %&amp;gt;% 
  sample_n(1) %&amp;gt;% 
  mutate(seed = seed %&amp;gt;% as.character()) %&amp;gt;% 

  ggplot(aes(x = Estimate, xmin = Q2.5, xmax = Q97.5, y = seed)) +
  geom_vline(xintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange() +
  labs(x = expression(beta[1]),
       y = &amp;quot;seed #&amp;quot;) +
  xlim(0, 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Though the posterior mean suggests the most probable value for &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is about 0.6, the intervals suggest values from about 0.2 to almost 1 are within the 95% probability range. That’s a wide spread. Within psychology, a standardized mean difference of 0.2 would typically be considered small, whereas a difference of 1 would be large enough to raise a skeptical eyebrow or two.&lt;/p&gt;
&lt;p&gt;So instead of focusing on rejecting a null hypothesis like &lt;span class=&#34;math inline&#34;&gt;\(\mu_\text{control} = \mu_\text{treatment}\)&lt;/span&gt;, we might instead use our simulation skills to determine the sample size we need to have most of our 95% intervals come in at a certain level of precision. This has been termed the accuracy in parameter estimation [AIPE; &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-maxwellSampleSizePlanning2008&#34; role=&#34;doc-biblioref&#34;&gt;Maxwell et al.&lt;/a&gt; (&lt;a href=&#34;#ref-maxwellSampleSizePlanning2008&#34; role=&#34;doc-biblioref&#34;&gt;2008&lt;/a&gt;)&lt;/span&gt;; see also &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;Kruschke&lt;/a&gt; (&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;] approach to sample size planning.&lt;/p&gt;
&lt;p&gt;Thinking in terms of AIPE, in terms of precision, let’s say we wanted widths of 0.7 or smaller. Here’s how we did with &lt;code&gt;s3&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 %&amp;gt;% 
  mutate(check = ifelse(width &amp;lt; .7, 1, 0)) %&amp;gt;% 
  summarise(`width power` = mean(check))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   `width power`
##           &amp;lt;dbl&amp;gt;
## 1           0.1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We did terrible. I’m not sure the term “width power” is even a thing. But hopefully you get the point. Our baby 100-iteration simulation suggests we have about a .08 probability of achieving 95% CI widths of 0.7 or smaller with &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt; per group. Though we’re pretty good at excluding zero, we don’t tend to do so with precision above that.&lt;/p&gt;
&lt;p&gt;That last bit about excluding zero brings up an important point. Once we’re concerned about width size, about precision, the null hypothesis is no longer of direct relevance. And since we’re no longer wed to thinking in terms of the null hypothesis, there’s no real need to stick with a .8 threshold for evaluating width power (okay, I’ll stop using that term). Now if we wanted to stick with .8, we could. Though a little nonsensical, the .8 criterion would give our AIPE analyses a sense of familiarity with traditional power analyses, which some reviewers might appreciate. But in his text, Kruschke mentioned several other alternatives. One would be to set maximum value for our CI widths and simulate to find the &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; necessary so all our simulations pass that criterion. Another would follow Joseph, Wolfson, and du Berger &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-josephSampleSizeCalculations1995&#34; role=&#34;doc-biblioref&#34;&gt;1995a&lt;/a&gt;, &lt;a href=&#34;#ref-josephCommentsBayesianSample1995&#34; role=&#34;doc-biblioref&#34;&gt;1995b&lt;/a&gt;)&lt;/span&gt;, who suggested we shoot for an &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; that produces widths that pass that criterion on average. Here’s how we did based on the average-width criterion.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 %&amp;gt;% 
  summarise(`average width` = mean(width))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   `average width`
##             &amp;lt;dbl&amp;gt;
## 1           0.783&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Close. Let’s see how increasing our sample size to 75 per group effects these metrics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s4 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 75)) %&amp;gt;% 
  unnest(b1) %&amp;gt;%
  mutate(width = Q97.5 - Q2.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s what our new batch of 95% intervals looks like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s4 %&amp;gt;% 
  ggplot(aes(x = reorder(seed, Q2.5), y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1/2) +
  scale_x_discrete(&amp;quot;reordered by the lower level of the 95% intervals&amp;quot;, breaks = NULL) +
  ylab(expression(beta[1])) +
  # this kept the scale on the y-axis the same as the simulation with n = 50
  coord_cartesian(ylim = c(-.5, 1.3))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Some of the intervals are still more precise than others, but they all now hover more tightly around their true data-generating value of 0.5. Here’s our updated “power” for producing interval widths smaller than 0.7.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s4 %&amp;gt;% 
  mutate(check = ifelse(width &amp;lt; .7, 1, 0)) %&amp;gt;% 
  summarise(`proportion below 0.7` = mean(check),
            `average width`        = mean(width))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   `proportion below 0.7` `average width`
##                    &amp;lt;dbl&amp;gt;           &amp;lt;dbl&amp;gt;
## 1                   0.94           0.639&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we hold to the NHST-oriented .8 threshold, we did great and are even “overpowered.” We didn’t quite meet Kruschke’s strict limiting-worst-precision threshold, but we got close enough we’d have a good sense of what range of &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; values we might evaluate over next. As far as the mean-precision criterion, we did great by that one and even beat it.&lt;/p&gt;
&lt;p&gt;Here’s a look at how this batch of widths is distributed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s4 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .02) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Let’s see if we can nail down the &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;s for our three AIPE criteria. Since we’re so close to fulfilling Kruschke’s limiting-worst-precision criterion, we’ll start there. I’m thinking &lt;span class=&#34;math inline&#34;&gt;\(n = 85\)&lt;/span&gt; should just about do it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s5 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 85)) %&amp;gt;% 
  unnest(b1) %&amp;gt;%
  mutate(width = Q97.5 - Q2.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Did we pass?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s5 %&amp;gt;% 
  mutate(check = ifelse(width &amp;lt; .7, 1, 0)) %&amp;gt;% 
  summarise(`proportion below 0.7` = mean(check))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   `proportion below 0.7`
##                    &amp;lt;dbl&amp;gt;
## 1                      1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Success! We might look at how they’re distributed.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s5 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .01) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;A few of our simulated widths were approaching the 0.7 boundary. If we were to do a proper simulation with 1,000+ iterations, I’d worry one or two would creep over that boundary. So perhaps &lt;span class=&#34;math inline&#34;&gt;\(n = 90\)&lt;/span&gt; would be a better candidate for a large-scale simulation.&lt;/p&gt;
&lt;p&gt;If we just wanted to meet the mean-precision criterion, we might look at something like &lt;span class=&#34;math inline&#34;&gt;\(n = 65\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s6 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 65)) %&amp;gt;% 
  unnest(b1) %&amp;gt;%
  mutate(width = Q97.5 - Q2.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Did we pass the mean-precision criterion?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s6 %&amp;gt;% 
  summarise(`average width` = mean(width))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   `average width`
##             &amp;lt;dbl&amp;gt;
## 1           0.688&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We got it! It looks like something like &lt;span class=&#34;math inline&#34;&gt;\(n = 65\)&lt;/span&gt; would be a good candidate for a larger-scale simulation. Here’s the distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s6 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .02) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For our final possible criterion, just get .8 of the widths below the threshold, we’ll want an &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; somewhere between 65 and 85. 70, perhaps?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s7 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 70)) %&amp;gt;% 
  unnest(b1) %&amp;gt;%
  mutate(width = Q97.5 - Q2.5)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Did we pass the .8-threshold criterion?&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s7 %&amp;gt;% 
  mutate(check = ifelse(width &amp;lt; .7, 1, 0)) %&amp;gt;% 
  summarise(`proportion below 0.7` = mean(check))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   `proportion below 0.7`
##                    &amp;lt;dbl&amp;gt;
## 1                   0.82&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Yep. Here’s the distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s7 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .02) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-are-we-defining-our-widths&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How are we defining our widths?&lt;/h2&gt;
&lt;p&gt;In frequentist analyses, we typically work with 95% confidence intervals because of their close connection to the conventional &lt;span class=&#34;math inline&#34;&gt;\(p &amp;lt; .05\)&lt;/span&gt; threshold. Another consequence of dropping our focus on rejecting &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; is that it no longer seems necessary to evaluate our posteriors with 95% intervals. And as it turns out, some Bayesians aren’t fans of the 95% interval. McElreath, for example, defiantly used 89% intervals in both editions of his &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;, &lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;http://xcelab.net/rm/statistical-rethinking/&#34;&gt;text&lt;/a&gt;. In contrast, Gelman has &lt;a href=&#34;https://statmodeling.stat.columbia.edu/2016/11/05/why-i-prefer-50-to-95-intervals/&#34;&gt;blogged&lt;/a&gt; on his fondness for 50% intervals. Just for kicks, let’s follow Gelman’s lead and practice evaluating an &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; based on 50% intervals. This will require us to update our &lt;code&gt;sim_d_and_fit()&lt;/code&gt; function to allow us to change the &lt;code&gt;probs&lt;/code&gt; setting in the &lt;code&gt;fixef()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_d_and_fit &amp;lt;- function(seed, n, probs = c(.25, .75)) {
  
  mu_c &amp;lt;- 0
  mu_t &amp;lt;- 0.5
  
  set.seed(seed)
  
  d &amp;lt;-
    tibble(group = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
    mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
           y         = ifelse(group == &amp;quot;control&amp;quot;, 
                              rnorm(n, mean = mu_c, sd = 1),
                              rnorm(n, mean = mu_t, sd = 1)))
  
  update(fit,
         newdata = d, 
         seed = seed) %&amp;gt;% 
    fixef(probs = probs) %&amp;gt;% 
    data.frame() %&amp;gt;% 
    rownames_to_column(&amp;quot;parameter&amp;quot;) %&amp;gt;% 
    filter(parameter == &amp;quot;treatment&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To make things simple, we just set the default &lt;code&gt;probs&lt;/code&gt; settings to return 50% intervals. Now we simulate to examine those 50% intervals. We’ll start with the original &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n_sim &amp;lt;- 100

s8 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 50)) %&amp;gt;% 
  unnest(b1) %&amp;gt;% 
  # notice the change to this line of code
  mutate(width = Q75 - Q25)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is the distribution of our 50% interval widths.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s8 %&amp;gt;% 
  mutate(width = Q75 - Q25) %&amp;gt;% 
  
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .01) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Since we’ve gone from 95% to 50% intervals, it should be no surprise that their widths are narrower. Accordingly, we should evaluate then with a higher standard. Perhaps it’s more reasonable to ask for an average width of 0.1. Let’s see how close &lt;span class=&#34;math inline&#34;&gt;\(n = 150\)&lt;/span&gt; gets us.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s9 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 150)) %&amp;gt;% 
  unnest(b1) %&amp;gt;% 
  mutate(width = Q75 - Q25)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Look at the distribution.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s9 %&amp;gt;% 
  ggplot(aes(x = width)) +
  geom_histogram(binwidth = .0025) +
  geom_rug(size = 1/6)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-ii/index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;384&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Nope, we’re not there yet. Perhaps &lt;span class=&#34;math inline&#34;&gt;\(n = 200\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(250\)&lt;/span&gt; is the ticket. This is an iterative process. Anyway, once we’re talking that AIPE/precision/interval-width talk, we can get all kinds of creative with which intervals we’re even interested in. As far as I can tell, the topic is wide open for fights and collaborations between statisticians, methodologists, and substantive researchers to find sensible ways forward.&lt;/p&gt;
&lt;p&gt;Maybe you should write a dissertation on it.&lt;/p&gt;
&lt;p&gt;Regardless, get ready for &lt;a href=&#34;https://solomonkurz.netlify.app/post/bayesian-power-analysis-part-iii-a/&#34;&gt;part III&lt;/a&gt; where we’ll liberate ourselves from the tyranny of the Gauss.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] brms_2.15.0     Rcpp_1.0.6      forcats_0.5.1   stringr_1.4.0  
##  [5] dplyr_1.0.5     purrr_0.3.4     readr_1.4.0     tidyr_1.1.3    
##  [9] tibble_3.1.0    ggplot2_3.3.3   tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6          
##   [4] igraph_1.2.6         splines_4.0.4        crosstalk_1.1.0.1   
##   [7] TH.data_1.0-10       rstantools_2.1.1     inline_0.3.17       
##  [10] digest_0.6.27        htmltools_0.5.1.1    rsconnect_0.8.16    
##  [13] fansi_0.4.2          magrittr_2.0.1       modelr_0.1.8        
##  [16] RcppParallel_5.0.2   matrixStats_0.57.0   xts_0.12.1          
##  [19] sandwich_3.0-0       prettyunits_1.1.1    colorspace_2.0-0    
##  [22] rvest_0.3.6          haven_2.3.1          xfun_0.22           
##  [25] callr_3.5.1          crayon_1.4.1         jsonlite_1.7.2      
##  [28] lme4_1.1-25          survival_3.2-10      zoo_1.8-8           
##  [31] glue_1.4.2           gtable_0.3.0         emmeans_1.5.2-1     
##  [34] V8_3.4.0             pkgbuild_1.2.0       rstan_2.21.2        
##  [37] abind_1.4-5          scales_1.1.1         mvtnorm_1.1-1       
##  [40] DBI_1.1.0            miniUI_0.1.1.1       xtable_1.8-4        
##  [43] stats4_4.0.4         StanHeaders_2.21.0-7 DT_0.16             
##  [46] htmlwidgets_1.5.2    httr_1.4.2           threejs_0.3.3       
##  [49] ellipsis_0.3.1       pkgconfig_2.0.3      loo_2.4.1           
##  [52] farver_2.0.3         dbplyr_2.0.0         utf8_1.1.4          
##  [55] tidyselect_1.1.0     labeling_0.4.2       rlang_0.4.10        
##  [58] reshape2_1.4.4       later_1.1.0.1        munsell_0.5.0       
##  [61] cellranger_1.1.0     tools_4.0.4          cli_2.3.1           
##  [64] generics_0.1.0       broom_0.7.5          ggridges_0.5.2      
##  [67] evaluate_0.14        fastmap_1.0.1        yaml_2.2.1          
##  [70] processx_3.4.5       knitr_1.31           fs_1.5.0            
##  [73] nlme_3.1-152         mime_0.10            projpred_2.0.2      
##  [76] xml2_1.3.2           compiler_4.0.4       bayesplot_1.8.0     
##  [79] shinythemes_1.1.2    rstudioapi_0.13      gamm4_0.2-6         
##  [82] curl_4.3             reprex_0.3.0         statmod_1.4.35      
##  [85] stringi_1.5.3        highr_0.8            ps_1.6.0            
##  [88] blogdown_1.3         Brobdingnag_1.2-6    lattice_0.20-41     
##  [91] Matrix_1.3-2         nloptr_1.2.2.2       markdown_1.1        
##  [94] shinyjs_2.0.0        vctrs_0.3.6          pillar_1.5.1        
##  [97] lifecycle_1.0.0      bridgesampling_1.0-0 estimability_1.3    
## [100] httpuv_1.5.4         R6_2.5.0             bookdown_0.21       
## [103] promises_1.1.1       gridExtra_2.3        codetools_0.2-18    
## [106] boot_1.3-26          colourpicker_1.1.0   MASS_7.3-53         
## [109] gtools_3.8.2         assertthat_0.2.1     withr_2.4.1         
## [112] shinystan_2.5.0      multcomp_1.4-16      mgcv_1.8-33         
## [115] parallel_4.0.4       hms_0.5.3            grid_4.0.4          
## [118] coda_0.19-4          minqa_1.2.4          rmarkdown_2.7       
## [121] shiny_1.5.0          lubridate_1.7.9.2    base64enc_0.1-3     
## [124] dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-josephSampleSizeCalculations1995&#34; class=&#34;csl-entry&#34;&gt;
Joseph, L., Wolfson, D. B., &amp;amp; Berger, R. D. (1995a). Sample size calculations for binomial proportions via highest posterior density intervals. &lt;em&gt;Journal of the Royal Statistical Society: Series D (The Statistician)&lt;/em&gt;, &lt;em&gt;44&lt;/em&gt;(2), 143–154. &lt;a href=&#34;https://doi.org/10.2307/2348439&#34;&gt;https://doi.org/10.2307/2348439&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-josephCommentsBayesianSample1995&#34; class=&#34;csl-entry&#34;&gt;
Joseph, L., Wolfson, D. B., &amp;amp; Berger, R. D. (1995b). Some comments on &lt;span&gt;Bayesian&lt;/span&gt; sample size determination. &lt;em&gt;Journal of the Royal Statistical Society: Series D (The Statistician)&lt;/em&gt;, &lt;em&gt;44&lt;/em&gt;(2), 167–171. &lt;a href=&#34;https://doi.org/10.2307/2348442&#34;&gt;https://doi.org/10.2307/2348442&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kruschkeDoingBayesianData2015&#34; class=&#34;csl-entry&#34;&gt;
Kruschke, J. K. (2015). &lt;em&gt;Doing &lt;span&gt;Bayesian&lt;/span&gt; data analysis: &lt;span&gt;A&lt;/span&gt; tutorial with &lt;span&gt;R&lt;/span&gt;, &lt;span&gt;JAGS&lt;/span&gt;, and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;Academic Press&lt;/span&gt;. &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;https://sites.google.com/site/doingbayesiandataanalysis/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-maxwellSampleSizePlanning2008&#34; class=&#34;csl-entry&#34;&gt;
Maxwell, S. E., Kelley, K., &amp;amp; Rausch, J. R. (2008). Sample size planning for statistical power and accuracy in parameter estimation. &lt;em&gt;Annual Review of Psychology&lt;/em&gt;, &lt;em&gt;59&lt;/em&gt;(1), 537–563. &lt;a href=&#34;https://doi.org/10.1146/annurev.psych.59.103006.093735&#34;&gt;https://doi.org/10.1146/annurev.psych.59.103006.093735&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2020&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2020). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt; (Second Edition). &lt;span&gt;CRC Press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2015&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2015). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-moreyBayesFactorApproaches2011&#34; class=&#34;csl-entry&#34;&gt;
Morey, R. D., &amp;amp; Rouder, J. N. (2011). Bayes factor approaches for testing interval null hypotheses. &lt;em&gt;Psychological Methods&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;(4), 406–419. &lt;a href=&#34;https://doi.org/10.1037/a0024377&#34;&gt;https://doi.org/10.1037/a0024377&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rouderBayesianTestsAccepting2009&#34; class=&#34;csl-entry&#34;&gt;
Rouder, J. N., Speckman, P. L., Sun, D., Morey, R. D., &amp;amp; Iverson, G. (2009). Bayesian t tests for accepting and rejecting the null hypothesis. &lt;em&gt;Psychonomic Bulletin &amp;amp; Review&lt;/em&gt;, &lt;em&gt;16&lt;/em&gt;(2), 225–237. &lt;a href=&#34;https://doi.org/10.3758/PBR.16.2.225&#34;&gt;https://doi.org/10.3758/PBR.16.2.225&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wassersteinMovingWorld052019&#34; class=&#34;csl-entry&#34;&gt;
Wasserstein, R. L., Schirm, A. L., &amp;amp; Lazar, N. A. (2019). Moving to a &lt;span&gt;World Beyond&lt;/span&gt; &lt;span&gt;“p &lt;span&gt;&lt;span class=&#34;math inline&#34;&gt;\(&amp;lt;\)&lt;/span&gt;&lt;/span&gt; 0.05.”&lt;/span&gt; &lt;em&gt;The American Statistician&lt;/em&gt;, &lt;em&gt;73&lt;/em&gt;(sup1), 1–19. &lt;a href=&#34;https://doi.org/10.1080/00031305.2019.1583913&#34;&gt;https://doi.org/10.1080/00031305.2019.1583913&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;To be clear, one can consider the null hypothesis within the Bayesian paradigm. I don’t tend to take this approach, but it’d be unfair not to at least mention some resources. Kurschke covered the topic in chapters 11 and 12 in his &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; text, &lt;a href=&#34;http://www.indiana.edu/~kruschke/DoingBayesianDataAnalysis/&#34;&gt;&lt;em&gt;Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan&lt;/em&gt;&lt;/a&gt;. You might also check out &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-rouderBayesianTestsAccepting2009&#34; role=&#34;doc-biblioref&#34;&gt;Rouder et al.&lt;/a&gt; (&lt;a href=&#34;#ref-rouderBayesianTestsAccepting2009&#34; role=&#34;doc-biblioref&#34;&gt;2009&lt;/a&gt;)&lt;/span&gt;, &lt;a href=&#34;https://link.springer.com/content/pdf/10.3758/PBR.16.2.225.pdf&#34;&gt;&lt;em&gt;Bayesian t tests for accepting and rejecting the null hypothesis&lt;/em&gt;&lt;/a&gt;, or &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-moreyBayesFactorApproaches2011&#34; role=&#34;doc-biblioref&#34;&gt;Morey &amp;amp; Rouder&lt;/a&gt; (&lt;a href=&#34;#ref-moreyBayesFactorApproaches2011&#34; role=&#34;doc-biblioref&#34;&gt;2011&lt;/a&gt;)&lt;/span&gt;, &lt;a href=&#34;https://d1wqtxts1xzle7.cloudfront.net/45416179/Bayes_Factor_Approaches_for_Testing_Inte20160506-23207-1t89l96.pdf?1462571611=&amp;amp;response-content-disposition=inline%3B+filename%3DBayes_factor_approaches_for_testing_inte.pdf&amp;amp;Expires=1597530412&amp;amp;Signature=QAJQOISIvwxUlHd2uTfzgOMzf2TRcuWTcfwgki7JL4AIoYDziVCAfmDFOgUDi-h1mMEViTKFhOLTJF0-9u2IEyF2lR7-yhM67CYdKhqs8EEJOnhT9iK9MaaM2FBwZM8QoVtOXkOUaOXRHIt7C76UV5dbErTUx0r5Y1yym4a~-hDClb0696a6EB~dj0arYeDdylP7a3tfczmSxbIvrH8pOE4kQeHwsZXoANSh-eKXKYIYf6VD1yed~CSVPRkqlhMq6udOjg4INPZ33QBv3QQqYCk2esRC2DxxNmDF~rRVrIp0ebr6VMZkuMflVaj2~I2BFz7WS32Lb2hGFHT3jHskDA__&amp;amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA&#34;&gt;&lt;em&gt;Bayes factor approaches for testing interval null hypotheses&lt;/em&gt;&lt;/a&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;For a contemporary discussion of the uses and misuses of &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values, see &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-wassersteinMovingWorld052019&#34; role=&#34;doc-biblioref&#34;&gt;Wasserstein et al.&lt;/a&gt; (&lt;a href=&#34;#ref-wassersteinMovingWorld052019&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; and the other articles contained in that &lt;a href=&#34;https://www.tandfonline.com/toc/utas20/73/sup1?nav=tocList&#34;&gt;special issue of &lt;em&gt;The American Statistician&lt;/em&gt;&lt;/a&gt;.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian power analysis: Part I. Prepare to reject $H_0$ with simulation.</title>
      <link>/post/bayesian-power-analysis-part-i/</link>
      <pubDate>Thu, 18 Jul 2019 00:00:00 +0000</pubDate>
      <guid>/post/bayesian-power-analysis-part-i/</guid>
      <description>
&lt;script src=&#34;/post/bayesian-power-analysis-part-i/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;version-1.1.0&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Version 1.1.0&lt;/h2&gt;
&lt;p&gt;Edited on April 21, 2021, to remove the &lt;code&gt;broom::tidy()&lt;/code&gt; portion of the workflow.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;tldr&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;tl;dr&lt;/h2&gt;
&lt;p&gt;If you’d like to learn how to do Bayesian power calculations using &lt;strong&gt;brms&lt;/strong&gt;, stick around for this multi-part blog series. Here with part I, we’ll set the foundation.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;power-is-hard-especially-for-bayesians.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Power is hard, especially for Bayesians.&lt;/h2&gt;
&lt;p&gt;Many journals, funding agencies, and dissertation committees require power calculations for your primary analyses. Frequentists have a variety of tools available to perform these calculations (e.g., &lt;a href=&#34;https://rpsychologist.com/analytical-and-simulation-based-power-analyses-for-mixed-design-anovas&#34;&gt;here&lt;/a&gt;). Bayesians, however, have a more difficult time of it. Most of our research questions and data issues are sufficiently complicated that we cannot solve the problems by hand. We need Markov chain Monte Carlo methods to iteratively sample from the posterior to summarize the parameters from our models. Same deal for power. If you’d like to compute the power for a given combination of &lt;span class=&#34;math inline&#34;&gt;\(N\)&lt;/span&gt;, likelihood &lt;span class=&#34;math inline&#34;&gt;\(p(\text{data} | \theta)\)&lt;/span&gt;, and set of priors &lt;span class=&#34;math inline&#34;&gt;\(p (\theta)\)&lt;/span&gt;, you’ll need to simulate.&lt;/p&gt;
&lt;p&gt;It’s been one of my recent career goals to learn how to do this. You know how they say: &lt;em&gt;The best way to learn is to teach&lt;/em&gt;. This series of blog posts is the evidence of me learning by teaching. It will be an exploration of what a Bayesian power simulation workflow might look like. The overall statistical framework will be within &lt;strong&gt;R&lt;/strong&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-base&#34; role=&#34;doc-biblioref&#34;&gt;R Core Team, 2020&lt;/a&gt;)&lt;/span&gt;, with an emphasis on code style based on the &lt;a href=&#34;https://www.tidyverse.org&#34;&gt;&lt;strong&gt;tidyverse&lt;/strong&gt;&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-tidyverse&#34; role=&#34;doc-biblioref&#34;&gt;Wickham, 2019&lt;/a&gt;; &lt;a href=&#34;#ref-wickhamWelcomeTidyverse2019&#34; role=&#34;doc-biblioref&#34;&gt;Wickham et al., 2019&lt;/a&gt;)&lt;/span&gt;. We’ll be fitting our Bayesian models with Bürkner’s &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;&lt;strong&gt;brms&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-burknerBrmsPackageBayesian2017&#34; role=&#34;doc-biblioref&#34;&gt;Bürkner, 2017&lt;/a&gt;, &lt;a href=&#34;#ref-burknerAdvancedBayesianMultilevel2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;, &lt;a href=&#34;#ref-R-brms&#34; role=&#34;doc-biblioref&#34;&gt;2020a&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;What this series is not, however, is an introduction to statistical power itself. Keep reading if you’re ready to roll up your sleeves, put on your applied hat, and learn how to get things done. If you’re more interested in introductions to power, see the references in the next section.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;i-make-assumptions.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I make assumptions.&lt;/h2&gt;
&lt;p&gt;For this series, I’m presuming you are familiar with linear regression, familiar with the basic differences between frequentist and Bayesian approaches to statistics, and have a basic sense of what we mean by statistical power. Here are some resources if you’d like to shore up.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you’re unfamiliar with statistical power, Kruschke covered it in chapter 13 of his &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;http://www.indiana.edu/~kruschke/DoingBayesianDataAnalysis/&#34;&gt;text&lt;/a&gt;. You might also check out the &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-maxwellSampleSizePlanning2008&#34; role=&#34;doc-biblioref&#34;&gt;2008&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://www3.nd.edu/~kkelley/publications/articles/Maxwell_Kelley_Rausch_2008.pdf&#34;&gt;review paper&lt;/a&gt; by Maxwell, Kelley, and Rausch. There’s always, of course, the original work by Cohen &lt;span class=&#34;citation&#34;&gt;(e.g., &lt;a href=&#34;#ref-cohenStatisticalPowerAnalysis1988a&#34; role=&#34;doc-biblioref&#34;&gt;Cohen, 1988&lt;/a&gt;)&lt;/span&gt;. You might also like this &lt;a href=&#34;https://www.khanacademy.org/math/ap-statistics/tests-significance-ap/error-probabilities-power/v/introduction-to-power-in-significance-tests&#34;&gt;Khan Academy video&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;To learn about Bayesian regression, I recommend the introductory text books by either McElreath &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;, &lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; or &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;Kruschke&lt;/a&gt; (&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;. Both authors host blogs (&lt;a href=&#34;http://doingbayesiandataanalysis.blogspot.com&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://elevanth.org/blog/&#34;&gt;here&lt;/a&gt;, respectively). If you go with McElreath, do check out his &lt;a href=&#34;https://www.youtube.com/channel/UCNJK6_DZvcMqNSzQdEkzvzA/playlists&#34;&gt;online lectures&lt;/a&gt; and my &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kurzStatisticalRethinkingBrms2020&#34; role=&#34;doc-biblioref&#34;&gt;2020a&lt;/a&gt;, &lt;a href=&#34;#ref-kurzStatisticalRethinkingSecondEd2020&#34; role=&#34;doc-biblioref&#34;&gt;2020c&lt;/a&gt;)&lt;/span&gt; ebooks translating his text to &lt;strong&gt;brms&lt;/strong&gt; and &lt;strong&gt;tidyverse&lt;/strong&gt; code. I have an ebook for Kruschke’s text &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kurzDoingBayesianData2020&#34; role=&#34;doc-biblioref&#34;&gt;Kurz, 2020b&lt;/a&gt;)&lt;/span&gt;, too.&lt;/li&gt;
&lt;li&gt;For even more &lt;strong&gt;brms&lt;/strong&gt;-related resources, you can find vignettes and documentation at &lt;a href=&#34;https://cran.r-project.org/package=brms/index.html&#34;&gt;https://cran.r-project.org/package=brms/index.html&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;For &lt;strong&gt;tidyverse&lt;/strong&gt; introductions, your best bets are Grolemund and Wickham’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-grolemundDataScience2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://r4ds.had.co.nz&#34;&gt;&lt;em&gt;R for data science&lt;/em&gt;&lt;/a&gt; and Wickham’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-wickhamTidyverseStyleGuide2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://style.tidyverse.org&#34;&gt;&lt;em&gt;The tidyverse style guide&lt;/em&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;We’ll be simulating data. If that’s new to you, both Kruschke and McElreath cover that a little in their texts. You can find nice online tutorials &lt;a href=&#34;https://debruine.github.io/tutorials/sim-data.html&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://aosmith.rbind.io/2018/08/29/getting-started-simulating-data/&#34;&gt;here&lt;/a&gt;, too.&lt;/li&gt;
&lt;li&gt;We’ll also be making a couple custom functions. If that’s new, you might check out &lt;a href=&#34;https://r4ds.had.co.nz/functions.html&#34;&gt;&lt;em&gt;R4DS&lt;/em&gt;, chapter 19&lt;/a&gt; or &lt;a href=&#34;https://bookdown.org/rdpeng/rprogdatascience/functions.html&#34;&gt;chapter 14&lt;/a&gt; of Roger Peng’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-pengProgrammingDataScience2019&#34; role=&#34;doc-biblioref&#34;&gt;2019&lt;/a&gt;)&lt;/span&gt; &lt;em&gt;R Programming for Data Science&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;we-need-to-warm-up-before-jumping-into-power.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;We need to warm up before jumping into power.&lt;/h2&gt;
&lt;p&gt;Let’s load our primary packages. The &lt;strong&gt;tidyverse&lt;/strong&gt; helps organize data and we model with &lt;strong&gt;brms&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Consider a case where you have some dependent variable &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; that you’d like to compare between two groups, which we’ll call treatment and control. Here we presume &lt;span class=&#34;math inline&#34;&gt;\(Y\)&lt;/span&gt; is continuous and, for the sake of simplicity, is in a standardized metric for the control condition. Letting &lt;span class=&#34;math inline&#34;&gt;\(c\)&lt;/span&gt; stand for control and &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; index the data row for a given case, we might write that as &lt;span class=&#34;math inline&#34;&gt;\(y_{i, c} \sim \operatorname{Normal} (0, 1)\)&lt;/span&gt;. The mean for our treatment condition is 0.5, with the standard deviation still in the standardized metric. In the social sciences a standardized mean difference of 0.5 would typically be considered a medium effect size. Here’s what that’d look like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set our theme because, though I love the default ggplot theme, I hate gridlines
theme_set(theme_grey() +
            theme(panel.grid = element_blank()))

# define the means
mu_c &amp;lt;- 0
mu_t &amp;lt;- 0.5

# set up the data
tibble(x = seq(from = -4, to = 5, by = .01)) %&amp;gt;%
  mutate(c = dnorm(x, mean = mu_c, sd = 1),
         t = dnorm(x, mean = mu_t, sd = 1)) %&amp;gt;% 
  
  # plot
  ggplot(aes(x = x)) +
  geom_area(aes(y = c),
            size = 0, alpha = 1/3, fill = &amp;quot;grey25&amp;quot;) +
  geom_area(aes(y = t),
            size = 0, alpha = 1/3, fill = &amp;quot;blue2&amp;quot;) +
 annotate(geom = &amp;quot;text&amp;quot;,
           x = c(-.5, 1), y = .385,
           label = c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;),
           hjust = 1:0,
           size = 5) +
  scale_x_continuous(NULL, breaks = -4:5) +
  scale_y_continuous(NULL, breaks = NULL) +
  scale_color_manual(values = c(&amp;quot;grey25&amp;quot;, &amp;quot;blue2&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Sure, those distributions have a lot of overlap. But their means are clearly different and we’d like to make sure we plan on collecting enough data to do a good job showing that. A power analysis will help.&lt;/p&gt;
&lt;p&gt;Within the conventional frequentist paradigm, power is the probability of rejecting the null hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; in favor of the alternative hypothesis &lt;span class=&#34;math inline&#34;&gt;\(H_1\)&lt;/span&gt;, given the alternative hypothesis is “true.” In this case, the typical null hypothesis is&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_0\text{: } \mu_c = \mu_t,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or put differently,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
H_0\text{: } \mu_t - \mu_c = 0.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And the alternative hypothesis is often just&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[H_1\text{: } \mu_c \neq \mu_t,\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or otherwise put,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
H_1\text{: } \mu_t - \mu_c \neq 0.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Within the regression framework, we’ll be comparing &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;s using the formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_i &amp;amp; \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i &amp;amp; = \beta_0 + \beta_1 \text{treatment}_i,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\text{treatment}\)&lt;/span&gt; is a dummy variable coded 0 = control 1 = treatment and varies across cases indexed by &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;. In this setup, &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the estimate for &lt;span class=&#34;math inline&#34;&gt;\(\mu_c\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is the estimate of the difference between condition means, &lt;span class=&#34;math inline&#34;&gt;\(\mu_t - \mu_c\)&lt;/span&gt;. Thus our focal parameter, the one we care about the most in our power analysis, will be &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Within the frequentist paradigm, we typically compare these hypotheses using a &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value for &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; with the critical value, &lt;span class=&#34;math inline&#34;&gt;\(\alpha\)&lt;/span&gt;, set to .05. Thus, power is the probability we’ll have &lt;span class=&#34;math inline&#34;&gt;\(p &amp;lt; .05\)&lt;/span&gt; when it is indeed the case that &lt;span class=&#34;math inline&#34;&gt;\(\mu_c \neq \mu_t\)&lt;/span&gt;. We won’t be computing &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-values in this project, but we will use 95% intervals. Recall that the result of a Bayesian analysis, the posterior distribution, is the probability of the parameters, given the data &lt;span class=&#34;math inline&#34;&gt;\(p (\theta | \text{data})\)&lt;/span&gt;. With our 95% Bayesian credible intervals, we’ll be able to describe the parameter space over which our estimate of &lt;span class=&#34;math inline&#34;&gt;\(\mu_t - \mu_c\)&lt;/span&gt; is 95% probable. That is, for our power analysis, we’re interested in the probability our 95% credible intervals for &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; contain zero within their bounds when we know a priori &lt;span class=&#34;math inline&#34;&gt;\(\mu_c \neq \mu_t\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The reason we know &lt;span class=&#34;math inline&#34;&gt;\(\mu_c \neq \mu_t\)&lt;/span&gt; is because we’ll be simulating the data that way. What our power analysis will help us determine is how many cases we’ll need to achieve a predetermined level of power. The conventional threshold is .8.&lt;/p&gt;
&lt;div id=&#34;dry-run-number-1.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Dry run number 1.&lt;/h3&gt;
&lt;p&gt;To make this all concrete, let’s start with a simple example. We’ll simulate a single set of data, fit a Bayesian regression model, and examine the results for the critical parameter &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;. For the sake of simplicity, let’s keep our two groups, treatment and control, the same size. We’ll start with &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt; for each.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;n &amp;lt;- 50&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We already decided above that&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{i, c} &amp;amp; \sim \operatorname{Normal}(0, 1) \text{ and} \\
y_{i, t} &amp;amp; \sim \operatorname{Normal}(0.5, 1).
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here’s how we might simulate data along those lines.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)

d &amp;lt;-
  tibble(group = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
  mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
         y         = ifelse(group == &amp;quot;control&amp;quot;, 
                            rnorm(n, mean = mu_c, sd = 1),
                            rnorm(n, mean = mu_t, sd = 1)))

glimpse(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 100
## Columns: 3
## $ group     &amp;lt;chr&amp;gt; &amp;quot;control&amp;quot;, &amp;quot;control&amp;quot;, &amp;quot;control&amp;quot;, &amp;quot;control&amp;quot;, &amp;quot;control&amp;quot;, &amp;quot;cont…
## $ treatment &amp;lt;dbl&amp;gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
## $ y         &amp;lt;dbl&amp;gt; -0.62645381, 0.18364332, -0.83562861, 1.59528080, 0.32950777…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In case it wasn’t clear, the two variables &lt;code&gt;group&lt;/code&gt; and &lt;code&gt;treatment&lt;/code&gt; are redundant. Whereas the former is composed of names, the latter is the dummy-variable equivalent (i.e., control = 0, treatment = 1). The main event was how we used the &lt;code&gt;rnorm()&lt;/code&gt; function to simulate the normally-distributed values for &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Before we fit our model, we need to decide on priors. To give us ideas, here are the &lt;strong&gt;brms&lt;/strong&gt; defaults for our model and data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;get_prior(data = d,
          family = gaussian,
          y ~ 0 + Intercept + treatment)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                 prior class      coef group resp dpar nlpar bound       source
##                (flat)     b                                            default
##                (flat)     b Intercept                             (vectorized)
##                (flat)     b treatment                             (vectorized)
##  student_t(3, 0, 2.5) sigma                                            default&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A few things: Notice that here we’re using the &lt;code&gt;0 + Intercept&lt;/code&gt; syntax. This is because &lt;strong&gt;brms&lt;/strong&gt; handles the priors for the default intercept under the presumption you’ve mean-centered all your predictor variables. However, since our &lt;code&gt;treatment&lt;/code&gt; variable is a dummy, that assumption won’t fly. The &lt;code&gt;0 + Intercept&lt;/code&gt; allows us to treat the model intercept as just another &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; parameter, which makes no assumptions about centering. Along those lines, you’ll notice &lt;strong&gt;brms&lt;/strong&gt; currently defaults to flat priors for the &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; parameters (i.e., those for which &lt;code&gt;class = b&lt;/code&gt;). And finally, the default prior on &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is moderately wide &lt;code&gt;student_t(3, 0, 2.5)&lt;/code&gt;. By default, &lt;strong&gt;brms&lt;/strong&gt; also sets the left bounds for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; parameters at zero, making that a folded-&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; distribution. If you’re confused by these details, spend some time with the &lt;a href=&#34;https://cran.r-project.org/package=brms/brms.pdf&#34;&gt;&lt;strong&gt;brms&lt;/strong&gt; reference manual&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-brms2020RM&#34; role=&#34;doc-biblioref&#34;&gt;Bürkner, 2020b&lt;/a&gt;)&lt;/span&gt;, particularly the &lt;code&gt;brm&lt;/code&gt; and &lt;code&gt;brmsformula&lt;/code&gt; sections.&lt;/p&gt;
&lt;p&gt;In this project, we’ll be primarily using two kinds of priors: default flat priors and weakly-regularizing priors. Hopefully flat priors are self-explanatory. They let the likelihood (data) dominate the posterior and tend to produce results similar to those from frequentist estimators.&lt;/p&gt;
&lt;p&gt;As for weakly-regularizing priors, McElreath covered them in his text. They’re mentioned a bit in the &lt;strong&gt;Stan&lt;/strong&gt; team’s &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;&lt;em&gt;Prior Choice Recommendations&lt;/em&gt;&lt;/a&gt; wiki, and you can learn even more from Gelman, Simpson, and Betancourt’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-gelmanPriorCanOften2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/research/published/entropy-19-00555-v2.pdf&#34;&gt;&lt;em&gt;The prior can only be understood in the context of the likelihood&lt;/em&gt;&lt;/a&gt;. These priors aren’t strongly informative and aren’t really representative of our research hypotheses. But they’re not as absurd as flat priors, either. Rather, with just a little bit of knowledge about the data, these priors are set to keep the MCMC chains on target. Since our &lt;code&gt;y&lt;/code&gt; variable has a mean near zero and a standard deviation near one and since our sole predictor, &lt;code&gt;treatment&lt;/code&gt; is a dummy, setting &lt;span class=&#34;math inline&#34;&gt;\(\operatorname{Normal}(0, 2)\)&lt;/span&gt; as the prior for both &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; parameters might be a good place to start. The prior is permissive enough that it will let likelihood dominate the posterior, but it also rules out ridiculous parts of the parameter space (e.g., a standardized mean difference of 20, an intercept of -93). And since we know the data are on the unit scale, we might just center our folded-Student-&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; prior on one and add a gentle scale setting of one.&lt;/p&gt;
&lt;p&gt;Feel free to disagree and use your own priors. The great thing about priors is that they can be proposed, defended, criticized and improved. The point is to settle on the priors you can defend with written reasons. Select ones you’d feel comfortable defending to a skeptical reviewer.&lt;/p&gt;
&lt;p&gt;Here’s how we might fit the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit &amp;lt;-
  brm(data = d,
      family = gaussian,
      y ~ 0 + Intercept + treatment,
      prior = c(prior(normal(0, 2), class = b),
                prior(student_t(3, 1, 1), class = sigma)),
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we look at the summary, we might check the chains in a trace plot. We’re looking for “stuck” chains that don’t appear to come from a normal distribution (the chains are a profile-like view rather than histogram, allowing for inspection of dependence between samples).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Yep, the chains all look good. Here’s the parameter summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y ~ 0 + Intercept + treatment 
##    Data: d (Number of observations: 100) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.10      0.13    -0.16     0.36 1.00     2094     2048
## treatment     0.51      0.18     0.16     0.90 1.00     2079     1989
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.92      0.07     0.80     1.06 1.00     2684     2122
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The 95% credible intervals for our &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; parameter, termed &lt;code&gt;treatment&lt;/code&gt; in the output, are well above zero.&lt;/p&gt;
&lt;p&gt;Another way to look at the parameter summary is with the &lt;code&gt;brms::fixef()&lt;/code&gt; function.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            Estimate Est.Error       Q2.5     Q97.5
## Intercept 0.1033326 0.1312632 -0.1556192 0.3640170
## treatment 0.5142275 0.1847559  0.1587896 0.8976941&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;you-can-reuse-a-fit.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;You can reuse a fit.&lt;/h3&gt;
&lt;p&gt;Especially with simple models like this, a lot of the time we spend waiting for &lt;code&gt;brms::brm()&lt;/code&gt; to return the model is wrapped up in compilation. This is because &lt;strong&gt;brms&lt;/strong&gt; is a collection of user-friendly functions designed to fit models with &lt;a href=&#34;https://mc-stan.org&#34;&gt;&lt;strong&gt;Stan&lt;/strong&gt;&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-standevelopmentteamRStanInterfaceStan2020&#34; role=&#34;doc-biblioref&#34;&gt;Stan Development Team, 2020&lt;/a&gt;, &lt;a href=&#34;#ref-standevelopmentteamStanReferenceManual2021&#34; role=&#34;doc-biblioref&#34;&gt;2021a&lt;/a&gt;, &lt;a href=&#34;#ref-standevelopmentteamStanUserGuide2021&#34; role=&#34;doc-biblioref&#34;&gt;2021b&lt;/a&gt;)&lt;/span&gt;. With each new model, &lt;code&gt;brm()&lt;/code&gt; translates your model into &lt;strong&gt;Stan&lt;/strong&gt; code, which then gets translated to C++ and is compiled afterwards (see &lt;a href=&#34;https://cran.r-project.org/package=brms/vignettes/brms_overview.pdf&#34;&gt;here&lt;/a&gt; or &lt;a href=&#34;https://cran.r-project.org/package=brms/brms.pdf&#34;&gt;here&lt;/a&gt;). However, we can use the &lt;code&gt;update()&lt;/code&gt; function to update a previously-compiled fit object with new data. This cuts out the compilation time and allows us to get directly to sampling. Here’s how to do it.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set a new seed
set.seed(2)

# simulate new data based on that new seed
d &amp;lt;-
  tibble(group = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
  mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
         y         = ifelse(group == &amp;quot;control&amp;quot;, 
                            rnorm(n, mean = mu_c, sd = 1),
                            rnorm(n, mean = mu_t, sd = 1)))

updated_fit &amp;lt;-
  update(fit,
         newdata = d,
         seed = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Behold the &lt;code&gt;fixef()&lt;/code&gt; parameter summary for our updated model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(updated_fit)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate Est.Error       Q2.5     Q97.5
## Intercept 0.06410605 0.1692172 -0.2700568 0.3995847
## treatment 0.30654690 0.2387028 -0.1434469 0.7815116&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well how about that? In this case, our 95% credible intervals for the &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; &lt;code&gt;treatment&lt;/code&gt; coefficient did include zero within their bounds. Though the posterior mean, 0.30, is still well away from zero, here we’d fail to reject &lt;span class=&#34;math inline&#34;&gt;\(H_0\)&lt;/span&gt; at the conventional level. This is why we simulate.&lt;/p&gt;
&lt;p&gt;To recap, we’ve&lt;/p&gt;
&lt;ol style=&#34;list-style-type: lower-alpha&#34;&gt;
&lt;li&gt;determined our primary data type,&lt;/li&gt;
&lt;li&gt;cast our research question in terms of a regression model,&lt;/li&gt;
&lt;li&gt;identified the parameter of interest,&lt;/li&gt;
&lt;li&gt;settled on defensible priors,&lt;/li&gt;
&lt;li&gt;picked an initial sample size,&lt;/li&gt;
&lt;li&gt;fit an initial model with a single simulated data set, and&lt;/li&gt;
&lt;li&gt;practiced reusing that fit with &lt;code&gt;update()&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We’re more than half way there! It’s time to do our first power simulation.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;simulate-to-determine-power.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Simulate to determine power.&lt;/h2&gt;
&lt;p&gt;In this post, we’ll play with three ways to do a Bayesian power simulation. They’ll all be similar, but hopefully you’ll learn a bit as we transition from one to the next. Though if you’re impatient and all this seems remedial, you could probably just skip down to the final example, &lt;a href=&#34;#version-3-still-talking-about-memory-we-can-be-even-stingier.&#34;&gt;Version 3&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;version-1-lets-introduce-making-a-custom-model-fitting-function.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Version 1: Let’s introduce making a custom model-fitting function.&lt;/h3&gt;
&lt;p&gt;For our power analysis, we’ll need to simulate a large number of data sets, each of which we’ll fit a model to. Here we’ll make a custom function, &lt;code&gt;sim_d()&lt;/code&gt;, that will simulate new data sets just like before. Our function will have two parameters: we’ll set our seeds with &lt;code&gt;seed&lt;/code&gt; and determine how many cases we’d like per group with &lt;code&gt;n&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_d &amp;lt;- function(seed, n) {
  
  mu_t &amp;lt;- .5
  mu_c &amp;lt;- 0

  set.seed(seed)
  
  tibble(group = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
  mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
         y         = ifelse(group == &amp;quot;control&amp;quot;, 
                            rnorm(n, mean = mu_c, sd = 1),
                            rnorm(n, mean = mu_t, sd = 1)))
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s a quick example of how our function works.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_d(seed = 123, n = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 3
##   group     treatment      y
##   &amp;lt;chr&amp;gt;         &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 control           0 -0.560
## 2 control           0 -0.230
## 3 treatment         1  2.06 
## 4 treatment         1  0.571&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we’re ready to get down to business. We’re going to be saving our simulation results in a nested data frame, &lt;code&gt;s&lt;/code&gt;. Initially, &lt;code&gt;s&lt;/code&gt; will have one column of &lt;code&gt;seed&lt;/code&gt; values. These will serve a dual function. First, they are the values we’ll be feeding into the &lt;code&gt;seed&lt;/code&gt; argument of our custom data-generating function, &lt;code&gt;sim_d()&lt;/code&gt;. Second, since the &lt;code&gt;seed&lt;/code&gt; values serially increase, they also stand in as iteration indexes.&lt;/p&gt;
&lt;p&gt;For our second step, we add the data simulations and save them in a nested column, &lt;code&gt;d&lt;/code&gt;. In the first argument of the &lt;code&gt;purrr::map()&lt;/code&gt; function, we indicate we want to iterate over the values in &lt;code&gt;seed&lt;/code&gt;. In the second argument, we indicate we want to serially plug those &lt;code&gt;seed&lt;/code&gt; values into the first argument within the &lt;code&gt;sim_d()&lt;/code&gt; function. That argument, recall, is the well-named &lt;code&gt;seed&lt;/code&gt; argument. With the final argument in &lt;code&gt;map()&lt;/code&gt;, &lt;code&gt;n = 50&lt;/code&gt;, we hard code 50 into the &lt;code&gt;n&lt;/code&gt; argument of &lt;code&gt;sim_d()&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For the third step, we expand our &lt;code&gt;purrr::map()&lt;/code&gt; skills from above to &lt;code&gt;purrr::map2()&lt;/code&gt;, which allows us to iteratively insert two arguments into a function. Within this paradigm, the two arguments are generically termed &lt;code&gt;.x&lt;/code&gt; and &lt;code&gt;.y&lt;/code&gt;. Thus our approach will be &lt;code&gt;.x = d, .y = seed&lt;/code&gt;. For our function, we specify &lt;code&gt;~update(fit, newdata = .x, seed = .y)&lt;/code&gt;. Thus we’ll be iteratively inserting our simulated &lt;code&gt;d&lt;/code&gt; data into the &lt;code&gt;newdata&lt;/code&gt; argument and will be simultaneously inserting our &lt;code&gt;seed&lt;/code&gt; values into the &lt;code&gt;seed&lt;/code&gt; argument.&lt;/p&gt;
&lt;p&gt;Also notice that the number of iterations we’ll be working with is determined by the number of rows in the &lt;code&gt;seed&lt;/code&gt; column. We are defining that number as &lt;code&gt;n_sim&lt;/code&gt;. Since this is just a blog post, I’m going to take it easy and use 100. But if this was a real power analysis for one of your projects, something like 1,000 would be better.&lt;/p&gt;
&lt;p&gt;Finally, you don’t have to do this, but I’m timing my simulation by saving &lt;code&gt;Sys.time()&lt;/code&gt; values at the beginning and end of the simulation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# how many simulations would you like?
n_sim &amp;lt;- 100

# this will help us track time
t1 &amp;lt;- Sys.time()

# here&amp;#39;s the main event!
s &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(d = map(seed, sim_d, n = 50)) %&amp;gt;% 
  mutate(fit = map2(d, seed, ~update(fit, newdata = .x, seed = .y)))

t2 &amp;lt;- Sys.time()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The entire simulation took just about a minute on my &lt;a href=&#34;https://twitter.com/SolomonKurz/status/1250193047096299520&#34;&gt;new laptop&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t2 - t1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 44.20048 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Your mileage may vary.&lt;/p&gt;
&lt;p&gt;Let’s take a look at what we’ve done.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(s)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##    seed d                  fit      
##   &amp;lt;int&amp;gt; &amp;lt;list&amp;gt;             &amp;lt;list&amp;gt;   
## 1     1 &amp;lt;tibble [100 × 3]&amp;gt; &amp;lt;brmsfit&amp;gt;
## 2     2 &amp;lt;tibble [100 × 3]&amp;gt; &amp;lt;brmsfit&amp;gt;
## 3     3 &amp;lt;tibble [100 × 3]&amp;gt; &amp;lt;brmsfit&amp;gt;
## 4     4 &amp;lt;tibble [100 × 3]&amp;gt; &amp;lt;brmsfit&amp;gt;
## 5     5 &amp;lt;tibble [100 × 3]&amp;gt; &amp;lt;brmsfit&amp;gt;
## 6     6 &amp;lt;tibble [100 × 3]&amp;gt; &amp;lt;brmsfit&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In our 100-row nested tibble, we have all our simulated data sets in the &lt;code&gt;d&lt;/code&gt; column and all of our &lt;strong&gt;brms&lt;/strong&gt; fit objects nested in the &lt;code&gt;fit&lt;/code&gt; column. Next we’ll use &lt;code&gt;fixef()&lt;/code&gt; and a little wrangling to extract the parameter of interest, &lt;code&gt;treatment&lt;/code&gt; (i.e., &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt;), from each simulation. We’ll save the results as &lt;code&gt;parameters&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;parameters &amp;lt;-
  s %&amp;gt;% 
  mutate(treatment = map(fit, ~ fixef(.) %&amp;gt;% 
                           data.frame() %&amp;gt;% 
                           rownames_to_column(&amp;quot;parameter&amp;quot;))) %&amp;gt;% 
  unnest(treatment)

parameters %&amp;gt;% 
  select(-d, -fit) %&amp;gt;% 
  filter(parameter == &amp;quot;treatment&amp;quot;) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
##    seed parameter Estimate Est.Error    Q2.5 Q97.5
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1 treatment    0.514     0.185  0.159  0.898
## 2     2 treatment    0.307     0.239 -0.143  0.782
## 3     3 treatment    0.643     0.171  0.310  0.975
## 4     4 treatment    0.224     0.182 -0.128  0.574
## 5     5 treatment    0.429     0.189  0.0596 0.792
## 6     6 treatment    0.304     0.208 -0.114  0.711&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an aside, I know I’m moving kinda fast with all this wacky &lt;code&gt;purrr::map()&lt;/code&gt;/&lt;code&gt;purrr::map2()&lt;/code&gt; stuff. If you’re new to using the &lt;strong&gt;tidyverse&lt;/strong&gt; for iterating and saving the results in nested data structures, I recommend fixing an adult beverage and cozying up with Hadley Wickham’s presentation, &lt;a href=&#34;https://www.youtube.com/watch?v=rz3_FDVt9eg&#34;&gt;&lt;em&gt;Managing many models&lt;/em&gt;&lt;/a&gt;. And if you really hate it, both Kruschke and McElreath texts contain many examples of how to iterate in a more base &lt;strong&gt;R&lt;/strong&gt; sort of way.&lt;/p&gt;
&lt;p&gt;Anyway, here’s what those 100 &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; summaries look like in bulk.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;parameters %&amp;gt;% 
  filter(parameter == &amp;quot;treatment&amp;quot;) %&amp;gt;% 
  
  ggplot(aes(x = seed, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1/2) +
  labs(x = &amp;quot;seed (i.e., simulation index)&amp;quot;,
       y = expression(beta[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The horizontal lines show the idealized effect size (0.5) and the null hypothesis (0). Already, it’s apparent that most of our intervals indicate there’s more than a 95% probability the null hypothesis is not credible. Several do. Here’s how to quantify that.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;parameters %&amp;gt;% 
  filter(parameter == &amp;quot;treatment&amp;quot;) %&amp;gt;% 
  mutate(check = ifelse(Q2.5 &amp;gt; 0, 1, 0)) %&amp;gt;% 
  summarise(power = mean(check))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   power
##   &amp;lt;dbl&amp;gt;
## 1  0.66&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the second &lt;code&gt;mutate()&lt;/code&gt; line, we used a logical statement within &lt;code&gt;ifelse()&lt;/code&gt; to code all instances where the lower limit of the 95% interval (&lt;code&gt;Q2.5&lt;/code&gt;) was greater than 0 as a 1, with the rest as 0. That left us with a vector of 1’s and 0’s, which we saved as &lt;code&gt;check&lt;/code&gt;. In the &lt;code&gt;summarise()&lt;/code&gt; line, we took the mean of that column, which returned our Bayesian power estimate.&lt;/p&gt;
&lt;p&gt;That is, in 66 of our 100 simulations, an &lt;span class=&#34;math inline&#34;&gt;\(n = 50\)&lt;/span&gt; per group was enough to produce a 95% Bayesian credible interval that did not straddle 0.&lt;/p&gt;
&lt;p&gt;I should probably point out that a 95% interval for which &lt;code&gt;Q97.5 &amp;lt; 0&lt;/code&gt; would have also been consistent with the alternative hypothesis of &lt;span class=&#34;math inline&#34;&gt;\(\mu_c \neq \mu_t\)&lt;/span&gt;. However, I didn’t bother to work that option into the definition of our &lt;code&gt;check&lt;/code&gt; variable because I knew from the outset that that would be a highly unlikely result. But if you’d like to work more rigor into your checks, by all means do.&lt;/p&gt;
&lt;p&gt;And if you’ve gotten this far and have been following along with code of your own, congratulations! You did it! You’ve estimated the power of a Bayesian model with a given &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt;. Now let’s refine our approach.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;version-2-we-might-should-be-more-careful-with-memory.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Version 2: We might should be more careful with memory.&lt;/h3&gt;
&lt;p&gt;I really like it that our &lt;code&gt;s&lt;/code&gt; object contains all our &lt;code&gt;brm()&lt;/code&gt; fits. It makes it really handy to do global diagnostics like making sure our &lt;span class=&#34;math inline&#34;&gt;\(\widehat R\)&lt;/span&gt; values are all within a respectable range.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s %&amp;gt;% 
  mutate(rhat = map(fit, rhat)) %&amp;gt;% 
  unnest(rhat) %&amp;gt;% 
  
  ggplot(aes(x = rhat)) +
  geom_histogram(bins = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-17-1.png&#34; width=&#34;288&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Man those &lt;span class=&#34;math inline&#34;&gt;\(\widehat R\)&lt;/span&gt; values look sweet. It’s great to have a workflow that lets you check them. But holding on to all those fits can take up a lot of memory. If the only thing you’re interested in are the parameter summaries, a better approach might be to do the model refitting and parameter extraction in one step. That way you only save the parameter summaries. Here’s how you might do that.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t3 &amp;lt;- Sys.time()

s2 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(d = map(seed, sim_d, n = 50)) %&amp;gt;% 
  # here&amp;#39;s the new part
  mutate(b1 = map2(d, seed, ~update(fit, newdata = .x, seed = .y) %&amp;gt;% 
                     fixef() %&amp;gt;% 
                     data.frame() %&amp;gt;% 
                     rownames_to_column(&amp;quot;parameter&amp;quot;) %&amp;gt;% 
                     filter(parameter == &amp;quot;treatment&amp;quot;)))

t4 &amp;lt;- Sys.time()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Like before, this only about a minute.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t4 - t3&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 48.12622 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As a point of comparison, here are the sizes of the results from our first approach to those from the second.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;object.size(s)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 79822320 bytes&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;object.size(s2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 503120 bytes&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s a big difference. Hopefully you get the idea. With more complicated models and 10+ times the number of simulations, size will eventually matter.&lt;/p&gt;
&lt;p&gt;Anyway, here are the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s2 %&amp;gt;% 
  unnest(b1) %&amp;gt;% 

  ggplot(aes(x = seed, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1/2) +
  labs(x = &amp;quot;seed (i.e., simulation index)&amp;quot;,
       y = expression(beta[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Same parameter summaries, lower memory burden.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;version-3-still-talking-about-memory-we-can-be-even-stingier.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Version 3: Still talking about memory, we can be even stingier.&lt;/h3&gt;
&lt;p&gt;So far, both of our simulation attempts resulted in our saving the simulated data sets. It’s a really nice option if you ever want to go back and take a look at those simulated data. For example, you might want to inspect a random subset of the data simulations with box plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)

s2 %&amp;gt;% 
  sample_n(12) %&amp;gt;% 
  unnest(d) %&amp;gt;% 
  
  ggplot(aes(x = group, y = y)) +
  geom_boxplot(aes(fill = group), 
               alpha = 2/3, show.legend = F) +
  scale_fill_manual(values = c(&amp;quot;grey25&amp;quot;, &amp;quot;blue2&amp;quot;)) +
  xlab(NULL) +
  facet_wrap(~ seed)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this case, it’s no big deal if we keep the data around or not. The data sets are fairly small and we’re only simulating 100 of them. But in cases where the data are larger and you’re doing thousands of simulations, keeping the data could become a memory drain.&lt;/p&gt;
&lt;p&gt;If you’re willing to forgo the luxury of inspecting your data simulations, it might make sense to run our power analysis in a way that avoids saving them. One way to do so would be to just wrap the data simulation and model fitting all in one function. We’ll call it &lt;code&gt;sim_d_and_fit()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sim_d_and_fit &amp;lt;- function(seed, n) {
  
  mu_t &amp;lt;- .5
  mu_c &amp;lt;- 0
  
  set.seed(seed)
  
  d &amp;lt;-
    tibble(group     = rep(c(&amp;quot;control&amp;quot;, &amp;quot;treatment&amp;quot;), each = n)) %&amp;gt;% 
    mutate(treatment = ifelse(group == &amp;quot;control&amp;quot;, 0, 1),
           y         = ifelse(group == &amp;quot;control&amp;quot;, 
                              rnorm(n, mean = mu_c, sd = 1),
                              rnorm(n, mean = mu_t, sd = 1)))
  
  update(fit,
         newdata = d, 
         seed = seed) %&amp;gt;% 
    fixef() %&amp;gt;% 
    data.frame() %&amp;gt;% 
    rownames_to_column(&amp;quot;parameter&amp;quot;) %&amp;gt;% 
    filter(parameter == &amp;quot;treatment&amp;quot;)
}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now iterate 100 times once more.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t5 &amp;lt;- Sys.time()

s3 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 50)) %&amp;gt;% 
  unnest(b1)

t6 &amp;lt;- Sys.time()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That was pretty quick.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;t6 - t5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Time difference of 48.48654 secs&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s what it returned.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(s3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
##    seed parameter Estimate Est.Error    Q2.5 Q97.5
##   &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;        &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1     1 treatment    0.514     0.185  0.159  0.898
## 2     2 treatment    0.307     0.239 -0.143  0.782
## 3     3 treatment    0.643     0.171  0.310  0.975
## 4     4 treatment    0.224     0.182 -0.128  0.574
## 5     5 treatment    0.429     0.189  0.0596 0.792
## 6     6 treatment    0.304     0.208 -0.114  0.711&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By wrapping our data simulation, model fitting, and parameter extraction steps all in one function, we simplified the output such that we’re no longer holding on to the data simulations or the &lt;strong&gt;brms&lt;/strong&gt; fit objects. We just have the parameter summaries and the &lt;code&gt;seed&lt;/code&gt;, making the product even smaller.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(object = c(&amp;quot;s&amp;quot;, &amp;quot;s2&amp;quot;, &amp;quot;s3&amp;quot;)) %&amp;gt;% 
  mutate(bytes = map_dbl(object, ~get(.) %&amp;gt;% object.size()))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##   object    bytes
##   &amp;lt;chr&amp;gt;     &amp;lt;dbl&amp;gt;
## 1 s      79822320
## 2 s2       503120
## 3 s3         5952&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But the primary results are the same.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 %&amp;gt;% 
  ggplot(aes(x = seed, y = Estimate, ymin = Q2.5, ymax = Q97.5)) +
  geom_hline(yintercept = c(0, .5), color = &amp;quot;white&amp;quot;) +
  geom_pointrange(fatten = 1/2) +
  labs(x = &amp;quot;seed (i.e., simulation index)&amp;quot;,
       y = expression(beta[1]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-power-analysis-part-i/index_files/figure-html/unnamed-chunk-26-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We still get the same power estimate, too.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s3 %&amp;gt;% 
  mutate(check = ifelse(Q2.5 &amp;gt; 0, 1, 0)) %&amp;gt;% 
  summarise(power = mean(check))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   power
##   &amp;lt;dbl&amp;gt;
## 1  0.66&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;next-steps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Next steps&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;But my goal was to figure out what &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; will get me power of .8 or more!&lt;/em&gt;, you say. Fair enough. Try increasing &lt;code&gt;n&lt;/code&gt; to 65 or something.&lt;/p&gt;
&lt;p&gt;If that seems unsatisfying, welcome to the world of simulation. Since our Bayesian models are complicated, we don’t have the luxury of plugging a few values into some quick power formula. Just as simulation is an iterative process, determining on the right values to simulate over might well be an iterative process, too.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;wrap-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Wrap-up&lt;/h2&gt;
&lt;p&gt;Anyway, that’s the essence of the &lt;strong&gt;brms/tidyverse&lt;/strong&gt; workflow for Bayesian power analysis. You follow these steps:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Determine your primary data type.&lt;/li&gt;
&lt;li&gt;Determine your primary regression model and parameter(s) of interest.&lt;/li&gt;
&lt;li&gt;Pick defensible priors for all parameters–the kinds of priors you intend to use once you have the real data in hand.&lt;/li&gt;
&lt;li&gt;Select a sample size.&lt;/li&gt;
&lt;li&gt;Fit an initial model and save the fit object.&lt;/li&gt;
&lt;li&gt;Simulate some large number of data sets all following your prechosen form and use the &lt;code&gt;update()&lt;/code&gt; function to iteratively fit the models.&lt;/li&gt;
&lt;li&gt;Extract the parameter(s) of interest.&lt;/li&gt;
&lt;li&gt;Summarize.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;In addition, we played with a few approaches based on logistical concerns like memory. In the next post, &lt;a href=&#34;https://solomonkurz.netlify.app/post/bayesian-power-analysis-part-ii/&#34;&gt;part II&lt;/a&gt;, we’ll see how the precision-oriented approach to sample-size planning is a viable alternative to power focused on rejecting null hypotheses.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;i-had-help.&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I had help.&lt;/h2&gt;
&lt;p&gt;Special thanks to Christopher Peters (&lt;a href=&#34;https://github.com/statwonk&#34;&gt;@statwonk&lt;/a&gt;) for the helpful edits and suggestions.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] brms_2.15.0     Rcpp_1.0.6      forcats_0.5.1   stringr_1.4.0  
##  [5] dplyr_1.0.5     purrr_0.3.4     readr_1.4.0     tidyr_1.1.3    
##  [9] tibble_3.1.0    ggplot2_3.3.3   tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6          
##   [4] igraph_1.2.6         splines_4.0.4        crosstalk_1.1.0.1   
##   [7] TH.data_1.0-10       rstantools_2.1.1     inline_0.3.17       
##  [10] digest_0.6.27        htmltools_0.5.1.1    rsconnect_0.8.16    
##  [13] fansi_0.4.2          magrittr_2.0.1       modelr_0.1.8        
##  [16] RcppParallel_5.0.2   matrixStats_0.57.0   xts_0.12.1          
##  [19] sandwich_3.0-0       prettyunits_1.1.1    colorspace_2.0-0    
##  [22] rvest_0.3.6          haven_2.3.1          xfun_0.22           
##  [25] callr_3.5.1          crayon_1.4.1         jsonlite_1.7.2      
##  [28] lme4_1.1-25          survival_3.2-10      zoo_1.8-8           
##  [31] glue_1.4.2           gtable_0.3.0         emmeans_1.5.2-1     
##  [34] V8_3.4.0             pkgbuild_1.2.0       rstan_2.21.2        
##  [37] abind_1.4-5          scales_1.1.1         mvtnorm_1.1-1       
##  [40] DBI_1.1.0            miniUI_0.1.1.1       xtable_1.8-4        
##  [43] stats4_4.0.4         StanHeaders_2.21.0-7 DT_0.16             
##  [46] htmlwidgets_1.5.2    httr_1.4.2           threejs_0.3.3       
##  [49] ellipsis_0.3.1       pkgconfig_2.0.3      loo_2.4.1           
##  [52] farver_2.0.3         dbplyr_2.0.0         utf8_1.1.4          
##  [55] tidyselect_1.1.0     labeling_0.4.2       rlang_0.4.10        
##  [58] reshape2_1.4.4       later_1.1.0.1        munsell_0.5.0       
##  [61] cellranger_1.1.0     tools_4.0.4          cli_2.3.1           
##  [64] generics_0.1.0       broom_0.7.5          ggridges_0.5.2      
##  [67] evaluate_0.14        fastmap_1.0.1        yaml_2.2.1          
##  [70] processx_3.4.5       knitr_1.31           fs_1.5.0            
##  [73] nlme_3.1-152         mime_0.10            projpred_2.0.2      
##  [76] xml2_1.3.2           compiler_4.0.4       bayesplot_1.8.0     
##  [79] shinythemes_1.1.2    rstudioapi_0.13      gamm4_0.2-6         
##  [82] curl_4.3             reprex_0.3.0         statmod_1.4.35      
##  [85] stringi_1.5.3        highr_0.8            ps_1.6.0            
##  [88] blogdown_1.3         Brobdingnag_1.2-6    lattice_0.20-41     
##  [91] Matrix_1.3-2         nloptr_1.2.2.2       markdown_1.1        
##  [94] shinyjs_2.0.0        vctrs_0.3.6          pillar_1.5.1        
##  [97] lifecycle_1.0.0      bridgesampling_1.0-0 estimability_1.3    
## [100] httpuv_1.5.4         R6_2.5.0             bookdown_0.21       
## [103] promises_1.1.1       gridExtra_2.3        codetools_0.2-18    
## [106] boot_1.3-26          colourpicker_1.1.0   MASS_7.3-53         
## [109] gtools_3.8.2         assertthat_0.2.1     withr_2.4.1         
## [112] shinystan_2.5.0      multcomp_1.4-16      mgcv_1.8-33         
## [115] parallel_4.0.4       hms_0.5.3            grid_4.0.4          
## [118] coda_0.19-4          minqa_1.2.4          rmarkdown_2.7       
## [121] shiny_1.5.0          lubridate_1.7.9.2    base64enc_0.1-3     
## [124] dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# for the hard-core scrollers:
# if you increase n to 65, the power becomes about .85
n_sim &amp;lt;- 100

t7 &amp;lt;- Sys.time()

s4 &amp;lt;-
  tibble(seed = 1:n_sim) %&amp;gt;% 
  mutate(b1 = map(seed, sim_d_and_fit, n = 65))

t8 &amp;lt;- Sys.time()

t8 - t7

object.size(s4)

s4 %&amp;gt;% 
  unnest(b1) %&amp;gt;% 
  mutate(check = ifelse(Q2.5 &amp;gt; 0, 1, 0)) %&amp;gt;% 
  summarise(power = mean(check))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-burknerBrmsPackageBayesian2017&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2017). &lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;An R&lt;/span&gt; package for &lt;span&gt;Bayesian&lt;/span&gt; multilevel models using &lt;span&gt;Stan&lt;/span&gt;. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;80&lt;/em&gt;(1), 1–28. &lt;a href=&#34;https://doi.org/10.18637/jss.v080.i01&#34;&gt;https://doi.org/10.18637/jss.v080.i01&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerAdvancedBayesianMultilevel2018&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2018). Advanced &lt;span&gt;Bayesian&lt;/span&gt; multilevel modeling with the &lt;span&gt;R&lt;/span&gt; package brms. &lt;em&gt;The R Journal&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(1), 395–411. &lt;a href=&#34;https://doi.org/10.32614/RJ-2018-017&#34;&gt;https://doi.org/10.32614/RJ-2018-017&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-brms&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2020a). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;Bayesian&lt;/span&gt; regression models using ’&lt;span&gt;Stan&lt;/span&gt;’&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=brms&#34;&gt;https://CRAN.R-project.org/package=brms&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-brms2020RM&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2020b). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt; reference manual, &lt;span&gt;Version&lt;/span&gt; 2.14.4&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=brms/brms.pdf&#34;&gt;https://CRAN.R-project.org/package=brms/brms.pdf&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-cohenStatisticalPowerAnalysis1988a&#34; class=&#34;csl-entry&#34;&gt;
Cohen, J. (1988). &lt;em&gt;Statistical power analysis for the behavioral sciences&lt;/em&gt;. &lt;span&gt;L. Erlbaum Associates&lt;/span&gt;. &lt;a href=&#34;https://www.worldcat.org/title/statistical-power-analysis-for-the-behavioral-sciences/oclc/17877467&#34;&gt;https://www.worldcat.org/title/statistical-power-analysis-for-the-behavioral-sciences/oclc/17877467&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelmanPriorCanOften2017&#34; class=&#34;csl-entry&#34;&gt;
Gelman, A., Simpson, D., &amp;amp; Betancourt, M. (2017). The prior can often only be understood in the context of the likelihood. &lt;em&gt;Entropy&lt;/em&gt;, &lt;em&gt;19&lt;/em&gt;(10), 555. &lt;a href=&#34;https://doi.org/10.3390/e19100555&#34;&gt;https://doi.org/10.3390/e19100555&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-grolemundDataScience2017&#34; class=&#34;csl-entry&#34;&gt;
Grolemund, G., &amp;amp; Wickham, H. (2017). &lt;em&gt;R for data science&lt;/em&gt;. &lt;span&gt;O’Reilly&lt;/span&gt;. &lt;a href=&#34;https://r4ds.had.co.nz&#34;&gt;https://r4ds.had.co.nz&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kruschkeDoingBayesianData2015&#34; class=&#34;csl-entry&#34;&gt;
Kruschke, J. K. (2015). &lt;em&gt;Doing &lt;span&gt;Bayesian&lt;/span&gt; data analysis: &lt;span&gt;A&lt;/span&gt; tutorial with &lt;span&gt;R&lt;/span&gt;, &lt;span&gt;JAGS&lt;/span&gt;, and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;Academic Press&lt;/span&gt;. &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;https://sites.google.com/site/doingbayesiandataanalysis/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kurzStatisticalRethinkingBrms2020&#34; class=&#34;csl-entry&#34;&gt;
Kurz, A. S. (2020a). &lt;em&gt;Statistical rethinking with brms, &lt;span class=&#34;nocase&#34;&gt;ggplot2&lt;/span&gt;, and the tidyverse&lt;/em&gt; (version 1.2.0). &lt;a href=&#34;https://doi.org/10.5281/zenodo.3693202&#34;&gt;https://doi.org/10.5281/zenodo.3693202&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kurzDoingBayesianData2020&#34; class=&#34;csl-entry&#34;&gt;
Kurz, A. S. (2020b). &lt;em&gt;Doing &lt;span&gt;Bayesian&lt;/span&gt; data analysis in brms and the tidyverse&lt;/em&gt; (version 0.3.0). &lt;a href=&#34;https://bookdown.org/content/3686/&#34;&gt;https://bookdown.org/content/3686/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kurzStatisticalRethinkingSecondEd2020&#34; class=&#34;csl-entry&#34;&gt;
Kurz, A. S. (2020c). &lt;em&gt;Statistical rethinking with brms, Ggplot2, and the tidyverse: &lt;span&gt;Second&lt;/span&gt; edition&lt;/em&gt; (version 0.1.1). &lt;a href=&#34;https://bookdown.org/content/4857/&#34;&gt;https://bookdown.org/content/4857/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-maxwellSampleSizePlanning2008&#34; class=&#34;csl-entry&#34;&gt;
Maxwell, S. E., Kelley, K., &amp;amp; Rausch, J. R. (2008). Sample size planning for statistical power and accuracy in parameter estimation. &lt;em&gt;Annual Review of Psychology&lt;/em&gt;, &lt;em&gt;59&lt;/em&gt;(1), 537–563. &lt;a href=&#34;https://doi.org/10.1146/annurev.psych.59.103006.093735&#34;&gt;https://doi.org/10.1146/annurev.psych.59.103006.093735&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2020&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2020). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt; (Second Edition). &lt;span&gt;CRC Press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2015&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2015). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-pengProgrammingDataScience2019&#34; class=&#34;csl-entry&#34;&gt;
Peng, R. D. (2019). &lt;em&gt;R programming for data science&lt;/em&gt;. &lt;a href=&#34;https://bookdown.org/rdpeng/rprogdatascience/&#34;&gt;https://bookdown.org/rdpeng/rprogdatascience/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-base&#34; class=&#34;csl-entry&#34;&gt;
R Core Team. (2020). &lt;em&gt;R: &lt;span&gt;A&lt;/span&gt; language and environment for statistical computing&lt;/em&gt;. &lt;span&gt;R Foundation for Statistical Computing&lt;/span&gt;. &lt;a href=&#34;https://www.R-project.org/&#34;&gt;https://www.R-project.org/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-standevelopmentteamRStanInterfaceStan2020&#34; class=&#34;csl-entry&#34;&gt;
Stan Development Team. (2020). &lt;em&gt;&lt;span&gt;RStan&lt;/span&gt;: The &lt;span&gt;R&lt;/span&gt; interface to &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;a href=&#34;https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html&#34;&gt;https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-standevelopmentteamStanReferenceManual2021&#34; class=&#34;csl-entry&#34;&gt;
Stan Development Team. (2021a). &lt;em&gt;Stan reference manual, &lt;span&gt;Version&lt;/span&gt; 2.26&lt;/em&gt;. &lt;a href=&#34;https://mc-stan.org/docs/2_26/reference-manual/&#34;&gt;https://mc-stan.org/docs/2_26/reference-manual/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-standevelopmentteamStanUserGuide2021&#34; class=&#34;csl-entry&#34;&gt;
Stan Development Team. (2021b). &lt;em&gt;Stan user’s guide, &lt;span&gt;Version&lt;/span&gt; 2.26&lt;/em&gt;. &lt;a href=&#34;https://mc-stan.org/docs/2_26/stan-users-guide/index.html&#34;&gt;https://mc-stan.org/docs/2_26/stan-users-guide/index.html&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-tidyverse&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H. (2019). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;tidyverse&lt;/span&gt;: &lt;span&gt;Easily&lt;/span&gt; install and load the ’tidyverse’&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=tidyverse&#34;&gt;https://CRAN.R-project.org/package=tidyverse&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wickhamTidyverseStyleGuide2020&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H. (2020). &lt;em&gt;The tidyverse style guide&lt;/em&gt;. &lt;a href=&#34;https://style.tidyverse.org/&#34;&gt;https://style.tidyverse.org/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wickhamWelcomeTidyverse2019&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. &lt;em&gt;Journal of Open Source Software&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(43), 1686. &lt;a href=&#34;https://doi.org/10.21105/joss.01686&#34;&gt;https://doi.org/10.21105/joss.01686&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
