<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>emmeans | Fahim Ahmad</title>
    <link>/tag/emmeans/</link>
      <atom:link href="/tag/emmeans/index.xml" rel="self" type="application/rss+xml" />
    <description>emmeans</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Fahim Ahmad (2020)</copyright><lastBuildDate>Thu, 16 Dec 2021 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png</url>
      <title>emmeans</title>
      <link>/tag/emmeans/</link>
    </image>
    
    <item>
      <title>Use emmeans() to include 95% CIs around your lme4-based fitted lines</title>
      <link>/post/2021-12-16-use-emmeans-to-include-95-cis-around-your-lme4-based-fitted-lines/</link>
      <pubDate>Thu, 16 Dec 2021 00:00:00 +0000</pubDate>
      <guid>/post/2021-12-16-use-emmeans-to-include-95-cis-around-your-lme4-based-fitted-lines/</guid>
      <description>
&lt;script src=&#34;/post/2021-12-16-use-emmeans-to-include-95-cis-around-your-lme4-based-fitted-lines/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;scenario&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Scenario&lt;/h2&gt;
&lt;p&gt;You’re an &lt;strong&gt;R&lt;/strong&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-base&#34; role=&#34;doc-biblioref&#34;&gt;R Core Team, 2020&lt;/a&gt;)&lt;/span&gt; user and just fit a nice multilevel model to some grouped data and you’d like to showcase the results in a plot. In your plots, it would be ideal to express the model uncertainty with 95% interval bands. If you’re a Bayesian working with &lt;a href=&#34;https://mc-stan.org/&#34;&gt;Stan&lt;/a&gt;-based software, such as &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;&lt;strong&gt;brms&lt;/strong&gt;&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-burknerBrmsPackageBayesian2017&#34; role=&#34;doc-biblioref&#34;&gt;Bürkner, 2017&lt;/a&gt;, &lt;a href=&#34;#ref-burknerAdvancedBayesianMultilevel2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;, &lt;a href=&#34;#ref-R-brms&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt;, this is pretty trivial. But if you’re a frequentist and like using the popular &lt;a href=&#34;https://CRAN.R-project.org/package=lme4&#34;&gt;&lt;strong&gt;lme4&lt;/strong&gt;&lt;/a&gt; package &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-lme4&#34; role=&#34;doc-biblioref&#34;&gt;Bates et al., 2015b&lt;/a&gt;, &lt;a href=&#34;#ref-batesFittingLinearMixedeffects2015&#34; role=&#34;doc-biblioref&#34;&gt;2015a&lt;/a&gt;)&lt;/span&gt;, you might be surprised how difficult it is to get those 95% intervals. I recently stumbled upon a solution with the &lt;a href=&#34;https://github.com/rvlenth/emmeans&#34;&gt;&lt;strong&gt;emmeans&lt;/strong&gt;&lt;/a&gt; package &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-emmeans&#34; role=&#34;doc-biblioref&#34;&gt;Lenth, 2021&lt;/a&gt;)&lt;/span&gt; and the purpose of this blog post is to show you how it works.&lt;/p&gt;
&lt;div id=&#34;i-make-assumptions.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;I make assumptions.&lt;/h3&gt;
&lt;p&gt;You’ll want to be familiar with multilevel regression. For frequentist resources, I recommend the texts by &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-roback2021beyond&#34; role=&#34;doc-biblioref&#34;&gt;Roback &amp;amp; Legler&lt;/a&gt; (&lt;a href=&#34;#ref-roback2021beyond&#34; role=&#34;doc-biblioref&#34;&gt;2021&lt;/a&gt;)&lt;/span&gt;, &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;Hoffman&lt;/a&gt; (&lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;, or &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-singerAppliedLongitudinalData2003&#34; role=&#34;doc-biblioref&#34;&gt;Singer &amp;amp; Willett&lt;/a&gt; (&lt;a href=&#34;#ref-singerAppliedLongitudinalData2003&#34; role=&#34;doc-biblioref&#34;&gt;2003&lt;/a&gt;)&lt;/span&gt;. For the Bayesians in the room, I recommend the texts by McElreath &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;, &lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; or Kruschke &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;All code is in &lt;strong&gt;R&lt;/strong&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-base&#34; role=&#34;doc-biblioref&#34;&gt;R Core Team, 2020&lt;/a&gt;)&lt;/span&gt;, with healthy doses of the &lt;strong&gt;tidyverse&lt;/strong&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-tidyverse&#34; role=&#34;doc-biblioref&#34;&gt;Wickham, 2019&lt;/a&gt;; &lt;a href=&#34;#ref-wickhamWelcomeTidyverse2019&#34; role=&#34;doc-biblioref&#34;&gt;Wickham et al., 2019&lt;/a&gt;)&lt;/span&gt;. Probably the best place to learn about the &lt;strong&gt;tidyverse&lt;/strong&gt;-style of coding, as well as an introduction to &lt;strong&gt;R&lt;/strong&gt;, is Grolemund and Wickham’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-grolemundDataScience2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; freely-available online text, &lt;a href=&#34;https://r4ds.had.co.nz&#34;&gt;&lt;em&gt;R for data science&lt;/em&gt;&lt;/a&gt;. We will also make good use of the &lt;strong&gt;patchwork&lt;/strong&gt; package &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-patchwork&#34; role=&#34;doc-biblioref&#34;&gt;Pedersen, 2019&lt;/a&gt;)&lt;/span&gt;. Our two modeling packages will be the aforementioned &lt;strong&gt;lme4&lt;/strong&gt; and &lt;strong&gt;brms&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Load the primary &lt;strong&gt;R&lt;/strong&gt; packages and adjust the plotting theme.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# load
library(tidyverse)
library(lme4)
library(brms)
library(patchwork)
library(emmeans)

# adjust the plotting theme
theme_set(
  theme_linedraw() +
  theme(panel.grid = element_blank(),
        strip.background = element_rect(fill = &amp;quot;grey92&amp;quot;, color = &amp;quot;grey92&amp;quot;),
        strip.text = element_text(color = &amp;quot;black&amp;quot;, size = 10))
)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;we-need-data.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;We need data.&lt;/h3&gt;
&lt;p&gt;In this post we’ll use the base-&lt;strong&gt;R&lt;/strong&gt; &lt;code&gt;ChickWeight&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data(ChickWeight)

glimpse(ChickWeight)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 578
## Columns: 4
## $ weight &amp;lt;dbl&amp;gt; 42, 51, 59, 64, 76, 93, 106, 125, 149, 171, 199, 205, 40, 49, 58, 72, 84, 103, 122, 138, 162,…
## $ Time   &amp;lt;dbl&amp;gt; 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4…
## $ Chick  &amp;lt;ord&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, …
## $ Diet   &amp;lt;fct&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;ChickWeight&lt;/code&gt; data set contains the &lt;code&gt;weight&lt;/code&gt; measurements in grams for 50 chicks, each of which was randomized into one of four experimental diets. To get a sense of the data, here are their &lt;code&gt;weight&lt;/code&gt; values plotted across &lt;code&gt;Time&lt;/code&gt;, separated by the levels of &lt;code&gt;Diet&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ChickWeight %&amp;gt;%
  ggplot(aes(x = Time, y = weight, group = Chick)) +
  geom_line(alpha = 3/4, size = 1/4) +
  ylim(0, NA) +
  facet_wrap(~ Diet, labeller = label_both)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-16-use-emmeans-to-include-95-cis-around-your-lme4-based-fitted-lines/index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Our goal will be to fit a couple models to these data and practice plotting the model-based trajectories at both the population- and chick-levels.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Models&lt;/h2&gt;
&lt;p&gt;Our first model with be the unconditional linear growth model&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\text{weight}_{ij} &amp;amp; \sim \operatorname{Normal}(\mu_{ij}, \sigma_\epsilon^2) \\
\mu_{ij} &amp;amp; = a_i + b_i \text{Time}_{ij} \\
a_i &amp;amp; = \alpha_0 + u_i \\
b_i &amp;amp; = \beta_0 + v_i \\
\begin{bmatrix} u_i \\ v_i \end{bmatrix} &amp;amp; \sim \operatorname{Normal} \left (
  \begin{bmatrix} 0 \\ 0 \end{bmatrix}, 
  \begin{bmatrix} \sigma_u^2 &amp;amp; \\ \sigma_{uv} &amp;amp; \sigma_v^2 \end{bmatrix} 
\right ),
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; indexes the different levels of &lt;code&gt;Chick&lt;/code&gt; and &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; indexes the various measurements taken across &lt;code&gt;Time&lt;/code&gt;. The &lt;span class=&#34;math inline&#34;&gt;\(a_i\)&lt;/span&gt; intercepts and &lt;span class=&#34;math inline&#34;&gt;\(b_i\)&lt;/span&gt; slopes are both random with a level-2 covariance &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{uv}\)&lt;/span&gt;. The second model will be the conditional quadratic growth model&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\text{weight}_{ij} &amp;amp; \sim \operatorname{Normal}(\mu_{ij}, \sigma_\epsilon^2) \\
\mu_{ij} &amp;amp; = a_i + b_i \text{Time}_{ij} + c_i \text{Time}_{ij}^2 \\
a_i &amp;amp; = \alpha_0 + \alpha_1 \text{Diet}_i + u_i \\
b_i &amp;amp; = \beta_0 + \beta_1 \text{Diet}_i + v_i \\
c_i &amp;amp; = \gamma_0 + \gamma_1 \text{Diet}_i + w_i \\
\begin{bmatrix} u_i \\ v_i \\ w_i \end{bmatrix} &amp;amp; \sim \operatorname{Normal} \left (
  \begin{bmatrix} 0 \\ 0 \\ 0 \end{bmatrix}, 
  \begin{bmatrix} \sigma_u^2 &amp;amp; &amp;amp; \\ \sigma_{uv} &amp;amp; \sigma_v^2 &amp;amp; \\ \sigma_{uw} &amp;amp; \sigma_{vw} &amp;amp; \sigma_w^2 \end{bmatrix} 
\right ),
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;which adds a new quadratic growth parameter &lt;span class=&#34;math inline&#34;&gt;\(c_i\)&lt;/span&gt;, which varies across chicks. The random intercepts, linear slopes, and quadratic slopes all covary in a &lt;span class=&#34;math inline&#34;&gt;\(3 \times 3\)&lt;/span&gt; level-2 variance/covariance matrix and all three parameters are conditioned on the experimental variable &lt;code&gt;Diet&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here’s how to fit the two models with &lt;code&gt;lme4::lmer()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# unconditional linear growth model
fit1 &amp;lt;- lmer(
  data = ChickWeight,
  weight ~ 1 + Time + (1 + Time | Chick)
)

# conditional quadratic growth model
fit2 &amp;lt;- lmer(
  data = ChickWeight,
  weight ~ 1 + Time + I(Time^2) + Diet + Time:Diet + I(Time^2):Diet + (1 + Time + I(Time^2) | Chick)
)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## boundary (singular) fit: see ?isSingular&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you fit the second model, you probably got the warning message reading &lt;code&gt;boundary (singular) fit: see ?isSingular&lt;/code&gt;. That often pops up when one or more of your level-2 variance parameters are zero or close to zero, which isn’t necessarily a problem but it’s just something to take note of. Unless there are other problems with the model, I wouldn’t worry about it.&lt;/p&gt;
&lt;p&gt;As this post isn’t a full multilevel growth model tutorial, I’m not going to go through the model &lt;code&gt;summary()&lt;/code&gt; output. If you’re new to models like this, it’s worth your time to inspect the model parameters with care.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;plot&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Plot&lt;/h2&gt;
&lt;p&gt;There are many ways to plot the results from models like these. If you do a quick web search, you’ll find a variety of other blog posts exploring how to model and visualize the &lt;code&gt;ChickWeight&lt;/code&gt; data. In this post, I’m going to recommend a two-panel approach where you (a) plot the chick-level trajectories, (b) plot the population average trajectory, and (c) combine the two plots with &lt;strong&gt;patchwork&lt;/strong&gt; syntax. You can then generalize from there to suit your own needs.&lt;/p&gt;
&lt;div id=&#34;chick-level-trajectories-wo-uncertainty-with-predict.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Chick-level trajectories w/o uncertainty with &lt;code&gt;predict()&lt;/code&gt;.&lt;/h3&gt;
&lt;p&gt;If you’re tricky, there are many post-processing methods you can use to compute and plot the chick-level trajectories. In this post, we’ll focus on the &lt;code&gt;predict()&lt;/code&gt; method. For simple models fit with the &lt;code&gt;lmer()&lt;/code&gt; function, I recommend the following steps.&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Insert your model fit object into &lt;code&gt;predict()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Covert the results into a data frame.&lt;/li&gt;
&lt;li&gt;Rename the vector of predicted values something generic like &lt;code&gt;y_hat&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Append the original data set with &lt;code&gt;bind_cols()&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Save the results with a descriptive name.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Here’s what those steps look like in action with &lt;code&gt;fit1&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit1.predict.chicks &amp;lt;- predict(fit1) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  set_names(&amp;quot;y_hat&amp;quot;) %&amp;gt;% 
  bind_cols(ChickWeight)

# what have we done?
glimpse(fit1.predict.chicks)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 578
## Columns: 5
## $ y_hat  &amp;lt;dbl&amp;gt; 29.64524, 45.01241, 60.37958, 75.74675, 91.11392, 106.48109, 121.84826, 137.21543, 152.58260,…
## $ weight &amp;lt;dbl&amp;gt; 42, 51, 59, 64, 76, 93, 106, 125, 149, 171, 199, 205, 40, 49, 58, 72, 84, 103, 122, 138, 162,…
## $ Time   &amp;lt;dbl&amp;gt; 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 21, 0, 2, 4…
## $ Chick  &amp;lt;ord&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, …
## $ Diet   &amp;lt;fct&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can plot the results like so.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p1 &amp;lt;- fit1.predict.chicks %&amp;gt;% 
  ggplot(aes(x = Time, y = y_hat, group = Chick)) +
  geom_line(alpha = 2/4, size = 1/4) +
  labs(title = &amp;quot;Chick-level trajectories&amp;quot;,
       subtitle = &amp;quot;predict() method&amp;quot;,
       y = expression(widehat(weight)[italic(i)])) +
  ylim(0, 400)

p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-16-use-emmeans-to-include-95-cis-around-your-lme4-based-fitted-lines/index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now here’s how to follow the same steps to get the chick-level trajectories for the conditional quadratic growth model, &lt;code&gt;fit2&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# compute
fit2.predict.chicks &amp;lt;- predict(fit2) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  set_names(&amp;quot;y_hat&amp;quot;) %&amp;gt;% 
  bind_cols(ChickWeight)

# plot
p2 &amp;lt;- fit2.predict.chicks %&amp;gt;% 
  ggplot(aes(x = Time, y = y_hat, group = Chick)) +
  geom_line(alpha = 2/4, size = 1/4) +
  labs(title = &amp;quot;Chick-level trajectories&amp;quot;,
       subtitle = &amp;quot;predict() method&amp;quot;,
       y = expression(widehat(weight)[italic(i)])) +
  ylim(0, 400) +
  facet_wrap(~ Diet, labeller = label_both)

p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-16-use-emmeans-to-include-95-cis-around-your-lme4-based-fitted-lines/index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;I should point out that this variant of the &lt;code&gt;predict()&lt;/code&gt; method will break down if you have markedly non-linear trajectories and relatively few points the are defined over on the &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;-axis. In those cases, you’ll have to generalize with skillful use of the &lt;code&gt;newdata&lt;/code&gt; argument within &lt;code&gt;predict()&lt;/code&gt;. But that’s an issue for another tutorial.&lt;/p&gt;
&lt;p&gt;A limitation with both these plots is there is no expression of uncertainty for our chick-level trajectories. My go-to approach would be to depict that with 95% interval bands. However, to my knowledge there is no good way to get the frequentist 95% confidence intervals for the chick-level trajectories with a model fit with &lt;strong&gt;lme4&lt;/strong&gt;. You’re just SOL on that one, friends. If you really need those, switch to a Bayesian paradigm.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;population-level-trajectories-wo-uncertainty-with-predict.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Population-level trajectories w/o uncertainty with &lt;code&gt;predict()&lt;/code&gt;.&lt;/h3&gt;
&lt;p&gt;The click-level trajectories are great and IMO not enough researchers make plots like that when they fit multilevel models. &lt;em&gt;Show us the group-level differences implied by your level-2 variance parameters!&lt;/em&gt; But the motivation for this blog post is to show how you can use &lt;strong&gt;emmeans&lt;/strong&gt; to improve your population-level plots. Before we get to the good stuff, let’s first explore the limitations in the &lt;code&gt;predict()&lt;/code&gt; method.&lt;/p&gt;
&lt;p&gt;When using &lt;code&gt;predict()&lt;/code&gt; to compute population-level trajectories, we’ll need to adjust our approach in two important ways. Instead of simply computing the fitted values for each case in the original data set, we’re going to want to define the predictor values beforehand, save those values in a data frame, and then plug that data frame into &lt;code&gt;predict()&lt;/code&gt; via the &lt;code&gt;newdata&lt;/code&gt; argument. Our second adjustment will be to explicitly tell &lt;code&gt;predict()&lt;/code&gt; we only want the population-level values by setting &lt;code&gt;re.form = NA&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here’s what that adjusted workflow looks like for our unconditional model &lt;code&gt;fit1&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define and save the predictor values beforehand
nd &amp;lt;- tibble(Time = 0:21)

fit1.predict.population &amp;lt;- 
  predict(fit1,
          # notice the two new lines
          newdata = nd, 
          re.form = NA) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  set_names(&amp;quot;y_hat&amp;quot;) %&amp;gt;% 
  bind_cols(nd)

# what have we done?
glimpse(fit1.predict.population)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 22
## Columns: 2
## $ y_hat &amp;lt;dbl&amp;gt; 29.17800, 37.63105, 46.08410, 54.53716, 62.99021, 71.44326, 79.89631, 88.34936, 96.80241, 105.…
## $ Time  &amp;lt;int&amp;gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you compare this output to the corresponding output from our &lt;code&gt;fit1.predict.chicks&lt;/code&gt; data frame, you’ll notice the results have fewer rows and columns. If it’s not clear to you why that would be, spend some time pondering the difference between group-level and population-level effects. This can be easy to lose track of when you’re new to multilevel models.&lt;/p&gt;
&lt;p&gt;Now we’re all ready to make the &lt;code&gt;predict()&lt;/code&gt;-based population-level plot, save it as &lt;code&gt;p3&lt;/code&gt;, and use &lt;strong&gt;patchwork&lt;/strong&gt; syntax to display those results along with the chick-level trajectories from before.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p3 &amp;lt;- fit1.predict.population %&amp;gt;% 
  ggplot(aes(x = Time, y = y_hat)) +
  geom_line(size = 1) +
  labs(title = &amp;quot;Population-level trajectory&amp;quot;,
       subtitle = &amp;quot;predict() method&amp;quot;,
       y = expression(widehat(weight))) +
  ylim(0, 400)

# combine the two ggplots
p1 + p3 &amp;amp; 
  # add an overall title
  plot_annotation(title = &amp;quot;Unconditional linear growth model&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-16-use-emmeans-to-include-95-cis-around-your-lme4-based-fitted-lines/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Our population-level plot on the right is okay at showing the expected values, but it’s terrible at expressing the uncertainty we have around those expectations. Before we learn how to solve that problem, let’s first practice this method a once more with our conditional model &lt;code&gt;fit2&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# define and save the predictor values beforehand
nd &amp;lt;- ChickWeight %&amp;gt;% distinct(Diet, Time)

# compute the expected values
fit2.predict.population &amp;lt;- 
  predict(fit2,
          newdata = nd, 
          re.form = NA) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  set_names(&amp;quot;y_hat&amp;quot;) %&amp;gt;% 
  bind_cols(nd)

# make and save the plot
p4 &amp;lt;- fit2.predict.population %&amp;gt;% 
  ggplot(aes(x = Time, y = y_hat)) +
  geom_line(size = 1) +
  labs(title = &amp;quot;Population-level trajectories&amp;quot;,
       subtitle = &amp;quot;predict() method&amp;quot;,
       y = expression(widehat(weight))) +
  ylim(0, 400) +
  facet_wrap(~ Diet, labeller = label_both)

# combine the two ggplots
p2 + p4 &amp;amp; 
  # add an overall title
  plot_annotation(title = &amp;quot;Conditional quadratic growth model&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-16-use-emmeans-to-include-95-cis-around-your-lme4-based-fitted-lines/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This plot’s okay if you’re starting out, but careful scientists can do better. In the next section, we’ll finally learn how.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;population-level-trajectories-with-uncertainty-with-emmeans.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Population-level trajectories &lt;em&gt;with&lt;/em&gt; uncertainty with &lt;code&gt;emmeans()&lt;/code&gt;.&lt;/h3&gt;
&lt;p&gt;Our goal is to use the &lt;code&gt;emmeans::emmeans()&lt;/code&gt; function to compute 95% confidence intervals around our fitted values. Here are the fine points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The first argument, &lt;code&gt;object&lt;/code&gt;, takes our model object. Here we start with unconditional growth model &lt;code&gt;fit1&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;specs&lt;/code&gt; argument allows us to specify which variable(s) we’d like to condition our expected values on. For the unconditional growth model, we just want to condition on &lt;code&gt;Time&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;at&lt;/code&gt; argument allows to specify exactly which values of &lt;code&gt;Time&lt;/code&gt; we’d like to condition on. In this context, the &lt;code&gt;at&lt;/code&gt; argument functions much the same way the &lt;code&gt;newdata&lt;/code&gt; argument functioned within &lt;code&gt;predict()&lt;/code&gt;. Here, though, we define our &lt;code&gt;Time&lt;/code&gt; values within a list.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;lmer.df&lt;/code&gt; argument is not necessary, but I recommend giving it some thought. The default approach to computing the 95% confidence intervals uses the Kenward-Roger method. My understanding is this method is generally excellent and is probably a sensible choice for the default. However, the Kenward-Roger method can be a little slow for some models and you should know about your options. Another fine option is the Satterthwaite method, which is often very close to the Kenward-Roger method, but faster. For the sake of practice, here we’ll set &lt;code&gt;lmer.df = &#34;satterthwaite&#34;&lt;/code&gt;. To learn more about the issue, I recommend reading through &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-kuznetsova2017lmertest&#34; role=&#34;doc-biblioref&#34;&gt;Kuznetsova et al.&lt;/a&gt; (&lt;a href=&#34;#ref-kuznetsova2017lmertest&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-luke2017EvaluatingSignificance&#34; role=&#34;doc-biblioref&#34;&gt;Luke&lt;/a&gt; (&lt;a href=&#34;#ref-luke2017EvaluatingSignificance&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Finally, we convert the output to a data frame and save it with a descriptive name.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit1.emmeans.population &amp;lt;- emmeans(
  object = fit1, 
  specs = ~ Time, 
  at = list(Time = seq(from = 0, to = 21, length.out = 30)), 
  lmer.df = &amp;quot;satterthwaite&amp;quot;) %&amp;gt;% 
  data.frame()

# what is this?
glimpse(fit1.emmeans.population)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 30
## Columns: 6
## $ Time     &amp;lt;dbl&amp;gt; 0.0000000, 0.7241379, 1.4482759, 2.1724138, 2.8965517, 3.6206897, 4.3448276, 5.0689655, 5.7…
## $ emmean   &amp;lt;dbl&amp;gt; 29.17800, 35.29918, 41.42035, 47.54153, 53.66270, 59.78388, 65.90505, 72.02623, 78.14740, 8…
## $ SE       &amp;lt;dbl&amp;gt; 1.9572766, 1.6274605, 1.3315708, 1.0974018, 0.9706994, 0.9934691, 1.1569189, 1.4130459, 1.7…
## $ df       &amp;lt;dbl&amp;gt; 49.13050, 49.27943, 49.47338, 49.56893, 49.12761, 48.30421, 47.99833, 48.07510, 48.20401, 4…
## $ lower.CL &amp;lt;dbl&amp;gt; 25.24497, 32.02914, 38.74511, 45.33685, 51.71214, 57.78670, 63.57891, 69.18522, 74.68756, 8…
## $ upper.CL &amp;lt;dbl&amp;gt; 33.11103, 38.56921, 44.09560, 49.74620, 55.61327, 61.78106, 68.23120, 74.86723, 81.60724, 8…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The expected values are in the &lt;code&gt;emmean&lt;/code&gt; column. See those values in the &lt;code&gt;SE&lt;/code&gt;, &lt;code&gt;df&lt;/code&gt;, and &lt;code&gt;.CL&lt;/code&gt; columns? Those are what we’ve been building up to. In particular, the values in the &lt;code&gt;lower.CL&lt;/code&gt; and &lt;code&gt;upper.CL&lt;/code&gt; columns mark off our 95% confidence-interval bounds. Let’s show those off in a plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p5 &amp;lt;- fit1.emmeans.population %&amp;gt;% 
  ggplot(aes(x = Time, y = emmean, ymin = lower.CL, ymax = upper.CL)) +
  geom_ribbon(alpha = 1/2, fill = &amp;quot;red3&amp;quot;) +
  geom_line(size = 1) +
  labs(title = &amp;quot;Population-level trajectory&amp;quot;,
       subtitle = &amp;quot;emmeans() method&amp;quot;,
       y = expression(widehat(weight))) +
  ylim(0, 400) +
  theme(plot.subtitle = element_text(color = &amp;quot;red4&amp;quot;))

# combine the two ggplots
p1 + p5 &amp;amp; 
  # add an overall title
  plot_annotation(title = &amp;quot;Unconditional linear growth model&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-16-use-emmeans-to-include-95-cis-around-your-lme4-based-fitted-lines/index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Now our population-level plot explicitly expresses the uncertainty in our trajectory with a 95% confidence-interval band. The red shading is a little silly, but I wanted to make sure it was easy to see the change in the plot. Here’s how to extend our &lt;code&gt;emmeans()&lt;/code&gt; method to the more complicated conditional quadratic growth model. Note the changes in the &lt;code&gt;specs&lt;/code&gt; argument.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit2.emmeans.population &amp;lt;- emmeans(
  object = fit2, 
  # this line has changed
  specs = ~ Time : Diet, 
  at = list(Time = seq(from = 0, to = 21, length.out = 30)), 
  lmer.df = &amp;quot;satterthwaite&amp;quot;) %&amp;gt;% 
  data.frame()

# what is this?
glimpse(fit2.emmeans.population)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 120
## Columns: 7
## $ Time     &amp;lt;dbl&amp;gt; 0.0000000, 0.7241379, 1.4482759, 2.1724138, 2.8965517, 3.6206897, 4.3448276, 5.0689655, 5.7…
## $ Diet     &amp;lt;fct&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2…
## $ emmean   &amp;lt;dbl&amp;gt; 37.53433, 41.26093, 45.04110, 48.87484, 52.76214, 56.70301, 60.69745, 64.74545, 68.84702, 7…
## $ SE       &amp;lt;dbl&amp;gt; 1.6868681, 1.2258006, 0.9062629, 0.8356543, 1.0232620, 1.3408419, 1.7023042, 2.0762953, 2.4…
## $ df       &amp;lt;dbl&amp;gt; 56.00845, 71.36390, 162.12707, 120.87857, 55.54711, 47.95749, 46.83404, 46.67509, 46.67226,…
## $ lower.CL &amp;lt;dbl&amp;gt; 34.15514, 38.81697, 43.25150, 47.22043, 50.71193, 54.00701, 57.27253, 60.56771, 63.91091, 6…
## $ upper.CL &amp;lt;dbl&amp;gt; 40.91352, 43.70490, 46.83071, 50.52926, 54.81235, 59.39902, 64.12236, 68.92318, 73.78313, 7…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note how our output now has a &lt;code&gt;Diet&lt;/code&gt; column and that there are four times as many rows as before. That’s all because of our changes to the &lt;code&gt;specs&lt;/code&gt; argument. Here’s the plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p6 &amp;lt;- fit2.emmeans.population %&amp;gt;% 
  ggplot(aes(x = Time, y = emmean, ymin = lower.CL, ymax = upper.CL)) +
  geom_ribbon(alpha = 1/2, fill = &amp;quot;red3&amp;quot;) +
  geom_line(size = 1) +
  labs(title = &amp;quot;Population-level trajectories&amp;quot;,
       subtitle = &amp;quot;emmeans() method&amp;quot;,
       y = expression(widehat(weight))) +
  ylim(0, 400) +
  facet_wrap(~ Diet, labeller = label_both) +
  theme(plot.subtitle = element_text(color = &amp;quot;red4&amp;quot;))

# combine the two ggplots
p2 + p6 &amp;amp; 
  # add an overall title
  plot_annotation(title = &amp;quot;Conditional quadratic growth model&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-16-use-emmeans-to-include-95-cis-around-your-lme4-based-fitted-lines/index_files/figure-html/unnamed-chunk-16-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Glorious.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;but-that-bayes-though&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;But that Bayes, though&lt;/h2&gt;
&lt;p&gt;The Bayesians in the room have been able to compute 95% intervals of this kind all along. They just set their priors, sample from the posterior, and summarize the posterior samples as needed. It’s no big deal. Which brings us to an important caveat:&lt;/p&gt;
&lt;p&gt;Whether you use &lt;code&gt;emmeans()&lt;/code&gt; to compute 95% confidence intervals by the Kenward-Roger method or the Satterthwaite method, both approaches are approximate and will occasionally return questionable results. Again, see &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-kuznetsova2017lmertest&#34; role=&#34;doc-biblioref&#34;&gt;Kuznetsova et al.&lt;/a&gt; (&lt;a href=&#34;#ref-kuznetsova2017lmertest&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; and &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-luke2017EvaluatingSignificance&#34; role=&#34;doc-biblioref&#34;&gt;Luke&lt;/a&gt; (&lt;a href=&#34;#ref-luke2017EvaluatingSignificance&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt; for introductions to the issue. So if you’re going to use the &lt;code&gt;emmeans()&lt;/code&gt; method, you should heed this warning from the great &lt;a href=&#34;https://math.mcmaster.ca/~bolker/&#34;&gt;Ben Bolker&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;Nice. I&amp;#39;m not surprised, but strongly encourage everyone using the emmeans-style CIs to do their own comparison with Bayesian methods (brms/MCMCglmm) or parametric bootstrap; everyone&amp;#39;s data is different ... (machinery for importance-sampling CIs wd be useful - devel volunteers?)&lt;/p&gt;&amp;mdash; Ben Bolker (@bolkerb) &lt;a href=&#34;https://twitter.com/bolkerb/status/1465826587060940806?ref_src=twsrc%5Etfw&#34;&gt;November 30, 2021&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;
&lt;/p&gt;
&lt;p&gt;It’s wise to inspect the quality of your &lt;code&gt;emmeans()&lt;/code&gt;-based Kenward-Roger or Satterthwaite intervals against intervals computed using the parametric bootstrap, or with Bayesian software. Though it’s my understanding that &lt;code&gt;emmeans()&lt;/code&gt; is capable of bootstrapping, I have not explored that functionality and will have to leave that guidance up to others. I can, however, give you an example of how to compare our Satterthwaite intervals to those from a Bayesian model computed with the &lt;strong&gt;brms&lt;/strong&gt; package. Here we’ll use &lt;code&gt;brms::brm()&lt;/code&gt; to fit the Bayesian version of our unconditional growth model. For simplicity, we’ll use the default minimally-informative priors&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit3 &amp;lt;- brm(
  data = ChickWeight,
  family = gaussian,
  weight ~ 1 + Time + (1 + Time | Chick),
  cores = 4, seed = 1
)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When working with a &lt;strong&gt;brms&lt;/strong&gt; model, it’s the &lt;code&gt;fitted()&lt;/code&gt; function that will most readily take the place of what we were doing with &lt;code&gt;emmeans()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nd &amp;lt;- tibble(Time = 0:21)

fit3.fitted.population &amp;lt;- fitted(
  fit3,
  newdata = nd,
  re_formula = NA) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  bind_cols(nd)

# what is this?
glimpse(fit3.fitted.population)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 22
## Columns: 5
## $ Estimate  &amp;lt;dbl&amp;gt; 29.21441, 37.65529, 46.09618, 54.53707, 62.97796, 71.41885, 79.85973, 88.30062, 96.74151, …
## $ Est.Error &amp;lt;dbl&amp;gt; 2.021475, 1.564884, 1.199970, 1.029351, 1.143576, 1.478018, 1.920905, 2.413252, 2.930232, …
## $ Q2.5      &amp;lt;dbl&amp;gt; 25.26062, 34.64450, 43.77749, 52.54076, 60.71001, 68.49214, 76.10985, 83.63797, 91.21743, …
## $ Q97.5     &amp;lt;dbl&amp;gt; 33.26492, 40.71766, 48.43553, 56.53052, 65.18467, 74.32911, 83.64334, 93.01031, 102.54640,…
## $ Time      &amp;lt;int&amp;gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;Estimate&lt;/code&gt; column is our posterior mean, which roughly corresponds to the expectations from our frequentist models. The percentile-based 95% Bayesian interval bounds are listed in the &lt;code&gt;Q2.5&lt;/code&gt; and &lt;code&gt;Q97.5&lt;/code&gt; columns. Here’s how you can compare these results with the Satterthwaite-based intervals, from above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fit3.fitted.population %&amp;gt;% 
  ggplot(aes(x = Time)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),
              alpha = 1/2, fill = &amp;quot;blue3&amp;quot;) +
  geom_ribbon(data = fit1.emmeans.population,
              aes(ymin = lower.CL, ymax = upper.CL),
              alpha = 1/2, fill = &amp;quot;red3&amp;quot;) +
  labs(title = &amp;quot;The Satterthwaite intervals versus the Bayesian intervals&amp;quot;,
       subtitle = &amp;quot;The Bayesian percentile-based intervals are in semitransparent blue.\nThe frequentist Satterthwaite-based intervals are in semitransparent red.\nIt appears as if there&amp;#39;s just a purple band because the two interval types largely overlap.&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2021-12-16-use-emmeans-to-include-95-cis-around-your-lme4-based-fitted-lines/index_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this case, the two sets of 95% intervals are in near perfect agreement. On the one hand, this is great and it suggests that we’re on good footing to move ahead with our &lt;code&gt;emmeans()&lt;/code&gt; approach. On the other hand, be cautioned: Though Bayesian and frequentist intervals often times overlap, this won’t always be the case and it’s not necessarily a problem when they don’t. Remember that Bayesian models are combinations of the likelihood AND the prior and if you fit your Bayesian models with informative priors, the resulting posterior might well be different from the frequentist solution.&lt;/p&gt;
&lt;p&gt;Another thing to consider is that if we’re using Bayesian intervals as the benchmark for quality, then why not just switch to a Bayesian modeling paradigm altogether? Indeed, friends. Indeed.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.1.1 (2021-08-10)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] emmeans_1.7.1-1 patchwork_1.1.1 brms_2.16.2     Rcpp_1.0.7      lme4_1.1-27.1   Matrix_1.3-4   
##  [7] forcats_0.5.1   stringr_1.4.0   dplyr_1.0.7     purrr_0.3.4     readr_2.0.1     tidyr_1.1.3    
## [13] tibble_3.1.6    ggplot2_3.3.5   tidyverse_1.3.1
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.3.0      plyr_1.8.6           igraph_1.2.6         splines_4.1.1       
##   [6] crosstalk_1.1.1      TH.data_1.0-10       rstantools_2.1.1     inline_0.3.19        digest_0.6.28       
##  [11] htmltools_0.5.2      rsconnect_0.8.24     lmerTest_3.1-3       fansi_0.5.0          magrittr_2.0.1      
##  [16] checkmate_2.0.0      tzdb_0.1.2           modelr_0.1.8         RcppParallel_5.1.4   matrixStats_0.61.0  
##  [21] xts_0.12.1           sandwich_3.0-1       prettyunits_1.1.1    colorspace_2.0-2     rvest_1.0.1         
##  [26] haven_2.4.3          xfun_0.25            callr_3.7.0          crayon_1.4.2         jsonlite_1.7.2      
##  [31] survival_3.2-11      zoo_1.8-9            glue_1.5.0           gtable_0.3.0         V8_3.4.2            
##  [36] distributional_0.2.2 pkgbuild_1.2.0       rstan_2.26.3         abind_1.4-5          scales_1.1.1        
##  [41] mvtnorm_1.1-2        DBI_1.1.1            miniUI_0.1.1.1       xtable_1.8-4         stats4_4.1.1        
##  [46] StanHeaders_2.26.3   DT_0.19              htmlwidgets_1.5.3    httr_1.4.2           threejs_0.3.3       
##  [51] posterior_1.1.0.9000 ellipsis_0.3.2       pkgconfig_2.0.3      loo_2.4.1            farver_2.1.0        
##  [56] sass_0.4.0           dbplyr_2.1.1         utf8_1.2.2           labeling_0.4.2       tidyselect_1.1.1    
##  [61] rlang_0.4.12         reshape2_1.4.4       later_1.3.0          cellranger_1.1.0     munsell_0.5.0       
##  [66] tools_4.1.1          cli_3.1.0            generics_0.1.1       broom_0.7.9          ggridges_0.5.3      
##  [71] evaluate_0.14        fastmap_1.1.0        yaml_2.2.1           fs_1.5.0             processx_3.5.2      
##  [76] knitr_1.33           nlme_3.1-152         mime_0.11            projpred_2.0.2       xml2_1.3.2          
##  [81] compiler_4.1.1       bayesplot_1.8.1      shinythemes_1.2.0    rstudioapi_0.13      curl_4.3.2          
##  [86] gamm4_0.2-6          reprex_2.0.1         bslib_0.3.0          stringi_1.7.4        highr_0.9           
##  [91] ps_1.6.0             blogdown_1.5         Brobdingnag_1.2-6    lattice_0.20-44      nloptr_1.2.2.2      
##  [96] markdown_1.1         shinyjs_2.0.0        tensorA_0.36.2       vctrs_0.3.8          pillar_1.6.4        
## [101] lifecycle_1.0.1      jquerylib_0.1.4      bridgesampling_1.1-2 estimability_1.3     httpuv_1.6.2        
## [106] R6_2.5.1             bookdown_0.23        promises_1.2.0.1     gridExtra_2.3        codetools_0.2-18    
## [111] boot_1.3-28          colourpicker_1.1.0   MASS_7.3-54          gtools_3.9.2         assertthat_0.2.1    
## [116] withr_2.4.2          shinystan_2.5.0      multcomp_1.4-17      mgcv_1.8-36          parallel_4.1.1      
## [121] hms_1.1.0            grid_4.1.1           coda_0.19-4          minqa_1.2.4          rmarkdown_2.10      
## [126] numDeriv_2016.8-1.1  shiny_1.6.0          lubridate_1.7.10     base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-R-lme4&#34; class=&#34;csl-entry&#34;&gt;
Bates, D., Mächler, M., Bolker, B., &amp;amp; Walker, S. (2015b). Fitting linear mixed-effects models using &lt;span class=&#34;nocase&#34;&gt;lme4&lt;/span&gt;. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;67&lt;/em&gt;(1), 1–48. &lt;a href=&#34;https://doi.org/10.18637/jss.v067.i01&#34;&gt;https://doi.org/10.18637/jss.v067.i01&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-batesFittingLinearMixedeffects2015&#34; class=&#34;csl-entry&#34;&gt;
Bates, D., Mächler, M., Bolker, B., &amp;amp; Walker, S. (2015a). Fitting linear mixed-effects models using Lme4. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;67&lt;/em&gt;(1), 1–48. &lt;a href=&#34;https://doi.org/10.18637/jss.v067.i01&#34;&gt;https://doi.org/10.18637/jss.v067.i01&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerBrmsPackageBayesian2017&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2017). &lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;An R&lt;/span&gt; package for &lt;span&gt;Bayesian&lt;/span&gt; multilevel models using &lt;span&gt;Stan&lt;/span&gt;. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;80&lt;/em&gt;(1), 1–28. &lt;a href=&#34;https://doi.org/10.18637/jss.v080.i01&#34;&gt;https://doi.org/10.18637/jss.v080.i01&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerAdvancedBayesianMultilevel2018&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2018). Advanced &lt;span&gt;Bayesian&lt;/span&gt; multilevel modeling with the &lt;span&gt;R&lt;/span&gt; package brms. &lt;em&gt;The R Journal&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(1), 395–411. &lt;a href=&#34;https://doi.org/10.32614/RJ-2018-017&#34;&gt;https://doi.org/10.32614/RJ-2018-017&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-brms&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;Bayesian&lt;/span&gt; regression models using ’&lt;span&gt;Stan&lt;/span&gt;’&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=brms&#34;&gt;https://CRAN.R-project.org/package=brms&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-grolemundDataScience2017&#34; class=&#34;csl-entry&#34;&gt;
Grolemund, G., &amp;amp; Wickham, H. (2017). &lt;em&gt;R for data science&lt;/em&gt;. &lt;span&gt;O’Reilly&lt;/span&gt;. &lt;a href=&#34;https://r4ds.had.co.nz&#34;&gt;https://r4ds.had.co.nz&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hoffmanLongitudinalAnalysisModeling2015&#34; class=&#34;csl-entry&#34;&gt;
Hoffman, L. (2015). &lt;em&gt;Longitudinal analysis: &lt;span&gt;Modeling&lt;/span&gt; within-person fluctuation and change&lt;/em&gt; (1 edition). &lt;span&gt;Routledge&lt;/span&gt;. &lt;a href=&#34;https://www.routledge.com/Longitudinal-Analysis-Modeling-Within-Person-Fluctuation-and-Change/Hoffman/p/book/9780415876025&#34;&gt;https://www.routledge.com/Longitudinal-Analysis-Modeling-Within-Person-Fluctuation-and-Change/Hoffman/p/book/9780415876025&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kruschkeDoingBayesianData2015&#34; class=&#34;csl-entry&#34;&gt;
Kruschke, J. K. (2015). &lt;em&gt;Doing &lt;span&gt;Bayesian&lt;/span&gt; data analysis: &lt;span&gt;A&lt;/span&gt; tutorial with &lt;span&gt;R&lt;/span&gt;, &lt;span&gt;JAGS&lt;/span&gt;, and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;Academic Press&lt;/span&gt;. &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;https://sites.google.com/site/doingbayesiandataanalysis/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kuznetsova2017lmertest&#34; class=&#34;csl-entry&#34;&gt;
Kuznetsova, A., Brockhoff, P. B., &amp;amp; Christensen, R. H. (2017). &lt;span class=&#34;nocase&#34;&gt;lmerTest&lt;/span&gt; package: &lt;span&gt;Tests&lt;/span&gt; in linear mixed effects models. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;82&lt;/em&gt;(13), 1–26. &lt;a href=&#34;https://doi.org/10.18637/jss.v082.i13&#34;&gt;https://doi.org/10.18637/jss.v082.i13&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-emmeans&#34; class=&#34;csl-entry&#34;&gt;
Lenth, R. V. (2021). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;emmeans&lt;/span&gt;: &lt;span&gt;Estimated&lt;/span&gt; marginal means, aka least-squares means&lt;/em&gt; [Manual]. &lt;a href=&#34;https://github.com/rvlenth/emmeans&#34;&gt;https://github.com/rvlenth/emmeans&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-luke2017EvaluatingSignificance&#34; class=&#34;csl-entry&#34;&gt;
Luke, S. G. (2017). Evaluating significance in linear mixed-effects models in &lt;span&gt;R&lt;/span&gt;. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;49&lt;/em&gt;(4), 1494–1502. &lt;a href=&#34;https://doi.org/10.3758/s13428-016-0809-y&#34;&gt;https://doi.org/10.3758/s13428-016-0809-y&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2020&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2020). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt; (Second Edition). &lt;span&gt;CRC Press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2015&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2015). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-patchwork&#34; class=&#34;csl-entry&#34;&gt;
Pedersen, T. L. (2019). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;patchwork&lt;/span&gt;: &lt;span&gt;The&lt;/span&gt; composer of plots&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=patchwork&#34;&gt;https://CRAN.R-project.org/package=patchwork&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-base&#34; class=&#34;csl-entry&#34;&gt;
R Core Team. (2020). &lt;em&gt;R: &lt;span&gt;A&lt;/span&gt; language and environment for statistical computing&lt;/em&gt;. &lt;span&gt;R Foundation for Statistical Computing&lt;/span&gt;. &lt;a href=&#34;https://www.R-project.org/&#34;&gt;https://www.R-project.org/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-roback2021beyond&#34; class=&#34;csl-entry&#34;&gt;
Roback, P., &amp;amp; Legler, J. (2021). &lt;em&gt;Beyond multiple linear regression: &lt;span&gt;Applied&lt;/span&gt; generalized linear models and multilevel models in &lt;span&gt;R&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC Press&lt;/span&gt;. &lt;a href=&#34;https://bookdown.org/roback/bookdown-BeyondMLR/&#34;&gt;https://bookdown.org/roback/bookdown-BeyondMLR/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-singerAppliedLongitudinalData2003&#34; class=&#34;csl-entry&#34;&gt;
Singer, J. D., &amp;amp; Willett, J. B. (2003). &lt;em&gt;Applied longitudinal data analysis: &lt;span&gt;Modeling&lt;/span&gt; change and event occurrence&lt;/em&gt;. &lt;span&gt;Oxford University Press, USA&lt;/span&gt;. &lt;a href=&#34;https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780195152968.001.0001/acprof-9780195152968&#34;&gt;https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780195152968.001.0001/acprof-9780195152968&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-tidyverse&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H. (2019). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;tidyverse&lt;/span&gt;: &lt;span&gt;Easily&lt;/span&gt; install and load the ’tidyverse’&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=tidyverse&#34;&gt;https://CRAN.R-project.org/package=tidyverse&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wickhamWelcomeTidyverse2019&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. &lt;em&gt;Journal of Open Source Software&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(43), 1686. &lt;a href=&#34;https://doi.org/10.21105/joss.01686&#34;&gt;https://doi.org/10.21105/joss.01686&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Often times, default priors will return posterior distributions that closely resemble the solutions from their frequentist counterparts. But this won’t always be the case, so do keep your wits about you when comparing Bayesian and frequentist models.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
