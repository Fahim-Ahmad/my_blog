<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>robust | Fahim Ahmad</title>
    <link>/tag/robust/</link>
      <atom:link href="/tag/robust/index.xml" rel="self" type="application/rss+xml" />
    <description>robust</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Fahim Ahmad (2020)</copyright><lastBuildDate>Tue, 29 Dec 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png</url>
      <title>robust</title>
      <link>/tag/robust/</link>
    </image>
    
    <item>
      <title>Regression models for 2-timepoint non-experimental data</title>
      <link>/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/</link>
      <pubDate>Tue, 29 Dec 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/</guid>
      <description>
&lt;script src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;purpose&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Purpose&lt;/h2&gt;
&lt;p&gt;In the contemporary longitudinal data analysis literature, 2-timepoint data (a.k.a. pre/post data) get a bad wrap. Singer and Willett &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-singerAppliedLongitudinalData2003&#34; role=&#34;doc-biblioref&#34;&gt;2003, p. 10&lt;/a&gt;)&lt;/span&gt; described 2-timepoint data as only “marginally better” than cross-sectional data and &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-rogosaGrowthCurveApproach1982&#34; role=&#34;doc-biblioref&#34;&gt;Rogosa et al.&lt;/a&gt; (&lt;a href=&#34;#ref-rogosaGrowthCurveApproach1982&#34; role=&#34;doc-biblioref&#34;&gt;1982&lt;/a&gt;)&lt;/span&gt; give a technical overview on the limitations of 2-timepoint data. Limitations aside, sometimes two timepoints are all you have. In those cases, researchers should have a good sense of which data analysis options they have at their disposal. I recently came across &lt;a href=&#34;https://twitter.com/jwalkrunski&#34;&gt;Jeffrey Walker&lt;/a&gt;’s free &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-walkerElementsOfStatisticalModeling2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; text, &lt;a href=&#34;https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/&#34;&gt;&lt;em&gt;Elements of statistical modeling for experimental biology&lt;/em&gt;&lt;/a&gt;, which contains a &lt;a href=&#34;https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/models-for-longitudinal-experiments-pre-post-designs.html&#34;&gt;nice chapter&lt;/a&gt; on 2-timepoint experimental designs. Inspired by his work, this post aims to explore how one might analyze &lt;em&gt;non-experimental&lt;/em&gt; 2-timepoint data within a regression model paradigm.&lt;/p&gt;
&lt;div id=&#34;i-make-assumptions.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;I make assumptions.&lt;/h3&gt;
&lt;p&gt;In this post, I’m presuming you are familiar with longitudinal data analysis with conventional and multilevel regression. Though I don’t emphasize it much, it will also help if you’re familiar with Bayesian statistics. All code is in &lt;strong&gt;R&lt;/strong&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-base&#34; role=&#34;doc-biblioref&#34;&gt;R Core Team, 2020&lt;/a&gt;)&lt;/span&gt;, with healthy doses of the &lt;strong&gt;tidyverse&lt;/strong&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-tidyverse&#34; role=&#34;doc-biblioref&#34;&gt;Wickham, 2019&lt;/a&gt;; &lt;a href=&#34;#ref-wickhamWelcomeTidyverse2019&#34; role=&#34;doc-biblioref&#34;&gt;Wickham et al., 2019&lt;/a&gt;)&lt;/span&gt;. The statistical models will be fit with &lt;strong&gt;brms&lt;/strong&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-burknerBrmsPackageBayesian2017&#34; role=&#34;doc-biblioref&#34;&gt;Bürkner, 2017&lt;/a&gt;, &lt;a href=&#34;#ref-burknerAdvancedBayesianMultilevel2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;, &lt;a href=&#34;#ref-R-brms&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; and we’ll also make some use of the &lt;strong&gt;tidybayes&lt;/strong&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-tidybayes&#34; role=&#34;doc-biblioref&#34;&gt;Kay, 2020&lt;/a&gt;)&lt;/span&gt; and &lt;strong&gt;patchwork&lt;/strong&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-patchwork&#34; role=&#34;doc-biblioref&#34;&gt;Pedersen, 2019&lt;/a&gt;)&lt;/span&gt; packages. If you need to shore up, I list some educational resources at the &lt;a href=&#34;#next-steps&#34;&gt;end of the post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Load the primary packages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)
library(brms)
library(tidybayes)
library(patchwork)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;warm-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Warm-up&lt;/h2&gt;
&lt;p&gt;Before we jump into 2-timepoint data, we’ll first explore how one might analyze a fuller data set of 6 timepoints. We will then reduce the data set to two different 2-timepoint versions for use in the remainder of the post.&lt;/p&gt;
&lt;div id=&#34;we-need-data.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;We need data.&lt;/h3&gt;
&lt;p&gt;We will simulate the data based on a conventional multilevel growth model of the kind you can learn about in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-singerAppliedLongitudinalData2003&#34; role=&#34;doc-biblioref&#34;&gt;Singer &amp;amp; Willett&lt;/a&gt; (&lt;a href=&#34;#ref-singerAppliedLongitudinalData2003&#34; role=&#34;doc-biblioref&#34;&gt;2003&lt;/a&gt;)&lt;/span&gt;, &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;Hoffman&lt;/a&gt; (&lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;, or Kurz &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kurzStatisticalRethinkingSecondEd2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;, Chapter 14)&lt;/span&gt;. We’ll have one criterion variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; which will vary across participants &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and over time &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. For simplicity, the systemic change over time will be linear. We might express it in statistical notation&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt; as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti} &amp;amp; \sim \operatorname{Normal}(\mu_{ti}, \sigma) \\
\mu_{ti} &amp;amp; = \beta_0 + \beta_1 \text{time}_{ti} + u_{0i} + u_{1i} \text{time}_{ti} \\
\sigma &amp;amp; = \sigma_\epsilon \\
\begin{bmatrix} u_{0i} \\ u_{1i} \end{bmatrix} &amp;amp; \sim \operatorname{MVNormal} \left (\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \mathbf \Sigma \right) \\
\mathbf \Sigma &amp;amp; = \mathbf{SRS} \\
\mathbf S &amp;amp; = \begin{bmatrix} \sigma_0 &amp;amp; 0 \\ 0 &amp;amp; \sigma_1 \end{bmatrix} \\
\mathbf R &amp;amp; = \begin{bmatrix} 1 &amp;amp; \rho \\ \rho &amp;amp; 1 \end{bmatrix},
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the population-level intercept (initial status) and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is the population-level slope (change over time). The &lt;span class=&#34;math inline&#34;&gt;\(u_{0i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(u_{1i}\)&lt;/span&gt; terms are the participant-level deviations around the population-level intercept and slope. Those &lt;span class=&#34;math inline&#34;&gt;\(u\)&lt;/span&gt; deviations follow a bivariate normal distribution centered on zero (they are deviations, after all) and including a covariance matrix, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf \Sigma\)&lt;/span&gt;. As is typical within the &lt;strong&gt;brms&lt;/strong&gt; framework &lt;span class=&#34;citation&#34;&gt;(see &lt;a href=&#34;#ref-burknerBrmsPackageBayesian2017&#34; role=&#34;doc-biblioref&#34;&gt;Bürkner, 2017&lt;/a&gt;)&lt;/span&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\mathbf \Sigma\)&lt;/span&gt; is decomposed into a matrix of standard deviations (&lt;span class=&#34;math inline&#34;&gt;\(\mathbf S\)&lt;/span&gt;) and a correlation matrix (&lt;span class=&#34;math inline&#34;&gt;\(\mathbf R\)&lt;/span&gt;). Also notice we renamed our original &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; parameter as &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\epsilon\)&lt;/span&gt; to help distinguish it from the multilevel standard deviations in the &lt;span class=&#34;math inline&#34;&gt;\(\mathbf S\)&lt;/span&gt; matrix (&lt;span class=&#34;math inline&#34;&gt;\(\sigma_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt;). In this way, &lt;span class=&#34;math inline&#34;&gt;\(\sigma_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; capture differences &lt;em&gt;between&lt;/em&gt; participants in their intercepts and slopes, whereas &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\epsilon\)&lt;/span&gt; captures the differences &lt;em&gt;within&lt;/em&gt; participants over time that occur apart from their linear trajectories.&lt;/p&gt;
&lt;p&gt;To simulate data of this kind, we’ll first set the true values for &lt;span class=&#34;math inline&#34;&gt;\(\beta_0, \beta_1, \sigma_0, \sigma_1, \rho,\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\epsilon\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b0     &amp;lt;- 0      # starting point (average intercept)
b1     &amp;lt;- 1      # growth over time (average slope)
sigma0 &amp;lt;- 1      # std dev in intercepts
sigma1 &amp;lt;- 1      # std dev in slopes
rho    &amp;lt;- -.5    # correlation between intercepts and slopes
sigma_e &amp;lt;- 0.75  # std dev within participants&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now combine several of those values to define the &lt;span class=&#34;math inline&#34;&gt;\(\mathbf S, \mathbf R,\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\mathbf \Sigma\)&lt;/span&gt; matrices. Then simulate &lt;span class=&#34;math inline&#34;&gt;\(N = 100\)&lt;/span&gt; participant-level intercepts and slopes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;mu     &amp;lt;- c(b0, b1)          # combine the means in a vector
sigmas &amp;lt;- c(sigma0, sigma1)  # combine the std devs in a vector

s &amp;lt;- diag(sigmas)      # standard deviation matrix
r &amp;lt;- matrix(c(1, rho,  # correlation matrix
             rho, 1), nrow = 2)

# now matrix multiply s and r to get a covariance matrix
sigma &amp;lt;- s %*% r %*% s

# how many participants would you like?
n_id &amp;lt;- 100

# make the simulation reproducible
set.seed(1)

vary_effects &amp;lt;- 
  MASS::mvrnorm(n_id, mu = mu, Sigma = sigma) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  set_names(&amp;quot;intercepts&amp;quot;, &amp;quot;slopes&amp;quot;) %&amp;gt;% 
  mutate(id = 1:n_id) %&amp;gt;% 
  select(id, everything())

head(vary_effects)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   id  intercepts     slopes
## 1  1  0.85270825  0.7676584
## 2  2 -0.18009772  1.1379818
## 3  3  1.17913643  0.7317852
## 4  4 -1.46056809  2.3025393
## 5  5  0.04193022  1.6126544
## 6  6 -0.17309717 -0.5941901&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have our random intercepts and slopes, we’re almost ready to simulate our &lt;span class=&#34;math inline&#34;&gt;\(y_{ti}\)&lt;/span&gt; values. We just need to decide on how many values we’d like to collect over time and how we’d like to structure those assessment periods. To keep things simple, I’m going to specify six evenly-spaced timepoints. The first timepoint will be set to 0, the last timepoint will be set to 1, and the four timepoints in the middle will be the corresponding fractions.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# how many timepoints?
time_points &amp;lt;- 6

d &amp;lt;-
  vary_effects %&amp;gt;% 
  # add in time
  expand(nesting(id, intercepts, slopes),
         time = seq(from = 0, to = 1, length.out = time_points)) %&amp;gt;% 
  # now use the model formula to compute y
  mutate(y = rnorm(n(), mean = intercepts + slopes * time, sd = sigma_e))

head(d, n = 10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 10 x 5
##       id intercepts slopes  time      y
##    &amp;lt;int&amp;gt;      &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
##  1     1      0.853  0.768   0    1.16 
##  2     1      0.853  0.768   0.2  2.27 
##  3     1      0.853  0.768   0.4  2.35 
##  4     1      0.853  0.768   0.6  1.07 
##  5     1      0.853  0.768   0.8 -0.247
##  6     1      0.853  0.768   1    3.49 
##  7     2     -0.180  1.14    0    0.320
##  8     2     -0.180  1.14    0.2  0.453
##  9     2     -0.180  1.14    0.4  0.265
## 10     2     -0.180  1.14    0.6  0.885&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we move on, I should acknowledge that this simulation workflow is heavily influenced by McElreath &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;, Chapter 14)&lt;/span&gt;. You can find a similar workflow in the &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-debruineUnderstandingMixedEffects2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; preprint by DeBruine and Barr, &lt;a href=&#34;https://psyarxiv.com/xp5cy/&#34;&gt;&lt;em&gt;Understanding mixed effects models through data simulation&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;explore-the-data.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Explore the data.&lt;/h3&gt;
&lt;p&gt;Before fitting the model, it might help if we look at what we’ve done. Here’s a scatter plot of the random intercepts and slopes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# set the global plotting theme
theme_set(theme_linedraw() +
            theme(text = element_text(family = &amp;quot;Times&amp;quot;),
                  panel.grid = element_blank()))

p1 &amp;lt;-
  vary_effects %&amp;gt;% 
  ggplot(aes(x = intercepts, y = slopes)) +
  geom_point() +
  stat_ellipse(color = &amp;quot;grey50&amp;quot;)

p1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;288&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The 95%-interval ellipse helps point out the negative correlation between the intercepts and slopes. Here’s the Pearson’s correlation.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vary_effects %&amp;gt;% 
  summarise(rho = cor(intercepts, slopes))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##          rho
## 1 -0.4502206&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s no coincidence that value is very close to our data-generating &lt;code&gt;rho&lt;/code&gt; value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rho&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now check the sample means and standard deviations of our &lt;code&gt;intercepts&lt;/code&gt; and &lt;code&gt;slopes&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;vary_effects %&amp;gt;% 
  summarise(b0 = mean(intercepts),
            b1 = mean(slopes),
            sigma0 = sd(intercepts),
            sigma1 = sd(slopes)) %&amp;gt;% 
  mutate_all(round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      b0   b1 sigma0 sigma1
## 1 -0.08 1.11   0.91   0.91&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Those aren’t quite the true data-generating values for &lt;code&gt;b0&lt;/code&gt; through &lt;code&gt;sigma1&lt;/code&gt;, from above. But they’re pretty decent sample approximations. With only &lt;span class=&#34;math inline&#34;&gt;\(N = 100\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(T = 6\)&lt;/span&gt;, this is about as close as we should expect.&lt;/p&gt;
&lt;p&gt;To get a sense of the &lt;code&gt;time&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; values, we’ll plot them in two ways. First we’ll plot a random subset from nine of our simulated participants. Then we’ll plot the linear trajectories from all 100 participants, along with the grand mean trajectory.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(1)

p2 &amp;lt;-
  d %&amp;gt;% 
  nest(data = c(intercepts, slopes, time, y)) %&amp;gt;% 
  slice_sample(n = 9) %&amp;gt;% 
  unnest(data) %&amp;gt;% 
  
  ggplot(aes(x = time, y = y)) +
  geom_point() +
  geom_abline(aes(intercept = intercepts, slope = slopes),
              color = &amp;quot;blue&amp;quot;) +
  labs(subtitle = &amp;quot;random subset of 9 participants&amp;quot;) +
  theme(strip.background = element_blank(),
        strip.text = element_blank()) +
  facet_wrap(~slopes)

p3 &amp;lt;-
  d %&amp;gt;% 
  ggplot(aes(x = time, y = y)) +
  geom_point(color = &amp;quot;transparent&amp;quot;) +
  geom_abline(aes(intercept = intercepts, slope = slopes, group = id),
              color = &amp;quot;blue&amp;quot;, size = 1/10, alpha = 1/2) +
  geom_abline(intercept = b0, slope = b1,
              color = &amp;quot;blue&amp;quot;, size = 2) +
  labs(subtitle = &amp;quot;All participant-level trajectories, along\nwith the grand mean&amp;quot;)

# combine
(p2 + p3) &amp;amp;
  scale_x_continuous(breaks = 0:5 / 5, labels = c(0, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, &amp;quot;&amp;quot;, 1)) &amp;amp;
  coord_cartesian(ylim = c(-2.5, 3.5))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;See how the points in the plots on the left deviate quite a bit from their linear trajectories? That’s the result of &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\epsilon\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-the-multilevel-growth-model.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fit the multilevel growth model.&lt;/h3&gt;
&lt;p&gt;Now we’ll use &lt;strong&gt;brms&lt;/strong&gt; to fit the multilevel growth model. If all goes well, we should largely reproduce our data-generating values in the posterior. Before fitting the model, we should consider a few things about the &lt;code&gt;brm()&lt;/code&gt; syntax.&lt;/p&gt;
&lt;p&gt;In this model and in most of the models to follow, we’re relying on the default &lt;code&gt;brm()&lt;/code&gt; priors. When fitting real-world models, you are much better off going beyond the defaults. However, I will generally deemphasize priors, in this post, to help keep the focus on the conceptual models.&lt;/p&gt;
&lt;p&gt;Note how we set the &lt;code&gt;seed&lt;/code&gt; argument. Though you don’t need to do this, setting the &lt;code&gt;seed&lt;/code&gt; makes the results more reproducible.&lt;/p&gt;
&lt;p&gt;Also, note the custom settings for &lt;code&gt;iter&lt;/code&gt; and &lt;code&gt;warmup&lt;/code&gt;. Often times, the default settings are fine. But since we’ll be comparing a lot of models, I want to make sure we have enough posterior draws from each to ensure stable estimates.&lt;/p&gt;
&lt;p&gt;Okay, fit the model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m0 &amp;lt;-
  brm(data = d,
      y ~ 1 + time + (1 + time | id),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check the model summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y ~ 1 + time + (1 + time | id) 
##    Data: d (Number of observations: 600) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Group-Level Effects: 
## ~id (Number of levels: 100) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.89      0.09     0.72     1.07 1.00     3663     5989
## sd(time)                0.84      0.15     0.53     1.14 1.00     1782     2936
## cor(Intercept,time)    -0.40      0.15    -0.65    -0.05 1.00     3758     4228
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -0.13      0.11    -0.33     0.08 1.00     4153     6181
## time          1.16      0.13     0.91     1.42 1.00     6636     6477
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.81      0.03     0.76     0.87 1.00     4706     5720
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A series of plots might help show how well our model captured the data-generating values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# name the parameters with the Greek terms
names &amp;lt;- c(&amp;quot;beta[0]&amp;quot;, &amp;quot;beta[1]&amp;quot;, &amp;quot;sigma[0]&amp;quot;, &amp;quot;sigma[1]&amp;quot;, &amp;quot;rho&amp;quot;, &amp;quot;sigma[epsilon]&amp;quot;)

# for the vertical lines marking off the true values
vline &amp;lt;-
  tibble(name = names,
         true_value = c(b0, b1, sigma0, sigma1, rho, sigma_e))

# wrangle
posterior_samples(m0) %&amp;gt;% 
  select(b_Intercept:sigma) %&amp;gt;% 
  set_names(names) %&amp;gt;% 
  pivot_longer(everything()) %&amp;gt;% 
  
  # plot
  ggplot(aes(x = value, y = 0)) +
  stat_halfeye(.width = .95, normalize = &amp;quot;panels&amp;quot;, size = 1/2) +
  geom_vline(data = vline,
             aes(xintercept = true_value),
             size = 1/4, linetype = 2) +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(&amp;quot;marginal posterior&amp;quot;) +
  facet_wrap(~name, scales = &amp;quot;free&amp;quot;, labeller = label_parsed)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;480&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The marginal posterior distribution for all the major summary parameters is summarized by the median (dot) and percentile-based 95% interval (horizontal line). The true values are shown in the dashed vertical lines. Overall, we did okay.&lt;/p&gt;
&lt;p&gt;As fun as this has all been, we’ve just been warming up.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;make-the-2-timepoint-data.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Make the 2-timepoint data.&lt;/h3&gt;
&lt;p&gt;Before fitting the 2-timepoint longitudinal models, we’ll need to adjust the data, which currently contains values over six timepoints. Since it’s easy to think of 2-timepoint data in terms of pre and post, we’ll keep the data points for which &lt;code&gt;time == 0&lt;/code&gt; and &lt;code&gt;time == 1&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_data_long &amp;lt;-
  d %&amp;gt;% 
  filter(time == 0 | time == 1) %&amp;gt;% 
  select(-intercepts, -slopes) %&amp;gt;% 
  mutate(`pre/post` = factor(if_else(time == 0, &amp;quot;pre&amp;quot;, &amp;quot;post&amp;quot;),
                             levels = c(&amp;quot;pre&amp;quot;, &amp;quot;post&amp;quot;))) 

head(small_data_long)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
##      id  time     y `pre/post`
##   &amp;lt;int&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;     
## 1     1     0 1.16  pre       
## 2     1     1 3.49  post      
## 3     2     0 0.320 pre       
## 4     2     1 1.27  post      
## 5     3     0 0.879 pre       
## 6     3     1 0.971 post&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As the name implies, the &lt;code&gt;small_data_long&lt;/code&gt; data are still in the long format. &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;Hoffman&lt;/a&gt; (&lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; described this as the &lt;em&gt;stacked format&lt;/em&gt; and Singer and Willett &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-singerAppliedLongitudinalData2003&#34; role=&#34;doc-biblioref&#34;&gt;2003&lt;/a&gt;)&lt;/span&gt; called this a &lt;em&gt;person-period data set&lt;/em&gt;. Each level of &lt;code&gt;id&lt;/code&gt; has two rows, one for each level of &lt;code&gt;time&lt;/code&gt;, which is an explicit variable. In this formulation, &lt;code&gt;time == 0&lt;/code&gt; is the same as the “pre” timepoint and &lt;code&gt;time == 1&lt;/code&gt; is the same as “post.” To help clarify that, we added a &lt;code&gt;pre/post&lt;/code&gt; column.&lt;/p&gt;
&lt;p&gt;We’ll need a second variant of this data set, this time in the wide format.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_data_wide &amp;lt;-
  small_data_long %&amp;gt;% 
  select(-time) %&amp;gt;% 
  pivot_wider(names_from = `pre/post`, values_from = y) %&amp;gt;% 
  mutate(change = post - pre)

head(small_data_wide)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 4
##      id    pre   post change
##   &amp;lt;int&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     1  1.16   3.49  2.33  
## 2     2  0.320  1.27  0.953 
## 3     3  0.879  0.971 0.0920
## 4     4 -0.979  0.586 1.57  
## 5     5 -0.825  1.85  2.68  
## 6     6 -0.912 -0.841 0.0715&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With our &lt;code&gt;small_data_wide&lt;/code&gt; data, each level of &lt;code&gt;id&lt;/code&gt; only has one row. The time-structured &lt;code&gt;y&lt;/code&gt; column was broken up into a &lt;code&gt;pre&lt;/code&gt; and &lt;code&gt;post&lt;/code&gt; column, and we no longer have a variable explicitly defining &lt;em&gt;time&lt;/em&gt;. We have a new column, &lt;code&gt;change&lt;/code&gt;, which is the result of subtracting &lt;code&gt;pre&lt;/code&gt; from &lt;code&gt;post&lt;/code&gt;. In her text, Hoffman referred to this type of data structure as the &lt;em&gt;multivariate format&lt;/em&gt; and Singer and Willett called it a &lt;em&gt;person-level data set&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The information is essentially the same in these two data sets, &lt;code&gt;small_data_long&lt;/code&gt; and &lt;code&gt;small_data_wide&lt;/code&gt;. Yet, the models supported by them will provide different insights.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;timepoint-longitudinal-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;2-timepoint longitudinal models&lt;/h2&gt;
&lt;p&gt;Before we start fitting and interpreting models, we should prepare ourselves with an overview.&lt;/p&gt;
&lt;div id=&#34;overview.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Overview.&lt;/h3&gt;
&lt;p&gt;We will consider 20 ways to fit models based on 2-timepoint data. It seems like there multiple ways to categorize these. Here we’ll break them up into four groupings.&lt;/p&gt;
&lt;p&gt;The first four model types will take &lt;code&gt;post&lt;/code&gt; as the criterion:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_1 \colon\)&lt;/span&gt; The unconditional post model (&lt;code&gt;post ~ 1&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_2 \colon\)&lt;/span&gt; The simple autoregressive model (&lt;code&gt;post ~ 1 + pre&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_3 \colon\)&lt;/span&gt; The bivariate autoregressive model (&lt;code&gt;bf(post ~ 1 + pre) + bf(pre ~ 1) + set_rescor(rescor = FALSE)&lt;/code&gt;), and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_4 \colon\)&lt;/span&gt; The bivariate correlational pre/post model (&lt;code&gt;bf(post ~ 1) + bf(pre ~ 1) + set_rescor(rescor = TRUE)&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next four model types will take &lt;code&gt;change&lt;/code&gt; as the criterion:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_5 \colon\)&lt;/span&gt; The unconditional change-score model (&lt;code&gt;change ~ 1&lt;/code&gt;) and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_6 \colon\)&lt;/span&gt; The conditional change-score model (&lt;code&gt;change ~ 1 + pre&lt;/code&gt;).&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_7 \colon\)&lt;/span&gt; The bivariate conditional change-score model (&lt;code&gt;bf(change ~ 1 + pre) + bf(pre ~ 1) + set_rescor(rescor = FALSE)&lt;/code&gt;), and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_8 \colon\)&lt;/span&gt; The bivariate correlational pre/change model (&lt;code&gt;bf(change ~ 1) + bf(pre ~ 1) + set_rescor(rescor = TRUE)&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The next eight model types will take &lt;code&gt;y&lt;/code&gt; as the criterion:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_9 \colon\)&lt;/span&gt; The grand-mean model (&lt;code&gt;y ~ 1&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{10} \colon\)&lt;/span&gt; The random-intercept model (&lt;code&gt;y ~ 1 + (1 | id)&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{11} \colon\)&lt;/span&gt; The cross-classified model (&lt;code&gt;y ~ 1 + (1 | id) + (1 | time)&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{12} \colon\)&lt;/span&gt; The simple liner model (&lt;code&gt;y ~ 1 + time&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{13} \colon\)&lt;/span&gt; The liner model with a random intercept (&lt;code&gt;y ~ 1 + time + (1 | id)&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{14} \colon\)&lt;/span&gt; The liner model with a random slope (&lt;code&gt;y ~ 1 + time + (0 + time | id)&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{15} \colon\)&lt;/span&gt; The multilevel growth model with regularizing priors (&lt;code&gt;y ~ 1 + time + (1 + time | id)&lt;/code&gt;), and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{16} \colon\)&lt;/span&gt; The fixed effects with correlated error model (&lt;code&gt;y ~ 1 + time + ar(time = time, p = 1, gr = id&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The final four model types will expand previous ones with robust variance parameters:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{17} \colon\)&lt;/span&gt; The cross-classified model with robust variances for discrete time (&lt;code&gt;bf(y ~ 1 + (1 | id) + (1 | time), sigma ~ 0 + factor(time))&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{18} \colon\)&lt;/span&gt; The simple liner model with robust variance for linear time (&lt;code&gt;bf(y ~ 1 + time, sigma ~ 1 + time)&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{19} \colon\)&lt;/span&gt; The liner model with correlated random intercepts for &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; (&lt;code&gt;bf(y ~ 1 + time + (1 |x| id), sigma ~ 1 + (1 |x| id))&lt;/code&gt;), and&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{20} \colon\)&lt;/span&gt; The liner model with a random slope for &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and uncorrelated random intercept for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; (&lt;code&gt;bf(y ~ 1 + time + (0 + time | id), sigma ~ 1 + (1 | id))&lt;/code&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;As far as these model names go, I’m making no claim they are canonical. Call them what you want. My goal, here, is to use names that are minimally descriptive and similar to the terms you might find used by other authors.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;models-focusing-on-the-second-timepoint-post.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Models focusing on the second timepoint, &lt;code&gt;post&lt;/code&gt;.&lt;/h3&gt;
&lt;div id=&#34;mathcal-m_1-colon-the-unconditional-post-model.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_1 \colon\)&lt;/span&gt; The unconditional post model.&lt;/h4&gt;
&lt;p&gt;We can write the unconditional post model as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\text{post}_i &amp;amp; \sim \operatorname{Normal}(\mu, \sigma) \\
\mu &amp;amp; = \beta_0,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is both the model intercept and the estimate for the mean value of &lt;code&gt;post&lt;/code&gt;. The focus this model places on &lt;code&gt;post&lt;/code&gt; comes at the cost of any contextual information on what earlier values we might compare &lt;code&gt;post&lt;/code&gt; to. Also, since the only variable in the model is &lt;code&gt;post&lt;/code&gt;, this technically is &lt;em&gt;not&lt;/em&gt; a 2-timepoint model. But given its connection to the models to follow, it’s worth working through.&lt;/p&gt;
&lt;p&gt;Here’s how to fit the model with &lt;strong&gt;brms&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m1 &amp;lt;-
  brm(data = small_data_wide,
      post ~ 1,
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: post ~ 1 
##    Data: small_data_wide (Number of observations: 100) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     1.02      0.12     0.79     1.25 1.00     6972     5683
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.17      0.08     1.02     1.36 1.00     8412     6599
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We might compare those parameters with their sample values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_data_wide %&amp;gt;% 
  summarise(mean = mean(post),
            sd = sd(post))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##    mean    sd
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1  1.02  1.16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you only care about computing the population estimates for &lt;span class=&#34;math inline&#34;&gt;\(\mu_\text{post}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\text{post}\)&lt;/span&gt;, this model does a great job. With no other variables in the model, this approach does a poor job telling us about growth processes.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_2-colon-the-simple-autoregressive-model.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_2 \colon\)&lt;/span&gt; The simple autoregressive model.&lt;/h4&gt;
&lt;p&gt;The simple model with the &lt;code&gt;pre&lt;/code&gt; scores predicting &lt;code&gt;post&lt;/code&gt; is a substantial improvement from the previous one. It follows the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\text{post}_i &amp;amp; \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i &amp;amp; = \beta_0 + \beta_1 \text{pre}_i,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the expected value of &lt;code&gt;post&lt;/code&gt; when &lt;code&gt;pre&lt;/code&gt; is at zero. As with many other regression contexts, centering the predictor &lt;code&gt;pre&lt;/code&gt; at the mean or some other meaningful value can help make &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; more interpretable. Of greater interest is the &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; coefficient, which is the expected deviation from &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; for a one-unit increase in &lt;code&gt;pre&lt;/code&gt;. But since &lt;code&gt;pre&lt;/code&gt; and &lt;code&gt;post&lt;/code&gt; are really the same variable &lt;code&gt;y&lt;/code&gt; measured at two timepoints, it might be helpful if we express this model in another way. In perhaps more technical form, the simple model with &lt;code&gt;pre&lt;/code&gt; predicting &lt;code&gt;post&lt;/code&gt; is really an autoregressive model following the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti} &amp;amp; \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i &amp;amp; = \beta_0 + \phi y_{t - 1,i},
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the criterion &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; varies across persons &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; and timepoints &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. Here we only have two timepoints, &lt;span class=&#34;math inline&#34;&gt;\(\text{post} = t\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\text{pre} = t - 1\)&lt;/span&gt;. The strength of association between &lt;span class=&#34;math inline&#34;&gt;\(y_t\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y_{t - 1}\)&lt;/span&gt; captured by the autoregressive parameter &lt;span class=&#34;math inline&#34;&gt;\(\phi\)&lt;/span&gt;, which is often expressed in a correlation metric.&lt;/p&gt;
&lt;p&gt;Here’s how to fit the model with &lt;code&gt;brm()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m2 &amp;lt;-
  brm(data = small_data_wide,
      post ~ 1 + pre,
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: post ~ 1 + pre 
##    Data: small_data_wide (Number of observations: 100) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     1.05      0.12     0.83     1.28 1.00     8995     6957
## pre           0.24      0.10     0.04     0.43 1.00     9548     6404
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.15      0.08     1.00     1.32 1.00     8407     7109
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s compare the &lt;code&gt;pre&lt;/code&gt; coefficient with the Pearson’s correlation between &lt;code&gt;pre&lt;/code&gt; and &lt;code&gt;post&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_data_wide %&amp;gt;% 
  summarise(correlation = cor(pre, post))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   correlation
##         &amp;lt;dbl&amp;gt;
## 1       0.232&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well look at that. Recall that the &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; parameter is the expected value in &lt;code&gt;post&lt;/code&gt; when the predictor &lt;code&gt;pre&lt;/code&gt; is at zero. Though the sample mean for &lt;code&gt;pre&lt;/code&gt; is very close to zero, it’s not exactly so.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_data_wide %&amp;gt;% 
  summarise(pre_mean = mean(pre))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   pre_mean
##      &amp;lt;dbl&amp;gt;
## 1   -0.154&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s how to use that information to predict the mean value for &lt;code&gt;post&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(m2)[1, 1] + fixef(m2)[2, 1] * mean(small_data_wide$pre)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.015851&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can get a full posterior summary with aid from &lt;code&gt;fitted()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nd &amp;lt;- tibble(pre = mean(small_data_wide$pre))

fitted(m2, newdata = nd)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Estimate Est.Error      Q2.5    Q97.5
## [1,] 1.015851 0.1142147 0.7939083 1.241721&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_3-colon-the-bivariate-autoregressive-model.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_3 \colon\)&lt;/span&gt; The bivariate autoregressive model.&lt;/h4&gt;
&lt;p&gt;Though the simple autoregressive model gives us a sense of the strength of association between &lt;code&gt;pre&lt;/code&gt; and &lt;code&gt;post&lt;/code&gt;–and thus a sense of the stability in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; over time–, it still lacks an explicit parameter for mean value of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; at &lt;span class=&#34;math inline&#34;&gt;\(t - 1\)&lt;/span&gt;. Enter the bivariate autoregressive model,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\text{post}_i &amp;amp; \sim \operatorname{Normal}(\mu_i, \sigma) \\
\text{pre}_i &amp;amp; \sim \operatorname{Normal}(\nu, \tau) \\
\mu_i &amp;amp; = \beta_0 + \beta_1 \text{pre}_i \\
\nu   &amp;amp; = \gamma_0,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\text{post}_i\)&lt;/span&gt; is still modeled as a simple linear function of &lt;span class=&#34;math inline&#34;&gt;\(\text{pre}_i\)&lt;/span&gt;, but now we also include an unconditional model for &lt;span class=&#34;math inline&#34;&gt;\(\text{pre}_i\)&lt;/span&gt;. This will give us an explicit comparison for where we started at the outset (&lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;) and where we ended up (&lt;span class=&#34;math inline&#34;&gt;\(\mu_i\)&lt;/span&gt;). We can fit this model using the &lt;strong&gt;brms&lt;/strong&gt; multivariate syntax where the two submodels are encased in &lt;code&gt;bf()&lt;/code&gt; statements &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Bürkner2021Multivariate&#34; role=&#34;doc-biblioref&#34;&gt;Bürkner, 2021b&lt;/a&gt;)&lt;/span&gt;. Also, be careful to use &lt;code&gt;set_rescor(rescor = FALSE)&lt;/code&gt; to omit a residual correlation between the two. Their association is already handled with the &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m3 &amp;lt;-
  brm(data = small_data_wide,
      bf(post ~ 1 + pre) +
        bf(pre ~ 1) +
        set_rescor(rescor = FALSE),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: post ~ 1 + pre 
##          pre ~ 1 
##    Data: small_data_wide (Number of observations: 100) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Population-Level Effects: 
##                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## post_Intercept     1.05      0.12     0.82     1.28 1.00    10717     7470
## pre_Intercept     -0.15      0.11    -0.38     0.07 1.00    12822     7706
## post_pre           0.24      0.10     0.04     0.43 1.00    11030     7641
## 
## Family Specific Parameters: 
##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_post     1.15      0.08     1.00     1.33 1.00    10955     7694
## sigma_pre      1.16      0.08     1.01     1.33 1.00    13273     7703
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now that we’ve broken out the multivariate syntax, we might consider a second bivariate model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_4-colon-the-bivariate-correlational-model.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_4 \colon\)&lt;/span&gt; The bivariate correlational model.&lt;/h4&gt;
&lt;p&gt;The bivariate correlational model follows the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\begin{bmatrix} \text{post}_i \\ \text{pre}_i \end{bmatrix} &amp;amp; \sim \operatorname{MVNormal} \left (\begin{bmatrix} \mu \\ \nu \end{bmatrix}, \mathbf \Sigma \right) \\
\mu &amp;amp; = \beta_0 \\
\nu &amp;amp; = \gamma_0 \\
\mathbf \Sigma &amp;amp; = \mathbf{SRS} \\
\mathbf S &amp;amp; = \begin{bmatrix} \sigma &amp;amp; 0 \\ 0 &amp;amp; \tau \end{bmatrix} \\
\mathbf R &amp;amp; = \begin{bmatrix} 1 &amp;amp; \rho \\ \rho &amp;amp; 1 \end{bmatrix},
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where means of both &lt;code&gt;pre&lt;/code&gt; and &lt;code&gt;post&lt;/code&gt; are modeled in intercept-only models. However, the association between the two timepoints is captured in the residual correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. Yet because we have no predictors in for either variable, the “residual” correlation is really just a correlation. We might also gain some insights if we re-express this model in terms of &lt;span class=&#34;math inline&#34;&gt;\(y_{ti}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y_{t - 1,i}\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\begin{bmatrix} y_{ti} \\ y_{t - 1,i} \end{bmatrix} &amp;amp; \sim \operatorname{MVNormal} \left (\begin{bmatrix} \mu_t \\ \mu_{t - 1} \end{bmatrix}, \mathbf \Sigma \right) \\
\mu_t &amp;amp; = \beta_t \\
\mu_{t - 1} &amp;amp; = \beta_{t - 1} \\
\mathbf \Sigma &amp;amp; = \mathbf{SRS} \\
\mathbf S &amp;amp; = \begin{bmatrix} \sigma_t &amp;amp; 0 \\ 0 &amp;amp; \sigma_{t - 1} \end{bmatrix} \\
\mathbf R &amp;amp; = \begin{bmatrix} 1 &amp;amp; \rho \\ \rho &amp;amp; 1 \end{bmatrix},
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where what we formerly called an autoregressive coefficient in &lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_2\)&lt;/span&gt;, we’re now calling a correlation. Note also that this model freely estimates &lt;span class=&#34;math inline&#34;&gt;\(\sigma_t\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{t - 1}\)&lt;/span&gt;. In some contexts, these are presumed to be equal. Though we won’t be imposing that constraint, here, I believe it is possible with the &lt;strong&gt;brms&lt;/strong&gt; &lt;a href=&#34;https://CRAN.R-project.org/package=brms/vignettes/brms_nonlinear.html&#34;&gt;non-linear syntax&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-Bürkner2021Non_linear&#34; role=&#34;doc-biblioref&#34;&gt;Bürkner, 2021c&lt;/a&gt;)&lt;/span&gt;. Anyway, here’s how to fit the model with the &lt;code&gt;brm()&lt;/code&gt; function .&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m4 &amp;lt;-
  brm(data = small_data_wide,
      bf(post ~ 1) +
        bf(pre ~ 1) +
        set_rescor(rescor = TRUE),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note out use of the &lt;code&gt;set_rescor(rescor = TRUE)&lt;/code&gt; syntax in the model &lt;code&gt;formula&lt;/code&gt;. This explicitly told &lt;code&gt;brm()&lt;/code&gt; to include the residual correlation. Here’s the summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: post ~ 1 
##          pre ~ 1 
##    Data: small_data_wide (Number of observations: 100) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Population-Level Effects: 
##                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## post_Intercept     1.02      0.12     0.79     1.24 1.00    10992     8033
## pre_Intercept     -0.15      0.12    -0.39     0.08 1.00    10679     8012
## 
## Family Specific Parameters: 
##            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_post     1.18      0.08     1.03     1.36 1.00    11342     7819
## sigma_pre      1.16      0.08     1.02     1.34 1.00    11150     7777
## 
## Residual Correlations: 
##                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(post,pre)     0.23      0.09     0.03     0.40 1.00    10074     7292
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the intercept and sigma parameters do a good job capturing the sample statistics.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_data_wide %&amp;gt;% 
  pivot_longer(pre:post) %&amp;gt;% 
  group_by(name) %&amp;gt;% 
  summarise(mean = mean(value),
            sd = sd(value)) %&amp;gt;% 
  mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 3
##   name   mean    sd
##   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 post   1.02  1.16
## 2 pre   -0.15  1.14&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The new ‘rescor’ line at the bottom of the &lt;code&gt;print()&lt;/code&gt; summary approximates the Pearson’s correlation of the two variables, much like the autoregressive parameter did two models up.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_data_wide %&amp;gt;% 
  summarise(correlation = cor(pre, post))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   correlation
##         &amp;lt;dbl&amp;gt;
## 1       0.232&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another nice quality of this model is if you subtract &lt;span class=&#34;math inline&#34;&gt;\(\gamma_0\)&lt;/span&gt; from &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; (i.e., &lt;span class=&#34;math inline&#34;&gt;\(\beta_t - \beta_{t - 1}\)&lt;/span&gt;), you’d end up with the posterior mean of the change score.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(m4) %&amp;gt;% 
  mutate(change = b_post_Intercept - b_pre_Intercept) %&amp;gt;% 
  summarise(mu_change = mean(change))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   mu_change
## 1  1.168898&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Keeping that in mind, let’s switch gears to the first of the change-score models.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;change-score-models.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Change-score models.&lt;/h3&gt;
&lt;p&gt;Instead of modeling &lt;code&gt;post&lt;/code&gt;, &lt;span class=&#34;math inline&#34;&gt;\(y_{ti}\)&lt;/span&gt;, we might instead want to focus on the change from &lt;code&gt;pre&lt;/code&gt; to &lt;code&gt;post&lt;/code&gt;, &lt;span class=&#34;math inline&#34;&gt;\(y_{ti} - y_{t - 1,i}\)&lt;/span&gt;. When you subtract &lt;code&gt;pre&lt;/code&gt; from &lt;code&gt;post&lt;/code&gt; in your data set–like we did to make the &lt;code&gt;change&lt;/code&gt; variable–, the product is often referred to as a change score or difference score, &lt;span class=&#34;math inline&#34;&gt;\(y_\Delta\)&lt;/span&gt;. Though they’re conceptually intuitive and simple to compute, change scores have a long history of criticisms in the methodological literature, particularly around issues of reliability &lt;span class=&#34;citation&#34;&gt;(see &lt;a href=&#34;#ref-lordStatisticalTheoriesMental1968&#34; role=&#34;doc-biblioref&#34;&gt;Lord &amp;amp; Novick, 1968&lt;/a&gt;; &lt;a href=&#34;#ref-rogosaGrowthCurveApproach1982&#34; role=&#34;doc-biblioref&#34;&gt;Rogosa et al., 1982&lt;/a&gt;; cf. &lt;a href=&#34;#ref-kisbu2013monte&#34; role=&#34;doc-biblioref&#34;&gt;Kisbu-Sakarya et al., 2013&lt;/a&gt;)&lt;/span&gt;. Here we consider four change-score models simply as options.&lt;/p&gt;
&lt;div id=&#34;mathcal-m_5-colon-the-unconditional-change-score-model.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_5 \colon\)&lt;/span&gt; The unconditional change-score model.&lt;/h4&gt;
&lt;p&gt;We’ve already saved that in our &lt;code&gt;small_data_wide&lt;/code&gt; data as &lt;code&gt;change&lt;/code&gt;. Here’s what the unconditional change-score model&lt;a href=&#34;#fn2&#34; class=&#34;footnote-ref&#34; id=&#34;fnref2&#34;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt; looks like:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\text{change}_i &amp;amp; \sim \operatorname{Normal}(\mu, \sigma) \\
\mu &amp;amp; = \beta_0,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the expected value for &lt;span class=&#34;math inline&#34;&gt;\(\text{change}_i\)&lt;/span&gt;. In the terms of the last model, &lt;span class=&#34;math inline&#34;&gt;\(\text{change}_i = \text{post}_i - \text{pre}_i\)&lt;/span&gt; or, in the terms of the simple autoregressive model, &lt;span class=&#34;math inline&#34;&gt;\(y_{\Delta i} = y_{ti} - y_{t - 1,i}\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m5 &amp;lt;-
  brm(data = small_data_wide,
      change ~ 1,
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: change ~ 1 
##    Data: small_data_wide (Number of observations: 100) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     1.17      0.14     0.89     1.45 1.00     8075     6240
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.44      0.10     1.26     1.66 1.00     8673     6829
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thus, this model suggests the average change from &lt;code&gt;pre&lt;/code&gt; to &lt;code&gt;post&lt;/code&gt; was about 1.2 units. We can compute the sample statistics for that in two ways.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_data_wide %&amp;gt;% 
  summarise(change = mean(change),
            `post - pre` = mean(post - pre))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   change `post - pre`
##    &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt;
## 1   1.17         1.17&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The major deficit in the unconditional change model is that change is disconnected from any reference points. We have no explicit way of knowing what number we changed from or what number we changed to. The next model offers a solution.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_6-colon-the-conditional-change-score-model.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_6 \colon\)&lt;/span&gt; The conditional change-score model.&lt;/h4&gt;
&lt;p&gt;Instead of fitting an unconditional model of &lt;code&gt;change&lt;/code&gt;, why not condition on the initial &lt;code&gt;pre&lt;/code&gt; value? We might express this as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\text{change}_i &amp;amp; \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i &amp;amp; = \beta_0 + \beta_1 \text{pre}_i,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is now the expected value for &lt;code&gt;change&lt;/code&gt; when &lt;code&gt;pre&lt;/code&gt; is at zero. As with the simple autoregressive model, centering the predictor &lt;code&gt;pre&lt;/code&gt; at the mean or some other meaningful value can help make &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; more interpretable. Perhaps of greater interest, the &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; coefficient allows us to predict different levels of &lt;code&gt;change&lt;/code&gt;, conditional in the initial values at &lt;code&gt;pre&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m6 &amp;lt;-
  brm(data = small_data_wide,
      change ~ 1 + pre,
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m6)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: change ~ 1 + pre 
##    Data: small_data_wide (Number of observations: 100) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     1.05      0.12     0.82     1.28 1.00     9315     7108
## pre          -0.76      0.10    -0.96    -0.57 1.00    10559     7804
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.15      0.08     1.00     1.33 1.00     9745     7268
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since the intercept in this model is the expected &lt;code&gt;change&lt;/code&gt; value based on when &lt;code&gt;pre == 0&lt;/code&gt;, it might be easiest to interpret that value when using the mean of &lt;code&gt;pre&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(m6)[1, 1] + fixef(m6)[2, 1] * mean(small_data_wide$pre)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1.167458&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That is the point prediction for the mean of &lt;code&gt;change&lt;/code&gt;. Let’s compare that to the sample value.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_data_wide %&amp;gt;% 
  summarise(mean = mean(change))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##    mean
##   &amp;lt;dbl&amp;gt;
## 1  1.17&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of course, we can get a fuller summary using the &lt;code&gt;fitted()&lt;/code&gt; method.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nd &amp;lt;- tibble(pre = mean(small_data_wide$pre))

fitted(m6, newdata = nd)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      Estimate Est.Error      Q2.5   Q97.5
## [1,] 1.167458 0.1151598 0.9428394 1.39075&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note how the coefficient for &lt;code&gt;pre&lt;/code&gt; is about -0.76. This is a rough analogue of the negative correlation among the intercepts and slopes in the original data-generating model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rho&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It tells us something very similar; participants with higher values at &lt;code&gt;pre&lt;/code&gt; tended to have lower &lt;code&gt;change&lt;/code&gt; values. Much like with the simple autoregressive model, a deficit of this model is there is no explicit parameter for the expected value of &lt;code&gt;pre&lt;/code&gt;, which we can amend by fitting a bivariate model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_7-colon-the-bivariate-conditional-change-score-model.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_7 \colon\)&lt;/span&gt; The bivariate conditional change-score model.&lt;/h4&gt;
&lt;p&gt;The bivariate conditional change-score model follows the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\text{change}_i &amp;amp; \sim \operatorname{Normal}(\mu_i, \sigma) \\
\text{pre}_i &amp;amp; \sim \operatorname{Normal}(\nu, \tau) \\
\mu_i &amp;amp; = \beta_0 + \beta_1 \text{pre}_i \\
\nu   &amp;amp; = \gamma_0,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the simple linear model of &lt;span class=&#34;math inline&#34;&gt;\(\text{change}_i\)&lt;/span&gt; conditional on &lt;span class=&#34;math inline&#34;&gt;\(\text{pre}_i\)&lt;/span&gt; is coupled with an unconditional intercept-only model for &lt;span class=&#34;math inline&#34;&gt;\(\text{pre}_i\)&lt;/span&gt;. We can fit this model with &lt;strong&gt;brms&lt;/strong&gt; by way of the multivariate syntax, where the two submodels are encased in &lt;code&gt;bf()&lt;/code&gt; statements and we set &lt;code&gt;set_rescor(rescor = FALSE)&lt;/code&gt; to omit a residual correlation between the two.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m7 &amp;lt;-
  brm(data = small_data_wide,
      bf(change ~ 1 + pre) +
        bf(pre ~ 1) +
        set_rescor(rescor = FALSE),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m7)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: change ~ 1 + pre 
##          pre ~ 1 
##    Data: small_data_wide (Number of observations: 100) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Population-Level Effects: 
##                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## change_Intercept     1.05      0.12     0.82     1.28 1.00    11908     7575
## pre_Intercept       -0.16      0.12    -0.39     0.07 1.00    13113     8030
## change_pre          -0.76      0.10    -0.96    -0.57 1.00    12023     7190
## 
## Family Specific Parameters: 
##              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_change     1.15      0.08     1.00     1.33 1.00    13064     7696
## sigma_pre        1.16      0.08     1.01     1.33 1.00    11419     7142
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have an intercept for &lt;code&gt;pre&lt;/code&gt;, we can use the model parameters to compute the expected values for &lt;code&gt;pre&lt;/code&gt;, &lt;code&gt;change&lt;/code&gt;, and &lt;code&gt;post&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(m7) %&amp;gt;% 
  mutate(pre    = b_pre_Intercept,
         change = b_change_Intercept + b_change_pre * b_pre_Intercept) %&amp;gt;% 
  mutate(post = pre + change) %&amp;gt;% 
  pivot_longer(pre:post) %&amp;gt;% 
  group_by(name) %&amp;gt;% 
  mean_qi(value) %&amp;gt;% 
  mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 7
##   name   value .lower .upper .width .point .interval
##   &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;    
## 1 change  1.17   0.88   1.45   0.95 mean   qi       
## 2 post    1.01   0.78   1.25   0.95 mean   qi       
## 3 pre    -0.16  -0.39   0.07   0.95 mean   qi&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The posterior means are in the &lt;code&gt;value&lt;/code&gt; column and the lower- and upper-levels of the percentile-based 95% intervals are in the &lt;code&gt;.lower&lt;/code&gt; and &lt;code&gt;.upper&lt;/code&gt; columns. Now compare those mean estimates with the sample means.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_data_wide %&amp;gt;% 
  pivot_longer(-id) %&amp;gt;% 
  group_by(name) %&amp;gt;% 
  summarise(mean = mean(value)) %&amp;gt;% 
  mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 2
##   name    mean
##   &amp;lt;chr&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 change  1.17
## 2 post    1.02
## 3 pre    -0.15&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As handy as this model is, the &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; coefficient might not be in the most intuitive metric. Let’s reparameterize.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_8-colon-the-bivariate-correlational-prechange-model.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_8 \colon\)&lt;/span&gt; The bivariate correlational pre/change model.&lt;/h4&gt;
&lt;p&gt;The bivariate correlational pre/change model follows the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
\begin{bmatrix} \text{change}_i \\ \text{pre}_i \end{bmatrix} &amp;amp; \sim \operatorname{MVNormal} \left (\begin{bmatrix} \mu \\ \nu \end{bmatrix}, \mathbf \Sigma \right) \\
\mu &amp;amp; = \beta_0 \\
\nu &amp;amp; = \gamma_0 \\
\mathbf \Sigma &amp;amp; = \mathbf{SRS} \\
\mathbf S &amp;amp; = \begin{bmatrix} \sigma &amp;amp; 0 \\ 0 &amp;amp; \tau \end{bmatrix} \\
\mathbf R &amp;amp; = \begin{bmatrix} 1 &amp;amp; \rho \\ \rho &amp;amp; 1 \end{bmatrix},
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where means of both &lt;code&gt;pre&lt;/code&gt; and &lt;code&gt;change&lt;/code&gt; are modeled in intercept-only models and the association between the two is captured by the correlation &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;. And again, because we have no predictors in for either variable, the “residual” correlation is really just a correlation. Here’s how to fit the model with &lt;strong&gt;brms&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m8 &amp;lt;-
  brm(data = small_data_wide,
      bf(change ~ 1) +
        bf(pre ~ 1) +
        set_rescor(rescor = TRUE),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: change ~ 1 
##          pre ~ 1 
##    Data: small_data_wide (Number of observations: 100) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Population-Level Effects: 
##                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## change_Intercept     1.17      0.15     0.88     1.45 1.00     8200     7551
## pre_Intercept       -0.15      0.12    -0.38     0.08 1.00     8160     7194
## 
## Family Specific Parameters: 
##              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_change     1.44      0.10     1.26     1.67 1.00     8811     7147
## sigma_pre        1.16      0.08     1.01     1.33 1.00     8996     7487
## 
## Residual Correlations: 
##                    Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(change,pre)    -0.60      0.06    -0.71    -0.46 1.00     8299     7233
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now the parameter in the ‘Residual Correlations’ section of the summary output is a close analogue to our original data-generating &lt;code&gt;rho&lt;/code&gt; parameter.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;rho&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Those with higher &lt;code&gt;pre&lt;/code&gt; values tended to have lower &lt;code&gt;change&lt;/code&gt; values. We can look at that with a plot of the data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;p2 &amp;lt;-
  small_data_wide %&amp;gt;% 
  ggplot(aes(x = pre, y = change)) +
  geom_point() +
  stat_ellipse(color = &amp;quot;grey50&amp;quot;)

(p1 + p2) &amp;amp;
  coord_cartesian(xlim = range(small_data_wide$pre),
                  ylim = range(small_data_wide$change))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-39-1.png&#34; width=&#34;576&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Here we’ve placed the scatter plot of the data-generating &lt;code&gt;id&lt;/code&gt;-level &lt;code&gt;intercepts&lt;/code&gt; and &lt;code&gt;slopes&lt;/code&gt; next to the scatter plot of the &lt;code&gt;pre&lt;/code&gt; and &lt;code&gt;change&lt;/code&gt; scores. They are not exactly the same, but the latter are a partial consequence of the former. This is why the correlation parameter in our &lt;code&gt;m8&lt;/code&gt; model closely, but not exactly, resembled the data-generating &lt;code&gt;rho&lt;/code&gt; parameter.&lt;/p&gt;
&lt;p&gt;Okay, let’s switch gears again.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;models-modeling-the-criterion-y_ti-directly.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Models modeling the criterion &lt;span class=&#34;math inline&#34;&gt;\(y_{ti}\)&lt;/span&gt; directly.&lt;/h3&gt;
&lt;p&gt;All of the models focusing on &lt;code&gt;post&lt;/code&gt; or &lt;code&gt;change&lt;/code&gt; used the wide version of the data, &lt;code&gt;small_data_wide&lt;/code&gt;. The remaining models will all take advantage of the long data set, &lt;code&gt;small_data_long&lt;/code&gt;, and take &lt;span class=&#34;math inline&#34;&gt;\(y_{ti}\)&lt;/span&gt; as the criterion. Consequently, most of these models will use some version of the multilevel model.&lt;/p&gt;
&lt;div id=&#34;mathcal-m_9-colon-the-grand-mean-model.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_9 \colon\)&lt;/span&gt; The grand-mean model.&lt;/h4&gt;
&lt;p&gt;The simplest model we might fit using the long version of the 2-timepoint data, &lt;code&gt;small_data_long&lt;/code&gt;, is what we might call the grand-mean model, or what &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;Hoffman&lt;/a&gt; (&lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; called the &lt;em&gt;between-person empty model&lt;/em&gt;. It follows the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti} &amp;amp; \sim \operatorname{Normal}(\mu, \sigma) \\
\mu &amp;amp; = \beta_0,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the expected value value for &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; across all &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; participants and &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; timepoints. We fit this with &lt;code&gt;brm()&lt;/code&gt; much like we fit the unconditional post model and the unconditional change-score model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m9 &amp;lt;-
  brm(data = small_data_long,
      y ~ 1 ,
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m9)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y ~ 1 
##    Data: small_data_long (Number of observations: 200) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.43      0.09     0.25     0.61 1.00     8486     6236
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.30      0.07     1.18     1.43 1.00     9455     6868
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We might check these with the sample statistics for &lt;code&gt;y&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;small_data_long %&amp;gt;% 
  summarise(mean = mean(y),
            sd = sd(y))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##    mean    sd
##   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 0.431  1.29&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Though this model did to a good job describing the population values for the mean and standard deviation for &lt;code&gt;y&lt;/code&gt;, it did a terrible job telling us about change in &lt;code&gt;y&lt;/code&gt;, about individual differences in that change, or about anything else of interest we might have as longitudinal researchers.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_10-colon-the-random-intercept-model.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{10} \colon\)&lt;/span&gt; The random-intercept model.&lt;/h4&gt;
&lt;p&gt;Now that we have a grand mean, we might want to ask what kinds of variables would help explain the variation around the grand mean. From a multilevel perspective, the first source of variation of interest will be across participants, which we can express by allowing the mean to vary by participant. This is what Hoffman called the &lt;em&gt;within-person empty model&lt;/em&gt; and the &lt;em&gt;empty means, random intercept model&lt;/em&gt;. It follows the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti} &amp;amp; \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i  &amp;amp; = \beta_0 + u_{\text{id},i} \\
u_\text{id} &amp;amp; \sim \operatorname{Normal}(0, \sigma_\text{id}) \\
\sigma &amp;amp; = \sigma_\epsilon,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is now the grand mean among the participant-level means in &lt;span class=&#34;math inline&#34;&gt;\(y_{ti}\)&lt;/span&gt;. The participant-level deviations from the grand mean are expressed as &lt;span class=&#34;math inline&#34;&gt;\(u_{\text{id},i}\)&lt;/span&gt;, which is normally distributed with a mean at zero (these are &lt;em&gt;deviations&lt;/em&gt;, after all) and a standard deviation of &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\text{id}\)&lt;/span&gt;. The &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\epsilon\)&lt;/span&gt; parameter is a mixture of the variation within participants and over time. With &lt;strong&gt;brms&lt;/strong&gt;, we can fit the random-intercept model model like so.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m10 &amp;lt;-
  brm(data = small_data_long,
      y ~ 1 + (1 | id),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000,
      control = list(adapt_delta = .99))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m10)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y ~ 1 + (1 | id) 
##    Data: small_data_long (Number of observations: 200) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Group-Level Effects: 
## ~id (Number of levels: 100) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.23      0.15     0.01     0.56 1.00     2079     4188
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.43      0.09     0.24     0.61 1.00    13669     6976
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.27      0.07     1.14     1.41 1.00     6211     5523
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; intercept returned a very similar estimate for the grand mean, but we now interpret it as the grand mean for the within-person means for &lt;code&gt;y&lt;/code&gt;. The variation in the &lt;code&gt;id&lt;/code&gt;-level deviations around the grand mean, which we called &lt;span class=&#34;math inline&#34;&gt;\(u_{\text{id},i}\)&lt;/span&gt;, is summarized by &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\text{id}\)&lt;/span&gt; in the ‘Group-Level Effects’ section of the summary output.&lt;/p&gt;
&lt;p&gt;Authors of many longitudinal text books &lt;span class=&#34;citation&#34;&gt;(e.g., &lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;Hoffman, 2015&lt;/a&gt;; &lt;a href=&#34;#ref-singerAppliedLongitudinalData2003&#34; role=&#34;doc-biblioref&#34;&gt;Singer &amp;amp; Willett, 2003&lt;/a&gt;)&lt;/span&gt; typically present this model as a way to directly compare the between- and within-person variation in the data by way of the intraclass correlation coefficient (ICC),&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\text{ICC} = \frac{\text{between-person variance}}{\text{total variance}} = \frac{\sigma_\text{id}^2}{\sigma_\text{id}^2 + \sigma_\epsilon^2}.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;When using frequentist methods, the ICC is typically expressed with a point estimate. When working with all our posterior draws, we can get full posterior distributions within the Bayesian framework.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(m10) %&amp;gt;% 
  mutate(icc = sd_id__Intercept^2 / (sd_id__Intercept^2 + sigma^2)) %&amp;gt;% 
  ggplot(aes(x = icc, y = 0)) +
  stat_halfeye(.width = .95) +
  scale_x_continuous(&amp;quot;Intraclass correlation coefficient (ICC)&amp;quot;, 
                     breaks = 0:5 / 5, expand = c(0, 0), limits = 0:1) +
  scale_y_continuous(NULL, breaks = NULL)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-43-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The ICC is a proportion, which limits it to the range of zero to one. Here it suggests that 0–20% of the variation in our data is due to differences &lt;em&gt;between&lt;/em&gt; participants; the remaining variation occurs within them. Given that our data were collected across time, it might make sense to fit a model that explicitly accounts for time.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_11-colon-the-cross-classified-model.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{11} \colon\)&lt;/span&gt; The cross-classified model.&lt;/h4&gt;
&lt;p&gt;A direct extension of the random-intercept model is the cross-classified multilevel model &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;McElreath, 2015&lt;/a&gt;, Chapter 12)&lt;/span&gt;, which we might express as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti}   &amp;amp; \sim \operatorname{Normal}(\mu_{ti}, \sigma) \\
\mu_{ti} &amp;amp; = \beta_0 + u_{\text{id},i} + u_{\text{time},i} \\
u_\text{id} &amp;amp; \sim \operatorname{Normal}(0, \sigma_\text{id}) \\
u_\text{time} &amp;amp; \sim \operatorname{Normal}(0, \sigma_\text{time}) \\
\sigma &amp;amp; = \sigma_\epsilon,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\text{id}\)&lt;/span&gt; captures systemic differences between participants, &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\text{time}\)&lt;/span&gt; captures systemic variation across the two timepoints, and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\epsilon\)&lt;/span&gt; captures the variation within participants over time. Another way to think of this model is as a Bayesian multilevel version of the repeated-measures ANOVA&lt;a href=&#34;#fn3&#34; class=&#34;footnote-ref&#34; id=&#34;fnref3&#34;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;, where variance is partitioned into a between level (&lt;span class=&#34;math inline&#34;&gt;\(\sigma_\text{id} \approx \text{SS}_\text{between}\)&lt;/span&gt;), a model level (&lt;span class=&#34;math inline&#34;&gt;\(\sigma_\text{time} \approx \text{SS}_\text{model}\)&lt;/span&gt;), and error (&lt;span class=&#34;math inline&#34;&gt;\(\sigma_\epsilon \approx \text{SS}_\text{error}\)&lt;/span&gt;).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m11 &amp;lt;-
  brm(data = small_data_long,
      y ~ 1 + (1 | time) + (1 | id),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000,
      control = list(adapt_delta = .9999,
                     max_treedepth = 11))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m11)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y ~ 1 + (1 | time) + (1 | id) 
##    Data: small_data_long (Number of observations: 200) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Group-Level Effects: 
## ~id (Number of levels: 100) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.51      0.16     0.14     0.78 1.00     1519     1545
## 
## ~time (Number of levels: 2) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     1.67      1.30     0.41     5.00 1.00     5240     7037
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.46      1.07    -1.78     2.81 1.00     4541     4935
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.04      0.08     0.90     1.20 1.00     2313     3750
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The intercept is the grand mean across all measures of &lt;code&gt;y&lt;/code&gt;. The first row in the ‘Group-Level Effects’ section is our summary for &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\text{id}\)&lt;/span&gt;, which gives us a sense of the variation between participants in their overall tendencies in the criterion &lt;code&gt;y&lt;/code&gt;. If we use the &lt;code&gt;posterior_samples()&lt;/code&gt;, we can even look at the posteriors for the &lt;span class=&#34;math inline&#34;&gt;\(u_{\text{id},i}\)&lt;/span&gt; parameters, themselves.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(m11) %&amp;gt;% 
  pivot_longer(starts_with(&amp;quot;r_id&amp;quot;)) %&amp;gt;% 
  
  ggplot(aes(x = value, y = reorder(name, value))) +
  stat_pointinterval(point_interval = mean_qi, .width = .95, size = 1/6) +
  scale_y_discrete(expression(italic(i)), breaks = NULL) +
  labs(subtitle = expression(sigma[id]~is~the~summary~of~the~variation~across~these),
       x = expression(italic(u)[id][&amp;#39;,&amp;#39;*italic(i)]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-45-1.png&#34; width=&#34;336&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Given that each of the &lt;span class=&#34;math inline&#34;&gt;\(u_{\text{id},i}\)&lt;/span&gt; parameters is based primarily on two data points (the two data points per participant), it should be no surprise they are fairly wide. Even a few more measurement occasions within participants will narrow them substantially. If you fit the same model using the original 6-timepoint data, you’ll see the 95% intervals are almost half as wide.&lt;/p&gt;
&lt;p&gt;Perhaps of greater interest are the &lt;span class=&#34;math inline&#34;&gt;\(u_{\text{time},i}\)&lt;/span&gt; parameters. If you combine them with the intercept, you’ll get the model-based expected values at both timepoints.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(m11) %&amp;gt;% 
  transmute(pre  = b_Intercept + `r_time[0,Intercept]`,
            post = b_Intercept + `r_time[1,Intercept]`) %&amp;gt;% 
  pivot_longer(everything()) %&amp;gt;% 
  group_by(name) %&amp;gt;% 
  mean_qi(value) %&amp;gt;% 
  mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 7
##   name  value .lower .upper .width .point .interval
##   &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;  &amp;lt;chr&amp;gt;    
## 1 post   1.01   0.78   1.24   0.95 mean   qi       
## 2 pre   -0.15  -0.38   0.09   0.95 mean   qi&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The final variance parameter, &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\text{time}\)&lt;/span&gt;, captures the within-participant variation over time. With a model like this, it seems natural to directly compare the magnitudes of the three variance parameters, which answers the question: &lt;em&gt;Where’s the variance at&lt;/em&gt;? Here we’ll do so with a plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(m11) %&amp;gt;% 
  select(sd_id__Intercept:sigma) %&amp;gt;% 
  set_names(&amp;quot;sigma[id]&amp;quot;, &amp;quot;sigma[time]&amp;quot;, &amp;quot;sigma[epsilon]&amp;quot;) %&amp;gt;% 
  pivot_longer(everything()) %&amp;gt;% 
  mutate(name = factor(name, levels = c(&amp;quot;sigma[epsilon]&amp;quot;, &amp;quot;sigma[time]&amp;quot;, &amp;quot;sigma[id]&amp;quot;))) %&amp;gt;%
  
  ggplot(aes(x = value, y = name)) +
  tidybayes::stat_halfeye(.width = .95, size = 1, normalize = &amp;quot;xy&amp;quot;) +
  scale_x_continuous(&amp;quot;marginal posterior&amp;quot;, expand = expansion(mult = c(0, 0.05)), breaks = c(0, 1, 2, 5)) +
  scale_y_discrete(NULL, labels = ggplot2:::parse_safe) +
  coord_cartesian(xlim = c(0, 5.25),
                  ylim = c(1.5, 3.5)) +
  theme(axis.text.y = element_text(hjust = 0))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-48-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;At first glance, it might be surprising how wide the &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\text{time}\)&lt;/span&gt; posterior is compared to the other two. Yet recall this parameter is summarizing the standard deviation of only two levels. If you have experience with multilevel models, you’ll know that it can be difficult to estimate a variance parameter with few levels–two levels is the extreme lower limit. This is why we had to fiddle with the &lt;code&gt;adapt_delta&lt;/code&gt; and &lt;code&gt;max_treedepth&lt;/code&gt; parameters within the &lt;code&gt;brm()&lt;/code&gt; function to get the model to sample properly. Though we pulled this off using default priors, don’t be surprised if you have to use tighter priors when fitting a model like this.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_12-colon-the-simple-liner-model.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{12} \colon\)&lt;/span&gt; The simple liner model.&lt;/h4&gt;
&lt;p&gt;The last three models focused on the grand mean and sources of variance around that grand mean. A more familiar looking approach might be to fit a simple linear model with &lt;code&gt;y&lt;/code&gt; conditional on &lt;code&gt;time&lt;/code&gt;,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti} &amp;amp; \sim \operatorname{Normal}(\mu_{ti}, \sigma) \\
\mu_{ti} &amp;amp; = \beta_0 + \beta_1 \text{time}_{ti},
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the expected value at the first timepoint and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; captures the change in &lt;span class=&#34;math inline&#34;&gt;\(y_{ti}\)&lt;/span&gt; for the final timepoint.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m12 &amp;lt;-
  brm(data = small_data_long,
      y ~ 1 + time,
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m12)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y ~ 1 + time 
##    Data: small_data_long (Number of observations: 200) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -0.15      0.12    -0.38     0.08 1.00     9459     7344
## time          1.17      0.16     0.85     1.49 1.00     9582     7294
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.16      0.06     1.05     1.28 1.00     9982     7362
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now our &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; parameters are the direct pre/post single-level analogues to the population-level &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; parameters from our original multilevel model based on the full 6-timepoint data set.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(m0) %&amp;gt;% round(digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           Estimate Est.Error  Q2.5 Q97.5
## Intercept    -0.13      0.11 -0.33  0.08
## time          1.16      0.13  0.91  1.42&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The major deficit in this model, which is the reason you’ll see it criticized in the methodological literature, is it ignores how the &lt;code&gt;y&lt;/code&gt; values are nested within levels of &lt;code&gt;id&lt;/code&gt;. The only variance parameter, &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, was estimated under the typical assumption that the residuals are all independent of one another. Sure, the model formula accounted for the overall trend in &lt;code&gt;time&lt;/code&gt;, but it ignored the insights revealed from many of the other models the capture between-participant correlations in intercepts and slopes. This means that if you know something about the value of one’s residual for when &lt;code&gt;time == 0&lt;/code&gt;, you’ll also know something about where to expect their residual for when &lt;code&gt;time == 1&lt;/code&gt;. The two are not independent. As long as we’re working with the data in the long format, we’ll want to account for this, somehow.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_13-colon-the-liner-model-with-a-random-intercept.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{13} \colon\)&lt;/span&gt; The liner model with a random intercept.&lt;/h4&gt;
&lt;p&gt;A natural first step to accounting for how the &lt;code&gt;y&lt;/code&gt; values are nested within levels of &lt;code&gt;id&lt;/code&gt; is to fit a random-intercept model, or what &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;Hoffman&lt;/a&gt; (&lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; called the &lt;em&gt;fixed linear time, random intercept model&lt;/em&gt;. It follows the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti} &amp;amp; \sim \operatorname{Normal}(\mu_{ti}, \sigma) \\
\mu_{ti} &amp;amp; = \beta_{0i} + \beta_1 \text{time}_{ti} \\
\beta_{0i} &amp;amp; = \gamma_0 + u_{0i} \\
u_{0i}  &amp;amp; \sim \operatorname{Normal}(0, \sigma_0) \\
\sigma &amp;amp; = \sigma_\epsilon,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_{0i}\)&lt;/span&gt; is the intercept and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is the time slope. Although this parameterization holds the variation in slopes constant across participants, between-participant variation is at least captured in &lt;span class=&#34;math inline&#34;&gt;\(\beta_{0i}\)&lt;/span&gt;, which is decomposed into a grand mean, &lt;span class=&#34;math inline&#34;&gt;\(\gamma_0\)&lt;/span&gt;, and participant-level deviations around that grand mean, &lt;span class=&#34;math inline&#34;&gt;\(u_{0i}\)&lt;/span&gt;. Those participant-level deviations are summarized by the &lt;span class=&#34;math inline&#34;&gt;\(\sigma_0\)&lt;/span&gt; parameter. In this model, &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\epsilon\)&lt;/span&gt; is a mixture of within-participant variation and between-participant variation in slopes.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m13 &amp;lt;-
  brm(data = small_data_long,
      y ~ 1 + time + (1 | id),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m13)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y ~ 1 + time + (1 | id) 
##    Data: small_data_long (Number of observations: 200) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Group-Level Effects: 
## ~id (Number of levels: 100) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.52      0.15     0.14     0.78 1.00     1645     1960
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -0.15      0.12    -0.38     0.08 1.00     9441     7715
## time          1.17      0.15     0.88     1.46 1.00    14821     6993
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.03      0.08     0.90     1.19 1.00     2403     4360
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; parameters are very similar to those from the simple linear model, above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(m12) %&amp;gt;% round(digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           Estimate Est.Error  Q2.5 Q97.5
## Intercept    -0.15      0.12 -0.38  0.08
## time          1.17      0.16  0.85  1.49&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But now look at the size of &lt;span class=&#34;math inline&#34;&gt;\(\sigma_0\)&lt;/span&gt;, which suggests substantial differences in staring points. To get a sense of what this means, we’ll plot all 100 participant-level trajectories with a little help from &lt;code&gt;fitted()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;nd &amp;lt;- distinct(small_data_long, id, time)

fitted(m13, 
       newdata = nd) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  bind_cols(nd) %&amp;gt;% 
  
  ggplot(aes(x = time, y = Estimate, group = id)) +
  geom_abline(intercept = fixef(m13)[1, 1],
              slope = fixef(m13)[2, 1],
              size = 3, color = &amp;quot;blue&amp;quot;) +
  geom_line(size = 1/4, alpha = 2/3) +
  scale_x_continuous(breaks = 0:1) +
  labs(subtitle = &amp;quot;Random intercepts, fixed slope&amp;quot;,
       y = &amp;quot;y&amp;quot;) +
  coord_cartesian(ylim = c(-1, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-53-1.png&#34; width=&#34;288&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The bold blue line in the middle is based on the population-level intercept and slope, whereas the thinner black lines are the participant-level trajectories. To keep from &lt;a href=&#34;https://www.data-to-viz.com/caveat/overplotting.html&#34;&gt;overplotting&lt;/a&gt;, we’re only showing the posterior means, here. Because we only allowed the intercept to vary across participants, all the slopes are identical. And indeed, look at all the variation we see in the intercepts–an insight lacking in the simple linear model.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_14-colon-the-liner-model-with-a-random-slope.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{14} \colon\)&lt;/span&gt; The liner model with a random slope.&lt;/h4&gt;
&lt;p&gt;The counterpoint to the last model is to allow the time slopes, but not the intercepts, vary across participants:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti} &amp;amp; \sim \operatorname{Normal}(\mu_{ti}, \sigma) \\
\mu_{ti} &amp;amp; = \beta_0 + \beta_{1i} \text{time}_{ti} \\
\beta_{1i} &amp;amp; = \gamma_1 + u_{1i} \\
u_{1i} &amp;amp; \sim \operatorname{Normal}(0, \sigma_1) \\
\sigma   &amp;amp; = \sigma_\epsilon,
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the intercept for all participants. Now &lt;span class=&#34;math inline&#34;&gt;\(\beta_{1i}\)&lt;/span&gt; is the population mean for the distribution of slopes, which vary across participants, the standard deviation for which is measured by &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m14 &amp;lt;-
  brm(data = small_data_long,
      y ~ 1 + time + (0 + time | id),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000,
      control = list(adapt_delta = .95))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m14)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y ~ 1 + time + (0 + time | id) 
##    Data: small_data_long (Number of observations: 200) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Group-Level Effects: 
## ~id (Number of levels: 100) 
##          Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(time)     0.33      0.21     0.02     0.75 1.00     2240     4641
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -0.15      0.11    -0.38     0.08 1.00    20513     7195
## time          1.17      0.16     0.85     1.49 1.00    18079     7133
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.13      0.06     1.01     1.26 1.00     6825     6149
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s random-slopes alternative to the random-intercepts plot from the last section.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fitted(m14, 
       newdata = nd) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  bind_cols(nd) %&amp;gt;% 
  
  ggplot(aes(x = time, y = Estimate, group = id)) +
  geom_abline(intercept = fixef(m14)[1, 1],
              slope = fixef(m14)[2, 1],
              size = 3, color = &amp;quot;blue&amp;quot;) +
  geom_line(size = 1/4, alpha = 2/3) +
  scale_x_continuous(breaks = 0:1) +
  labs(subtitle = &amp;quot;Fixed intercept, random slopes&amp;quot;,
       y = &amp;quot;y&amp;quot;) +
  coord_cartesian(ylim = c(-1, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-55-1.png&#34; width=&#34;288&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;But why choose between random intercepts or random slopes?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_15-colon-the-multilevel-growth-model-with-regularizing-priors.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{15} \colon\)&lt;/span&gt; The multilevel growth model with regularizing priors.&lt;/h4&gt;
&lt;p&gt;If you were modeling 2-timepoint data with conventional frequentist estimators (e.g., maximum likelihood), you can have random intercepts or random slopes, but you can’t have both; that would require data from three timepoints or more. But because Bayesian models bring in extra information by way of the priors, you can actually fit a full multilevel growth model with both random intercepts and slopes:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti}   &amp;amp; \sim \operatorname{Normal}(\mu_{ti}, \sigma_\epsilon ) \\
\mu_{ti} &amp;amp; = \beta_0 + \beta_1 \text{time}_{ti} + u_{0i} + u_{1i} \text{time}_{ti} \\
\begin{bmatrix} u_{0i} \\ u_{1i} \end{bmatrix} &amp;amp; \sim \operatorname{MVNormal} \left (\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \mathbf \Sigma \right) \\
\mathbf \Sigma &amp;amp; = \mathbf{SRS} \\
\mathbf S &amp;amp; = \begin{bmatrix} \sigma_0 &amp;amp; 0 \\ 0 &amp;amp; \sigma_1 \end{bmatrix} \\
\mathbf R &amp;amp; = \begin{bmatrix} 1 &amp;amp; \rho \\ \rho &amp;amp; 1 \end{bmatrix}.
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The trick is you have to go beyond the diffuse &lt;strong&gt;brms&lt;/strong&gt; default settings for the priors for &lt;span class=&#34;math inline&#34;&gt;\(\sigma_0\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt;. If you have high-quality information from theory or previous studies, you can base the priors on those. Another approach is to use regularizing priors. Given standardized data, members of the Stan team like either &lt;span class=&#34;math inline&#34;&gt;\(\operatorname{Normal}^+(0, 1)\)&lt;/span&gt; or &lt;span class=&#34;math inline&#34;&gt;\(\operatorname{Student-t}^+(3, 0, 1)\)&lt;/span&gt; for variance parameters (see the &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations#generic-prior-for-anything&#34;&gt;Generic prior for anything&lt;/a&gt; section from the &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;&lt;em&gt;Prior choice recommendations&lt;/em&gt; wiki&lt;/a&gt;). In the second edition of his text, McElreath generally favored the &lt;span class=&#34;math inline&#34;&gt;\(\operatorname{Exponential}(1)\)&lt;/span&gt; prior &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;McElreath, 2020&lt;/a&gt;)&lt;/span&gt;, which is the approach we’ll experiment with, here. It’ll also help if we use a regularizing prior on the correlation among the intercepts and slopes, &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m15 &amp;lt;-
  brm(data = small_data_long,
      y ~ 1 + time + (1 + time | id),
      seed = 1,
      prior = prior(exponential(1), class = sd) +
        prior(lkj(4), class = cor),
      cores = 4, chains = 4, iter = 3500, warmup = 1000,
      control = list(adapt_delta = .9995))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even with our tighter priors, we still had to adjust the &lt;code&gt;adapt_delta&lt;/code&gt; parameter to improve the quality of the MCMC sampling. Take a look at the model summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y ~ 1 + time + (1 + time | id) 
##    Data: small_data_long (Number of observations: 200) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Group-Level Effects: 
## ~id (Number of levels: 100) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)           0.52      0.18     0.12     0.84 1.01     1012     1473
## sd(time)                0.31      0.23     0.01     0.88 1.00     1021      876
## cor(Intercept,time)    -0.05      0.33    -0.63     0.59 1.00     4039     6272
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -0.15      0.11    -0.38     0.07 1.00    10022     8348
## time          1.17      0.15     0.88     1.46 1.00    13870     7175
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.01      0.10     0.80     1.18 1.00     1060      946
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Though the posteriors, particularly for the &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; parameters, are not as precise as with the 6-timepoint data, we now have a model with a summary mirroring the structure of the data-generating model. Yet compared to the data-generating values, the estimates for &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; are particularly biased toward zero. Here’s a look at the trajectories.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fitted(m15,
       newdata = nd) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  bind_cols(nd) %&amp;gt;% 
  
  ggplot(aes(x = time, y = Estimate, group = id)) +
  geom_abline(intercept = fixef(m15)[1, 1],
              slope = fixef(m15)[2, 1],
              size = 3, color = &amp;quot;blue&amp;quot;) +
  geom_line(size = 1/4, alpha = 2/3) +
  scale_x_continuous(breaks = 0:1) +
  labs(subtitle = &amp;quot;Random intercepts AND random slopes\n(2-timepoint data)&amp;quot;,
       y = &amp;quot;y&amp;quot;) +
  coord_cartesian(ylim = c(-1, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-57-1.png&#34; width=&#34;288&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For comparision, here’s the plot for the original 6-timepoint model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fitted(m0,
       newdata = nd) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  bind_cols(nd) %&amp;gt;% 
  
  ggplot(aes(x = time, y = Estimate, group = id)) +
  geom_abline(intercept = fixef(m0)[1, 1],
              slope = fixef(m0)[2, 1],
              size = 3, color = &amp;quot;blue&amp;quot;) +
  geom_line(size = 1/4, alpha = 2/3) +
  scale_x_continuous(breaks = 0:1) +
  labs(subtitle = &amp;quot;Random intercepts AND random slopes\n(6-timepoint data)&amp;quot;,
       y = &amp;quot;y&amp;quot;) +
  coord_cartesian(ylim = c(-1, 2))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-58-1.png&#34; width=&#34;288&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There wasn’t enough information in the 2-timepoint data set to capture the complexity in the full 6-timepoint data set.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_16-colon-the-fixed-effects-with-correlated-error-model.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{16} \colon\)&lt;/span&gt; The fixed effects with correlated error model.&lt;/h4&gt;
&lt;p&gt;Though our Bayesian 2-timepoint version of the full multilevel growth model was exciting, it’s not generally used in the wild. Even with our tighter regularizing priors, there just wasn’t enough information in the data to do the model justice. A very different and humbler approach is to combine the simple linear model with the autoregressive model,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti} &amp;amp; \sim \operatorname{Normal}(\mu_{ti}, \mathbf \Sigma) \\
\mu_{ti} &amp;amp; = \beta_0 + \beta_1 \text{time}_{ti} \\
\mathbf \Sigma &amp;amp; = \mathbf{SRS} \\
\mathbf S &amp;amp; = \begin{bmatrix} \sigma &amp;amp; 0 \\ 0 &amp;amp; \sigma \end{bmatrix} \\
\mathbf R &amp;amp; = \begin{bmatrix} 1 &amp;amp; \rho \\ \rho &amp;amp; 1 \end{bmatrix},
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; captures the correlation between the responses in the two timepoints, &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(t - 1\)&lt;/span&gt;, which is an alternative to the way the mixed model from above handles the dependencies (a.k.a &lt;a href=&#34;https://en.wikipedia.org/wiki/Heteroscedasticity&#34;&gt;heteroskedasticity&lt;/a&gt;) inherent in longitudinal data. Note how &lt;span class=&#34;math inline&#34;&gt;\(\mathbf \Sigma\)&lt;/span&gt; in this model is defined very differently from the full multilevel growth model from above. To fit this model with &lt;strong&gt;brms&lt;/strong&gt;, we use the &lt;code&gt;ar()&lt;/code&gt; syntax.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m16 &amp;lt;-
  brm(data = small_data_long,
      y ~ time + ar(time = time, p = 1, gr = id),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m16)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: y ~ time + ar(time = time, p = 1, gr = id) 
##    Data: small_data_long (Number of observations: 200) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Correlation Structures:
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## ar[1]     0.23      0.10     0.04     0.43 1.00     9766     7458
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept    -0.15      0.12    -0.38     0.07 1.00    10593     7136
## time          1.17      0.15     0.89     1.46 1.00     9607     6546
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     1.15      0.06     1.04     1.27 1.00    10604     7665
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This summary suggests that, after you account for the linear trend, the correlation between &lt;span class=&#34;math inline&#34;&gt;\(y_{ti}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(y_{t - 1,i}\)&lt;/span&gt; is about 0.23. Though we don’t get &lt;code&gt;id&lt;/code&gt;-specific variance parameters, this model does account for the nonindependence of the data over time. If you scroll back up, notice how similar this is to the correlation from the bivariate correlational model, &lt;code&gt;m4&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;the-models-with-robust-variance-parameters.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;The models with robust variance parameters.&lt;/h3&gt;
&lt;p&gt;In the social sciences, many of our theories and statistical models are comparisons of or changes in group means. Every model in this blog post uses the normal likelihood, which parameterizes the criterion in terms of &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Every time we added some kind of linear model, we focused that model around the &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;. But contemporary Bayesian software allows us to model the &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; parameter, too. Within the &lt;strong&gt;brms&lt;/strong&gt; framework, &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-Bürkner2021Distributional&#34; role=&#34;doc-biblioref&#34;&gt;Bürkner&lt;/a&gt; (&lt;a href=&#34;#ref-Bürkner2021Distributional&#34; role=&#34;doc-biblioref&#34;&gt;2021a&lt;/a&gt;)&lt;/span&gt; calls these &lt;a href=&#34;https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html&#34;&gt;distributional models&lt;/a&gt;. The final four models under consideration all use some form of the distributional modeling syntax to relax unnecessarily restrictive assumptions on the variance parameters. Though this section is not exhaustive, it should give a sense of how flexible this approach can be.&lt;/p&gt;
&lt;div id=&#34;mathcal-m_17-colon-the-cross-classified-model-with-robust-variances-for-discrete-time.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{17} \colon\)&lt;/span&gt; The cross-classified model with robust variances for discrete time.&lt;/h4&gt;
&lt;p&gt;One of the criticisms of the conventional repeated measures ANOVA approach is how it presumes the variances in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; are constant over time. However, we can relax that constraint with a model like&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti} &amp;amp; \sim \operatorname{Normal}(\mu_{ti}, \sigma_{ti}) \\
\mu_{ti} &amp;amp; = \beta_0 + u_{\text{id},i} + u_{\text{time},t} \\
\log (\sigma_{ti}) &amp;amp; = \eta_{\text{time},t} \\
u_\text{id} &amp;amp; \sim \operatorname{Normal}(0, \sigma_\text{id}) \\
u_\text{time} &amp;amp; \sim \operatorname{Normal}(0, \sigma_\text{time}),
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where we are now modeling both parameters in the likelihood, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; AND &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. The second line shows a typical-looking model for &lt;span class=&#34;math inline&#34;&gt;\(\mu_{ti}\)&lt;/span&gt;. All the excitement lies in the third line, which contains the linear model for &lt;span class=&#34;math inline&#34;&gt;\(\log (\sigma_{ti})\)&lt;/span&gt;. The reason we are modeling &lt;span class=&#34;math inline&#34;&gt;\(\log (\sigma_{ti})\)&lt;/span&gt; rather than directly modeling &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is to avoid solutions that predict negative values for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. For this model, it’s unlikely we’d run into that problem. But since the &lt;strong&gt;brms&lt;/strong&gt; default is to use the log link anytime we model &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; within the distributional modeling syntax, we’ll just get used to the log link right from the start. If you are unfamiliar with link functions, they’re widely used within the generalized linear modeling framework. Logistic regression with the logit link and Poisson regression with the log link are two widely-used examples. For more on link functions and the generalized linear model, check out the texts by &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-agrestiFoundationsLinearGeneralized2015&#34; role=&#34;doc-biblioref&#34;&gt;Agresti&lt;/a&gt; (&lt;a href=&#34;#ref-agrestiFoundationsLinearGeneralized2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;; Gelman, Hill, and Vehtari &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-gelmanRegressionOtherStories2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt;; and McElreath &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;, &lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Anyway, the linear model for &lt;span class=&#34;math inline&#34;&gt;\(\mu_{ti}\)&lt;/span&gt; is exactly the same as with the original cross-classified model, &lt;code&gt;m11&lt;/code&gt;; it includes a grand mean (&lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt;) and two kinds of deviations around that grand mean (&lt;span class=&#34;math inline&#34;&gt;\(u_{\text{id},i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(u_{\text{time},t}\)&lt;/span&gt;). The model for &lt;span class=&#34;math inline&#34;&gt;\(\log (\sigma_{ti})\)&lt;/span&gt; contains an intercept, which varies across the two levels of time, &lt;span class=&#34;math inline&#34;&gt;\(\eta_{\text{time},t}\)&lt;/span&gt;. Here’s how to fit the model with &lt;code&gt;brms::brm()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m17 &amp;lt;-
  brm(data = small_data_long,
      bf(y ~ 1 + (1 | time) + (1 | id),
         sigma ~ 0 + factor(time)),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000,
      control = list(adapt_delta = .999,
                     max_treedepth = 12))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m17)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = log 
## Formula: y ~ 1 + (1 | time) + (1 | id) 
##          sigma ~ 0 + factor(time)
##    Data: small_data_long (Number of observations: 200) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Group-Level Effects: 
## ~id (Number of levels: 100) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.53      0.15     0.15     0.79 1.00     1376     1194
## 
## ~time (Number of levels: 2) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     1.66      1.26     0.41     5.00 1.00     5133     6854
## 
## Population-Level Effects: 
##                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept             0.45      1.07    -1.78     2.66 1.00     4653     5056
## sigma_factortime0     0.01      0.10    -0.18     0.20 1.00     3068     5577
## sigma_factortime1     0.03      0.10    -0.17     0.22 1.00     2678     4488
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even though we didn’t explicitly ask to use the log link in our &lt;code&gt;brm()&lt;/code&gt; syntax, you can look at the second line in the &lt;code&gt;print()&lt;/code&gt; output to see that it was automatically used. Though I won’t explore how to do so, here, one can fit this model without the log link. Anyway, the primary focus in this model is the &lt;code&gt;sigma_factortime0&lt;/code&gt; and &lt;code&gt;sigma_factortime1&lt;/code&gt; lines in the ‘Population-Level Effects’ section of the output. Those are the summaries for the &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; parameters, conditional on whether &lt;code&gt;time == 0&lt;/code&gt; or &lt;code&gt;time == 1&lt;/code&gt;. Though is might be difficult to evaluate parameters on the log scale, we can simply exponentiate them to convert them back to their natural metric.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(m17)[2:3, c(1, 3:4)] %&amp;gt;% exp()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                   Estimate      Q2.5    Q97.5
## sigma_factortime0 1.013928 0.8352872 1.223336
## sigma_factortime1 1.032290 0.8446723 1.247435&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this case, it looks like the two parameters are largely overlapping. If we work directly with the posterior draws, we can compute a formal difference score and plot the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(m17) %&amp;gt;% 
  mutate(`sigma[time==0]` = exp(b_sigma_factortime0),
         `sigma[time==1]` = exp(b_sigma_factortime1),
         `sigma[time==1]-sigma[time==0]` = exp(b_sigma_factortime1) - exp(b_sigma_factortime0)) %&amp;gt;% 
  pivot_longer(`sigma[time==0]`:`sigma[time==1]-sigma[time==0]`) %&amp;gt;% 
  
  ggplot(aes(x = value, y = name)) + 
  stat_halfeye(.width = .95) +
  scale_y_discrete(NULL, labels = ggplot2:::parse_safe) +
  coord_cartesian(ylim = c(1.5, 3.1)) +
  xlab(&amp;quot;marginal posterior&amp;quot;) +
  theme(axis.text.y = element_text(hjust = 0))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-62-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this case, it looks like there was little difference between &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\text{time} = 0}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_{\text{time} = 1}\)&lt;/span&gt;. This shouldn’t be a surprise; we simulated that data that way. However, it won’t always be like this in real-world data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_18-colon-the-simple-liner-model-with-robust-variance-for-linear-time.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{18} \colon\)&lt;/span&gt; The simple liner model with robust variance for linear time.&lt;/h4&gt;
&lt;p&gt;Our cross-classified approach treated &lt;code&gt;time&lt;/code&gt; as a factor. Here we’ll treat it as a continuous variable in the models of both &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. This will be a straight extension of the simple linear model, &lt;code&gt;m12&lt;/code&gt;, following the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti} &amp;amp; \sim \operatorname{Normal}(\mu_{ti}, \sigma_{ti}) \\
\mu_{ti} &amp;amp; = \beta_0 + \beta_1 \text{time}_{ti} \\
\log(\sigma_{ti}) &amp;amp; = \eta_0 + \eta_1 \text{time}_{ti},
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the intercept &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the expected value at the first timepoint and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; captures the change in &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; for the final timepoint. Now &lt;span class=&#34;math inline&#34;&gt;\(\log(\sigma_{ti})\)&lt;/span&gt; has a similar linear model, where &lt;span class=&#34;math inline&#34;&gt;\(\eta_0\)&lt;/span&gt; is the expected log of the standard deviation at the first timepoint and &lt;span class=&#34;math inline&#34;&gt;\(\eta_1\)&lt;/span&gt; captures the change standard deviation for the final timepoint.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m18 &amp;lt;-
  brm(data = small_data_long,
      bf(y ~ 1 + time, 
         sigma ~ 1 + time),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m18)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = log 
## Formula: y ~ 1 + time 
##          sigma ~ 1 + time
##    Data: small_data_long (Number of observations: 200) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Population-Level Effects: 
##                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept          -0.15      0.11    -0.38     0.06 1.00    11620     6673
## sigma_Intercept     0.14      0.07     0.00     0.28 1.00    11090     7442
## time                1.17      0.16     0.85     1.49 1.00    11137     7818
## sigma_time          0.01      0.10    -0.18     0.21 1.00    11157     7620
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Even though this model looks very different from the last one, we can wrangle the posterior draws a little to make a similar plot comparing &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; at the two timepoints.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(m18) %&amp;gt;% 
  mutate(`sigma[time==0]` = exp(b_sigma_Intercept),
         `sigma[time==1]` = exp(b_sigma_Intercept + b_sigma_time * 1),
         `sigma[time==1]-sigma[time==0]` = exp(b_sigma_Intercept) - exp(b_sigma_Intercept + b_sigma_time)) %&amp;gt;% 
  pivot_longer(`sigma[time==0]`:`sigma[time==1]-sigma[time==0]`) %&amp;gt;% 
  
  ggplot(aes(x = value, y = name)) + 
  stat_halfeye(.width = .95) +
  scale_y_discrete(NULL, labels = ggplot2:::parse_safe) +
  coord_cartesian(ylim = c(1.5, 3.1)) +
  xlab(&amp;quot;marginal posterior&amp;quot;) +
  theme(axis.text.y = element_text(hjust = 0))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-64-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Though this model is robust to differences in &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; based on timepoint, it still ignores systemic differences across participants. The next model tackles that that limitation in spades.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_19-colon-the-liner-model-with-correlated-random-intercepts-for-mu-and-sigma.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{19} \colon\)&lt;/span&gt; The liner model with correlated random intercepts for &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma.\)&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;Here we return to the multilevel model framework to accommodate participant-level differences for both &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti} &amp;amp; \sim \operatorname{Normal}(\mu_{ti}, \sigma_{ti}) \\
\mu_{ti} &amp;amp; = \beta_0 + \beta_1 \text{time}_{ti} + u_{0i}  \\
\log(\sigma_{ti}) &amp;amp; = \eta_0  + u_{2i} \\
\begin{bmatrix} u_{0i} \\ u_{2i} \end{bmatrix} &amp;amp; \sim \operatorname{MVNormal} \left (\begin{bmatrix} 0 \\ 0 \end{bmatrix}, \mathbf \Sigma \right) \\
\mathbf \Sigma &amp;amp; = \mathbf{SRS} \\
\mathbf S &amp;amp; = \begin{bmatrix} \sigma_0 &amp;amp; 0 \\ 0 &amp;amp; \sigma_2 \end{bmatrix} \\
\mathbf R &amp;amp; = \begin{bmatrix} 1 &amp;amp; \rho \\ \rho &amp;amp; 1 \end{bmatrix},
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; is the grand mean for the intercepts and &lt;span class=&#34;math inline&#34;&gt;\(u_{0i}\)&lt;/span&gt; are the participant-level deviations around that grand mean. &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is the time slope, which is invariant across all participants in this model. The &lt;span class=&#34;math inline&#34;&gt;\(\eta_0\)&lt;/span&gt; parameter is the grand mean for the log standard deviations and &lt;span class=&#34;math inline&#34;&gt;\(u_{2i}\)&lt;/span&gt; captures the participant-level deviations around that grand mean. In the fourth line, we learn that &lt;span class=&#34;math inline&#34;&gt;\(u_{0i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(u_{2i}\)&lt;/span&gt; are multivariate normal, with a mean vector of two zeros and a variance/covariance matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf \Sigma\)&lt;/span&gt;. As is typical within the &lt;strong&gt;brms&lt;/strong&gt; framework, we decompose &lt;span class=&#34;math inline&#34;&gt;\(\mathbf \Sigma\)&lt;/span&gt; into a variance matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf S\)&lt;/span&gt; and correlation matrix &lt;span class=&#34;math inline&#34;&gt;\(\mathbf R\)&lt;/span&gt;. Of particular interest is the &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; parameter, which captures the correlation in the participant-level intercepts and participant-level standard deviations. Here’s how to fit the model with &lt;strong&gt;brms&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m19 &amp;lt;-
  brm(data = small_data_long,
      bf(y ~ 1 + time + (1 |x| id),
         sigma ~ 1 + (1 |x| id)),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000,
      control = list(adapt_delta = .9))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You may have noticed the &lt;code&gt;|x|&lt;/code&gt; parts in the &lt;code&gt;formula&lt;/code&gt; lines for &lt;code&gt;y&lt;/code&gt; and &lt;code&gt;sigma&lt;/code&gt;. What that did was tell &lt;strong&gt;brms&lt;/strong&gt; we wanted those parameters to be correlated. That is, that’s how we estimated the &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; parameter. There was nothing special about including &lt;code&gt;x&lt;/code&gt; between the vertical lines. We could have used any other character. The important thing is that we used the same character in both. Anyway, here’s the model summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m19)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = log 
## Formula: y ~ 1 + time + (1 | x | id) 
##          sigma ~ 1 + (1 | x | id)
##    Data: small_data_long (Number of observations: 200) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Group-Level Effects: 
## ~id (Number of levels: 100) 
##                                Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)                      0.52      0.16     0.14     0.78 1.00     1496     1443
## sd(sigma_Intercept)                0.11      0.08     0.01     0.29 1.00     3032     4589
## cor(Intercept,sigma_Intercept)    -0.34      0.49    -0.97     0.80 1.00     5949     6097
## 
## Population-Level Effects: 
##                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept          -0.15      0.12    -0.38     0.08 1.00    10102     7923
## sigma_Intercept     0.02      0.08    -0.13     0.17 1.00     2344     3931
## time                1.17      0.15     0.88     1.45 1.00    14868     8009
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Once again, &lt;strong&gt;brms&lt;/strong&gt; used the log link for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. If you want to see &lt;span class=&#34;math inline&#34;&gt;\(\eta_0\)&lt;/span&gt; in its natural &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; metric, exponentiate.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(m19)[&amp;quot;sigma_Intercept&amp;quot;, c(1, 3:4)] %&amp;gt;% exp()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Estimate      Q2.5     Q97.5 
## 1.0171275 0.8759026 1.1849572&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;sd(sigma_Intercept)&lt;/code&gt; row in the ‘Group-Level Effects’ section shows the variation in those &lt;span class=&#34;math inline&#34;&gt;\(\log \sigma\)&lt;/span&gt;’s. It might be easier to appreciate them in a plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(m19) %&amp;gt;% 
  pivot_longer(starts_with(&amp;quot;r_id__sigma&amp;quot;)) %&amp;gt;% 
  mutate(sigma_i = exp(sd_id__sigma_Intercept + value)) %&amp;gt;% 
  
  ggplot(aes(x = sigma_i, y = reorder(name, sigma_i))) +
  stat_pointinterval(point_interval = mean_qi, .width = .95, size = 1/6) +
  scale_y_discrete(expression(italic(i)), breaks = NULL) +
  labs(subtitle = expression(sigma[2]~summarizes~the~variation~across~these),
       x = expression(sigma[italic(i)]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-67-1.png&#34; width=&#34;336&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;In this case, there was not a lot of variation in &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; across participants. This is because we simulated the data that way. Though it may be hard to model participant-level variances with 2-timepoint data, I have found it comes in handy in real-world data sets based on more measurement occasions.&lt;/p&gt;
&lt;p&gt;Finally, it might be useful to consider our &lt;span class=&#34;math inline&#34;&gt;\(\rho\)&lt;/span&gt; parameter, which suggested a mild negative correlation between the &lt;span class=&#34;math inline&#34;&gt;\(u_{0i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(u_{2i}\)&lt;/span&gt; deviations. Here’s how you might visualize that in a plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  posterior_samples(m19) %&amp;gt;% select(starts_with(&amp;quot;r_id[&amp;quot;)) %&amp;gt;% set_names(1:100),
  posterior_samples(m19) %&amp;gt;% select(starts_with(&amp;quot;r_id__sigma&amp;quot;) %&amp;gt;% set_names(1:100))
) %&amp;gt;% 
  mutate(iter = rep(1:c(n() / 2), times = 2),
         type = rep(c(&amp;quot;intercept&amp;quot;, &amp;quot;log_sigma&amp;quot;), each = n() / 2)) %&amp;gt;% 
  pivot_longer(-c(iter, type)) %&amp;gt;% 
  pivot_wider(names_from = type, values_from = value) %&amp;gt;% 
  
  ggplot(aes(x = intercept, y = log_sigma, group = name)) +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, level = .01, alpha = 1/4) +
  labs(x = expression(italic(u)[0][italic(i)]),
       y = expression(log(italic(u)[2][italic(i)])))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-68-1.png&#34; width=&#34;336&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Each of the ovals is a 1% ellipse of the bivariate posterior for &lt;span class=&#34;math inline&#34;&gt;\(u_{0i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\log(u_{2i})\)&lt;/span&gt;. Notice how using ellipses helps reveal the differences in the between- and within-person patterns.&lt;/p&gt;
&lt;p&gt;This approach where residual variance parameters vary across participants has its origins in the work of &lt;a href=&#34;https://health.uchicago.edu/faculty/donald-hedeker-phd&#34;&gt;Donald Hedeker&lt;/a&gt; and colleagues &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-hedekerApplicationMixedeffectsLocation2008&#34; role=&#34;doc-biblioref&#34;&gt;Hedeker et al., 2008&lt;/a&gt;, &lt;a href=&#34;#ref-hedekerModelingWithinsubjectVariance2012&#34; role=&#34;doc-biblioref&#34;&gt;2012&lt;/a&gt;)&lt;/span&gt;. More recently, &lt;a href=&#34;https://twitter.com/rastlab&#34;&gt;Philippe Rast&lt;/a&gt; and colleagues (particularly graduate student, &lt;a href=&#34;wdonald_1985&#34;&gt;Donald Williams&lt;/a&gt;) have adapted this approach for use within the Stan/&lt;strong&gt;brms&lt;/strong&gt; ecosystem &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-williamsBayesianMultivariateMixedeffects2019a&#34; role=&#34;doc-biblioref&#34;&gt;Williams, Liu, et al., 2019&lt;/a&gt;; &lt;a href=&#34;#ref-williamsSurfaceUnearthingWithinperson2019&#34; role=&#34;doc-biblioref&#34;&gt;Williams, Rouder, et al., 2019&lt;/a&gt;; &lt;a href=&#34;#ref-williamsPuttingIndividualReliability2019&#34; role=&#34;doc-biblioref&#34;&gt;Williams, Martin, et al., 2019&lt;/a&gt;; &lt;a href=&#34;#ref-williamsBayesianNonlinearMixedeffects2019a&#34; role=&#34;doc-biblioref&#34;&gt;Williams, Zimprich, et al., 2019&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;mathcal-m_20-colon-the-liner-model-with-a-random-slope-for-mu-and-uncorrelated-random-intercept-for-sigma.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;&lt;span class=&#34;math inline&#34;&gt;\(\mathcal M_{20} \colon\)&lt;/span&gt; The liner model with a random slope for &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and uncorrelated random intercept for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;.&lt;/h4&gt;
&lt;p&gt;Though we can find interesting things when we allow the random components in the &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; models, we don’t have to think of them as covarying. Here we fit an extension of the linear model with a random time slope, where we add an orthogonal random intercept for &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_{ti} &amp;amp; \sim \operatorname{Normal}(\mu_{ti}, \sigma_{ti}) \\
\mu_{ti} &amp;amp; = \beta_0 + \beta_1 \text{time}_{ti} + u_{1i} \\
\log(\sigma_{ti}) &amp;amp; = \eta_0  + u_{2i}  \\
u_{1i} &amp;amp; \sim \operatorname{Normal}(0, \sigma_1) \\
u_{2i} &amp;amp; \sim \operatorname{Normal}(0, \sigma_2),
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the two random components, &lt;span class=&#34;math inline&#34;&gt;\(u_{1i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(u_{2i}\)&lt;/span&gt;, are now modeled with separate normal distributions, &lt;span class=&#34;math inline&#34;&gt;\(\operatorname{Normal}(0, \sigma_1)\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\operatorname{Normal}(0, \sigma_2)\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m20 &amp;lt;-
  brm(data = small_data_long,
      bf(y ~ 1 + time + (0 + time | id),
         sigma ~ 1 + (1 | id)),
      seed = 1,
      cores = 4, chains = 4, iter = 3500, warmup = 1000)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that in sharp contrast with our syntax for the previous model, this time we did not employ the &lt;code&gt;|x|&lt;/code&gt; syntax in the &lt;code&gt;formula&lt;/code&gt; lines for &lt;code&gt;y&lt;/code&gt; and &lt;code&gt;sigma&lt;/code&gt;. By omitting the &lt;code&gt;|x|&lt;/code&gt; syntax, we omitted the correlation among those two random effects. Here’s the summary.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(m20)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = log 
## Formula: y ~ 1 + time + (0 + time | id) 
##          sigma ~ 1 + (1 | id)
##    Data: small_data_long (Number of observations: 200) 
## Samples: 4 chains, each with iter = 3500; warmup = 1000; thin = 1;
##          total post-warmup samples = 10000
## 
## Group-Level Effects: 
## ~id (Number of levels: 100) 
##                     Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(time)                0.33      0.21     0.02     0.75 1.00     2031     4346
## sd(sigma_Intercept)     0.12      0.09     0.00     0.32 1.00     2463     3519
## 
## Population-Level Effects: 
##                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept          -0.15      0.11    -0.37     0.07 1.00    13451     7317
## sigma_Intercept     0.11      0.06    -0.02     0.23 1.00     4612     4412
## time                1.18      0.16     0.86     1.49 1.00    12600     7054
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can see the &lt;span class=&#34;math inline&#34;&gt;\(\sigma_1\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_2\)&lt;/span&gt; summaries in the ‘Group-Level Effects’ section. It’s hard to compare them directly, because one is based on parameters in the log metric. But we can at least get a sense of what these parameters are summarizing by plotting the bivariate posterior for &lt;span class=&#34;math inline&#34;&gt;\(u_{1i}\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\log(u_{2i})\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  posterior_samples(m20) %&amp;gt;% select(starts_with(&amp;quot;r_id[&amp;quot;)) %&amp;gt;% set_names(1:100),
  posterior_samples(m20) %&amp;gt;% select(starts_with(&amp;quot;r_id__sigma&amp;quot;) %&amp;gt;% set_names(1:100))
) %&amp;gt;% 
  mutate(iter = rep(1:c(n() / 2), times = 2),
         type = rep(c(&amp;quot;slope&amp;quot;, &amp;quot;log_sigma&amp;quot;), each = n() / 2)) %&amp;gt;% 
  pivot_longer(-c(iter, type)) %&amp;gt;% 
  pivot_wider(names_from = type, values_from = value) %&amp;gt;% 
  
  ggplot(aes(x = slope, y = log_sigma, group = name)) +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, level = .01, alpha = 1/4) +
  labs(x = expression(italic(u)[1][italic(i)]),
       y = expression(log(italic(u)[2][italic(i)])))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-12-29-regression-models-for-2-timepoint-non-experimental-data/index_files/figure-html/unnamed-chunk-70-1.png&#34; width=&#34;336&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Notice how, this time, the 1% ellipses suggest no clear association between these two dimensions.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;next-steps&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Next steps&lt;/h2&gt;
&lt;p&gt;As promised, here I recommend some resources for understanding the models in this post.&lt;/p&gt;
&lt;div id=&#34;books-focusing-on-longutidinal-data-analysis.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Books focusing on longutidinal data analysis.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;My introduction to longitudinal data analysis was through Singer and Willett &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-singerAppliedLongitudinalData2003&#34; role=&#34;doc-biblioref&#34;&gt;2003&lt;/a&gt;)&lt;/span&gt;, &lt;a href=&#34;https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780195152968.001.0001/acprof-9780195152968&#34;&gt;&lt;em&gt;Applied longitudinal data analysis: Modeling change and event occurrence&lt;/em&gt;&lt;/a&gt;. Their focus was on the multilevel growth model and on survival analysis, primary from a maximum-likelihood frequentist framework. However, they generally avoided 2-timepoint data analysis.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Hoffman’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; text, &lt;a href=&#34;https://www.routledge.com/Longitudinal-Analysis-Modeling-Within-Person-Fluctuation-and-Change/Hoffman/p/book/9780415876025&#34;&gt;&lt;em&gt;Longitudinal analysis: Modeling within-person fluctuation and change&lt;/em&gt;&lt;/a&gt; is another thorough introduction to the multilevel growth model, from a frequentist perspective. Hoffman covered 2-timepoint data analysis and variants from the ANOVA family. The text comes with a companion website, &lt;a href=&#34;https://www.pilesofvariance.com/&#34;&gt;https://www.pilesofvariance.com/&lt;/a&gt;, which contains extensive data and code files for reproducing the material.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Newsom’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-newsom2015longitudinal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; text, &lt;a href=&#34;http://www.longitudinalsem.com/&#34;&gt;&lt;em&gt;Longitudinal structural equation modeling: A comprehensive introduction&lt;/em&gt;&lt;/a&gt;, covers longitudinal data analysis from a structural equation modeling (SEM) perspective. Even for those not interested in SEM, his Chapter 4 does a nice job introducing the autoregressive and change-score models. The companion website, &lt;a href=&#34;http://www.longitudinalsem.com/&#34;&gt;http://www.longitudinalsem.com/&lt;/a&gt;, contains data and script files for most of the problems in the text.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div id=&#34;books-introducing-regression.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Books introducing regression.&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Gelman, Hill, and Vehtari’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-gelmanRegressionOtherStories2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://www.cambridge.org/core/books/regression-and-other-stories/DD20DD6C9057118581076E54E40C372C&#34;&gt;&lt;em&gt;Regression and other stories&lt;/em&gt;&lt;/a&gt; contains a thorough introduction to single-level regression, primarily from a Bayesian framework. The text is not oriented around longitudinal analyses, per se, but it does include several chapters on causal inference. Vehtari hosts a GitHub repo, &lt;a href=&#34;https://github.com/avehtari/ROS-Examples&#34;&gt;https://github.com/avehtari/ROS-Examples&lt;/a&gt;, where you can download the data files and &lt;strong&gt;R&lt;/strong&gt; scripts for many of the examples.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Both editions of McElreath’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;, &lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;&lt;em&gt;Statistical rethinking: A Bayesian course with examples in R and Stan&lt;/em&gt;&lt;/a&gt; provide a thorough introduction to Bayesian regression, both single-level and multilevel. McElreath also touched on causal inference and included a few examples of longitudinal data analysis. His text includes extensive examples of &lt;strong&gt;R&lt;/strong&gt; code and his website, &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;, contains information about the accompanying statistical software.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] patchwork_1.1.1 tidybayes_2.3.1 brms_2.15.0     Rcpp_1.0.6      forcats_0.5.1   stringr_1.4.0  
##  [7] dplyr_1.0.5     purrr_0.3.4     readr_1.4.0     tidyr_1.1.3     tibble_3.1.0    ggplot2_3.3.3  
## [13] tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6           igraph_1.2.6        
##   [5] splines_4.0.4        svUnit_1.0.3         crosstalk_1.1.0.1    TH.data_1.0-10      
##   [9] rstantools_2.1.1     inline_0.3.17        digest_0.6.27        htmltools_0.5.1.1   
##  [13] rsconnect_0.8.16     fansi_0.4.2          magrittr_2.0.1       modelr_0.1.8        
##  [17] RcppParallel_5.0.2   matrixStats_0.57.0   xts_0.12.1           sandwich_3.0-0      
##  [21] prettyunits_1.1.1    colorspace_2.0-0     rvest_0.3.6          ggdist_2.4.0.9000   
##  [25] haven_2.3.1          xfun_0.22            callr_3.5.1          crayon_1.4.1        
##  [29] jsonlite_1.7.2       lme4_1.1-25          survival_3.2-10      zoo_1.8-8           
##  [33] glue_1.4.2           gtable_0.3.0         emmeans_1.5.2-1      V8_3.4.0            
##  [37] distributional_0.2.2 pkgbuild_1.2.0       rstan_2.21.2         abind_1.4-5         
##  [41] scales_1.1.1         mvtnorm_1.1-1        DBI_1.1.0            miniUI_0.1.1.1      
##  [45] xtable_1.8-4         stats4_4.0.4         StanHeaders_2.21.0-7 DT_0.16             
##  [49] htmlwidgets_1.5.2    httr_1.4.2           threejs_0.3.3        arrayhelpers_1.1-0  
##  [53] ellipsis_0.3.1       farver_2.0.3         pkgconfig_2.0.3      loo_2.4.1           
##  [57] dbplyr_2.0.0         utf8_1.1.4           labeling_0.4.2       tidyselect_1.1.0    
##  [61] rlang_0.4.10         reshape2_1.4.4       later_1.1.0.1        munsell_0.5.0       
##  [65] cellranger_1.1.0     tools_4.0.4          cli_2.3.1            generics_0.1.0      
##  [69] broom_0.7.5          ggridges_0.5.2       evaluate_0.14        fastmap_1.0.1       
##  [73] yaml_2.2.1           processx_3.4.5       knitr_1.31           fs_1.5.0            
##  [77] nlme_3.1-152         mime_0.10            projpred_2.0.2       xml2_1.3.2          
##  [81] compiler_4.0.4       bayesplot_1.8.0      shinythemes_1.1.2    rstudioapi_0.13     
##  [85] gamm4_0.2-6          curl_4.3             reprex_0.3.0         statmod_1.4.35      
##  [89] stringi_1.5.3        highr_0.8            ps_1.6.0             blogdown_1.3        
##  [93] Brobdingnag_1.2-6    lattice_0.20-41      Matrix_1.3-2         nloptr_1.2.2.2      
##  [97] markdown_1.1         shinyjs_2.0.0        vctrs_0.3.6          pillar_1.5.1        
## [101] lifecycle_1.0.0      bridgesampling_1.0-0 estimability_1.3     httpuv_1.5.4        
## [105] R6_2.5.0             bookdown_0.21        promises_1.1.1       gridExtra_2.3       
## [109] codetools_0.2-18     boot_1.3-26          colourpicker_1.1.0   MASS_7.3-53         
## [113] gtools_3.8.2         assertthat_0.2.1     withr_2.4.1          shinystan_2.5.0     
## [117] multcomp_1.4-16      mgcv_1.8-33          parallel_4.0.4       hms_0.5.3           
## [121] grid_4.0.4           coda_0.19-4          minqa_1.2.4          rmarkdown_2.7       
## [125] shiny_1.5.0          lubridate_1.7.9.2    base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-agrestiFoundationsLinearGeneralized2015&#34; class=&#34;csl-entry&#34;&gt;
Agresti, A. (2015). &lt;em&gt;Foundations of linear and generalized linear models&lt;/em&gt;. &lt;span&gt;John Wiley &amp;amp; Sons&lt;/span&gt;. &lt;a href=&#34;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&#34;&gt;https://www.wiley.com/en-us/Foundations+of+Linear+and+Generalized+Linear+Models-p-9781118730034&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Bürkner2021Distributional&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2021a). &lt;em&gt;Estimating distributional models with brms&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html&#34;&gt;https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Bürkner2021Multivariate&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2021b). &lt;em&gt;Estimating multivariate models with brms&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=brms/vignettes/brms_multivariate.html&#34;&gt;https://CRAN.R-project.org/package=brms/vignettes/brms_multivariate.html&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-Bürkner2021Non_linear&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2021c). &lt;em&gt;Estimating non-linear models with brms&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=brms/vignettes/brms_nonlinear.html&#34;&gt;https://CRAN.R-project.org/package=brms/vignettes/brms_nonlinear.html&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerBrmsPackageBayesian2017&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2017). &lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;An R&lt;/span&gt; package for &lt;span&gt;Bayesian&lt;/span&gt; multilevel models using &lt;span&gt;Stan&lt;/span&gt;. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;80&lt;/em&gt;(1), 1–28. &lt;a href=&#34;https://doi.org/10.18637/jss.v080.i01&#34;&gt;https://doi.org/10.18637/jss.v080.i01&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerAdvancedBayesianMultilevel2018&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2018). Advanced &lt;span&gt;Bayesian&lt;/span&gt; multilevel modeling with the &lt;span&gt;R&lt;/span&gt; package brms. &lt;em&gt;The R Journal&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(1), 395–411. &lt;a href=&#34;https://doi.org/10.32614/RJ-2018-017&#34;&gt;https://doi.org/10.32614/RJ-2018-017&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-brms&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;Bayesian&lt;/span&gt; regression models using ’&lt;span&gt;Stan&lt;/span&gt;’&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=brms&#34;&gt;https://CRAN.R-project.org/package=brms&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-debruineUnderstandingMixedEffects2020&#34; class=&#34;csl-entry&#34;&gt;
DeBruine, L. M., &amp;amp; Barr, D. J. (2020). &lt;em&gt;Understanding mixed effects models through data simulation&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.1177/2515245920965119&#34;&gt;https://doi.org/10.1177/2515245920965119&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelmanRegressionOtherStories2020&#34; class=&#34;csl-entry&#34;&gt;
Gelman, A., Hill, J., &amp;amp; Vehtari, A. (2020). &lt;em&gt;Regression and other stories&lt;/em&gt;. &lt;span&gt;Cambridge University Press&lt;/span&gt;. &lt;a href=&#34;https://doi.org/10.1017/9781139161879&#34;&gt;https://doi.org/10.1017/9781139161879&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hedekerApplicationMixedeffectsLocation2008&#34; class=&#34;csl-entry&#34;&gt;
Hedeker, D., Mermelstein, R. J., &amp;amp; Demirtas, H. (2008). An application of a mixed-effects location scale model for analysis of ecological momentary assessment (&lt;span&gt;EMA&lt;/span&gt;) data. &lt;em&gt;Biometrics&lt;/em&gt;, &lt;em&gt;64&lt;/em&gt;(2), 627–634. &lt;a href=&#34;https://doi.org/10.1111/j.1541-0420.2007.00924.x&#34;&gt;https://doi.org/10.1111/j.1541-0420.2007.00924.x&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hedekerModelingWithinsubjectVariance2012&#34; class=&#34;csl-entry&#34;&gt;
Hedeker, D., Mermelstein, R. J., &amp;amp; Demirtas, H. (2012). Modeling between- and within-subject variance in ecological momentary assessment (&lt;span&gt;EMA&lt;/span&gt;) data using mixed-effects location scale models. &lt;em&gt;Statistics in Medicine&lt;/em&gt;, &lt;em&gt;31&lt;/em&gt;(27). &lt;a href=&#34;https://doi.org/10.1002/sim.5338&#34;&gt;https://doi.org/10.1002/sim.5338&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hoffmanLongitudinalAnalysisModeling2015&#34; class=&#34;csl-entry&#34;&gt;
Hoffman, L. (2015). &lt;em&gt;Longitudinal analysis: &lt;span&gt;Modeling&lt;/span&gt; within-person fluctuation and change&lt;/em&gt; (1 edition). &lt;span&gt;Routledge&lt;/span&gt;. &lt;a href=&#34;https://www.routledge.com/Longitudinal-Analysis-Modeling-Within-Person-Fluctuation-and-Change/Hoffman/p/book/9780415876025&#34;&gt;https://www.routledge.com/Longitudinal-Analysis-Modeling-Within-Person-Fluctuation-and-Change/Hoffman/p/book/9780415876025&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-tidybayes&#34; class=&#34;csl-entry&#34;&gt;
Kay, M. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;tidybayes&lt;/span&gt;: &lt;span&gt;Tidy&lt;/span&gt; data and ’geoms’ for &lt;span&gt;Bayesian&lt;/span&gt; models&lt;/em&gt;. &lt;a href=&#34;https://mjskay.github.io/tidybayes/&#34;&gt;https://mjskay.github.io/tidybayes/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kisbu2013monte&#34; class=&#34;csl-entry&#34;&gt;
Kisbu-Sakarya, Y., MacKinnon, D. P., &amp;amp; Aiken, L. S. (2013). A &lt;span&gt;Monte Carlo&lt;/span&gt; comparison study of the power of the analysis of covariance, simple difference, and residual change scores in testing two-wave data. &lt;em&gt;Educational and Psychological Measurement&lt;/em&gt;, &lt;em&gt;73&lt;/em&gt;(1), 47–62. &lt;a href=&#34;https://doi.org/10.1177/0013164412450574&#34;&gt;https://doi.org/10.1177/0013164412450574&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kurzStatisticalRethinkingSecondEd2020&#34; class=&#34;csl-entry&#34;&gt;
Kurz, A. S. (2020). &lt;em&gt;Statistical rethinking with brms, Ggplot2, and the tidyverse: &lt;span&gt;Second&lt;/span&gt; edition&lt;/em&gt; (version 0.1.1). &lt;a href=&#34;https://bookdown.org/content/4857/&#34;&gt;https://bookdown.org/content/4857/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-lordStatisticalTheoriesMental1968&#34; class=&#34;csl-entry&#34;&gt;
Lord, F. M., &amp;amp; Novick, M. R. (1968). &lt;em&gt;Statistical theories of mental test scores&lt;/em&gt;. &lt;span&gt;Addison-Wesley&lt;/span&gt;.
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2020&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2020). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt; (Second Edition). &lt;span&gt;CRC Press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2015&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2015). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-newsom2015longitudinal&#34; class=&#34;csl-entry&#34;&gt;
Newsom, J. T. (2015). &lt;em&gt;Longitudinal structural equation modeling: &lt;span&gt;A&lt;/span&gt; comprehensive introduction&lt;/em&gt;. &lt;span&gt;Routledge&lt;/span&gt;. &lt;a href=&#34;http://www.longitudinalsem.com/&#34;&gt;http://www.longitudinalsem.com/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-patchwork&#34; class=&#34;csl-entry&#34;&gt;
Pedersen, T. L. (2019). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;patchwork&lt;/span&gt;: &lt;span&gt;The&lt;/span&gt; composer of plots&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=patchwork&#34;&gt;https://CRAN.R-project.org/package=patchwork&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-base&#34; class=&#34;csl-entry&#34;&gt;
R Core Team. (2020). &lt;em&gt;R: &lt;span&gt;A&lt;/span&gt; language and environment for statistical computing&lt;/em&gt;. &lt;span&gt;R Foundation for Statistical Computing&lt;/span&gt;. &lt;a href=&#34;https://www.R-project.org/&#34;&gt;https://www.R-project.org/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-rogosaGrowthCurveApproach1982&#34; class=&#34;csl-entry&#34;&gt;
Rogosa, D., Brandt, D., &amp;amp; Zimowski, M. (1982). A growth curve approach to the measurement of change. &lt;em&gt;Psychological Bulletin&lt;/em&gt;, &lt;em&gt;92&lt;/em&gt;(3), 726–748. &lt;a href=&#34;https://doi.org/10.1037/0033-2909.92.3.726&#34;&gt;https://doi.org/10.1037/0033-2909.92.3.726&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-singerAppliedLongitudinalData2003&#34; class=&#34;csl-entry&#34;&gt;
Singer, J. D., &amp;amp; Willett, J. B. (2003). &lt;em&gt;Applied longitudinal data analysis: &lt;span&gt;Modeling&lt;/span&gt; change and event occurrence&lt;/em&gt;. &lt;span&gt;Oxford University Press, USA&lt;/span&gt;. &lt;a href=&#34;https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780195152968.001.0001/acprof-9780195152968&#34;&gt;https://oxford.universitypressscholarship.com/view/10.1093/acprof:oso/9780195152968.001.0001/acprof-9780195152968&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-walkerElementsOfStatisticalModeling2018&#34; class=&#34;csl-entry&#34;&gt;
Walker, J. A. (2018). &lt;em&gt;Elements of statistical modeling for experimental biology&lt;/em&gt; (&#34;2020–11th–22&#34; ed.). &lt;a href=&#34;https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/&#34;&gt;https://www.middleprofessor.com/files/applied-biostatistics_bookdown/_book/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-tidyverse&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H. (2019). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;tidyverse&lt;/span&gt;: &lt;span&gt;Easily&lt;/span&gt; install and load the ’tidyverse’&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=tidyverse&#34;&gt;https://CRAN.R-project.org/package=tidyverse&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wickhamWelcomeTidyverse2019&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. &lt;em&gt;Journal of Open Source Software&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(43), 1686. &lt;a href=&#34;https://doi.org/10.21105/joss.01686&#34;&gt;https://doi.org/10.21105/joss.01686&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-williamsBayesianMultivariateMixedeffects2019a&#34; class=&#34;csl-entry&#34;&gt;
Williams, D. R., Liu, S., Martin, S. R., &amp;amp; Rast, P. (2019). &lt;em&gt;Bayesian multivariate mixed-effects location scale modeling of longitudinal relations among affective traits, states, and physical activity&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.31234/osf.io/4kfjp&#34;&gt;https://doi.org/10.31234/osf.io/4kfjp&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-williamsPuttingIndividualReliability2019&#34; class=&#34;csl-entry&#34;&gt;
Williams, D. R., Martin, S. R., &amp;amp; Rast, P. (2019). &lt;em&gt;Putting the individual into reliability: &lt;span&gt;Bayesian&lt;/span&gt; testing of homogeneous within-person variance in hierarchical models&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.31234/osf.io/hpq7w&#34;&gt;https://doi.org/10.31234/osf.io/hpq7w&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-williamsSurfaceUnearthingWithinperson2019&#34; class=&#34;csl-entry&#34;&gt;
Williams, D. R., Rouder, J., &amp;amp; Rast, P. (2019). &lt;em&gt;Beneath the surface: &lt;span&gt;Unearthing&lt;/span&gt; within-&lt;span&gt;Person&lt;/span&gt; variability and mean relations with &lt;span&gt;Bayesian&lt;/span&gt; mixed models&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.31234/osf.io/gwatq&#34;&gt;https://doi.org/10.31234/osf.io/gwatq&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-williamsBayesianNonlinearMixedeffects2019a&#34; class=&#34;csl-entry&#34;&gt;
Williams, D. R., Zimprich, D. R., &amp;amp; Rast, P. (2019). A &lt;span&gt;Bayesian&lt;/span&gt; nonlinear mixed-effects location scale model for learning. &lt;em&gt;Behavior Research Methods&lt;/em&gt;, &lt;em&gt;51&lt;/em&gt;(5), 1968–1986. &lt;a href=&#34;https://doi.org/10.3758/s13428-019-01255-9&#34;&gt;https://doi.org/10.3758/s13428-019-01255-9&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;Throughout this post, my statistical notation will be a blend of sensibilities from &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-singerAppliedLongitudinalData2003&#34; role=&#34;doc-biblioref&#34;&gt;Singer &amp;amp; Willett&lt;/a&gt; (&lt;a href=&#34;#ref-singerAppliedLongitudinalData2003&#34; role=&#34;doc-biblioref&#34;&gt;2003&lt;/a&gt;)&lt;/span&gt;, &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;Hoffman&lt;/a&gt; (&lt;a href=&#34;#ref-hoffmanLongitudinalAnalysisModeling2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;, and &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;McElreath&lt;/a&gt; (&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn2&#34;&gt;&lt;p&gt;Though I’m no fan of the null-hypothesis significance testing paradigm, it might be helpful to point out if one were to focus on whether zero is within the 95% interval bounds of our &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; parameter, you be viewing this model through the lens of the repeated-measures &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-test. For more on that connection, see Chapter 3 in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-newsom2015longitudinal&#34; role=&#34;doc-biblioref&#34;&gt;Newsom&lt;/a&gt; (&lt;a href=&#34;#ref-newsom2015longitudinal&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;.&lt;a href=&#34;#fnref2&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&#34;fn3&#34;&gt;&lt;p&gt;There’s some debate over how to think about the repeated measures ANOVA and what its closest multilevel analogue might be. For a nice collection of perspectives, check out &lt;a href=&#34;https://twitter.com/SolomonKurz/status/1342645143082594304&#34;&gt;this Twitter thread&lt;/a&gt;.&lt;a href=&#34;#fnref3&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian robust correlations with brms (and why you should love Student&#39;s $t$)</title>
      <link>/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/</link>
      <pubDate>Sun, 10 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/</guid>
      <description>
&lt;script src=&#34;/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;[edited Apr 21, 2021]&lt;/p&gt;
&lt;p&gt;In this post, we’ll show how Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution can produce better correlation estimates when your data have outliers. As is often the case, we’ll do so as Bayesians.&lt;/p&gt;
&lt;p&gt;This post is a direct consequence of Adrian Baez-Ortega’s great blog, “&lt;a href=&#34;https://baezortega.github.io/2018/05/28/robust-correlation/&#34;&gt;Bayesian robust correlation with Stan in R (and why you should use Bayesian methods)&lt;/a&gt;”. Baez-Ortega worked out the approach and code for direct use with &lt;a href=&#34;http://mc-stan.org&#34;&gt;Stan&lt;/a&gt; computational environment. That solution is great because Stan is free, open source, and very flexible. However, Stan’s interface might be prohibitively technical for non-statistician users. Happily, the &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms&lt;/a&gt; package allows users to access the computational power of Stan through a simpler interface. In this post, we show how to extend Baez-Ortega’s method to brms. To pay respects where they’re due, the synthetic data, priors, and other model settings are largely the same as those Baez-Ortega used in his blog.&lt;/p&gt;
&lt;div id=&#34;i-make-assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I make assumptions&lt;/h2&gt;
&lt;p&gt;For this post, I’m presuming you are vaguely familiar with linear regression, know about the basic differences between frequentist and Bayesian approaches to fitting models, and have a sense that the issue of outlier values is a pickle worth contending with. All code in is &lt;a href=&#34;https://www.r-bloggers.com/why-use-r-five-reasons/&#34;&gt;R&lt;/a&gt;, with a heavy use of the &lt;a href=&#34;http://style.tidyverse.org&#34;&gt;tidyverse&lt;/a&gt;–which you might learn a lot about &lt;a href=&#34;http://r4ds.had.co.nzhttp://r4ds.had.co.nz&#34;&gt;here, especially chapter 5&lt;/a&gt;–, and, of course, Bürkner’s &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;brms&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you’d like a warmup, consider checking out my related post, &lt;a href=&#34;https://solomonkurz.netlify.com/post/robust-linear-regression-with-the-robust-student-s-t-distribution/&#34;&gt;Robust Linear Regression with Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-Distribution&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;whats-the-deal&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What’s the deal?&lt;/h2&gt;
&lt;p&gt;Pearson’s correlations are designed to quantify the linear relationship between two normally distributed variables. The normal distribution and its multivariate generalization, the multivariate normal distribution, are sensitive to outliers. When you have well-behaved synthetic data, this isn’t an issue. But if you work real-world data, this can be a problem. One can have data for which the vast majority of cases are well-characterized by a nice liner relationship, but have a few odd cases for which that relationship does not hold. And if those odd cases happen to be overly influential–sometimes called leverage points–the resulting Pearson’s correlation coefficient might look off.&lt;/p&gt;
&lt;p&gt;Recall that the normal distribution is a special case of Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution with the &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter (i.e., &lt;em&gt;nu&lt;/em&gt;, degree of freedom) set to infinity. As it turns out, when &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; is small, Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution is more robust to multivariate outliers. It’s less influenced by them. I’m not going to cover why in any detail. For that you’ve got &lt;a href=&#34;https://baezortega.github.io/2018/05/28/robust-correlation/&#34;&gt;Baez-Ortega’s blog&lt;/a&gt;, an even earlier blog from &lt;a href=&#34;http://www.sumsar.net/blog/2013/08/bayesian-estimation-of-correlation/&#34;&gt;Rasmus Bååth&lt;/a&gt;, and textbook treatments on the topic by &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/arm/&#34;&gt;Gelman &amp;amp; Hill (2007, chapter 6)&lt;/a&gt; and &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;Kruschke (2015, chapter 16)&lt;/a&gt;. Here we’ll get a quick sense of how vulnerable Pearson’s correlations–with their reliance on the Gaussian–are to outliers, we’ll demonstrate how fitting correlations within the Bayesian paradigm using the conventional Gaussian likelihood is similarly vulnerable to distortion, and then see how Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution can save the day. And importantly, we’ll do the bulk of this with the brms package.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;we-need-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;We need data&lt;/h2&gt;
&lt;p&gt;To start off, we’ll make a multivariate normal simulated data set using the same steps Baez-Ortega’s used.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(mvtnorm)
library(tidyverse)

sigma &amp;lt;- c(20, 40)  # the variances
rho   &amp;lt;- -.95       # the desired correlation

# here&amp;#39;s the variance/covariance matrix
cov.mat &amp;lt;- 
  matrix(c(sigma[1] ^ 2,
           sigma[1] * sigma[2] * rho,
           sigma[1] * sigma[2] * rho,
           sigma[2] ^ 2),
         nrow = 2, byrow = T)

# after setting our seed, we&amp;#39;re ready to simulate with `rmvnorm()`
set.seed(210191)
x.clean &amp;lt;- 
  rmvnorm(n = 40, sigma = cov.mat) %&amp;gt;% 
  as_tibble() %&amp;gt;% 
  rename(x = V1,
         y = V2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we make our second data set, &lt;code&gt;x.noisy&lt;/code&gt;, which is identical to our well-behaved &lt;code&gt;x.clean&lt;/code&gt; data, but with the first three cases transformed to outlier values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x.noisy &amp;lt;- x.clean

x.noisy[1:3,] &amp;lt;-
  matrix(c(-40, -60,
           20, 100,
           40, 40),
         nrow = 3, byrow = T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we’ll add an &lt;code&gt;outlier&lt;/code&gt; index to the data sets, which will help us with plotting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x.clean &amp;lt;-
  x.clean %&amp;gt;% 
  mutate(outlier = factor(0))

x.noisy &amp;lt;- 
  x.noisy %&amp;gt;% 
  mutate(outlier = c(rep(1, 3), rep(0, 37)) %&amp;gt;% as.factor(.))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The plot below shows what the &lt;code&gt;x.clean&lt;/code&gt; data look like. I’m a fan of &lt;a href=&#34;http://fivethirtyeight.com&#34;&gt;FiveThirtyEight&lt;/a&gt;, so we’ll use a few convenience functions from the handy &lt;a href=&#34;https://github.com/jrnold/ggthemes&#34;&gt;ggthemes package&lt;/a&gt; to give our plots a FiveThirtyEight-like feel.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(ggthemes)

x.clean %&amp;gt;% 
  ggplot(aes(x = x, y = y, color = outlier, fill = outlier)) +
  geom_point() +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, alpha = .15, size = .15, level = .5) +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, alpha = .15, size = .15, level = .95) +
  scale_color_fivethirtyeight() +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = c(-50, 50),
                  ylim = c(-100, 100)) +
  theme_fivethirtyeight() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/index_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;312&#34; /&gt;&lt;/p&gt;
&lt;p&gt;And here are the &lt;code&gt;x.noisy&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;x.noisy %&amp;gt;% 
  ggplot(aes(x = x, y = y, color = outlier, fill = outlier)) +
  geom_point() +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, alpha = .15, size = .15, level = .5) +
  stat_ellipse(geom = &amp;quot;polygon&amp;quot;, alpha = .15, size = .15, level = .95) +
  scale_color_fivethirtyeight() +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = c(-50, 50),
                  ylim = c(-100, 100)) +
  theme_fivethirtyeight() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/index_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;312&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The three outliers are in red. Even in their presence, the old interocular trauma test suggests there is a pronounced overall trend in the data. I would like a correlation procedure that’s capable of capturing that overall trend. Let’s examine some candidates.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;how-does-old-pearson-hold-up&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How does old Pearson hold up?&lt;/h2&gt;
&lt;p&gt;A quick way to get a Pearson’s correlation coefficient in R is with the &lt;code&gt;cor()&lt;/code&gt; function, which does a nice job recovering the correlation we simulated the &lt;code&gt;x.clean&lt;/code&gt; data with:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(x.clean$x, x.clean$y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.959702&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;However, things fall apart if you use &lt;code&gt;cor()&lt;/code&gt; on the &lt;code&gt;x.noisy&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cor(x.noisy$x, x.noisy$y)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] -0.6365649&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So even though most of the &lt;code&gt;x.noisy&lt;/code&gt; data continue to show a clear strong relation, three outlier values reduced the Pearson’s correlation a third of the way toward zero. Let’s see what happens when we go Bayesian.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;bayesian-correlations-in-brms&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Bayesian correlations in brms&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/paulbuerkner&#34;&gt;Bürkner&lt;/a&gt;’s brms is a general purpose interface for fitting all manner of Bayesian regression models with &lt;a href=&#34;https://mc-stan.org&#34;&gt;Stan&lt;/a&gt; as the engine under the hood. It has popular &lt;a href=&#34;https://cran.r-project.org/web/packages/lme4/index.html&#34;&gt;lme4&lt;/a&gt;-like syntax and offers a variety of convenience functions for post processing. Let’s load it up.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;first-with-the-gaussian-likelihood.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;First with the Gaussian likelihood.&lt;/h3&gt;
&lt;p&gt;I’m not going to spend a lot of time walking through the syntax in the main brms function, &lt;code&gt;brm()&lt;/code&gt;. You can learn all about that &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;here&lt;/a&gt; or with my ebook &lt;a href=&#34;https://bookdown.org/content/3890/&#34;&gt;&lt;em&gt;Statistical Rethinking with brms, ggplot2, and the tidyverse&lt;/em&gt;&lt;/a&gt;. But our particular use of &lt;code&gt;brm()&lt;/code&gt; requires we make a few fine points.&lt;/p&gt;
&lt;p&gt;One doesn’t always think about bivariate correlations within the regression paradigm. But they work just fine. Within brms, you would typically specify the conventional Gaussian likelihood (i.e., &lt;code&gt;family = gaussian&lt;/code&gt;), use the &lt;code&gt;mvbind()&lt;/code&gt; syntax to set up a &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/vignettes/brms_multivariate.html&#34;&gt;multivariate model&lt;/a&gt;, and fit that model without predictors. For each variable specified in &lt;code&gt;cbind()&lt;/code&gt;, you’ll estimate an intercept (i.e., mean, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and sigma (i.e., &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, often called a residual variance). Since there are no predictors in the model, the residual variance is just the variance and the brms default for multivariate models is to allow the residual variances to covary. But since variances are parameterized in the standard deviation metric in brms, the residual variances and their covariance are &lt;em&gt;SD&lt;/em&gt;s and their correlation, respectively.&lt;/p&gt;
&lt;p&gt;Here’s what it looks like in practice.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f0 &amp;lt;- 
  brm(data = x.clean, 
      family = gaussian,
      bf(mvbind(x, y) ~ 1) + set_rescor(TRUE),
      prior = c(prior(normal(0, 100), class = Intercept, resp = x),
                prior(normal(0, 100), class = Intercept, resp = y),
                prior(normal(0, 100), class = sigma, resp = x),
                prior(normal(0, 100), class = sigma, resp = y),
                prior(lkj(1), class = rescor)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In a typical Bayesian workflow, you’d examine the quality of the chains with trace plots. The easy way to do that in brms is with &lt;code&gt;plot()&lt;/code&gt;. E.g., to get the trace plots for our first model, you’d code &lt;code&gt;plot(f0)&lt;/code&gt;. Happily, the trace plots look fine for all models in this post. For the sake of space, I’ll leave their inspection as exercises for interested readers.&lt;/p&gt;
&lt;p&gt;Our priors and such mirror those in Baez-Ortega’s blog. Here are the results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: x ~ 1 
##          y ~ 1 
##    Data: x.clean (Number of observations: 40) 
## Samples: 4 chains, each with iter = 2000; warmup = 500; thin = 1;
##          total post-warmup samples = 6000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## x_Intercept    -2.85      3.40    -9.28     3.81 1.00     2449     2471
## y_Intercept     3.69      6.80    -9.80    16.64 1.00     2428     2368
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_x    21.49      2.60    17.25    27.39 1.00     2051     2251
## sigma_y    43.01      5.18    34.59    54.89 1.00     2102     2226
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(x,y)    -0.95      0.02    -0.98    -0.92 1.00     2146     2715
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Way down there in the last line in the ‘Family Specific Parameters’ section we have &lt;code&gt;rescor(x,y)&lt;/code&gt;, which is our correlation. And indeed, our Gaussian intercept-only multivariate model did a great job recovering the correlation we used to simulate the &lt;code&gt;x.clean&lt;/code&gt; data with. Look at what happens when we try this approach with &lt;code&gt;x.noisy&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f1 &amp;lt;-
  update(f0,
         newdata = x.noisy,
         iter = 2000, warmup = 500, chains = 4, cores = 4, seed = 210191)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(gaussian, gaussian) 
##   Links: mu = identity; sigma = identity
##          mu = identity; sigma = identity 
## Formula: x ~ 1 
##          y ~ 1 
##    Data: x.noisy (Number of observations: 40) 
## Samples: 4 chains, each with iter = 2000; warmup = 500; thin = 1;
##          total post-warmup samples = 6000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## x_Intercept    -3.05      3.84   -10.60     4.44 1.00     4935     4170
## y_Intercept     6.71      7.59    -8.26    21.54 1.00     4832     4362
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_x    23.64      2.76    19.01    29.78 1.00     3699     3844
## sigma_y    47.17      5.54    37.86    59.66 1.00     4058     3752
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(x,y)    -0.61      0.10    -0.78    -0.39 1.00     3682     4159
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the correlation estimate is -.61. As it turns out, &lt;code&gt;data = x.noisy&lt;/code&gt; + &lt;code&gt;family = gaussian&lt;/code&gt; in &lt;code&gt;brm()&lt;/code&gt; failed us just like Pearson’s correlation failed us. Time to leave failure behind.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;now-with-students-t-distribution.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Now with Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution.&lt;/h3&gt;
&lt;p&gt;Before we jump into using &lt;code&gt;family = student&lt;/code&gt;, we should talk a bit about &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;. This is our new parameter which is silently fixed to infinity when we use the Gaussian likelihood. The &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter is bound at zero but, as discussed in Baez-Ortega’s blog, is somewhat nonsensical for values below 1. As it turns out, &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; is constrained to be equal to or greater than 1 in brms. So nothing for us to worry about, there. The &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;Stan team currently recommends the gamma(2, 0.1) prior for &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;&lt;/a&gt;, which is also the current brms default. This is what that distribution looks like.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tibble(x = seq(from = 1, to = 120, by = .5)) %&amp;gt;% 
  ggplot(aes(x = x, fill = factor(0))) +
  geom_ribbon(aes(ymin = 0, 
                  ymax = dgamma(x, 2, 0.1))) +
  scale_y_continuous(NULL, breaks = NULL) +
  scale_fill_fivethirtyeight() +
  coord_cartesian(xlim = c(0, 100)) +
  ggtitle(&amp;quot;gamma(2, 0.1)&amp;quot;) +
  theme_fivethirtyeight() +
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/index_files/figure-html/unnamed-chunk-11-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So gamma(2, 0.1) should gently push the &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; posterior toward low values, but it’s slowly-sloping right tail will allow higher values to emerge.&lt;/p&gt;
&lt;p&gt;Following the Stan team’s recommendation, the brms default and Baez-Ortega’s blog, here’s our robust Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; model for the &lt;code&gt;x.noisy&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f2 &amp;lt;- 
  brm(data = x.noisy, 
      family = student,
      bf(mvbind(x, y) ~ 1) + set_rescor(TRUE),
      prior = c(prior(gamma(2, .1), class = nu),
                prior(normal(0, 100), class = Intercept, resp = x),
                prior(normal(0, 100), class = Intercept, resp = y),
                prior(normal(0, 100), class = sigma, resp = x),
                prior(normal(0, 100), class = sigma, resp = y),
                prior(lkj(1), class = rescor)),
      iter = 2000, warmup = 500, chains = 4, cores = 4, 
      seed = 210191)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(student, student) 
##   Links: mu = identity; sigma = identity; nu = identity
##          mu = identity; sigma = identity; nu = identity 
## Formula: x ~ 1 
##          y ~ 1 
##    Data: x.noisy (Number of observations: 40) 
## Samples: 4 chains, each with iter = 2000; warmup = 500; thin = 1;
##          total post-warmup samples = 6000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## x_Intercept    -2.07      3.59    -9.49     4.72 1.00     2412     2651
## y_Intercept     1.93      7.20   -11.31    16.81 1.00     2454     2815
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_x    18.35      2.99    13.12    24.76 1.00     2313     2816
## sigma_y    36.52      5.90    26.13    49.49 1.00     2216     3225
## nu          2.65      0.99     1.36     4.99 1.00     3500     2710
## nu_x        1.00      0.00     1.00     1.00 1.00     6000     6000
## nu_y        1.00      0.00     1.00     1.00 1.00     6000     6000
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(x,y)    -0.93      0.03    -0.97    -0.85 1.00     2974     3366
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Whoa, look at that correlation, &lt;code&gt;rescore(x,y)&lt;/code&gt;! It’s right about what we’d hope for. Sure, it’s not a perfect -.95, but that’s way better than -.61.&lt;/p&gt;
&lt;p&gt;While we’re at it, we may as well see what happens when we fit a Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; model when we have perfectly multivariate normal data. Here it is with the &lt;code&gt;x.clean&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;f3 &amp;lt;- 
  update(f2,
         newdata = x.clean, 
         iter = 2000, warmup = 500, chains = 4, cores = 4, seed = 210191)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(f3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: MV(student, student) 
##   Links: mu = identity; sigma = identity; nu = identity
##          mu = identity; sigma = identity; nu = identity 
## Formula: x ~ 1 
##          y ~ 1 
##    Data: x.clean (Number of observations: 40) 
## Samples: 4 chains, each with iter = 2000; warmup = 500; thin = 1;
##          total post-warmup samples = 6000
## 
## Population-Level Effects: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## x_Intercept    -2.31      3.45    -9.10     4.41 1.00     2819     3208
## y_Intercept     2.63      6.85   -10.82    16.16 1.00     2813     2882
## 
## Family Specific Parameters: 
##         Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma_x    20.75      2.59    16.29    26.28 1.00     2504     3202
## sigma_y    41.29      5.19    32.31    52.36 1.00     2596     3424
## nu         22.63     14.11     5.42    58.63 1.00     4002     3228
## nu_x        1.00      0.00     1.00     1.00 1.00     6000     6000
## nu_y        1.00      0.00     1.00     1.00 1.00     6000     6000
## 
## Residual Correlations: 
##             Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## rescor(x,y)    -0.96      0.01    -0.98    -0.92 1.00     3147     3684
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So when you don’t need Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, it yields the right answer anyways. That’s a nice feature.&lt;/p&gt;
&lt;p&gt;We should probably compare the posteriors of the correlations across the four models. First we’ll collect the posterior samples into a tibble.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posts &amp;lt;-
  tibble(model = str_c(&amp;quot;f&amp;quot;, 0:3)) %&amp;gt;% 
  mutate(fit = map(model, get)) %&amp;gt;% 
  mutate(post = map(fit, posterior_samples)) %&amp;gt;% 
  unnest(post)

head(posts)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 11
##   model fit       b_x_Intercept b_y_Intercept sigma_x sigma_y rescor__x__y  lp__
##   &amp;lt;chr&amp;gt; &amp;lt;list&amp;gt;            &amp;lt;dbl&amp;gt;         &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;        &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 f0    &amp;lt;brmsfit&amp;gt;         -6.60        14.2      21.6    46.9       -0.968 -355.
## 2 f0    &amp;lt;brmsfit&amp;gt;         -4.85         8.20     19.5    42.5       -0.941 -353.
## 3 f0    &amp;lt;brmsfit&amp;gt;         -1.35        -0.678    19.8    37.9       -0.955 -352.
## 4 f0    &amp;lt;brmsfit&amp;gt;         -6.02         9.94     22.9    46.0       -0.963 -352.
## 5 f0    &amp;lt;brmsfit&amp;gt;         -9.25        13.8      24.9    45.6       -0.966 -355.
## 6 f0    &amp;lt;brmsfit&amp;gt;         -5.31         6.55     23.3    43.0       -0.955 -353.
## # … with 3 more variables: nu &amp;lt;dbl&amp;gt;, nu_x &amp;lt;dbl&amp;gt;, nu_y &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the posterior draws in hand, we just need to wrangle a bit before showing the correlation posteriors in a coefficient plot. To make things easier, we’ll do so with a couple convenience functions from the &lt;a href=&#34;https://github.com/mjskay/tidybayes&#34;&gt;tidybayes&lt;/a&gt; package.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidybayes)

# wrangle
posts %&amp;gt;% 
  group_by(model) %&amp;gt;% 
  median_qi(rescor__x__y, .width = c(.5, .95)) %&amp;gt;% 
  mutate(key = recode(model, 
                      f0 = &amp;quot;Gaussian likelihood with clean data&amp;quot;,
                      f1 = &amp;quot;Gaussian likelihood with noisy data&amp;quot;,
                      f2 = &amp;quot;Student likelihood with noisy data&amp;quot;,
                      f3 = &amp;quot;Student likelihood with clean data&amp;quot;),
         clean = ifelse(model %in% c(&amp;quot;f0&amp;quot;, &amp;quot;f3&amp;quot;), &amp;quot;0&amp;quot;, &amp;quot;1&amp;quot;)) %&amp;gt;%
  
  # plot
  ggplot(aes(x = rescor__x__y, xmin = .lower, xmax = .upper, y = key, 
             color = clean)) +
  geom_pointinterval() +
  scale_color_fivethirtyeight() +
  scale_x_continuous(breaks = -5:0 / 5, limits = -1:0, expand = expansion(mult = c(0, 0.05))) +
  labs(subtitle = expression(paste(&amp;quot;The posterior for &amp;quot;, rho, &amp;quot; depends on the likelihood. Why not go robust and use Student&amp;#39;s &amp;quot;, italic(t), &amp;quot;?&amp;quot;))) +
  theme_fivethirtyeight() +
  theme(axis.text.y = element_text(hjust = 0),
        legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-10-bayesian-robust-correlations-with-brms-and-why-you-should-love-student-s-t/index_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;960&#34; /&gt;&lt;/p&gt;
&lt;p&gt;From our &lt;code&gt;tidybayes::median_qi()&lt;/code&gt; code, the dots are the posterior medians, the thick inner lines the 50% intervals, and the thinner outer lines the 95% intervals. The posteriors for the &lt;code&gt;x.noisy&lt;/code&gt; data are in red and those for the &lt;code&gt;x.clean&lt;/code&gt; data are in blue. If the data are clean multivariate normal Gaussian or if they’re dirty but fit with robust Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;, everything is pretty much alright. But whoa, if you fit a correlation with a combination of &lt;code&gt;family = gaussian&lt;/code&gt; and noisy outlier-laden data, man that’s just a mess.&lt;/p&gt;
&lt;p&gt;Don’t let a few overly-influential outliers make a mess of your analyses. Try the robust Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.3.1 brms_2.15.0     Rcpp_1.0.6      ggthemes_4.2.4 
##  [5] forcats_0.5.1   stringr_1.4.0   dplyr_1.0.5     purrr_0.3.4    
##  [9] readr_1.4.0     tidyr_1.1.3     tibble_3.1.0    ggplot2_3.3.3  
## [13] tidyverse_1.3.0 mvtnorm_1.1-1  
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      Hmisc_4.4-2         
##   [4] plyr_1.8.6           igraph_1.2.6         svUnit_1.0.3        
##   [7] splines_4.0.4        crosstalk_1.1.0.1    TH.data_1.0-10      
##  [10] rstantools_2.1.1     inline_0.3.17        digest_0.6.27       
##  [13] htmltools_0.5.1.1    rsconnect_0.8.16     gdata_2.18.0        
##  [16] fansi_0.4.2          checkmate_2.0.0      magrittr_2.0.1      
##  [19] cluster_2.1.0        modelr_0.1.8         RcppParallel_5.0.2  
##  [22] matrixStats_0.57.0   xts_0.12.1           sandwich_3.0-0      
##  [25] prettyunits_1.1.1    jpeg_0.1-8.1         colorspace_2.0-0    
##  [28] rvest_0.3.6          ggdist_2.4.0.9000    haven_2.3.1         
##  [31] xfun_0.22            callr_3.5.1          crayon_1.4.1        
##  [34] jsonlite_1.7.2       lme4_1.1-25          survival_3.2-10     
##  [37] zoo_1.8-8            glue_1.4.2           gtable_0.3.0        
##  [40] emmeans_1.5.2-1      V8_3.4.0             distributional_0.2.2
##  [43] weights_1.0.1        pkgbuild_1.2.0       rstan_2.21.2        
##  [46] abind_1.4-5          scales_1.1.1         DBI_1.1.0           
##  [49] miniUI_0.1.1.1       htmlTable_2.1.0      xtable_1.8-4        
##  [52] foreign_0.8-81       Formula_1.2-4        stats4_4.0.4        
##  [55] StanHeaders_2.21.0-7 DT_0.16              htmlwidgets_1.5.2   
##  [58] httr_1.4.2           threejs_0.3.3        arrayhelpers_1.1-0  
##  [61] RColorBrewer_1.1-2   ellipsis_0.3.1       mice_3.13.0         
##  [64] pkgconfig_2.0.3      loo_2.4.1            farver_2.0.3        
##  [67] nnet_7.3-15          dbplyr_2.0.0         utf8_1.1.4          
##  [70] tidyselect_1.1.0     labeling_0.4.2       rlang_0.4.10        
##  [73] reshape2_1.4.4       later_1.1.0.1        munsell_0.5.0       
##  [76] cellranger_1.1.0     tools_4.0.4          cli_2.3.1           
##  [79] generics_0.1.0       broom_0.7.5          ggridges_0.5.2      
##  [82] evaluate_0.14        fastmap_1.0.1        yaml_2.2.1          
##  [85] processx_3.4.5       knitr_1.31           fs_1.5.0            
##  [88] nlme_3.1-152         mime_0.10            projpred_2.0.2      
##  [91] xml2_1.3.2           compiler_4.0.4       bayesplot_1.8.0     
##  [94] shinythemes_1.1.2    rstudioapi_0.13      png_0.1-7           
##  [97] gamm4_0.2-6          curl_4.3             reprex_0.3.0        
## [100] statmod_1.4.35       stringi_1.5.3        highr_0.8           
## [103] ps_1.6.0             blogdown_1.3         Brobdingnag_1.2-6   
## [106] lattice_0.20-41      Matrix_1.3-2         nloptr_1.2.2.2      
## [109] markdown_1.1         shinyjs_2.0.0        vctrs_0.3.6         
## [112] pillar_1.5.1         lifecycle_1.0.0      bridgesampling_1.0-0
## [115] estimability_1.3     data.table_1.14.0    httpuv_1.5.4        
## [118] latticeExtra_0.6-29  R6_2.5.0             bookdown_0.21       
## [121] promises_1.1.1       gridExtra_2.3        codetools_0.2-18    
## [124] boot_1.3-26          colourpicker_1.1.0   MASS_7.3-53         
## [127] gtools_3.8.2         assertthat_0.2.1     withr_2.4.1         
## [130] shinystan_2.5.0      multcomp_1.4-16      mgcv_1.8-33         
## [133] parallel_4.0.4       hms_0.5.3            rpart_4.1-15        
## [136] grid_4.0.4           coda_0.19-4          minqa_1.2.4         
## [139] rmarkdown_2.7        shiny_1.5.0          lubridate_1.7.9.2   
## [142] base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Robust Linear Regression with Student’s $t$-Distribution</title>
      <link>/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/</link>
      <pubDate>Sat, 02 Feb 2019 00:00:00 +0000</pubDate>
      <guid>/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/</guid>
      <description>
&lt;script src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;[edited Nov 30, 2020]&lt;/p&gt;
&lt;p&gt;The purpose of this post is to demonstrate the advantages of the Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution for regression with outliers, particularly within a &lt;a href=&#34;https://www.youtube.com/channel/UCNJK6_DZvcMqNSzQdEkzvzA/playlists&#34;&gt;Bayesian framework&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;i-make-assumptions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;I make assumptions&lt;/h2&gt;
&lt;p&gt;I’m presuming you are familiar with linear regression, familiar with the basic differences between frequentist and Bayesian approaches to fitting regression models, and have a sense that the issue of outlier values is a pickle worth contending with. All code in is &lt;a href=&#34;https://www.r-bloggers.com/why-use-r-five-reasons/&#34;&gt;&lt;strong&gt;R&lt;/strong&gt;&lt;/a&gt;, with a heavy use of the &lt;a href=&#34;https://style.tidyverse.org/&#34;&gt;&lt;strong&gt;tidyverse&lt;/strong&gt;&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-tidyverse&#34; role=&#34;doc-biblioref&#34;&gt;Wickham, 2019&lt;/a&gt;; &lt;a href=&#34;#ref-wickhamWelcomeTidyverse2019&#34; role=&#34;doc-biblioref&#34;&gt;Wickham et al., 2019&lt;/a&gt;)&lt;/span&gt;, about which you might learn a lot more from &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-grolemundDataScience2017&#34; role=&#34;doc-biblioref&#34;&gt;Grolemund &amp;amp; Wickham&lt;/a&gt; (&lt;a href=&#34;#ref-grolemundDataScience2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;, especially &lt;a href=&#34;https://r4ds.had.co.nz/transform.html&#34;&gt;chapter 5&lt;/a&gt;. The Bayesian models are fit with &lt;a href=&#34;https://twitter.com/paulbuerkner&#34;&gt;Paul Bürkner&lt;/a&gt;’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-burknerBrmsPackageBayesian2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;, &lt;a href=&#34;#ref-burknerAdvancedBayesianMultilevel2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;, &lt;a href=&#34;#ref-R-brms&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://github.com/paul-buerkner/brms&#34;&gt;&lt;strong&gt;brms&lt;/strong&gt; package&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;the-problem&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;The problem&lt;/h2&gt;
&lt;p&gt;Simple regression models typically use the Gaussian likelihood. Say you have some criterion variable &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, which you can reasonably describe with a mean &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and standard deviation &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;. Further, you’d like to describe &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; with a predictor &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. Using the Gaussian likelihood, we can describe the model as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{align*}
y_i &amp;amp; \sim \operatorname{Normal}(\mu_i, \sigma) \\
\mu_i &amp;amp; = \beta_0 + \beta_1 x_i.
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;With this formulation, we use &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt; to model the mean of &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;. The &lt;span class=&#34;math inline&#34;&gt;\(\beta_0\)&lt;/span&gt; parameter is the intercept of the regression model and &lt;span class=&#34;math inline&#34;&gt;\(\beta_1\)&lt;/span&gt; is its slope with respect to &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;. After accounting for &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;’s relation with &lt;span class=&#34;math inline&#34;&gt;\(x\)&lt;/span&gt;, the leftover variability in &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt; is described by &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt;, often called error or residual variance. The reason we describe the model in terms of &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; is because those are the two parameters by which we define the Normal distribution, the Gaussian likelihood.&lt;/p&gt;
&lt;p&gt;The Gaussian is a sensible default choice for many data types. You might say it works unreasonably well. Unfortunately, the normal (i.e., Gaussian) distribution is sensitive to outliers.&lt;/p&gt;
&lt;p&gt;The normal distribution is a special case of Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution with the &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter (i.e., the degree of freedom) set to infinity. However, when &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; is small, Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution is more robust to multivariate outliers. See Gelman &amp;amp; Hill &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-gelmanDataAnalysisUsing2006&#34; role=&#34;doc-biblioref&#34;&gt;2006, Chapter 6&lt;/a&gt;)&lt;/span&gt;, Kruschke &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;2015, Chapter 16&lt;/a&gt;)&lt;/span&gt;, or McElreath &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;2020, Chapter 7&lt;/a&gt;)&lt;/span&gt; for textbook treatments on the topic.&lt;/p&gt;
&lt;p&gt;In this post, we demonstrate how vulnerable the Gaussian likelihood is to outliers and then compare it to different ways of using Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-likelihood for the same data.&lt;/p&gt;
&lt;p&gt;First, we’ll get a sense of the distributions with a plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidyverse)

tibble(x = seq(from = -6, to = 6, by = .01)) %&amp;gt;% 
  expand(x, nu = c(1, 2.5, 5, 10, Inf)) %&amp;gt;% 
  mutate(density = dt(x = x, df = nu),
         nu      = factor(nu, levels = c(&amp;quot;Inf&amp;quot;, &amp;quot;10&amp;quot;, &amp;quot;5&amp;quot;, &amp;quot;2.5&amp;quot;, &amp;quot;1&amp;quot;))) %&amp;gt;% 
  
  ggplot(aes(x = x, y = density, group = nu, color = nu)) +
  geom_line() +
  scale_color_viridis_d(expression(nu),
                        direction = 1, option = &amp;quot;C&amp;quot;, end = .85) +
  scale_y_continuous(NULL, breaks = NULL) +
  coord_cartesian(xlim = c(-5, 5)) +
  xlab(NULL) +
  theme(panel.grid = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-1-1.png&#34; width=&#34;528&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So the difference is that a Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution with a low &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; will have notably heavier tails than the conventional Gaussian distribution. It’s easiest to see the difference when &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; approaches 1. Even then, the difference can be subtle when looking at a plot. Another way is to compare how probable relatively extreme values are in a Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution relative to the Gaussian. For the sake of demonstration, here we’ll compare Gauss with Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; with a &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; of 5. In the plot above, they are clearly different, but not shockingly so. However, that difference is very notable in the tails.&lt;/p&gt;
&lt;p&gt;Let’s look more closely with a table. Below, we compare the probability of a given &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;-score or lower within the Gaussian and a &lt;span class=&#34;math inline&#34;&gt;\(\nu = 5\)&lt;/span&gt; Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;. In the rightmost column, we compare the probabilities in a ratio.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# here we pic our nu
nu &amp;lt;- 5

tibble(z_score               = 0:-5,
       p_Gauss               = pnorm(z_score, mean = 0, sd = 1),
       p_Student_t           = pt(z_score, df = nu),
       `Student/Gauss ratio` = p_Student_t/p_Gauss) %&amp;gt;%
  mutate_if(is.double, round, digits = 5) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;right&#34;&gt;z_score&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p_Gauss&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;p_Student_t&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Student/Gauss ratio&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.50000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.50000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.00000&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.15866&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.18161&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.14468&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-2&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.02275&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.05097&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.24042&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-3&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00135&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.01505&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.14871&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00003&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00516&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;162.97775&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;right&#34;&gt;-5&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00000&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00205&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7159.76534&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Note how low &lt;span class=&#34;math inline&#34;&gt;\(z\)&lt;/span&gt;-scores are more probable in this Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; than in the Gaussian. This is most apparent in the &lt;code&gt;Student/Gauss ratio&lt;/code&gt; column on the right. A consequence of this is that extreme scores are less influential to your solutions when you use a small-&lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution in place of the Gaussian. That is, the small-&lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; is more robust than the Gaussian to unusual and otherwise influential observations.&lt;/p&gt;
&lt;p&gt;In order to demonstrate, let’s simulate our own. We’ll start by creating multivariate normal data.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-create-our-initial-tibble-of-well-behaved-data-d&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let’s create our initial &lt;a href=&#34;https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html&#34;&gt;tibble&lt;/a&gt; of well-behaved data, &lt;code&gt;d&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;First, we’ll need to define our variance/covariance matrix.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;s &amp;lt;- matrix(c(1, .6, 
              .6, 1), 
             nrow = 2, ncol = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;By the two &lt;code&gt;.6&lt;/code&gt;s on the off-diagonal positions, we indicated we’d like our two variables to have a correlation of .6.&lt;/p&gt;
&lt;p&gt;Second, our variables also need means, which we’ll define with a mean vector.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;m &amp;lt;- c(0, 0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With means of &lt;code&gt;0&lt;/code&gt; and variances of &lt;code&gt;1&lt;/code&gt;, our data are in a standardized metric.&lt;/p&gt;
&lt;p&gt;Third, we’ll use the &lt;code&gt;mvrnorm()&lt;/code&gt; function from the &lt;a href=&#34;https://CRAN.R-project.org/package=MASS&#34;&gt;&lt;strong&gt;MASS&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-MASS&#34; role=&#34;doc-biblioref&#34;&gt;Ripley, 2019&lt;/a&gt;)&lt;/span&gt; to simulate our data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(3)

d &amp;lt;- MASS::mvrnorm(n = 100, mu = m, Sigma = s) %&amp;gt;%
  as_tibble() %&amp;gt;%
  rename(y = V1, x = V2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first few rows look like so:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;head(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##         y      x
##     &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1 -1.14   -0.584
## 2 -0.0805 -0.443
## 3 -0.239   0.702
## 4 -1.30   -0.761
## 5 -0.280   0.630
## 6 -0.245   0.299&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As an aside, check out &lt;a href=&#34;https://www.r-bloggers.com/creating-sample-datasets-exercises/&#34;&gt;this nice r-bloggers post&lt;/a&gt; for more information on simulating data with this method.&lt;/p&gt;
&lt;p&gt;Anyway, this line reorders our data by &lt;code&gt;x&lt;/code&gt;, placing the smallest values on top.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;d &amp;lt;-
  d %&amp;gt;%
  arrange(x)

head(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##        y     x
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 -2.21  -1.84
## 2 -1.27  -1.71
## 3 -0.168 -1.60
## 4 -0.292 -1.46
## 5 -0.785 -1.40
## 6 -0.157 -1.37&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-create-our-outlier-tibble-o&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Let’s create our outlier tibble, &lt;code&gt;o&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;Here we’ll make two outlying and unduly influential values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;o &amp;lt;- d
o[c(1:2), 1] &amp;lt;- c(5, 4.5)

head(o)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##        y     x
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1  5     -1.84
## 2  4.5   -1.71
## 3 -0.168 -1.60
## 4 -0.292 -1.46
## 5 -0.785 -1.40
## 6 -0.157 -1.37&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With the code, above, we replaced the first two values of our first variable, &lt;code&gt;y&lt;/code&gt;. They both started out quite negative. Now they are positive values of a large magnitude within the standardized metric.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;frequentist-ols-models&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Frequentist &lt;a href=&#34;https://en.wikipedia.org/wiki/Ordinary_least_squares&#34;&gt;OLS&lt;/a&gt; models&lt;/h2&gt;
&lt;p&gt;To get a quick sense of what we’ve done, we’ll first fit two models with OLS regression via the &lt;code&gt;lm()&lt;/code&gt; function. The first model, &lt;code&gt;ols0&lt;/code&gt;, is of the multivariate normal data, &lt;code&gt;d&lt;/code&gt;. The second model, &lt;code&gt;ols1&lt;/code&gt;, is on the otherwise identical data with the two odd and influential values, &lt;code&gt;o&lt;/code&gt;. Here is our model code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ols0 &amp;lt;- lm(data = d, y ~ 1 + x)
ols1 &amp;lt;- lm(data = o, y ~ 1 + x)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll use the &lt;a href=&#34;https://cran.r-project.org/web/packages/broom/index.html&#34;&gt;&lt;strong&gt;broom&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-broom&#34; role=&#34;doc-biblioref&#34;&gt;Robinson &amp;amp; Hayes, 2020&lt;/a&gt;)&lt;/span&gt; to assist with model summaries and other things. Here are the parameter estimates for the first model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(broom)

tidy(ols0) %&amp;gt;% mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 5
##   term        estimate std.error statistic p.value
##   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 (Intercept)    -0.01      0.09     -0.08    0.94
## 2 x               0.45      0.1       4.55    0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And now the parameters for the second model, the one based on the &lt;code&gt;o&lt;/code&gt; outlier data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy(ols1) %&amp;gt;% mutate_if(is.double, round, digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 5
##   term        estimate std.error statistic p.value
##   &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 (Intercept)     0.13      0.11      1.15    0.25
## 2 x               0.14      0.13      1.1     0.27&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just two odd and influential values dramatically changed the model parameters, particularly the slope. Let’s plot the data and the models to get a visual sense of what happened.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# the well-behaved data
p1 &amp;lt;-
  ggplot(data = d, aes(x = x, y = y)) +
  stat_smooth(method = &amp;quot;lm&amp;quot;, color = &amp;quot;grey92&amp;quot;, fill = &amp;quot;grey67&amp;quot;, alpha = 1, fullrange = T) +
  geom_point(size = 1, alpha = 3/4) +
  scale_x_continuous(limits = c(-4, 4)) +
  coord_cartesian(xlim = c(-3, 3), 
                  ylim = c(-3, 5)) +
  labs(title = &amp;quot;No Outliers&amp;quot;) +
  theme(panel.grid = element_blank())

# the data with two outliers
p2 &amp;lt;-
  ggplot(data = o, aes(x = x, y = y, color = y &amp;gt; 3)) +
  stat_smooth(method = &amp;quot;lm&amp;quot;, color = &amp;quot;grey92&amp;quot;, fill = &amp;quot;grey67&amp;quot;, alpha = 1, fullrange = T) +
  geom_point(size = 1, alpha = 3/4) +
  scale_color_viridis_d(option = &amp;quot;A&amp;quot;, end = 4/7) +
  scale_x_continuous(limits = c(-4, 4)) +
  coord_cartesian(xlim = c(-3, 3), 
                  ylim = c(-3, 5)) +
  labs(title = &amp;quot;Two Outliers&amp;quot;) +
  theme(panel.grid = element_blank(),
        legend.position = &amp;quot;none&amp;quot;)

# combine the ggplots with patchwork syntax
library(patchwork)

p1 + p2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;648&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The two outliers were quite influential on the slope. It went from a nice clear diagonal to almost horizontal. You’ll also note how the 95% intervals (i.e., the bowtie shapes) were a bit wider when based on the &lt;code&gt;o&lt;/code&gt; data.&lt;/p&gt;
&lt;p&gt;One of the popular ways to quantify outlier status is with Mahalanobis’ distance. However, the Mahalanobis distance is primarily valid for multivariate normal data. Though the data in this example are indeed multivariate normal–or at least they were before we injected two outlying values into them–I am going to resist relying on Mahalanobis’ distance. There are other more general approaches that will be of greater use when you need to explore other variants of the generalized linear model. The &lt;code&gt;broom::augment()&lt;/code&gt; function will give us access to one.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;aug0 &amp;lt;- augment(ols0)
aug1 &amp;lt;- augment(ols1)

glimpse(aug1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 100
## Columns: 8
## $ y          &amp;lt;dbl&amp;gt; 5.00000000, 4.50000000, -0.16783167, -0.29164105, -0.784918…
## $ x          &amp;lt;dbl&amp;gt; -1.8439208, -1.7071418, -1.5996509, -1.4601550, -1.3954395,…
## $ .fitted    &amp;lt;dbl&amp;gt; -0.129991947, -0.110805943, -0.095728191, -0.076161086, -0.…
## $ .resid     &amp;lt;dbl&amp;gt; 5.12999195, 4.61080594, -0.07210348, -0.21547996, -0.717835…
## $ .hat       &amp;lt;dbl&amp;gt; 0.05521164, 0.04881414, 0.04412882, 0.03849763, 0.03605748,…
## $ .sigma     &amp;lt;dbl&amp;gt; 0.9887858, 1.0170749, 1.1246348, 1.1244384, 1.1222070, 1.12…
## $ .cooksd    &amp;lt;dbl&amp;gt; 6.500952e-01, 4.580898e-01, 1.002809e-04, 7.721988e-04, 7.9…
## $ .std.resid &amp;lt;dbl&amp;gt; 4.71688666, 4.22522826, -0.06591171, -0.19639831, -0.653439…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we can compare the observations with Cook’s distance, &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; (i.e., &lt;code&gt;.cooksd&lt;/code&gt;). Cook’s &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; is a measure of the influence of a given observation on the model. To compute &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt;, the model is fit once for each &lt;span class=&#34;math inline&#34;&gt;\(n\)&lt;/span&gt; case, after first dropping that case. Then the difference in the model with all observations and the model with all observations but the &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;th observation, as defined by the Euclidean distance between the estimators. Fahrmeir et al &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-fahrmeirRegressionModelsMethods2013&#34; role=&#34;doc-biblioref&#34;&gt;2013, p. 166&lt;/a&gt;)&lt;/span&gt; suggest that within the OLS framework “as a rule of thumb, observations with &lt;span class=&#34;math inline&#34;&gt;\(D_i &amp;gt; 0.5\)&lt;/span&gt; are worthy of attention, and observations with &lt;span class=&#34;math inline&#34;&gt;\(D_i &amp;gt; 1\)&lt;/span&gt; should always be examined.” Here we plot &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; against our observation index, &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, for both models.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bind_rows(
  aug0 %&amp;gt;% mutate(i = 1:n()),  # the well-behaved data
  aug1 %&amp;gt;% mutate(i = 1:n())   # the data with two outliers
) %&amp;gt;%
  mutate(fit = rep(c(&amp;quot;fit b0&amp;quot;, &amp;quot;fit b1&amp;quot;), each = n()/2)) %&amp;gt;%
  ggplot(aes(x = i, y = .cooksd)) +
  geom_hline(yintercept = .5, color = &amp;quot;white&amp;quot;) +
  geom_point(alpha = .5) +
  geom_text(data = tibble(i = 46, 
                          .cooksd = .53,
                          fit = &amp;quot;fit b0&amp;quot;),
            label = &amp;quot;Fahrmeir et al said we might worry around here&amp;quot;,
            color = &amp;quot;grey50&amp;quot;) +
  coord_cartesian(ylim = c(0, .7)) +
  theme(panel.grid = element_blank(),
        axis.title.x = element_text(face = &amp;quot;italic&amp;quot;, family = &amp;quot;Times&amp;quot;)) +
    facet_wrap(~ fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-14-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For the model of the well-behaved data, &lt;code&gt;ols0&lt;/code&gt;, we have &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; values all hovering near zero. However, the plot for &lt;code&gt;ols1&lt;/code&gt; shows one &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt; value well above the 0.5 level and another not quite that high but deviant relative to the rest. Our two outlier values look quite influential for the results of &lt;code&gt;ols1&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;switch-to-a-bayesian-framework&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Switch to a Bayesian framework&lt;/h2&gt;
&lt;p&gt;It’s time to fire up &lt;strong&gt;brms&lt;/strong&gt;, the package with which we’ll be fitting our Bayesian models. As with all Bayesian models, we’ll need to us use priors. To keep things simple, we’ll use weakly-regularizing priors of the sort &lt;a href=&#34;https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations&#34;&gt;discussed by the Stan team&lt;/a&gt;. For more thoughts on how to set priors, check out Kruschke’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kruschkeDoingBayesianData2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; text or either edition of McElreath’s text &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;, &lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;div id=&#34;stick-with-gauss.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Stick with Gauss.&lt;/h3&gt;
&lt;p&gt;For our first two Bayesian models, &lt;code&gt;b0&lt;/code&gt; and &lt;code&gt;b1&lt;/code&gt;, we’ll use the conventional Gaussian likelihood (i.e., &lt;code&gt;family = gaussian&lt;/code&gt; in the &lt;code&gt;brm()&lt;/code&gt; function). Like with &lt;code&gt;ols0&lt;/code&gt;, above, the first model is based on the nice &lt;code&gt;d&lt;/code&gt; data. The second, &lt;code&gt;b1&lt;/code&gt;, is based on the more-difficult &lt;code&gt;o&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b0 &amp;lt;- 
  brm(data = d, 
      family = gaussian,
      y ~ 1 + x,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(cauchy(0, 1),  class = sigma)),
      seed = 1)
b1 &amp;lt;- 
  update(b0, 
         newdata = o,
         seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the model summaries.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_summary(b0)[1:3, ] %&amp;gt;% round(digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate Est.Error  Q2.5 Q97.5
## b_Intercept    -0.01      0.09 -0.18  0.16
## b_x             0.44      0.10  0.25  0.64
## sigma           0.86      0.06  0.75  0.99&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_summary(b1)[1:3, ] %&amp;gt;% round(digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate Est.Error  Q2.5 Q97.5
## b_Intercept     0.13      0.11 -0.09  0.35
## b_x             0.14      0.13 -0.11  0.40
## sigma           1.13      0.08  0.98  1.29&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We summarized our model parameters with &lt;code&gt;brms::posterior_summary()&lt;/code&gt; rather than &lt;code&gt;broom::tid()&lt;/code&gt;. Otherwise, these should look familiar. They’re very much like the results from the OLS models. Hopefully this isn’t surprising. Our priors were quite weak, so there’s no reason to suspect the results would differ much.&lt;/p&gt;
&lt;div id=&#34;the-loo-and-other-goodies-help-with-diagnostics.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;The LOO and other goodies help with diagnostics.&lt;/h4&gt;
&lt;p&gt;With the &lt;code&gt;loo()&lt;/code&gt; function, we’ll extract loo objects, which contain some handy output.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_b0 &amp;lt;- loo(b0)
loo_b1 &amp;lt;- loo(b1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ll use &lt;code&gt;str()&lt;/code&gt; to get a sense of what’s all in there, using &lt;code&gt;loo_b1&lt;/code&gt; as an example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;str(loo_b1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## List of 10
##  $ estimates  : num [1:3, 1:2] -157.41 6.65 314.81 15.76 3.75 ...
##   ..- attr(*, &amp;quot;dimnames&amp;quot;)=List of 2
##   .. ..$ : chr [1:3] &amp;quot;elpd_loo&amp;quot; &amp;quot;p_loo&amp;quot; &amp;quot;looic&amp;quot;
##   .. ..$ : chr [1:2] &amp;quot;Estimate&amp;quot; &amp;quot;SE&amp;quot;
##  $ pointwise  : num [1:100, 1:5] -13.47 -10.79 -1.06 -1.08 -1.27 ...
##   ..- attr(*, &amp;quot;dimnames&amp;quot;)=List of 2
##   .. ..$ : NULL
##   .. ..$ : chr [1:5] &amp;quot;elpd_loo&amp;quot; &amp;quot;mcse_elpd_loo&amp;quot; &amp;quot;p_loo&amp;quot; &amp;quot;looic&amp;quot; ...
##  $ diagnostics:List of 2
##   ..$ pareto_k: num [1:100] 0.8171 0.6003 0.0139 -0.0705 -0.0817 ...
##   ..$ n_eff   : num [1:100] 71.1 186.8 2553.2 2795.7 3845.7 ...
##  $ psis_object: NULL
##  $ elpd_loo   : num -157
##  $ p_loo      : num 6.65
##  $ looic      : num 315
##  $ se_elpd_loo: num 15.8
##  $ se_p_loo   : num 3.75
##  $ se_looic   : num 31.5
##  - attr(*, &amp;quot;dims&amp;quot;)= int [1:2] 4000 100
##  - attr(*, &amp;quot;class&amp;quot;)= chr [1:3] &amp;quot;psis_loo&amp;quot; &amp;quot;importance_sampling_loo&amp;quot; &amp;quot;loo&amp;quot;
##  - attr(*, &amp;quot;yhash&amp;quot;)= chr &amp;quot;b52ef230de67f0bebc3480da360987ee2c0f4de8&amp;quot;
##  - attr(*, &amp;quot;model_name&amp;quot;)= chr &amp;quot;b1&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For a detailed explanation of all those elements, see the &lt;a href=&#34;https://CRAN.R-project.org/package=loo/loo.pdf&#34;&gt;&lt;strong&gt;loo&lt;/strong&gt; reference manual&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-loo2020RM&#34; role=&#34;doc-biblioref&#34;&gt;Vehtari et al., 2020&lt;/a&gt;)&lt;/span&gt;. For our purposes, we’ll focus on the &lt;code&gt;pareto_k&lt;/code&gt;. Here’s a glimpse of what it contains for the &lt;code&gt;b1&lt;/code&gt; model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_b1$diagnostics$pareto_k %&amp;gt;% as_tibble()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 100 x 1
##       value
##       &amp;lt;dbl&amp;gt;
##  1  0.817  
##  2  0.600  
##  3  0.0139 
##  4 -0.0705 
##  5 -0.0817 
##  6 -0.00611
##  7  0.0431 
##  8  0.00514
##  9  0.111  
## 10  0.0629 
## # … with 90 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We’ve got us a numeric vector of as many values as our data had observations–100 in this case. The &lt;code&gt;pareto_k&lt;/code&gt; values can be used to examine overly-influential cases. See, for example &lt;a href=&#34;https://stackoverflow.com/questions/39578834/linear-model-diagnostics-for-bayesian-models-using-rstan/39595436&#34;&gt;this discussion on stackoverflow.com&lt;/a&gt; in which several members of the &lt;a href=&#34;http://mc-stan.org&#34;&gt;Stan team&lt;/a&gt; weighed in. The issue is also discussed in &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-vehtariPracticalBayesianModel2017&#34; role=&#34;doc-biblioref&#34;&gt;Vehtari et al.&lt;/a&gt; (&lt;a href=&#34;#ref-vehtariPracticalBayesianModel2017&#34; role=&#34;doc-biblioref&#34;&gt;2017&lt;/a&gt;)&lt;/span&gt;, in the &lt;a href=&#34;https://CRAN.R-project.org/package=loo/loo.pdf&#34;&gt;&lt;strong&gt;loo&lt;/strong&gt; reference manual&lt;/a&gt;, and in &lt;a href=&#34;https://www.youtube.com/watch?v=FUROJM3u5HQ&amp;amp;feature=youtu.be&amp;amp;a=&#34;&gt;this presentation by Aki Vehtari&lt;/a&gt;, himself. If we explicitly open the &lt;a href=&#34;https://CRAN.R-project.org/package=loo&#34;&gt;&lt;strong&gt;loo&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-loo&#34; role=&#34;doc-biblioref&#34;&gt;Vehtari et al., 2019&lt;/a&gt;)&lt;/span&gt;, we can use a few convenience functions to leverage &lt;code&gt;pareto_k&lt;/code&gt; for diagnostic purposes. The &lt;code&gt;pareto_k_table()&lt;/code&gt; function will categorize the &lt;code&gt;pareto_k&lt;/code&gt; values and give us a sense of how many values are in problematic ranges.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(loo)

pareto_k_table(loo_b1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Pareto k diagnostic values:
##                          Count Pct.    Min. n_eff
## (-Inf, 0.5]   (good)     98    98.0%   2439      
##  (0.5, 0.7]   (ok)        1     1.0%   187       
##    (0.7, 1]   (bad)       1     1.0%   71        
##    (1, Inf)   (very bad)  0     0.0%   &amp;lt;NA&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Happily, most of our cases were in the “good” range. One pesky case was in the “bad” range [can you guess which one?] and another case was only “ok” [and can you guess that one, too?]. The &lt;code&gt;pareto_k_ids()&lt;/code&gt; function will tell exactly us which cases we’ll want to look at.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;pareto_k_ids(loo_b1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1 2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Those numbers correspond to the row numbers in the data, &lt;code&gt;o&lt;/code&gt;. These are exactly the cases that plagued our second OLS model, &lt;code&gt;fit1&lt;/code&gt;, and are also the ones we hand coded to be outliers. With the simple &lt;code&gt;plot()&lt;/code&gt; function, we can get a diagnostic plot for the &lt;code&gt;pareto_k&lt;/code&gt; values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;plot(loo_b1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-21-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There they are, cases 1 and 2, lurking in the “bad” and “[just] ok” ranges. We can also make a similar plot with &lt;strong&gt;ggplot2&lt;/strong&gt;. Though it takes a little more work, &lt;strong&gt;ggplot2&lt;/strong&gt; makes it easy to compare &lt;code&gt;pareto_k&lt;/code&gt; plots across models with a little faceting.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# for the annotation
text &amp;lt;-
  tibble(i     = 1, 
         k     = c(.45, .65, .95),
         label = c(&amp;quot;good&amp;quot;, &amp;quot;[just] ok&amp;quot;, &amp;quot;bad&amp;quot;),
         fit   = &amp;quot;fit b0&amp;quot;)

# extract the diagnostics
tibble(k   = c(loo_b0$diagnostics$pareto_k, loo_b1$diagnostics$pareto_k),
       i   = rep(1:100, times = 2),
       fit = rep(str_c(&amp;quot;fit b&amp;quot;, 0:1), each = 100)) %&amp;gt;%
  
  # plot!
  ggplot(aes(x = i, y = k)) +
  geom_hline(yintercept = c(.5, .7, 1), color = &amp;quot;white&amp;quot;) +
  geom_point(alpha = .5) +
  geom_text(data = text,
            aes(label = label),
            color = &amp;quot;grey50&amp;quot;, hjust = 0) +
  scale_y_continuous(expression(Pareto~italic(k)), breaks = c(0, .5, .7, 1)) +
  theme(panel.grid = element_blank(),
        axis.title.x = element_text(face = &amp;quot;italic&amp;quot;, family = &amp;quot;Times&amp;quot;)) +
  facet_wrap(~ fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-22-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So with &lt;code&gt;b0&lt;/code&gt;–the model based on the well-behaved multivariate normal data, &lt;code&gt;d&lt;/code&gt;–, all the &lt;code&gt;pareto_k&lt;/code&gt; values hovered around zero in the “good” range. Things got concerning with model &lt;code&gt;b1&lt;/code&gt;. But we know all that. Let’s move forward.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;what-do-we-do-with-those-overly-influential-outlying-values&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;What do we do with those overly-influential outlying values?&lt;/h4&gt;
&lt;p&gt;A typical way to handle outlying values is to delete them based on some criterion, such as the Mahalanobis distance, Cook’s &lt;span class=&#34;math inline&#34;&gt;\(D_i\)&lt;/span&gt;, or our new friend the &lt;code&gt;pareto_k&lt;/code&gt;. In our next two models, we’ll do that. In our &lt;code&gt;data&lt;/code&gt; arguments, we can use the &lt;code&gt;slice()&lt;/code&gt; function to omit cases. In model &lt;code&gt;b1.1&lt;/code&gt;, we simply omit the first and most influential case. In model &lt;code&gt;b1.2&lt;/code&gt;, we omitted both unduly-influential cases, the values from rows 1 and 2.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b1.1 &amp;lt;- 
  update(b1, 
         newdata = o %&amp;gt;% slice(2:100),
         seed = 1)
b1.2 &amp;lt;- 
  update(b1, 
         newdata = o %&amp;gt;% slice(3:100),
         seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the summaries for our models based on the &lt;code&gt;slice[d]&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_summary(b1.1)[1:3, ] %&amp;gt;% round(digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate Est.Error  Q2.5 Q97.5
## b_Intercept     0.07      0.10 -0.12  0.27
## b_x             0.27      0.12  0.04  0.50
## sigma           1.00      0.07  0.87  1.15&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_summary(b1.2)[1:3, ] %&amp;gt;% round(digits = 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Estimate Est.Error  Q2.5 Q97.5
## b_Intercept     0.01      0.09 -0.16  0.19
## b_x             0.39      0.10  0.19  0.59
## sigma           0.86      0.06  0.75  0.99&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;They are closer to the true data generating model (i.e., the code we used to make &lt;code&gt;d&lt;/code&gt;), especially &lt;code&gt;b1.2&lt;/code&gt;. However, there are other ways to handle the influential cases without dropping them. Finally, we’re ready to switch to Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;time-to-leave-gauss-for-the-more-general-students-t&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Time to leave Gauss for the more general Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Recall that the normal distribution is equivalent to a Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; with the degrees of freedom parameter, &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;, set to infinity. That is, &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; is fixed. Here we’ll relax that assumption and estimate &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; from the data just like we estimate &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; with the linear model and &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; as the residual spread. Since &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;’s now a parameter, we’ll have to give it a prior. For our first Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; model, we’ll estimate &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; with the &lt;strong&gt;brms&lt;/strong&gt; default &lt;code&gt;gamma(2, 0.1)&lt;/code&gt; prior.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b2 &amp;lt;- 
  brm(data = o, family = student,
      y ~ 1 + x,
      prior = c(prior(normal(0, 10), class = Intercept),
                prior(normal(0, 10), class = b),
                prior(gamma(2, 0.1), class = nu),
                prior(cauchy(0, 1),  class = sigma)),
      seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For the next model, we’ll switch out that weak &lt;code&gt;gamma(2, 0.1)&lt;/code&gt; for a stronger &lt;code&gt;gamma(4, 1)&lt;/code&gt;. In some disciplines, the gamma distribution is something of an exotic bird. So before fitting the model, it might be useful to take a peek at what these gamma priors looks like. In the plot, below, the orange density in the background is the default &lt;code&gt;gamma(2, 0.1)&lt;/code&gt; and the purple density in the foreground is the stronger &lt;code&gt;gamma(4, 1)&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# data
tibble(x = seq(from = 0, to = 60, by = .1)) %&amp;gt;% 
  expand(x, nesting(alpha = c(2, 4), 
                    beta  = c(0.1, 1))) %&amp;gt;% 
  mutate(density = dgamma(x, alpha, beta),
         group   = rep(letters[1:2], times = n() / 2)) %&amp;gt;% 
  
  # plot
  ggplot(aes(x = x, ymin = 0, ymax = density, 
             group = group, fill = group)) +
  geom_ribbon(size = 0, alpha = 3/4) +
  scale_fill_viridis_d(option = &amp;quot;B&amp;quot;, direction = -1, 
                       begin = 1/3, end = 2/3) +
  scale_x_continuous(expand = expansion(mult = c(0, 0.05))) +
  scale_y_continuous(NULL, breaks = NULL) +
  coord_cartesian(xlim = c(0, 50)) +
  theme(panel.grid = element_blank(),
        legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-24-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So the default prior is centered around values in the 2 to 30 range, but has a long gentle-sloping tail, allowing the model to yield much larger values for &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;, as needed. The prior we use below is almost entirely concentrated in the single-digit range. In this case, that will preference Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; likelihoods with very small &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameters and correspondingly thick tails–easily allowing for extreme values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b3 &amp;lt;- 
  update(b2,
         prior = c(prior(normal(0, 10), class = Intercept),
                   prior(normal(0, 10), class = b),
                   prior(gamma(4, 1),   class = nu),
                   prior(cauchy(0, 1),  class = sigma)),
         seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For our final model, we’ll fix the &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter in a &lt;code&gt;bf()&lt;/code&gt; statement.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b4 &amp;lt;-
  brm(data = o, family = student,
      bf(y ~ 1 + x, nu = 4),
      prior = c(prior(normal(0, 100), class = Intercept),
                prior(normal(0, 10),  class = b),
                prior(cauchy(0, 1),   class = sigma)),
         seed = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we’ve got all those models, we can gather their results into a single tibble.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b_estimates &amp;lt;-
  tibble(model = c(&amp;quot;b0&amp;quot;, &amp;quot;b1&amp;quot;, &amp;quot;b1.1&amp;quot;, &amp;quot;b1.2&amp;quot;, &amp;quot;b2&amp;quot;, &amp;quot;b3&amp;quot;, &amp;quot;b4&amp;quot;)) %&amp;gt;% 
  mutate(fit = map(model, get)) %&amp;gt;% 
  mutate(posterior_summary = map(fit, ~posterior_summary(.) %&amp;gt;% 
                                   data.frame() %&amp;gt;% 
                                   rownames_to_column(&amp;quot;term&amp;quot;))) %&amp;gt;% 
  unnest(posterior_summary) %&amp;gt;% 
  select(-fit) %&amp;gt;% 
  filter(term %in% c(&amp;quot;b_Intercept&amp;quot;, &amp;quot;b_x&amp;quot;)) %&amp;gt;%
  arrange(term)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get a sense of what we’ve done, let’s take a peek at our models tibble.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b_estimates %&amp;gt;%
  mutate_if(is.double, round, digits = 2)  # this is just to round the numbers&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 14 x 6
##    model term        Estimate Est.Error  Q2.5 Q97.5
##    &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
##  1 b0    b_Intercept    -0.01      0.09 -0.18 0.16 
##  2 b1    b_Intercept     0.13      0.11 -0.09 0.35 
##  3 b1.1  b_Intercept     0.07      0.1  -0.12 0.27 
##  4 b1.2  b_Intercept     0.01      0.09 -0.16 0.19 
##  5 b2    b_Intercept     0.04      0.09 -0.14 0.23 
##  6 b3    b_Intercept     0.04      0.09 -0.14 0.22 
##  7 b4    b_Intercept     0.04      0.09 -0.14 0.22 
##  8 b0    b_x             0.44      0.1   0.25 0.64 
##  9 b1    b_x             0.14      0.13 -0.11 0.4  
## 10 b1.1  b_x             0.27      0.12  0.04 0.5  
## 11 b1.2  b_x             0.39      0.1   0.19 0.59 
## 12 b2    b_x             0.36      0.11  0.15 0.56 
## 13 b3    b_x             0.36      0.1   0.16 0.56 
## 14 b4    b_x             0.37      0.11  0.16 0.580&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The models differ by their intercepts, slopes, sigmas, and &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt;s. For the sake of this post, we’ll focus on the slopes. Here we compare the different Bayesian models’ slopes by their posterior means and 95% intervals in a coefficient plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b_estimates %&amp;gt;%
  filter(term == &amp;quot;b_x&amp;quot;) %&amp;gt;% # b_Intercept b_x
  
  ggplot(aes(x = model)) +
  geom_pointrange(aes(y    = Estimate,
                      ymin = Q2.5,
                      ymax = Q97.5),
                  shape = 20) +
  coord_flip(ylim = c(-.2, 1)) +
  labs(title    = &amp;quot;The x slope, varying by model&amp;quot;,
       subtitle = &amp;quot;The dots are the posterior means and the lines the percentile-based 95% intervals.&amp;quot;,
       x        = NULL,
       y        = NULL) +
  theme(panel.grid   = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y  = element_text(hjust = 0))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-27-1.png&#34; width=&#34;576&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You might think of the &lt;code&gt;b0&lt;/code&gt; slope as the “true” slope. That’s the one estimated from the well-behaved multivariate normal data, &lt;code&gt;d&lt;/code&gt;. That estimate’s just where we’d want it to be. The &lt;code&gt;b1&lt;/code&gt; slope is a disaster–way lower than the others. The slopes for &lt;code&gt;b1.1&lt;/code&gt; and &lt;code&gt;b1.2&lt;/code&gt; get better, but at the expense of deleting data. All three of our Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; models produced slopes that were pretty close to the &lt;code&gt;b0&lt;/code&gt; slope. They weren’t perfect, but, all in all, Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt;-distribution did pretty okay.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;we-need-more-loo-and-more-pareto_k.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;We need more LOO and more &lt;code&gt;pareto_k&lt;/code&gt;.&lt;/h3&gt;
&lt;p&gt;We already have loo objects for our first two models, &lt;code&gt;b0&lt;/code&gt; and &lt;code&gt;b1&lt;/code&gt;. Let’s get some for models &lt;code&gt;b2&lt;/code&gt; through &lt;code&gt;b4&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_b2 &amp;lt;- loo(b2)
loo_b3 &amp;lt;- loo(b3)
loo_b4 &amp;lt;- loo(b4)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With a little data wrangling, we can compare our models by how they look in our custom &lt;code&gt;pareto_k&lt;/code&gt; diagnostic plots.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# make a custom function to work with the loo objects in bulk
get_pareto_k &amp;lt;- function(l) {
  l$diagnostics$pareto_k %&amp;gt;% 
    as_tibble() %&amp;gt;%
    mutate(i = 1:n()) %&amp;gt;% 
    rename(pareto_k = value)
}

# wrangle
tibble(name = str_c(&amp;quot;loo_b&amp;quot;, 1:4)) %&amp;gt;% 
  mutate(loo_object = map(name, get)) %&amp;gt;% 
  mutate(pareto_k = map(loo_object, get_pareto_k)) %&amp;gt;% 
  unnest(pareto_k) %&amp;gt;% 
  mutate(fit = rep(c(&amp;quot;fit b1&amp;quot;, &amp;quot;fit b2&amp;quot;, &amp;quot;fit b3&amp;quot;, &amp;quot;fit b4&amp;quot;), each = n() / 4)) %&amp;gt;%
  
  # plot
  ggplot(aes(x = i, y = pareto_k)) +
  geom_hline(yintercept = c(.5, .7),
             color = &amp;quot;white&amp;quot;) +
  geom_point(alpha = .5) +
  scale_y_continuous(expression(Pareto~italic(k)), breaks = c(0, .5, .7)) +
  theme(panel.grid = element_blank(),
        axis.title.x = element_text(face = &amp;quot;italic&amp;quot;, family = &amp;quot;Times&amp;quot;)) +
    facet_wrap(~ fit)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-28-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Oh man, those Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; models worked sweet! In a succession from &lt;code&gt;b2&lt;/code&gt; through &lt;code&gt;b4&lt;/code&gt;, each model looked better by &lt;code&gt;pareto_k&lt;/code&gt;. All were way better than the typical Gaussian model, &lt;code&gt;b1&lt;/code&gt;. While we’re at it, we might compare those by their LOO values.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;loo_compare(loo_b1, loo_b2, loo_b3, loo_b4) %&amp;gt;% print(simplify = F)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    elpd_diff se_diff elpd_loo se_elpd_loo p_loo  se_p_loo looic  se_looic
## b4    0.0       0.0  -143.5     10.3         2.7    0.3    287.1   20.7  
## b3   -0.8       0.4  -144.4     10.7         3.6    0.8    288.8   21.4  
## b2   -1.9       1.8  -145.5     11.7         4.6    1.5    291.0   23.4  
## b1  -13.9       7.6  -157.4     15.8         6.7    3.7    314.8   31.5&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In terms of the LOO, &lt;code&gt;b2&lt;/code&gt; through &lt;code&gt;b4&lt;/code&gt; were about the same, but all looked better than &lt;code&gt;b1&lt;/code&gt;. In fairness, though, the standard errors for the difference scores were a bit on the wide side.
If you’re new to using information criteria to compare models, you might sit down and soak in &lt;a href=&#34;https://www.youtube.com/watch?v=t0pRuy1_190&amp;amp;list=PLDcUM9US4XdM9_N6XUUFrhghGJ4K25bFc&amp;amp;index=8&#34;&gt;one of McElreath’s lectures on the topic&lt;/a&gt; or the &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-vehtariUsingLooPackage2020&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; vignette by Vehtari and Gabry, &lt;a href=&#34;https://cran.r-project.org/web/packages/loo/vignettes/loo2-example.html#plotting-pareto-k-diagnostics&#34;&gt;&lt;em&gt;Using the loo package (version &amp;gt;= 2.0.0)&lt;/em&gt;&lt;/a&gt;. For a more technical introduction, you might check out the references in the &lt;strong&gt;loo&lt;/strong&gt; package’s &lt;a href=&#34;https://CRAN.R-project.org/package=loo&#34;&gt;reference manual&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For one final LOO-related comparison, we can use the &lt;code&gt;brms::model_weights()&lt;/code&gt; function to see how much relative weight we might put on each of those four models if we were to use a model averaging approach. Here we use the default method, which is model averaging via posterior predictive stacking.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;model_weights(b1, b2, b3, b4)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           b1           b2           b3           b4 
## 3.310561e-07 8.617446e-07 1.808979e-06 9.999970e-01&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you’re not a fan of scientific notation, just tack on &lt;code&gt;round(digits = 2)&lt;/code&gt;. The stacking method suggests that we should place virtually all the weight on &lt;code&gt;b4&lt;/code&gt;, the model in which we fixed our Student-&lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; parameter at 4. To learn more about model stacking, check out Yao, Vehtari, Simpson, and Gelman’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-yaoUsingStackingAverage2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; paper, &lt;a href=&#34;https://projecteuclid.org/euclid.ba/1516093227&#34;&gt;&lt;em&gt;Using stacking to average Bayesian predictive distributions&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-compare-a-few-bayesian-models.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Let’s compare a few Bayesian models.&lt;/h3&gt;
&lt;p&gt;That’s enough with coefficients, &lt;code&gt;pareto_k&lt;/code&gt;, and the LOO. Let’s get a sense of the implications of the models by comparing a few in plots. Here we use convenience functions from &lt;a href=&#34;https://twitter.com/mjskay&#34;&gt;Matthew Kay&lt;/a&gt;’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-tidybayes&#34; role=&#34;doc-biblioref&#34;&gt;2020&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;http://mjskay.github.io/tidybayes&#34;&gt;&lt;strong&gt;tidybayes&lt;/strong&gt; package&lt;/a&gt; to streamline the data wrangling and plotting. The method came from a &lt;a href=&#34;https://twitter.com/mjskay/status/1091926564101599232&#34;&gt;kind twitter suggesion from Kay&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(tidybayes)

# these are the values of x we&amp;#39;d like model-implied summaries for
nd &amp;lt;- tibble(x = seq(from = -4, to = 4, length.out = 50))

# here&amp;#39;s another way to arrange the models
list(b0 = b0, b1 = b1, b3 = b3) %&amp;gt;% 
  # with help from `tidybayes::add_fitted_draws()`, here we use `fitted()` in bulk
  map_dfr(add_fitted_draws, newdata = nd, .id = &amp;quot;model&amp;quot;) %&amp;gt;% 
  
  # plot
  ggplot(aes(x = x)) +
  stat_lineribbon(aes(y = .value),
                  .width = .95,
                  color = &amp;quot;grey92&amp;quot;, fill = &amp;quot;grey67&amp;quot;) +
  geom_point(data = d %&amp;gt;%
               bind_rows(o, o) %&amp;gt;%
               mutate(model = rep(c(&amp;quot;b0&amp;quot;, &amp;quot;b1&amp;quot;, &amp;quot;b3&amp;quot;), each = 100)), 
             aes(y = y, color = y &amp;gt; 3),
             size = 1, alpha = 3/4) +
  scale_color_viridis_d(option = &amp;quot;A&amp;quot;, end = 4/7) +
  coord_cartesian(xlim = c(-3, 3), 
                  ylim = c(-3, 5)) +
  ylab(NULL) +
  theme(panel.grid = element_blank(),
        legend.position = &amp;quot;none&amp;quot;) +
  facet_wrap(~ model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019-02-02-robust-linear-regression-with-student-s-t-distribution/index_files/figure-html/unnamed-chunk-31-1.png&#34; width=&#34;768&#34; /&gt;&lt;/p&gt;
&lt;p&gt;For each subplot, the gray band is the 95% interval band and the overlapping light gray line is the posterior mean. Model &lt;code&gt;b0&lt;/code&gt;, recall, is our baseline comparison model. This is of the well-behaved no-outlier data, &lt;code&gt;d&lt;/code&gt;, using the good old Gaussian likelihood. Model &lt;code&gt;b1&lt;/code&gt; is of the outlier data, &lt;code&gt;o&lt;/code&gt;, but still using the non-robust Gaussian likelihood. Model &lt;code&gt;b3&lt;/code&gt; uses a robust Student’s &lt;span class=&#34;math inline&#34;&gt;\(t\)&lt;/span&gt; likelihood with &lt;span class=&#34;math inline&#34;&gt;\(\nu\)&lt;/span&gt; estimated with the fairly narrow &lt;code&gt;gamma(4, 1)&lt;/code&gt; prior. For my money, &lt;code&gt;b3&lt;/code&gt; did a pretty good job.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.3.1 loo_2.4.1       brms_2.15.0     Rcpp_1.0.6     
##  [5] patchwork_1.1.1 broom_0.7.5     forcats_0.5.1   stringr_1.4.0  
##  [9] dplyr_1.0.5     purrr_0.3.4     readr_1.4.0     tidyr_1.1.3    
## [13] tibble_3.1.0    ggplot2_3.3.3   tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6          
##   [4] igraph_1.2.6         svUnit_1.0.3         splines_4.0.4       
##   [7] crosstalk_1.1.0.1    TH.data_1.0-10       rstantools_2.1.1    
##  [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.1.1   
##  [13] rsconnect_0.8.16     fansi_0.4.2          checkmate_2.0.0     
##  [16] magrittr_2.0.1       modelr_0.1.8         RcppParallel_5.0.2  
##  [19] matrixStats_0.57.0   xts_0.12.1           sandwich_3.0-0      
##  [22] prettyunits_1.1.1    colorspace_2.0-0     rvest_0.3.6         
##  [25] ggdist_2.4.0.9000    haven_2.3.1          xfun_0.22           
##  [28] callr_3.5.1          crayon_1.4.1         jsonlite_1.7.2      
##  [31] lme4_1.1-25          survival_3.2-10      zoo_1.8-8           
##  [34] glue_1.4.2           gtable_0.3.0         emmeans_1.5.2-1     
##  [37] V8_3.4.0             distributional_0.2.2 pkgbuild_1.2.0      
##  [40] rstan_2.21.2         abind_1.4-5          scales_1.1.1        
##  [43] mvtnorm_1.1-1        DBI_1.1.0            miniUI_0.1.1.1      
##  [46] viridisLite_0.3.0    xtable_1.8-4         stats4_4.0.4        
##  [49] StanHeaders_2.21.0-7 DT_0.16              htmlwidgets_1.5.2   
##  [52] httr_1.4.2           threejs_0.3.3        arrayhelpers_1.1-0  
##  [55] ellipsis_0.3.1       pkgconfig_2.0.3      farver_2.0.3        
##  [58] dbplyr_2.0.0         utf8_1.1.4           tidyselect_1.1.0    
##  [61] labeling_0.4.2       rlang_0.4.10         reshape2_1.4.4      
##  [64] later_1.1.0.1        munsell_0.5.0        cellranger_1.1.0    
##  [67] tools_4.0.4          cli_2.3.1            generics_0.1.0      
##  [70] ggridges_0.5.2       evaluate_0.14        fastmap_1.0.1       
##  [73] yaml_2.2.1           processx_3.4.5       knitr_1.31          
##  [76] fs_1.5.0             nlme_3.1-152         mime_0.10           
##  [79] projpred_2.0.2       xml2_1.3.2           compiler_4.0.4      
##  [82] bayesplot_1.8.0      shinythemes_1.1.2    rstudioapi_0.13     
##  [85] gamm4_0.2-6          curl_4.3             reprex_0.3.0        
##  [88] statmod_1.4.35       stringi_1.5.3        highr_0.8           
##  [91] ps_1.6.0             blogdown_1.3         Brobdingnag_1.2-6   
##  [94] lattice_0.20-41      Matrix_1.3-2         nloptr_1.2.2.2      
##  [97] markdown_1.1         shinyjs_2.0.0        vctrs_0.3.6         
## [100] pillar_1.5.1         lifecycle_1.0.0      bridgesampling_1.0-0
## [103] estimability_1.3     httpuv_1.5.4         R6_2.5.0            
## [106] bookdown_0.21        promises_1.1.1       gridExtra_2.3       
## [109] codetools_0.2-18     boot_1.3-26          colourpicker_1.1.0  
## [112] MASS_7.3-53          gtools_3.8.2         assertthat_0.2.1    
## [115] withr_2.4.1          shinystan_2.5.0      multcomp_1.4-16     
## [118] mgcv_1.8-33          parallel_4.0.4       hms_0.5.3           
## [121] grid_4.0.4           coda_0.19-4          minqa_1.2.4         
## [124] rmarkdown_2.7        shiny_1.5.0          lubridate_1.7.9.2   
## [127] base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-burknerBrmsPackageBayesian2017&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2017). &lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;An R&lt;/span&gt; package for &lt;span&gt;Bayesian&lt;/span&gt; multilevel models using &lt;span&gt;Stan&lt;/span&gt;. &lt;em&gt;Journal of Statistical Software&lt;/em&gt;, &lt;em&gt;80&lt;/em&gt;(1), 1–28. &lt;a href=&#34;https://doi.org/10.18637/jss.v080.i01&#34;&gt;https://doi.org/10.18637/jss.v080.i01&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-burknerAdvancedBayesianMultilevel2018&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2018). Advanced &lt;span&gt;Bayesian&lt;/span&gt; multilevel modeling with the &lt;span&gt;R&lt;/span&gt; package brms. &lt;em&gt;The R Journal&lt;/em&gt;, &lt;em&gt;10&lt;/em&gt;(1), 395–411. &lt;a href=&#34;https://doi.org/10.32614/RJ-2018-017&#34;&gt;https://doi.org/10.32614/RJ-2018-017&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-brms&#34; class=&#34;csl-entry&#34;&gt;
Bürkner, P.-C. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;brms&lt;/span&gt;: &lt;span&gt;Bayesian&lt;/span&gt; regression models using ’&lt;span&gt;Stan&lt;/span&gt;’&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=brms&#34;&gt;https://CRAN.R-project.org/package=brms&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-fahrmeirRegressionModelsMethods2013&#34; class=&#34;csl-entry&#34;&gt;
Fahrmeir, L., Kneib, T., Lang, S., &amp;amp; Marx, B. (2013). &lt;em&gt;Regression: &lt;span&gt;Models&lt;/span&gt;, methods and applications&lt;/em&gt;. &lt;span&gt;Springer-Verlag&lt;/span&gt;. &lt;a href=&#34;https://doi.org/10.1007/978-3-642-34333-9&#34;&gt;https://doi.org/10.1007/978-3-642-34333-9&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-gelmanDataAnalysisUsing2006&#34; class=&#34;csl-entry&#34;&gt;
Gelman, A., &amp;amp; Hill, J. (2006). &lt;em&gt;Data analysis using regression and multilevel/hierarchical models&lt;/em&gt;. &lt;span&gt;Cambridge University Press&lt;/span&gt;. &lt;a href=&#34;https://doi.org/10.1017/CBO9780511790942&#34;&gt;https://doi.org/10.1017/CBO9780511790942&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-grolemundDataScience2017&#34; class=&#34;csl-entry&#34;&gt;
Grolemund, G., &amp;amp; Wickham, H. (2017). &lt;em&gt;R for data science&lt;/em&gt;. &lt;span&gt;O’Reilly&lt;/span&gt;. &lt;a href=&#34;https://r4ds.had.co.nz&#34;&gt;https://r4ds.had.co.nz&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-tidybayes&#34; class=&#34;csl-entry&#34;&gt;
Kay, M. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;tidybayes&lt;/span&gt;: &lt;span&gt;Tidy&lt;/span&gt; data and ’geoms’ for &lt;span&gt;Bayesian&lt;/span&gt; models&lt;/em&gt;. &lt;a href=&#34;https://mjskay.github.io/tidybayes/&#34;&gt;https://mjskay.github.io/tidybayes/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kruschkeDoingBayesianData2015&#34; class=&#34;csl-entry&#34;&gt;
Kruschke, J. K. (2015). &lt;em&gt;Doing &lt;span&gt;Bayesian&lt;/span&gt; data analysis: &lt;span&gt;A&lt;/span&gt; tutorial with &lt;span&gt;R&lt;/span&gt;, &lt;span&gt;JAGS&lt;/span&gt;, and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;Academic Press&lt;/span&gt;. &lt;a href=&#34;https://sites.google.com/site/doingbayesiandataanalysis/&#34;&gt;https://sites.google.com/site/doingbayesiandataanalysis/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2020&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2020). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt; (Second Edition). &lt;span&gt;CRC Press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2015&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2015). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-MASS&#34; class=&#34;csl-entry&#34;&gt;
Ripley, B. (2019). &lt;em&gt;&lt;span&gt;MASS&lt;/span&gt;: &lt;span&gt;Support&lt;/span&gt; functions and datasets for venables and ripley’s &lt;span&gt;MASS&lt;/span&gt;&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=MASS&#34;&gt;https://CRAN.R-project.org/package=MASS&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-broom&#34; class=&#34;csl-entry&#34;&gt;
Robinson, D., &amp;amp; Hayes, A. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;broom&lt;/span&gt;: &lt;span&gt;Convert&lt;/span&gt; statistical analysis objects into tidy tibbles&lt;/em&gt; [Manual]. &lt;a href=&#34;https://CRAN.R-project.org/package=broom&#34;&gt;https://CRAN.R-project.org/package=broom&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vehtariUsingLooPackage2020&#34; class=&#34;csl-entry&#34;&gt;
Vehtari, A., &amp;amp; Gabry, J. (2020). &lt;em&gt;Using the loo package (version &lt;span&gt;&lt;span class=&#34;math inline&#34;&gt;\(&amp;gt;\)&lt;/span&gt;&lt;/span&gt;= 2.0.0)&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=loo/vignettes/loo2-example.html&#34;&gt;https://CRAN.R-project.org/package=loo/vignettes/loo2-example.html&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-loo2020RM&#34; class=&#34;csl-entry&#34;&gt;
Vehtari, A., Gabry, J., Magnusson, M., Yao, Y., Bürkner, P.-C., Paananen, T., &amp;amp; Gelman, A. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;loo&lt;/span&gt; reference manual, &lt;span&gt;Version&lt;/span&gt; 2.3.1&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=loo/loo.pdf&#34;&gt;https://CRAN.R-project.org/package=loo/loo.pdf&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-loo&#34; class=&#34;csl-entry&#34;&gt;
Vehtari, A., Gabry, J., Magnusson, M., Yao, Y., &amp;amp; Gelman, A. (2019). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;loo&lt;/span&gt;: &lt;span&gt;Efficient&lt;/span&gt; leave-one-out cross-validation and &lt;span&gt;WAIC&lt;/span&gt; for bayesian models&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=loo/&#34;&gt;https://CRAN.R-project.org/package=loo/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-vehtariPracticalBayesianModel2017&#34; class=&#34;csl-entry&#34;&gt;
Vehtari, A., Gelman, A., &amp;amp; Gabry, J. (2017). Practical &lt;span&gt;Bayesian&lt;/span&gt; model evaluation using leave-one-out cross-validation and &lt;span&gt;WAIC&lt;/span&gt;. &lt;em&gt;Statistics and Computing&lt;/em&gt;, &lt;em&gt;27&lt;/em&gt;(5), 1413–1432. &lt;a href=&#34;https://doi.org/10.1007/s11222-016-9696-4&#34;&gt;https://doi.org/10.1007/s11222-016-9696-4&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-tidyverse&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H. (2019). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;tidyverse&lt;/span&gt;: &lt;span&gt;Easily&lt;/span&gt; install and load the ’tidyverse’&lt;/em&gt;. &lt;a href=&#34;https://CRAN.R-project.org/package=tidyverse&#34;&gt;https://CRAN.R-project.org/package=tidyverse&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-wickhamWelcomeTidyverse2019&#34; class=&#34;csl-entry&#34;&gt;
Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. &lt;em&gt;Journal of Open Source Software&lt;/em&gt;, &lt;em&gt;4&lt;/em&gt;(43), 1686. &lt;a href=&#34;https://doi.org/10.21105/joss.01686&#34;&gt;https://doi.org/10.21105/joss.01686&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-yaoUsingStackingAverage2018&#34; class=&#34;csl-entry&#34;&gt;
Yao, Y., Vehtari, A., Simpson, D., &amp;amp; Gelman, A. (2018). Using stacking to average &lt;span&gt;Bayesian&lt;/span&gt; predictive distributions (with discussion). &lt;em&gt;Bayesian Analysis&lt;/em&gt;, &lt;em&gt;13&lt;/em&gt;(3), 917–1007. &lt;a href=&#34;https://doi.org/10.1214/17-BA1091&#34;&gt;https://doi.org/10.1214/17-BA1091&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
