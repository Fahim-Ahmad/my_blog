<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>meta-analysis | Fahim Ahmad</title>
    <link>/tag/meta-analysis/</link>
      <atom:link href="/tag/meta-analysis/index.xml" rel="self" type="application/rss+xml" />
    <description>meta-analysis</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© Fahim Ahmad (2020)</copyright><lastBuildDate>Fri, 16 Oct 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_2.png</url>
      <title>meta-analysis</title>
      <link>/tag/meta-analysis/</link>
    </image>
    
    <item>
      <title>Bayesian meta-analysis in brms-II</title>
      <link>/post/2020-10-16-bayesian-meta-analysis-in-brms-ii/</link>
      <pubDate>Fri, 16 Oct 2020 00:00:00 +0000</pubDate>
      <guid>/post/2020-10-16-bayesian-meta-analysis-in-brms-ii/</guid>
      <description>
&lt;script src=&#34;/post/2020-10-16-bayesian-meta-analysis-in-brms-ii/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;preamble&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preamble&lt;/h2&gt;
&lt;p&gt;In &lt;a href=&#34;https://bookdown.org/content/3890/missing-data-and-other-opportunities.html#summary-bonus-meta-analysis&#34;&gt;Section 14.3&lt;/a&gt; of my &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kurzStatisticalRethinkingBrms2020&#34; role=&#34;doc-biblioref&#34;&gt;2020a&lt;/a&gt;)&lt;/span&gt; translation of the first edition of McElreath’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2015&#34; role=&#34;doc-biblioref&#34;&gt;2015&lt;/a&gt;)&lt;/span&gt; &lt;em&gt;Statistical rethinking&lt;/em&gt;, I included a bonus section covering Bayesian meta-analysis. For my &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kurzStatisticalRethinkingSecondEd2020&#34; role=&#34;doc-biblioref&#34;&gt;2020b&lt;/a&gt;)&lt;/span&gt; translation of the second edition of the text &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-mcelreathStatisticalRethinkingBayesian2020&#34; role=&#34;doc-biblioref&#34;&gt;McElreath, 2020&lt;/a&gt;)&lt;/span&gt;, I’d like to include another section on the topic, but from a different perspective. The first time around, we focused on standardized mean differences. This time, I’d like to tackle odds ratios and, while we’re at it, give a little bit of a plug for open science practices.&lt;/p&gt;
&lt;p&gt;The purpose of this post is to present a rough draft of the section. I intend to tack this section onto the end of Chapter 15 (&lt;em&gt;Missing Data and Other Opportunities&lt;/em&gt;), which covers measurement error. If you have any constrictive criticisms, please pass them along either in the &lt;a href=&#34;https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse_2_ed/issues&#34;&gt;GitHub issues for the ebook&lt;/a&gt; or on &lt;a href=&#34;https://twitter.com/SolomonKurz/status/1317854064839958531&#34;&gt;Twitter&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here’s the rough draft:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summary-bonus-bayesian-meta-analysis-with-odds-ratios&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;del&gt;Summary&lt;/del&gt; Bonus: Bayesian meta-analysis with odds ratios&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# these packages and setting alterations will already have been 
# opened and made before this section
library(tidyverse)
library(brms)
library(ggdark)
library(viridis)
library(broom)
library(tidybayes)

theme_set(
  dark_theme_bw() +
    theme(legend.position = &amp;quot;none&amp;quot;,
          panel.grid = element_blank())
  )

# to reset the default ggplot2 theme to its default parameters,
# execute `ggplot2::theme_set(theme_gray())` and `ggdark::invert_geom_defaults()`&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If your mind isn’t fully blown by those measurement-error and missing-data models, let’s keep building. As it turns out, meta-analyses are often just special kinds of multilevel measurement-error models. Thus, you can use &lt;code&gt;brms::brm()&lt;/code&gt; to fit Bayesian meta-analyses, too.&lt;/p&gt;
&lt;p&gt;Before we proceed, I should acknowledge that this section is heavily influenced by &lt;a href=&#34;https://mvuorre.github.io/#about&#34;&gt;Matti Vourre&lt;/a&gt;’s great blog post, &lt;a href=&#34;https://mvuorre.github.io/post/2016/09/29/meta-analysis-is-a-special-case-of-bayesian-multilevel-modeling/&#34;&gt;&lt;em&gt;Meta-analysis is a special case of Bayesian multilevel modeling&lt;/em&gt;&lt;/a&gt;. Since neither editions of McElreath’s text directly address meta-analyses, we’ll also have to borrow a bit from Gelman, Carlin, Stern, Dunson, Vehtari, and Rubin’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-gelman2013bayesian&#34; role=&#34;doc-biblioref&#34;&gt;2013&lt;/a&gt;)&lt;/span&gt; &lt;a href=&#34;https://stat.columbia.edu/~gelman/book/&#34;&gt;&lt;em&gt;Bayesian data analysis, Third edition&lt;/em&gt;&lt;/a&gt;.&lt;/p&gt;
&lt;div id=&#34;how-do-meta-analyses-fit-into-the-picture&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;How do meta-analyses fit into the picture?&lt;/h3&gt;
&lt;p&gt;Let Gelman and colleagues introduce the topic:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Discussions of meta-analysis are sometimes imprecise about the estimands of interest in the analysis, especially when the primary focus is on testing the null hypothesis of no effect in any of the studies to be combined. Our focus is on estimating meaningful parameters, and for this objective there appear to be three possibilities, accepting the overarching assumption that the studies are comparable in some broad sense. The first possibility is that we view the studies as identical replications of each other, in the sense we regard the individuals in all the studies as independent samples from a common population, with the same outcome measures and so on. A second possibility is that the studies are so different that the results of any one study provide no information about the results of any of the others. A third, more general, possibility is that we regard the studies as exchangeable but not necessarily either identical or completely unrelated; in other words we allow differences from study to study, but such that the differences are not expected &lt;em&gt;a priori&lt;/em&gt; to have predictable effects favoring one study over another…. this third possibility represents a continuum between the two extremes, and it is this exchangeable model (with unknown hyperparameters characterizing the population distribution) that forms the basis of our Bayesian analysis…&lt;/p&gt;
&lt;p&gt;The first potential estimand of a meta-analysis, or a hierarchically structured problem in general, is the mean of the distribution of effect sizes, since this represents the overall ‘average’ effect across all studies that could be regarded as exchangeable with the observed studies. Other possible estimands are the effect size in any of the observed studies and the effect size in another, comparable (exchangeable) unobserved study. (pp. 125–126, &lt;em&gt;emphasis&lt;/em&gt; in the original)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The basic version of a Bayesian meta-analysis follows the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_j \sim \operatorname{Normal}(\theta_j, \sigma_j),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y_j\)&lt;/span&gt; = the point estimate for the effect size of a single study, &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;, which is presumed to have been a draw from a Normal distribution centered on &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;. The data in meta-analyses are typically statistical summaries from individual studies. The one clear lesson from this chapter is that those estimates themselves come with error and those errors should be fully expressed in the meta-analytic model. The standard error from study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is specified &lt;span class=&#34;math inline&#34;&gt;\(\sigma_j\)&lt;/span&gt;, which is also a stand-in for the standard deviation of the Normal distribution from which the point estimate was drawn. Do note, we’re not estimating &lt;span class=&#34;math inline&#34;&gt;\(\sigma_j\)&lt;/span&gt;, here. Those values we take directly from the original studies.&lt;/p&gt;
&lt;p&gt;Building on the model, we further presume that study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; is itself just one draw from a population of related studies, each of which have their own effect sizes. As such, we presume &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt; itself has a distribution following the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\theta_j \sim \operatorname{Normal}(\mu, \tau),\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the meta-analytic effect (i.e., the population mean) and &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; is the variation around that mean, what you might also think of as &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\tau\)&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;we-need-some-data.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;We need some data.&lt;/h3&gt;
&lt;p&gt;Our data in this section come from the second large-scale replication project by the Many Labs team &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-kleinManyLabsInvestigating2018&#34; role=&#34;doc-biblioref&#34;&gt;Klein et al., 2018&lt;/a&gt;)&lt;/span&gt;. Of the 28 studies replicated in the study, we will focus on the replication of the trolley experiment from &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-hauserDissociationMoralJudgments2007&#34; role=&#34;doc-biblioref&#34;&gt;Hauser et al.&lt;/a&gt; (&lt;a href=&#34;#ref-hauserDissociationMoralJudgments2007&#34; role=&#34;doc-biblioref&#34;&gt;2007&lt;/a&gt;)&lt;/span&gt;. Here’s how the study was described by Klein and colleagues:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;According to the principle of double effect, an act that harms other people is more morally permissible if the act is a foreseen side effect rather than the means to the greater good. &lt;span class=&#34;citation&#34;&gt;&lt;a href=&#34;#ref-hauserDissociationMoralJudgments2007&#34; role=&#34;doc-biblioref&#34;&gt;Hauser et al.&lt;/a&gt; (&lt;a href=&#34;#ref-hauserDissociationMoralJudgments2007&#34; role=&#34;doc-biblioref&#34;&gt;2007&lt;/a&gt;)&lt;/span&gt; compared participants’ reactions to two scenarios to test whether their judgments followed this principle. In the &lt;em&gt;foreseen-side-effect&lt;/em&gt; scenario, a person on an out-of-control train changed the train’s trajectory so that the train killed one person instead of five. In the &lt;em&gt;greater-good&lt;/em&gt; scenario, a person pushed a fat man in front of a train, killing him, to save five people. Whereas &lt;span class=&#34;math inline&#34;&gt;\(89\%\)&lt;/span&gt; of participants judged the action in the foreseen-side-effect scenario as permissible &lt;span class=&#34;math inline&#34;&gt;\((95 \% \; \text{CI} = [87\%, 91\%]),\)&lt;/span&gt; only &lt;span class=&#34;math inline&#34;&gt;\(11\%\)&lt;/span&gt; of participants in the greater-good scenario judged it as permissible &lt;span class=&#34;math inline&#34;&gt;\((95 \% \; \text{CI} = [9\%, 13\%])\)&lt;/span&gt;. The difference between the percentages was significant&lt;span class=&#34;math inline&#34;&gt;\(, \chi^2(1, N = 2,646) = 1,615.96,\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(p &amp;lt; .001,\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(w = .78,\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(d = 2.50,\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(95 \% \; \text{CI} = [2.22, 2.86]\)&lt;/span&gt;. Thus, the results provided evidence for the principle of double effect. (p. 459, &lt;em&gt;emphasis&lt;/em&gt; in the original)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;You can find supporting materials for the replication project on the Open Science Framework at &lt;a href=&#34;https://osf.io/8cd4r/&#34;&gt;https://osf.io/8cd4r/&lt;/a&gt;. The relevant subset of the data for the replication of Hauser et al. come from the &lt;code&gt;Trolley Dilemma 1 (Hauser et al., 2007)&lt;/code&gt; folder within the &lt;code&gt;OSFdata.zip&lt;/code&gt; (&lt;a href=&#34;https://osf.io/ag2pd/&#34;&gt;https://osf.io/ag2pd/&lt;/a&gt;). I’ve downloaded the file and saved it on GitHub.&lt;/p&gt;
&lt;p&gt;Here we load the data and call it &lt;code&gt;h&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;h &amp;lt;- 
  readr::read_csv(&amp;quot;https://raw.githubusercontent.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse_2_ed/master/data/Hauser_1_study_by_order_all_CLEAN_CASE.csv&amp;quot;)

h &amp;lt;- 
  h %&amp;gt;% 
  mutate(y   = ifelse(variable == &amp;quot;Yes&amp;quot;, 1, 0),
         loc = factor(Location,
                      levels = distinct(h, Location) %&amp;gt;% pull(Location),
                      labels = 1:59))

glimpse(h)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 6,842
## Columns: 29
## $ uID              &amp;lt;dbl&amp;gt; 65, 68, 102, 126, 145, 263, 267, 298, 309, 318, 350, 356, 376, 431, 438, …
## $ variable         &amp;lt;chr&amp;gt; &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;No&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;No&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;…
## $ factor           &amp;lt;chr&amp;gt; &amp;quot;SideEffect&amp;quot;, &amp;quot;SideEffect&amp;quot;, &amp;quot;SideEffect&amp;quot;, &amp;quot;SideEffect&amp;quot;, &amp;quot;SideEffect&amp;quot;, &amp;quot;Si…
## $ .id              &amp;lt;chr&amp;gt; &amp;quot;ML2_Slate1_Brazil__Portuguese_execution_illegal_r.csv&amp;quot;, &amp;quot;ML2_Slate1_Braz…
## $ source           &amp;lt;chr&amp;gt; &amp;quot;brasilia&amp;quot;, &amp;quot;brasilia&amp;quot;, &amp;quot;brasilia&amp;quot;, &amp;quot;wilfredlaur&amp;quot;, &amp;quot;wilfredlaur&amp;quot;, &amp;quot;ubc&amp;quot;, …
## $ haus1.1          &amp;lt;dbl&amp;gt; 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1…
## $ haus1.1t_1       &amp;lt;dbl&amp;gt; 39.054, 36.792, 56.493, 21.908, 25.635, 50.633, 58.661, 50.137, 51.717, 2…
## $ haus2.1          &amp;lt;dbl&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
## $ haus2.1t_1       &amp;lt;dbl&amp;gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, N…
## $ Source.Global    &amp;lt;chr&amp;gt; &amp;quot;brasilia&amp;quot;, &amp;quot;brasilia&amp;quot;, &amp;quot;brasilia&amp;quot;, &amp;quot;wilfredlaur&amp;quot;, &amp;quot;wilfredlaur&amp;quot;, &amp;quot;ubc&amp;quot;, …
## $ Source.Primary   &amp;lt;chr&amp;gt; &amp;quot;brasilia&amp;quot;, &amp;quot;brasilia&amp;quot;, &amp;quot;brasilia&amp;quot;, &amp;quot;wilfredlaur&amp;quot;, &amp;quot;wilfredlaur&amp;quot;, &amp;quot;ubc&amp;quot;, …
## $ Source.Secondary &amp;lt;chr&amp;gt; &amp;quot;brasilia&amp;quot;, &amp;quot;brasilia&amp;quot;, &amp;quot;brasilia&amp;quot;, &amp;quot;wilfredlaur&amp;quot;, &amp;quot;wilfredlaur&amp;quot;, &amp;quot;ubc&amp;quot;, …
## $ Country          &amp;lt;chr&amp;gt; &amp;quot;Brazil&amp;quot;, &amp;quot;Brazil&amp;quot;, &amp;quot;Brazil&amp;quot;, &amp;quot;Canada&amp;quot;, &amp;quot;Canada&amp;quot;, &amp;quot;Canada&amp;quot;, &amp;quot;Canada&amp;quot;, &amp;quot;Ca…
## $ Location         &amp;lt;chr&amp;gt; &amp;quot;Social and Work Psychology Department, University of Brasilia, DF, Brazi…
## $ Language         &amp;lt;chr&amp;gt; &amp;quot;Portuguese&amp;quot;, &amp;quot;Portuguese&amp;quot;, &amp;quot;Portuguese&amp;quot;, &amp;quot;English&amp;quot;, &amp;quot;English&amp;quot;, &amp;quot;English&amp;quot;…
## $ Weird            &amp;lt;dbl&amp;gt; 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
## $ Execution        &amp;lt;chr&amp;gt; &amp;quot;illegal&amp;quot;, &amp;quot;illegal&amp;quot;, &amp;quot;illegal&amp;quot;, &amp;quot;illegal&amp;quot;, &amp;quot;illegal&amp;quot;, &amp;quot;illegal&amp;quot;, &amp;quot;illega…
## $ SubjectPool      &amp;lt;chr&amp;gt; &amp;quot;No&amp;quot;, &amp;quot;No&amp;quot;, &amp;quot;No&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;, &amp;quot;Yes&amp;quot;,…
## $ Setting          &amp;lt;chr&amp;gt; &amp;quot;In a classroom&amp;quot;, &amp;quot;In a classroom&amp;quot;, &amp;quot;In a classroom&amp;quot;, &amp;quot;In a lab&amp;quot;, &amp;quot;In a l…
## $ Tablet           &amp;lt;chr&amp;gt; &amp;quot;Computers&amp;quot;, &amp;quot;Computers&amp;quot;, &amp;quot;Computers&amp;quot;, &amp;quot;Computers&amp;quot;, &amp;quot;Computers&amp;quot;, &amp;quot;Compute…
## $ Pencil           &amp;lt;chr&amp;gt; &amp;quot;No, the whole study was on the computer (except maybe consent/debriefing…
## $ StudyOrderN      &amp;lt;chr&amp;gt; &amp;quot;Hauser|Ross.Slate1|Rottenstrich|Graham|Kay|Inbar|Anderson|VanLange|Huang…
## $ IDiffOrderN      &amp;lt;chr&amp;gt; &amp;quot;ID: Global self-esteem SISE|ID: Mood|ID: Subjective wellbeing|ID: Disgus…
## $ study.order      &amp;lt;dbl&amp;gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…
## $ analysis.type    &amp;lt;chr&amp;gt; &amp;quot;Order&amp;quot;, &amp;quot;Order&amp;quot;, &amp;quot;Order&amp;quot;, &amp;quot;Order&amp;quot;, &amp;quot;Order&amp;quot;, &amp;quot;Order&amp;quot;, &amp;quot;Order&amp;quot;, &amp;quot;Order&amp;quot;, &amp;quot;…
## $ subset           &amp;lt;chr&amp;gt; &amp;quot;all&amp;quot;, &amp;quot;all&amp;quot;, &amp;quot;all&amp;quot;, &amp;quot;all&amp;quot;, &amp;quot;all&amp;quot;, &amp;quot;all&amp;quot;, &amp;quot;all&amp;quot;, &amp;quot;all&amp;quot;, &amp;quot;all&amp;quot;, &amp;quot;all&amp;quot;, &amp;quot;al…
## $ case.include     &amp;lt;lgl&amp;gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, T…
## $ y                &amp;lt;dbl&amp;gt; 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1…
## $ loc              &amp;lt;fct&amp;gt; 1, 1, 1, 2, 2, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 4, 4, 3, 4, 4, 4, 4, 3…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The total sample size is &lt;span class=&#34;math inline&#34;&gt;\(N = 6,842\)&lt;/span&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;h %&amp;gt;% 
  distinct(uID) %&amp;gt;% 
  count()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##       n
##   &amp;lt;int&amp;gt;
## 1  6842&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All cases are to be included.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;h %&amp;gt;% 
  count(case.include)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   case.include     n
##   &amp;lt;lgl&amp;gt;        &amp;lt;int&amp;gt;
## 1 TRUE          6842&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The data were collected in 59 locations with sample sizes ranging from 34 to 325.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;h %&amp;gt;% 
  count(Location) %&amp;gt;% 
  arrange(desc(n))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 59 x 2
##    Location                                                                                        n
##    &amp;lt;chr&amp;gt;                                                                                       &amp;lt;int&amp;gt;
##  1 University of Toronto, Scarborough                                                            325
##  2 MTurk India Workers                                                                           308
##  3 MTurk US Workers                                                                              304
##  4 University of Illinois at Urbana-Champaign, Champaign, IL                                     198
##  5 Eotvos Lorand University, in Budapest, Hungary                                                180
##  6 Department of Social Psychology, Tilburg University, P.O. Box 90153, Tilburg, 5000 LE, Net…   173
##  7 Department of Psychology, San Diego State University, San Diego, CA 92182                     171
##  8 Department of Psychology, Pennsylvania State University Abington, Abington, PA 19001          166
##  9 American University of Sharjah, United Arab Emirates                                          162
## 10 University of British Columbia, Vancouver, Canada                                             147
## # … with 49 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;our-effect-size-will-be-an-odds-ratio.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Our effect size will be an odds ratio.&lt;/h3&gt;
&lt;p&gt;Here’s how Klein and colleagues summarized their primary results:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In the aggregate replication sample &lt;span class=&#34;math inline&#34;&gt;\((N = 6,842\)&lt;/span&gt; after removing participants who responded in less than &lt;span class=&#34;math inline&#34;&gt;\(4\)&lt;/span&gt; s&lt;span class=&#34;math inline&#34;&gt;\(), 71\%\)&lt;/span&gt; of participants judged the action in the foreseen-side-effect scenario as permissible, but only &lt;span class=&#34;math inline&#34;&gt;\(17\%\)&lt;/span&gt; of participants in the greater-good scenario judged it as permissible. The difference between the percentages was significant, &lt;span class=&#34;math inline&#34;&gt;\(p = 2.2 \text e^{-16},\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(\text{OR} = 11.54,\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(d = 1.35,\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(95\% \; \text{CI} = [1.28, 1.41]\)&lt;/span&gt;. The replication results were consistent with the double-effect hypothesis, and the effect was about half the magnitude of the original &lt;span class=&#34;math inline&#34;&gt;\((d = 1.35,\)&lt;/span&gt; &lt;span class=&#34;math inline&#34;&gt;\(95\% \; \text{CI} = [1.28, 1.41],\)&lt;/span&gt; vs. original &lt;span class=&#34;math inline&#34;&gt;\(d = 2.50)\)&lt;/span&gt;. (p. 459)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Here is the breakdown of the outcome and primary experimental condition, which will confirm the two empirical percentages mentioned, above.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;h %&amp;gt;% 
  count(variable, factor) %&amp;gt;% 
  group_by(factor) %&amp;gt;% 
  mutate(percent = 100 * n / sum(n))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 4
## # Groups:   factor [2]
##   variable factor          n percent
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;       &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 No       GreaterGood  2781    82.8
## 2 No       SideEffect   1026    29.4
## 3 Yes      GreaterGood   577    17.2
## 4 Yes      SideEffect   2458    70.6&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Though the authors presented their overall effect size with a &lt;span class=&#34;math inline&#34;&gt;\(p\)&lt;/span&gt;-value, an odds-ratio (OR), and a Cohen’s &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; (i.e., a kind of standardized mean difference), we will focus on the OR. The primary data are binomial counts, which are well-handled with logistic regression. When you perform a logistic regression where a control condition is compared with some experimental condition, the difference between those conditions may be expressed as an OR. To get a sense of what that is, we’ll first practice fitting a logistic regression model with the frequentist &lt;code&gt;glm()&lt;/code&gt; function. Here are the results based on the subset of data from the first location.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glm0 &amp;lt;- glm(y ~ factor, family = binomial(logit), data = h %&amp;gt;% filter(loc == 1))

summary(glm0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 
## Call:
## glm(formula = y ~ factor, family = binomial(logit), data = h %&amp;gt;% 
##     filter(loc == 1))
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.5227  -0.6231  -0.6231   0.8677   1.8626  
## 
## Coefficients:
##                  Estimate Std. Error z value Pr(&amp;gt;|z|)    
## (Intercept)       -1.5404     0.3673  -4.194 2.74e-05 ***
## factorSideEffect   2.3232     0.4754   4.887 1.02e-06 ***
## ---
## Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 139.47  on 101  degrees of freedom
## Residual deviance: 110.98  on 100  degrees of freedom
## AIC: 114.98
## 
## Number of Fisher Scoring iterations: 4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just like with &lt;strong&gt;brms&lt;/strong&gt;, the base-&lt;strong&gt;R&lt;/strong&gt; &lt;code&gt;glm()&lt;/code&gt; function returns the results of a logistic regression model in the log-odds metric. The intercept is the log-odds probability of selecting &lt;em&gt;yes&lt;/em&gt; in the study for participants in the &lt;code&gt;GreaterGood&lt;/code&gt; condition. The ‘factorSideEffect’ parameter is the difference in log-odds probability for participants in the &lt;code&gt;SideEffect&lt;/code&gt; condition. Here’s what happens when you exponentiate that coefficient.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;coef(glm0)[2] %&amp;gt;% exp()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## factorSideEffect 
##         10.20833&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That, my friends, is an odds ratio (OR). &lt;strong&gt;Odds ratios are simply exponentiated logistic regression coefficients&lt;/strong&gt;. The implication of this particular OR is that those in the &lt;code&gt;SideEffect&lt;/code&gt; condition have about 10 times the odds of selecting &lt;em&gt;yes&lt;/em&gt; compared to those in the &lt;code&gt;GreaterGood&lt;/code&gt; condition. In the case of this subset of the data, that’s 18% yeses versus 69%, which seems like a large difference, to me.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;h %&amp;gt;% 
  filter(loc == 1) %&amp;gt;% 
  count(variable, factor) %&amp;gt;% 
  group_by(factor) %&amp;gt;% 
  mutate(percent = 100 * n / sum(n)) %&amp;gt;% 
  filter(variable == &amp;quot;Yes&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 4
## # Groups:   factor [2]
##   variable factor          n percent
##   &amp;lt;chr&amp;gt;    &amp;lt;chr&amp;gt;       &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;
## 1 Yes      GreaterGood     9    17.6
## 2 Yes      SideEffect     35    68.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;log-odds-odds-ratios-and-modeling-effect-sizes.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Log-odds, odds ratios, and modeling effect sizes.&lt;/h3&gt;
&lt;p&gt;Though it’s common for researchers to express their effect sizes as odds ratios, we don’t want to work directly with odds ratios in a meta-analysis. &lt;em&gt;Why?&lt;/em&gt; Well, think back on why we model binomial data with the logit link. The logit link transforms a bounded &lt;span class=&#34;math inline&#34;&gt;\([0, 1]\)&lt;/span&gt; parameter space into an unbounded parameter space ranging from negative to positive infinity. For us Bayesians, it also provides a context in which our &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; parameters are approximately Gaussian. However, when we exponentiate those approximately Gaussian log-odds coefficients, the resulting odds ratios aren’t so Gaussian any more. This is why, even if our ultimate goal is to express a meta-analytic effect as an OR, we want to work with effect sizes in the log-odds metric. It allows us to use the Bayesian meta-analytic framework outlined by Gelman et al, above,&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
y_j      &amp;amp; \sim \operatorname{Normal}(\theta_j, \sigma_j) \\
\theta_j &amp;amp; \sim \operatorname{Normal}(\mu, \tau),
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y_j\)&lt;/span&gt; is the point estimate in the &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt;th study still in the log-odds scale. After fitting the model, we can then exponentiate the meta-analytic parameter &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; into the OR metric.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;compute-the-study-specific-effect-sizes.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Compute the study-specific effect sizes.&lt;/h3&gt;
&lt;p&gt;Our &lt;code&gt;h&lt;/code&gt; data from the Klein et al replication study includes the un-aggregated data from all of the study locations combined. Before we compute our meta-analysis, we’ll need to compute the study-specific effect sizes and standard errors. Here we do so within a nested tibble.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;glms &amp;lt;-
  h %&amp;gt;% 
  select(loc, y, factor) %&amp;gt;% 
  nest(data = c(y, factor)) %&amp;gt;% 
  mutate(glm = map(data, ~update(glm0, data = .))) %&amp;gt;% 
  mutate(coef = map(glm, tidy)) %&amp;gt;% 
  select(-data, -glm) %&amp;gt;% 
  unnest(coef) %&amp;gt;% 
  filter(term == &amp;quot;factorSideEffect&amp;quot;)

# what did we do?
glms %&amp;gt;% 
  mutate_if(is.double, round, digits = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 59 x 6
##    loc   term             estimate std.error statistic p.value
##    &amp;lt;fct&amp;gt; &amp;lt;chr&amp;gt;               &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
##  1 1     factorSideEffect     2.32     0.475      4.89       0
##  2 2     factorSideEffect     3.64     0.644      5.64       0
##  3 3     factorSideEffect     2.37     0.399      5.96       0
##  4 4     factorSideEffect     2.24     0.263      8.54       0
##  5 5     factorSideEffect     2.02     0.505      4.00       0
##  6 6     factorSideEffect     2.49     0.571      4.36       0
##  7 7     factorSideEffect     2.53     0.658      3.84       0
##  8 8     factorSideEffect     1.78     0.459      3.87       0
##  9 9     factorSideEffect     1.81     0.378      4.79       0
## 10 10    factorSideEffect     2.37     0.495      4.79       0
## # … with 49 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the &lt;code&gt;estimate&lt;/code&gt; column we have all the &lt;span class=&#34;math inline&#34;&gt;\(y_j\)&lt;/span&gt; values and &lt;code&gt;std.error&lt;/code&gt; contains the corresponding &lt;span class=&#34;math inline&#34;&gt;\(\sigma_j\)&lt;/span&gt; values. Here they are in a plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;color &amp;lt;- viridis_pal(option = &amp;quot;C&amp;quot;)(7)[5]

glms %&amp;gt;% 
  ggplot(aes(x = std.error, y = estimate)) +
  geom_point(color = color) +
  labs(x = expression(sigma[italic(j)]~(&amp;quot;log-odds&amp;quot;)),
       y = expression(italic(y[j])~(&amp;quot;log-odds&amp;quot;)))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-16-bayesian-meta-analysis-in-brms-ii/index_files/figure-html/unnamed-chunk-10-1.png&#34; width=&#34;384&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-the-bayesian-meta-analysis.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fit the Bayesian meta-analysis.&lt;/h3&gt;
&lt;p&gt;Now are data are ready, we can express our first Bayesian meta-analysis with the formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
\text{estimate}_j &amp;amp; \sim \operatorname{Normal}(\theta_j, \; \text{std.error}_j) \\
\theta_j   &amp;amp; \sim \operatorname{Normal}(\mu, \tau) \\
\mu        &amp;amp; \sim \operatorname{Normal}(0, 1.5) \\
\tau       &amp;amp; \sim \operatorname{Exponential}(1),
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the last two lines spell out our priors. As we learned in &lt;a href=&#34;https://bookdown.org/content/4857/god-spiked-the-integers.html#binomial-regression&#34;&gt;Section 11.1&lt;/a&gt;, the &lt;span class=&#34;math inline&#34;&gt;\(\operatorname{Normal}(0, 1.5)\)&lt;/span&gt; prior in the log-odds space is just about flat on the probability space. If you wanted to be more conservative, consider something like &lt;span class=&#34;math inline&#34;&gt;\(\operatorname{Normal}(0, 1)\)&lt;/span&gt;. Here’s how to fit the model with &lt;strong&gt;brms&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;me0 &amp;lt;- 
  brm(data = glms, 
      family = gaussian,
      estimate | se(std.error) ~ 1 + (1 | loc),
      prior = c(prior(normal(0, 1.5), class = Intercept),
                prior(exponential(1), class = sd)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      seed = 15)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;se()&lt;/code&gt; is one of the &lt;strong&gt;brms&lt;/strong&gt; helper functions designed to provide additional information about the criterion variable. Here it informs &lt;code&gt;brm()&lt;/code&gt; that each &lt;code&gt;estimate&lt;/code&gt; value has an associated measurement error defined in the &lt;code&gt;std.error&lt;/code&gt; column. Unlike the &lt;code&gt;mi()&lt;/code&gt; function, which we used earlier in the chapter to accommodate measurement error and the Bayesian imputation of missing data, the &lt;code&gt;se()&lt;/code&gt; function is specially designed to handle meta-analyses. &lt;code&gt;se()&lt;/code&gt; contains a &lt;code&gt;sigma&lt;/code&gt; argument which is set to &lt;code&gt;FALSE&lt;/code&gt; by default. This will return a model with no estimate for sigma, which is what we want. The uncertainty around the &lt;code&gt;estimate&lt;/code&gt;-value for each study &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; has already been encoded in the data as &lt;code&gt;std.error&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Let’s look at the model results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(me0)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: estimate | se(std.error) ~ 1 + (1 | loc) 
##    Data: glms (Number of observations: 59) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~loc (Number of levels: 59) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.43      0.09     0.26     0.62 1.00     1956     2389
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     2.55      0.09     2.38     2.72 1.00     3443     2631
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.00      0.00     0.00     0.00 1.00     4000     4000
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our estimate for heterogeneity across studies, &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt;, is about 0.4, suggesting modest differences across the studies. The meta-analytic effect, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;, is about 2.5. Both, recall, are in the log-odds metric. Here we exponentiate &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; to get our odds ratio.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(me0) %&amp;gt;% exp()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           Estimate Est.Error     Q2.5    Q97.5
## Intercept 12.79272  1.091829 10.85899 15.25431&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you look back up to the results reported by Klein and colleagues, you’ll see this is rather close to their OR estimate of 11.54.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;fit-the-bayesian-muiltilevel-alternative.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Fit the Bayesian muiltilevel alternative.&lt;/h3&gt;
&lt;p&gt;We said earlier that meta-analysis is just a special case of the multilevel model, applied to summary data. We typically perform meta-analyses on data summaries because historically it has not been the norm among researchers to make their data publicly available. So effect size summaries were the best we typically had for aggregating study results. However, times are changing (e.g., &lt;a href=&#34;https://www.apa.org/monitor/2017/11/trends-open-science.aspx&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;https://www.blog.google/products/search/making-it-easier-discover-datasets/&#34;&gt;here&lt;/a&gt;). In this case, Klein and colleagues engaged in open-science practices and reported all their data. Thus we can just directly fit the model&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\begin{align*}
\text{y}_{ij} &amp;amp; \sim \operatorname{Binomial}(n = 1, p_{ij}) \\
\operatorname{logit}(p_{ij}) &amp;amp; \sim \alpha + \beta \text{factor}_{ij} + u_{\alpha j} + u_{\beta j} \text{factor}_{ij} \\

\begin{bmatrix} u_{\alpha j} \\ u_{\beta j} \end{bmatrix} &amp;amp; \sim \operatorname{MVNormal} \begin{pmatrix} \begin{bmatrix} 0 \\ 0 \end{bmatrix}, \mathbf{SRS} \end{pmatrix} \\

\mathbf S &amp;amp; = \begin{bmatrix} \sigma_\alpha &amp;amp; 0 \\ 0 &amp;amp; \sigma_\beta \end{bmatrix} \\
\mathbf R &amp;amp; = \begin{bmatrix} 0 &amp;amp; \rho_{\alpha \beta} \\ \rho_{\beta \alpha} &amp;amp; 0 \end{bmatrix} \\

\alpha &amp;amp; \sim \operatorname{Normal}(0, 1.5) \\
\beta  &amp;amp; \sim \operatorname{Normal}(0, 1.5) \\
\sigma_\alpha &amp;amp; \sim \operatorname{Exponential}(1) \\
\sigma_\beta  &amp;amp; \sim \operatorname{Exponential}(1) \\
\mathbf R &amp;amp; \sim \operatorname{LKJ}(2),
\end{align*}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where the criterion variable, &lt;span class=&#34;math inline&#34;&gt;\(y\)&lt;/span&gt;, is nested in &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; participants within &lt;span class=&#34;math inline&#34;&gt;\(j\)&lt;/span&gt; locations. The &lt;span class=&#34;math inline&#34;&gt;\(\beta\)&lt;/span&gt; parameter is analogous to the meta-analytic effect (&lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;) and &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\beta\)&lt;/span&gt; is analogous to the expression of heterogeneity in the meta-analytic effect (&lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt;). Here is how to fit the model with &lt;strong&gt;brms&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;me1 &amp;lt;- 
  brm(data = h, 
      family = binomial,
      y | trials(1) ~ 0 + Intercept + factor + (1 + factor | loc),
      prior = c(prior(normal(0, 1.5), class = b),
                prior(exponential(1), class = sd),
                prior(lkj(2), class = cor)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      seed = 15)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The results for the focal parameters are very similar to those from &lt;code&gt;me0&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(me1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: binomial 
##   Links: mu = logit 
## Formula: y | trials(1) ~ 0 + Intercept + factor + (1 + factor | loc) 
##    Data: h (Number of observations: 6842) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~loc (Number of levels: 59) 
##                                 Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)                       0.42      0.07     0.30     0.57 1.00     2120     2870
## sd(factorSideEffect)                0.48      0.09     0.32     0.66 1.01     1107     2010
## cor(Intercept,factorSideEffect)    -0.31      0.19    -0.62     0.08 1.00     1487     2276
## 
## Population-Level Effects: 
##                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept           -1.66      0.08    -1.82    -1.52 1.00     2012     2675
## factorSideEffect     2.57      0.09     2.39     2.76 1.00     2044     2623
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the multilevel version of the effect size as an odds ratio.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;fixef(me1)[2, -2] %&amp;gt;% exp()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Estimate     Q2.5    Q97.5 
## 13.02704 10.93772 15.73129&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here we compare the study specific effect sizes, &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;, by our two modeling approaches.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;color &amp;lt;- viridis_pal(option = &amp;quot;C&amp;quot;)(7)[3]

# how many levels are there?
n_loc &amp;lt;- distinct(h, loc) %&amp;gt;% count() %&amp;gt;% pull(n)

# rank by meta-analysis
ranks &amp;lt;-
  tibble(Estimate = coef(me0)$loc[, 1, &amp;quot;Intercept&amp;quot;],
         index    = 1:n_loc) %&amp;gt;% 
  arrange(Estimate) %&amp;gt;% 
  mutate(rank = 1:n_loc)

rbind(coef(me0)$loc[, , &amp;quot;Intercept&amp;quot;],
      coef(me1)$loc[, , &amp;quot;factorSideEffect&amp;quot;]) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  mutate(index = rep(1:n_loc, times = 2),
         type  = rep(c(&amp;quot;meta-analysis&amp;quot;, &amp;quot;multilevel model&amp;quot;), each = n_loc)) %&amp;gt;% 
  left_join(select(ranks, -Estimate), 
            by = &amp;quot;index&amp;quot;) %&amp;gt;% 
  
  ggplot(aes(x = Estimate, xmin = Q2.5, xmax = Q97.5, y = rank)) +
  geom_pointrange(fatten = 1, color = color) +
  scale_x_continuous(expression(log-odds~effect~size~(theta[italic(j)])), limits = c(0, 4.5)) +
  scale_y_continuous(NULL, breaks = NULL) +
  facet_wrap(~type)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-16-bayesian-meta-analysis-in-brms-ii/index_files/figure-html/unnamed-chunk-15-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The results are very similar. You might be curious how to show these results in a more conventional looking forest plot where the names of the groups (typically studies) for the &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt; values are listed on the left, the point estimate and 95% interval summaries are listed on the right, and the summary for the population level effect, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt;, is listed beneath all all the &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;’s. That’ll require some prep work. First we’ll need to reformat the location names. I’ll save the results in an object called &lt;code&gt;labs&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;labs &amp;lt;-
  h %&amp;gt;% 
  mutate(lab = case_when(
    Location == &amp;quot;Social and Work Psychology Department, University of Brasilia, DF, Brazil&amp;quot; ~ &amp;quot;University of Brasilia&amp;quot;,
    Location == &amp;quot;Wilfrid Laurier University, Waterloo, Ontario, Canada&amp;quot; ~ &amp;quot;Wilfrid Laurier University&amp;quot;,
    Location == &amp;quot;University of British Columbia, Vancouver, Canada&amp;quot; ~ &amp;quot;University of British Columbia&amp;quot;,
    Location == &amp;quot;University of Toronto, Scarborough&amp;quot; ~ &amp;quot;University of Toronto&amp;quot;,
    Location == &amp;quot;Division of Social Science, The Hong Kong University of Science and Technology, Hong Kong, China&amp;quot; ~ &amp;quot;Hong Kong University of Science and Technology&amp;quot;,
    Location == &amp;quot;Chinese Academy of Science, Beijing, China&amp;quot; ~ &amp;quot;Chinese Academy of Science&amp;quot;,
    Location == &amp;quot;Shanghai International Studies University, SISU Intercultural Institute, Shanghai, China&amp;quot; ~ &amp;quot;Shanghai International Studies University&amp;quot;,
    Location == &amp;quot;Guangdong Literature &amp;amp; Art Vocational College, Guangzhou, China&amp;quot; ~ &amp;quot;Guangdong Literature &amp;amp; Art Vocational College&amp;quot;,
    Location == &amp;quot;The University of J. E. Purkyně, Ústí nad Labem, Czech Republic&amp;quot; ~ &amp;quot;The University of J. E. Purkyně&amp;quot;,
    Location == &amp;quot;University of Leuven, Belgium&amp;quot; ~ &amp;quot;University of Leuven&amp;quot;,
    Location == &amp;quot;Department of Experimental and Applied Psychology, VU Amsterdam, 1081BT, Amsterdam, The Netherlands&amp;quot; ~ &amp;quot;VU Amsterdam&amp;quot;,
    Location == &amp;quot;Department of Social Psychology, Tilburg University, P.O. Box 90153, Tilburg, 5000 LE, Netherlands&amp;quot; ~ &amp;quot;Department of Social Psychology, Tilburg University&amp;quot;,
    Location == &amp;quot;Eindhoven University of Technology, Eindhoven, Netherlands&amp;quot; ~ &amp;quot;Eindhoven University of Technology&amp;quot;,
    Location == &amp;quot;Department of Communication and Information Sciences, P.O. Box 90153, Tilburg, 5000 LE, Netherlands&amp;quot; ~ &amp;quot;Department of Communication and Information Sciences, Tilburg University&amp;quot;,
    Location == &amp;quot;University of Navarra, Spain&amp;quot; ~ &amp;quot;University of Navarra&amp;quot;,
    Location == &amp;quot;University of Lausanne, Switzerland&amp;quot; ~ &amp;quot;University of Lausanne&amp;quot;,
    Location == &amp;quot;Université de Poitiers, France&amp;quot; ~ &amp;quot;Université de Poitiers&amp;quot;,
    Location == &amp;quot;Eotvos Lorand University, in Budapest, Hungary&amp;quot; ~ &amp;quot;Eotvos Lorand University&amp;quot;,
    Location == &amp;quot;MTurk India Workers&amp;quot; ~ &amp;quot;MTurk India Workers&amp;quot;,
    Location == &amp;quot;University of Winchester, Winchester, Hampshire, England&amp;quot; ~ &amp;quot;University of Winchester&amp;quot;,
    Location == &amp;quot;Doshisha University, Kyoto, Japan&amp;quot; ~ &amp;quot;Doshisha University&amp;quot;,
    Location == &amp;quot;Victoria University of Wellington, New Zealand&amp;quot; ~ &amp;quot;Victoria University of Wellington&amp;quot;,
    Location == &amp;quot;University of Social Sciences and Humanities, Wroclaw, Poland&amp;quot; ~ &amp;quot;University of Social Sciences and Humanities&amp;quot;,
    Location == &amp;quot;Department of Psychology, SWPS University of Social Sciences and Humanities Campus Sopot, Sopot, Poland&amp;quot; ~ &amp;quot;SWPS University of Social Sciences and Humanities Campus Sopot&amp;quot;,
    Location == &amp;quot;badania.net&amp;quot; ~ &amp;quot;badania.net&amp;quot;,
    Location == &amp;quot;Universidade do Porto, Portugal&amp;quot; ~ &amp;quot;Universidade do Porto&amp;quot;,
    Location == &amp;quot;University of Belgrade, Belgrade, Serbia&amp;quot; ~ &amp;quot;University of Belgrade&amp;quot;,
    Location == &amp;quot;University of Johannesburg, Johanneburg, South Africa&amp;quot; ~ &amp;quot;University of Johannesburg&amp;quot;,
    Location == &amp;quot;Santiago, Chile&amp;quot; ~ &amp;quot;Santiago, Chile&amp;quot;,
    Location == &amp;quot;Universidad de Costa Rica, Costa Rica&amp;quot; ~ &amp;quot;Universidad de Costa Rica&amp;quot;,
    Location == &amp;quot;National Autonomous University of Mexico in Mexico City&amp;quot; ~ &amp;quot;National Autonomous University of Mexico&amp;quot;,
    Location == &amp;quot;University of the Republic, Montevideo, Uruguay&amp;quot; ~ &amp;quot;University of the Republic&amp;quot;,
    Location == &amp;quot;Lund University, Lund, Sweden&amp;quot; ~ &amp;quot;Lund University&amp;quot;,
    Location == &amp;quot;Academia Sinica, Taiwan National Taiwan Normal University, Taiwan&amp;quot; ~ &amp;quot;Taiwan National Taiwan Normal University&amp;quot;,
    Location == &amp;quot;Bilgi University, Istanbul, Turkey&amp;quot; ~ &amp;quot;Bilgi University&amp;quot;,
    Location == &amp;quot;Koç University, Istanbul, Turkey&amp;quot; ~ &amp;quot;Koç University&amp;quot;,
    Location == &amp;quot;American University of Sharjah, United Arab Emirates&amp;quot; ~ &amp;quot;American University of Sharjah&amp;quot;,
    Location == &amp;quot;University of Hawaii, Honolulu, HI&amp;quot; ~ &amp;quot;University of Hawaii&amp;quot;,
    Location == &amp;quot;Social Science and Policy Studies Department, Worcester Polytechnic Institute, Worcester, MA 01609&amp;quot; ~ &amp;quot;Worcester Polytechnic Institute&amp;quot;,
    Location == &amp;quot;Department of Psychology, Washington and Lee University, Lexington, VA 24450&amp;quot; ~ &amp;quot;Washington and Lee University&amp;quot;,
    Location == &amp;quot;Department of Psychology, San Diego State University, San Diego, CA 92182&amp;quot; ~ &amp;quot;San Diego State University&amp;quot;,
    Location == &amp;quot;Tufts&amp;quot; ~ &amp;quot;Tufts&amp;quot;,
    Location == &amp;quot;University of Florida, Florida&amp;quot; ~ &amp;quot;University of Florida&amp;quot;,
    Location == &amp;quot;University of Illinois at Urbana-Champaign, Champaign, IL&amp;quot; ~ &amp;quot;University of Illinois at Urbana-Champaign&amp;quot;,
    Location == &amp;quot;Pacific Lutheran University, Tacoma, WA&amp;quot; ~ &amp;quot;Pacific Lutheran University&amp;quot;,
    Location == &amp;quot;University of Virginia, VA&amp;quot; ~ &amp;quot;University of Virginia&amp;quot;,
    Location == &amp;quot;Marian University, Indianapolis, IN&amp;quot; ~ &amp;quot;Marian University&amp;quot;,
    Location == &amp;quot;Department of Psychology, Ithaca College, Ithaca, NY 14850&amp;quot; ~ &amp;quot;Ithaca College&amp;quot;,
    Location == &amp;quot;University of Michigan&amp;quot; ~ &amp;quot;University of Michigan&amp;quot;,
    Location == &amp;quot;Department of Psychology, Pennsylvania State University Abington, Abington, PA 19001&amp;quot; ~ &amp;quot;Pennsylvania State University Abington&amp;quot;,
    Location == &amp;quot;Department of Psychology, Texas A&amp;amp;M University, College Station, TX 77843&amp;quot; ~ &amp;quot;Texas A&amp;amp;M University&amp;quot;,
    Location == &amp;quot;William Paterson University, Wayne, NJ&amp;quot; ~ &amp;quot;William Paterson University&amp;quot;,
    Location == &amp;quot;Department of Cognitive Science, Occidental College, Los Angeles, CA&amp;quot; ~ &amp;quot;Occidental College&amp;quot;,
    Location == &amp;quot;The Pennsylvania State University&amp;quot; ~ &amp;quot;The Pennsylvania State University&amp;quot;,
    Location == &amp;quot;MTurk US Workers&amp;quot; ~ &amp;quot;MTurk US Workers&amp;quot;,
    Location == &amp;quot;University of Graz AND the Universty of Vienna&amp;quot; ~ &amp;quot;University of Graz and the Universty of Vienna&amp;quot;,
    Location == &amp;quot;University of Potsdam, Germany&amp;quot; ~ &amp;quot;University of Potsdam&amp;quot;,
    Location == &amp;quot;Open University of Hong Kong&amp;quot; ~ &amp;quot;Open University of Hong Kong&amp;quot;,
    Location == &amp;quot;Concepción, Chile&amp;quot; ~ &amp;quot;Concepción&amp;quot;
  )) %&amp;gt;% 
  distinct(loc, lab)

# what is this?
labs %&amp;gt;% 
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 59
## Columns: 2
## $ loc &amp;lt;fct&amp;gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,…
## $ lab &amp;lt;chr&amp;gt; &amp;quot;University of Brasilia&amp;quot;, &amp;quot;Wilfrid Laurier University&amp;quot;, &amp;quot;University of British Columbi…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we’ll do some tricky wrangling with the output from &lt;code&gt;coef()&lt;/code&gt; and &lt;code&gt;fixef()&lt;/code&gt; to arrange the odds ratio summaries for the population average and the location-specific results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# this will help us format the labels on the secondary y-axis
my_format &amp;lt;- function(number) {
  formatC(number, digits = 2, format = &amp;quot;f&amp;quot;)
}

# grab the theta_j summaries
groups &amp;lt;-
  coef(me1)$loc[, , &amp;quot;factorSideEffect&amp;quot;] %&amp;gt;% 
  data.frame() %&amp;gt;% 
  mutate(loc = distinct(h, loc) %&amp;gt;% pull()) %&amp;gt;% 
  arrange(Estimate)

# grat the mu summary
average &amp;lt;-
  fixef(me1) %&amp;gt;% 
  data.frame() %&amp;gt;% 
  slice(2) %&amp;gt;% 
  mutate(loc = &amp;quot;Average&amp;quot;)

# combine and wrangle
post &amp;lt;-
  bind_rows(groups, average) %&amp;gt;% 
  mutate(rank     = c(1:59, 0),
         Estimate = exp(Estimate),
         Q2.5     = exp(Q2.5),
         Q97.5    = exp(Q97.5)) %&amp;gt;% 
  left_join(labs, by = &amp;quot;loc&amp;quot;) %&amp;gt;% 
  arrange(rank) %&amp;gt;% 
  mutate(label   = ifelse(is.na(lab), &amp;quot;POPULATION AVERAGE&amp;quot;, lab),
         summary = str_c(my_format(Estimate), &amp;quot; [&amp;quot;, my_format(Q2.5), &amp;quot;, &amp;quot;, my_format(Q97.5), &amp;quot;]&amp;quot;))

# what have we done?
post %&amp;gt;% 
  glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 60
## Columns: 9
## $ Estimate  &amp;lt;dbl&amp;gt; 13.027040, 5.994537, 7.225509, 7.894728, 7.896201, 7.989348, 8.158148, 8.425675,…
## $ Est.Error &amp;lt;dbl&amp;gt; 0.09183827, 0.23712115, 0.35418533, 0.32549107, 0.35978096, 0.23125168, 0.343829…
## $ Q2.5      &amp;lt;dbl&amp;gt; 10.937724, 3.752456, 3.537577, 4.170577, 3.898701, 5.147465, 4.109451, 4.488119,…
## $ Q97.5     &amp;lt;dbl&amp;gt; 15.731289, 9.501053, 14.080042, 15.016368, 15.701244, 12.588834, 16.272517, 15.8…
## $ loc       &amp;lt;chr&amp;gt; &amp;quot;Average&amp;quot;, &amp;quot;19&amp;quot;, &amp;quot;38&amp;quot;, &amp;quot;8&amp;quot;, &amp;quot;32&amp;quot;, &amp;quot;55&amp;quot;, &amp;quot;5&amp;quot;, &amp;quot;34&amp;quot;, &amp;quot;22&amp;quot;, &amp;quot;9&amp;quot;, &amp;quot;6&amp;quot;, &amp;quot;58&amp;quot;, &amp;quot;24&amp;quot;, &amp;quot;…
## $ rank      &amp;lt;dbl&amp;gt; 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22…
## $ lab       &amp;lt;chr&amp;gt; NA, &amp;quot;MTurk India Workers&amp;quot;, &amp;quot;University of Hawaii&amp;quot;, &amp;quot;Guangdong Literature &amp;amp; Art V…
## $ label     &amp;lt;chr&amp;gt; &amp;quot;POPULATION AVERAGE&amp;quot;, &amp;quot;MTurk India Workers&amp;quot;, &amp;quot;University of Hawaii&amp;quot;, &amp;quot;Guangdong …
## $ summary   &amp;lt;chr&amp;gt; &amp;quot;13.03 [10.94, 15.73]&amp;quot;, &amp;quot;5.99 [3.75, 9.50]&amp;quot;, &amp;quot;7.23 [3.54, 14.08]&amp;quot;, &amp;quot;7.89 [4.17, …&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s our custom forest plot.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post %&amp;gt;% 
  ggplot(aes(x = Estimate, xmin = Q2.5, xmax = Q97.5, y = rank)) +
  geom_interval(aes(color = label == &amp;quot;POPULATION AVERAGE&amp;quot;),
                size = 1/2) +
  geom_point(aes(size = 1 - Est.Error, color = label == &amp;quot;POPULATION AVERAGE&amp;quot;),
             shape = 15) +
  scale_color_viridis_d(option = &amp;quot;C&amp;quot;, begin = .33, end = .67) +
  scale_size_continuous(range = c(1, 3.5)) +
  scale_x_continuous(&amp;quot;odds ratio&amp;quot;, breaks = 1:6 * 10, expand = expansion(mult = c(0.005, 0.005))) +
  scale_y_continuous(NULL, breaks = 0:59, limits = c(-1, 60), expand = c(0, 0),
                     labels = pull(post, label),
                     sec.axis = dup_axis(labels = pull(post, summary))) +
  theme(text = element_text(family = &amp;quot;Times&amp;quot;),
        axis.text.y = element_text(hjust = 0, color = &amp;quot;white&amp;quot;, size = 7),
        axis.text.y.right = element_text(hjust = 1, size = 7),
        axis.ticks.y = element_blank(),
        panel.background = element_rect(fill = &amp;quot;grey8&amp;quot;),
        panel.border = element_rect(color = &amp;quot;transparent&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-16-bayesian-meta-analysis-in-brms-ii/index_files/figure-html/unnamed-chunk-18-1.png&#34; width=&#34;768&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;You may have noticed this plot is based on the results of our multilevel model, &lt;code&gt;me1&lt;/code&gt;. We could have done the same basic thing with the results from the more conventional meta-analysis model, &lt;code&gt;me0&lt;/code&gt;, too.&lt;/p&gt;
&lt;p&gt;I’m not aware this it typical in random effect meta-analyses, but it might be useful to further clarify the meaning of the two primary parameters, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt;. Like with the forest plot, above, we could examine these with either &lt;code&gt;me0&lt;/code&gt; or &lt;code&gt;me1&lt;/code&gt;. For kicks, we’ll use &lt;code&gt;me0&lt;/code&gt; (the conventional Bayesian meta-analysis). In the output from &lt;code&gt;posterior_samples(me0)&lt;/code&gt;, &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; and &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; are in the columns named &lt;code&gt;b_Intercept&lt;/code&gt; and &lt;code&gt;sd_loc__Intercept&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;post &amp;lt;- posterior_samples(me0)

post %&amp;gt;% 
  select(b_Intercept:sd_loc__Intercept) %&amp;gt;% 
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   b_Intercept sd_loc__Intercept
## 1    2.378526         0.4688289
## 2    2.562858         0.4555103
## 3    2.435846         0.3252279
## 4    2.658129         0.3895584
## 5    2.451356         0.3583352
## 6    2.672061         0.5595212&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you scroll back above, you’ll see our random effect meta-analysis explicitly presumed our empirical effect-size estimates &lt;span class=&#34;math inline&#34;&gt;\(y_j\)&lt;/span&gt; are approximations of the true effect sizes &lt;span class=&#34;math inline&#34;&gt;\(\theta_j\)&lt;/span&gt;, which are themselves normally distributed in the population of possible effect sizes from similar studies: &lt;span class=&#34;math inline&#34;&gt;\(\theta_j \sim \operatorname{Normal}(\mu, \tau)\)&lt;/span&gt;. Why not use our posterior samples to simulate draws from &lt;span class=&#34;math inline&#34;&gt;\(\operatorname{Normal}(\mu, \tau)\)&lt;/span&gt; to get a sense of what this distribution might look like? Recall that the parameters are in the log-odds metric. We’ll present the distribution in that metric and as odds ratios.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;color &amp;lt;- viridis_pal(option = &amp;quot;C&amp;quot;)(7)[6]
set.seed(15)

post %&amp;gt;% 
  transmute(lo = rnorm(n(), mean = b_Intercept, sd = sd_loc__Intercept),
            or = rnorm(n(), mean = b_Intercept, sd = sd_loc__Intercept) %&amp;gt;% exp()) %&amp;gt;% 
  slice(1:1e3) %&amp;gt;% 
  pivot_longer(lo:or, values_to = &amp;quot;effect size&amp;quot;) %&amp;gt;% 
  mutate(name = factor(name, labels = c(&amp;quot;log-odds&amp;quot;, &amp;quot;odds ratio&amp;quot;))) %&amp;gt;% 
  
  ggplot(aes(x = `effect size`, y = 0)) +
  geom_dots(color = color, fill = color) +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(expression(Normal(mu*&amp;#39;, &amp;#39;*tau))) +
  theme(text = element_text(family = &amp;quot;Times&amp;quot;),
        strip.background = element_rect(color = &amp;quot;transparent&amp;quot;)) +
  facet_wrap(~name, scales = &amp;quot;free&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020-10-16-bayesian-meta-analysis-in-brms-ii/index_files/figure-html/unnamed-chunk-20-1.png&#34; width=&#34;672&#34; style=&#34;display: block; margin: auto;&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Both panels show 1,000 draws, each of which is depicted by a single dot. If we were to run this experiment 1,000 times and compute the effect size separately for each one, this is what we’d expect those distributions of effect sizes to look like. Seems like there’s a lot of variation in there, eh? The next time you observe your fellow scientists debating over whether a study replicated or not, keep these distributions in mind. Once you start thinking about distributions, replication becomes a tricky notion.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;parting-thoughts.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Parting thoughts.&lt;/h3&gt;
&lt;p&gt;There are other things you might do with these data. For example, you might inspect how much the effect size varies between those from WEIRD and non-WEIRD countries. You might also model the data as clustered by &lt;code&gt;Language&lt;/code&gt; rather than by &lt;code&gt;Location&lt;/code&gt;. But I think we’ve gone far enough to get you started.&lt;/p&gt;
&lt;p&gt;If you’d like to learn more about these methods, do check out Vourre’s &lt;a href=&#34;https://mvuorre.github.io/post/2016/09/29/meta-analysis-is-a-special-case-of-bayesian-multilevel-modeling/&#34;&gt;&lt;em&gt;Meta-analysis is a special case of Bayesian multilevel modeling&lt;/em&gt;&lt;/a&gt;. You might also read Williams, Rast, and Bürkner’s &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-williamsBayesianMetaanalysisWeakly2018&#34; role=&#34;doc-biblioref&#34;&gt;2018&lt;/a&gt;)&lt;/span&gt; manuscript, &lt;a href=&#34;https://psyarxiv.com/7tbrm/&#34;&gt;&lt;em&gt;Bayesian meta-analysis with weakly informative prior distributions&lt;/em&gt;&lt;/a&gt;. For an alternative workflow, consider the &lt;a href=&#34;https://github.com/wwiecek/baggr&#34;&gt;&lt;strong&gt;baggr&lt;/strong&gt; package&lt;/a&gt; &lt;span class=&#34;citation&#34;&gt;(&lt;a href=&#34;#ref-R-baggr&#34; role=&#34;doc-biblioref&#34;&gt;Wiecek &amp;amp; Meager, 2020&lt;/a&gt;)&lt;/span&gt;, which is designed to fit hierarchical Bayesian meta-analyses with Stan under the hood.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.3.1   broom_0.7.5       viridis_0.5.1     viridisLite_0.3.0 ggdark_0.2.1     
##  [6] brms_2.15.0       Rcpp_1.0.6        forcats_0.5.1     stringr_1.4.0     dplyr_1.0.5      
## [11] purrr_0.3.4       readr_1.4.0       tidyr_1.1.3       tibble_3.1.0      ggplot2_3.3.3    
## [16] tidyverse_1.3.0  
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6           igraph_1.2.6        
##   [5] svUnit_1.0.3         splines_4.0.4        crosstalk_1.1.0.1    TH.data_1.0-10      
##   [9] rstantools_2.1.1     inline_0.3.17        digest_0.6.27        htmltools_0.5.1.1   
##  [13] rsconnect_0.8.16     fansi_0.4.2          magrittr_2.0.1       modelr_0.1.8        
##  [17] RcppParallel_5.0.2   matrixStats_0.57.0   xts_0.12.1           sandwich_3.0-0      
##  [21] prettyunits_1.1.1    colorspace_2.0-0     rvest_0.3.6          ggdist_2.4.0.9000   
##  [25] haven_2.3.1          xfun_0.22            callr_3.5.1          crayon_1.4.1        
##  [29] jsonlite_1.7.2       lme4_1.1-25          survival_3.2-10      zoo_1.8-8           
##  [33] glue_1.4.2           gtable_0.3.0         emmeans_1.5.2-1      V8_3.4.0            
##  [37] distributional_0.2.2 pkgbuild_1.2.0       rstan_2.21.2         abind_1.4-5         
##  [41] scales_1.1.1         mvtnorm_1.1-1        DBI_1.1.0            miniUI_0.1.1.1      
##  [45] xtable_1.8-4         stats4_4.0.4         StanHeaders_2.21.0-7 DT_0.16             
##  [49] htmlwidgets_1.5.2    httr_1.4.2           threejs_0.3.3        arrayhelpers_1.1-0  
##  [53] ellipsis_0.3.1       farver_2.0.3         pkgconfig_2.0.3      loo_2.4.1           
##  [57] dbplyr_2.0.0         utf8_1.1.4           labeling_0.4.2       tidyselect_1.1.0    
##  [61] rlang_0.4.10         reshape2_1.4.4       later_1.1.0.1        munsell_0.5.0       
##  [65] cellranger_1.1.0     tools_4.0.4          cli_2.3.1            generics_0.1.0      
##  [69] ggridges_0.5.2       evaluate_0.14        fastmap_1.0.1        yaml_2.2.1          
##  [73] processx_3.4.5       knitr_1.31           fs_1.5.0             nlme_3.1-152        
##  [77] mime_0.10            projpred_2.0.2       xml2_1.3.2           compiler_4.0.4      
##  [81] bayesplot_1.8.0      shinythemes_1.1.2    rstudioapi_0.13      gamm4_0.2-6         
##  [85] curl_4.3             reprex_0.3.0         statmod_1.4.35       stringi_1.5.3       
##  [89] highr_0.8            ps_1.6.0             blogdown_1.3         Brobdingnag_1.2-6   
##  [93] lattice_0.20-41      Matrix_1.3-2         nloptr_1.2.2.2       markdown_1.1        
##  [97] shinyjs_2.0.0        vctrs_0.3.6          pillar_1.5.1         lifecycle_1.0.0     
## [101] bridgesampling_1.0-0 estimability_1.3     httpuv_1.5.4         R6_2.5.0            
## [105] bookdown_0.21        promises_1.1.1       gridExtra_2.3        codetools_0.2-18    
## [109] boot_1.3-26          colourpicker_1.1.0   MASS_7.3-53          gtools_3.8.2        
## [113] assertthat_0.2.1     withr_2.4.1          shinystan_2.5.0      multcomp_1.4-16     
## [117] mgcv_1.8-33          parallel_4.0.4       hms_0.5.3            grid_4.0.4          
## [121] coda_0.19-4          minqa_1.2.4          rmarkdown_2.7        shiny_1.5.0         
## [125] lubridate_1.7.9.2    base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;references&#34; class=&#34;section level2 unnumbered&#34;&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;div id=&#34;refs&#34; class=&#34;references csl-bib-body hanging-indent&#34; line-spacing=&#34;2&#34;&gt;
&lt;div id=&#34;ref-gelman2013bayesian&#34; class=&#34;csl-entry&#34;&gt;
Gelman, A., Carlin, J. B., Stern, H. S., Dunson, D. B., Vehtari, A., &amp;amp; Rubin, D. B. (2013). &lt;em&gt;Bayesian data analysis&lt;/em&gt; (Third Edition). &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://stat.columbia.edu/~gelman/book/&#34;&gt;https://stat.columbia.edu/~gelman/book/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-hauserDissociationMoralJudgments2007&#34; class=&#34;csl-entry&#34;&gt;
Hauser, M., Cushman, F., Young, L., Jin, R. K.-X., &amp;amp; Mikhail, J. (2007). A dissociation between moral judgments and justifications. &lt;em&gt;Mind &amp;amp; Language&lt;/em&gt;, &lt;em&gt;22&lt;/em&gt;(1), 1–21. &lt;a href=&#34;https://doi.org/10.1111/j.1468-0017.2006.00297.x&#34;&gt;https://doi.org/10.1111/j.1468-0017.2006.00297.x&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kleinManyLabsInvestigating2018&#34; class=&#34;csl-entry&#34;&gt;
Klein, R. A., Vianello, M., Hasselman, F., Adams, B. G., Adams, R. B., Alper, S., Aveyard, M., Axt, J. R., Babalola, M. T., Bahník, Š., Batra, R., Berkics, M., Bernstein, M. J., Berry, D. R., Bialobrzeska, O., Binan, E. D., Bocian, K., Brandt, M. J., Busching, R., … Nosek, B. A. (2018). Many &lt;span&gt;Labs&lt;/span&gt; 2: &lt;span&gt;Investigating&lt;/span&gt; variation in replicability across samples and settings. &lt;em&gt;Advances in Methods and Practices in Psychological Science&lt;/em&gt;, &lt;em&gt;1&lt;/em&gt;(4), 443–490. &lt;a href=&#34;https://doi.org/10.1177/2515245918810225&#34;&gt;https://doi.org/10.1177/2515245918810225&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kurzStatisticalRethinkingBrms2020&#34; class=&#34;csl-entry&#34;&gt;
Kurz, A. S. (2020a). &lt;em&gt;Statistical rethinking with brms, &lt;span class=&#34;nocase&#34;&gt;ggplot2&lt;/span&gt;, and the tidyverse&lt;/em&gt; (version 1.2.0). &lt;a href=&#34;https://doi.org/10.5281/zenodo.3693202&#34;&gt;https://doi.org/10.5281/zenodo.3693202&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-kurzStatisticalRethinkingSecondEd2020&#34; class=&#34;csl-entry&#34;&gt;
Kurz, A. S. (2020b). &lt;em&gt;Statistical rethinking with brms, Ggplot2, and the tidyverse: &lt;span&gt;Second&lt;/span&gt; edition&lt;/em&gt; (version 0.1.1). &lt;a href=&#34;https://bookdown.org/content/4857/&#34;&gt;https://bookdown.org/content/4857/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2020&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2020). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt; (Second Edition). &lt;span&gt;CRC Press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-mcelreathStatisticalRethinkingBayesian2015&#34; class=&#34;csl-entry&#34;&gt;
McElreath, R. (2015). &lt;em&gt;Statistical rethinking: &lt;span&gt;A Bayesian&lt;/span&gt; course with examples in &lt;span&gt;R&lt;/span&gt; and &lt;span&gt;Stan&lt;/span&gt;&lt;/em&gt;. &lt;span&gt;CRC press&lt;/span&gt;. &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;https://xcelab.net/rm/statistical-rethinking/&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-R-baggr&#34; class=&#34;csl-entry&#34;&gt;
Wiecek, W., &amp;amp; Meager, R. (2020). &lt;em&gt;&lt;span class=&#34;nocase&#34;&gt;baggr&lt;/span&gt;: &lt;span&gt;Bayesian&lt;/span&gt; aggregate treatment effects&lt;/em&gt; [Manual]. &lt;a href=&#34;https://CRAN.R-project.org/package=baggr&#34;&gt;https://CRAN.R-project.org/package=baggr&lt;/a&gt;
&lt;/div&gt;
&lt;div id=&#34;ref-williamsBayesianMetaanalysisWeakly2018&#34; class=&#34;csl-entry&#34;&gt;
Williams, D. R., Rast, P., &amp;amp; Bürkner, P.-C. (2018). &lt;em&gt;Bayesian meta-analysis with weakly informative prior distributions&lt;/em&gt;. &lt;a href=&#34;https://doi.org/10.31234/osf.io/7tbrm&#34;&gt;https://doi.org/10.31234/osf.io/7tbrm&lt;/a&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Bayesian meta-analysis in brms</title>
      <link>/post/bayesian-meta-analysis/</link>
      <pubDate>Sun, 14 Oct 2018 00:00:00 +0000</pubDate>
      <guid>/post/bayesian-meta-analysis/</guid>
      <description>
&lt;script src=&#34;/post/bayesian-meta-analysis/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;[edited Apr 21, 2021]&lt;/p&gt;
&lt;div id=&#34;preamble&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Preamble&lt;/h2&gt;
&lt;p&gt;I released the first &lt;a href=&#34;https://bookdown.org&#34;&gt;bookdown&lt;/a&gt; version of my &lt;a href=&#34;https://bookdown.org/content/3890/&#34;&gt;&lt;em&gt;Statistical Rethinking&lt;/em&gt; with brms, ggplot2, and the tidyverse&lt;/a&gt; project a couple weeks ago. I consider it the 0.9.0 version&lt;a href=&#34;#fn1&#34; class=&#34;footnote-ref&#34; id=&#34;fnref1&#34;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. I wanted a little time to step back from the project before giving it a final edit for the first major edition. I also wanted to give others a little time to take a look and suggest edits, which some thankfully have.&lt;/p&gt;
&lt;p&gt;Now some time has passed, it’s become clear I’d like to add a bonus section on Bayesian meta-analysis. IMO, this is a natural extension of the hierarchical models McElreath introduced in chapter’s 12 and 13 of &lt;a href=&#34;https://xcelab.net/rm/statistical-rethinking/&#34;&gt;his text&lt;/a&gt; and of the measurement-error models he introduced in chapter 14. So the purpose of this post is to present a rough draft of how I’d like to introduce fitting meta-analyses with Bürkner’s great brms package.&lt;/p&gt;
&lt;p&gt;I intend to tack this section onto the end of chapter 14. If you have any &lt;a href=&#34;https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse/issues&#34;&gt;constrictive criticisms, please pass them along&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here’s the rough draft (which I updated on 2018-11-12):&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;rough-draft-meta-analysis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Rough draft: Meta-analysis&lt;/h2&gt;
&lt;p&gt;If your mind isn’t fully blown by those measurement-error and missing-data models, let’s keep building. As it turns out, meta-analyses are often just special kinds of multilevel measurement-error models. Thus, you can use &lt;code&gt;brms::brm()&lt;/code&gt; to fit Bayesian meta-analyses, too.&lt;/p&gt;
&lt;p&gt;Before we proceed, I should acknowledge that this section is heavily influenced by Matti Vourre’s great blog post, &lt;a href=&#34;https://mvuorre.github.io/blog/posts/2016-09-29-bayesian-meta-analysis/&#34;&gt;&lt;em&gt;Meta-analysis is a special case of Bayesian multilevel modeling&lt;/em&gt;&lt;/a&gt;. And since McElreath’s text doesn’t directly address meta-analyses, we’ll take further inspiration from Gelman, Carlin, Stern, Dunson, Vehtari, and Rubin’s &lt;a href=&#34;http://www.stat.columbia.edu/~gelman/book/&#34;&gt;&lt;em&gt;Bayesian data analysis, Third edition&lt;/em&gt;&lt;/a&gt;. We’ll let Gelman and colleagues introduce the topic:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Discussions of meta-analysis are sometimes imprecise about the estimands of interest in the analysis, especially when the primary focus is on testing the null hypothesis of no effect in any of the studies to be combined. Our focus is on estimating meaningful parameters, and for this objective there appear to be three possibilities, accepting the overarching assumption that the studies are comparable in some broad sense. The first possibility is that we view the studies as identical replications of each other, in the sense we regard the individuals in all the studies as independent samples from a common population, with the same outcome measures and so on. A second possibility is that the studies are so different that the results of any one study provide no information about the results of any of the others. A third, more general, possibility is that we regard the studies as exchangeable but not necessarily either identical or completely unrelated; in other words we allow differences from study to study, but such that the differences are not expected &lt;em&gt;a priori&lt;/em&gt; to have predictable effects favoring one study over another.… This third possibility represents a continuum between the two extremes, and it is this exchangeable model (with unknown hyperparameters characterizing the population distribution) that forms the basis of our Bayesian analysis…&lt;/p&gt;
&lt;p&gt;The first potential estimand of a meta-analysis, or a hierarchically structured problem in general, is the mean of the distribution of effect sizes, since this represents the overall ‘average’ effect across all studies that could be regarded as exchangeable with the observed studies. Other possible estimands are the effect size in any of the observed studies and the effect size in another, comparable (exchangeable) unobserved study. (pp. 125–126, &lt;em&gt;emphasis&lt;/em&gt; in the original)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The basic version of a Bayesian meta-analysis follows the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[y_i \sim \text{Normal}(\theta_i, \sigma_i)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(y_i\)&lt;/span&gt; = the point estimate for the effect size of a single study, &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt;, which is presumed to have been a draw from a Normal distribution centered on &lt;span class=&#34;math inline&#34;&gt;\(\theta_i\)&lt;/span&gt;. The data in meta-analyses are typically statistical summaries from individual studies. The one clear lesson from this chapter is that those estimates themselves come with error and those errors should be fully expressed in the meta-analytic model. Which we do. The standard error from study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is specified &lt;span class=&#34;math inline&#34;&gt;\(\sigma_i\)&lt;/span&gt;, which is also a stand-in for the standard deviation of the Normal distribution from which the point estimate was drawn. Do note, we’re not estimating &lt;span class=&#34;math inline&#34;&gt;\(\sigma_i\)&lt;/span&gt;, here. Those values we take directly from the original studies.&lt;/p&gt;
&lt;p&gt;Building on the model, we further presume that study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; is itself just one draw from a population of related studies, each of which have their own effect sizes. As such. we presume &lt;span class=&#34;math inline&#34;&gt;\(\theta_i\)&lt;/span&gt; itself has a distribution following the form&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\theta_i \sim \text{Normal} (\mu, \tau)\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where &lt;span class=&#34;math inline&#34;&gt;\(\mu\)&lt;/span&gt; is the meta-analytic effect (i.e., the population mean) and &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; is the variation around that mean, what you might also think of as &lt;span class=&#34;math inline&#34;&gt;\(\sigma_\tau\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Since there’s no example of a meta-analysis in the text, we’ll have to look elsewhere. We’ll focus on Gershoff and Grogan-Kaylor’s (2016) paper, &lt;a href=&#34;https://pdfs.semanticscholar.org/0d03/a2e9f085f0a268b4c0a52f5ac31c17a3e5f3.pdf&#34;&gt;&lt;em&gt;Spanking and Child Outcomes: Old Controversies and New Meta-Analyses&lt;/em&gt;&lt;/a&gt;. From their introduction, we read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Around the world, most children (80%) are spanked or otherwise physically punished by their parents (&lt;a href=&#34;https://www.unicef.org/publications/index_74865.html&#34;&gt;UNICEF, 2014&lt;/a&gt;). The question of whether parents should spank their children to correct misbehaviors sits at a nexus of arguments from ethical, religious, and human rights perspectives both in the U.S. and around the world (&lt;a href=&#34;https://onlinelibrary.wiley.com/doi/abs/10.1111/cdep.12038&#34;&gt;Gershoff, 2013&lt;/a&gt;). Several hundred studies have been conducted on the associations between parents’ use of spanking or physical punishment and children’s behavioral, emotional, cognitive, and physical outcomes, making spanking one of the most studied aspects of parenting. What has been learned from these hundreds of studies? (p. 453)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Our goal will be to learn Bayesian meta-analysis by answering part of that question. I’ve transcribed the values directly from Gershoff and Grogan-Kaylor’s paper and saved them as a file called &lt;code&gt;spank.xlsx&lt;/code&gt;.
You can find the data in &lt;a href=&#34;https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse&#34;&gt;this project’s GitHub repository&lt;/a&gt;. Let’s load them and &lt;code&gt;glimpse()&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spank &amp;lt;- readxl::read_excel(&amp;quot;spank.xlsx&amp;quot;)

library(tidyverse)
glimpse(spank)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 111
## Columns: 8
## $ study   &amp;lt;chr&amp;gt; &amp;quot;Bean and Roberts (1981)&amp;quot;, &amp;quot;Day and Roberts (1983)&amp;quot;, &amp;quot;Minton, …
## $ year    &amp;lt;dbl&amp;gt; 1981, 1983, 1971, 1988, 1990, 1961, 1962, 1990, 2002, 2005, 19…
## $ outcome &amp;lt;chr&amp;gt; &amp;quot;Immediate defiance&amp;quot;, &amp;quot;Immediate defiance&amp;quot;, &amp;quot;Immediate defianc…
## $ between &amp;lt;dbl&amp;gt; 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,…
## $ within  &amp;lt;dbl&amp;gt; 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,…
## $ d       &amp;lt;dbl&amp;gt; -0.74, 0.36, 0.34, -0.08, 0.10, 0.63, 0.19, 0.47, 0.14, -0.18,…
## $ ll      &amp;lt;dbl&amp;gt; -1.76, -1.04, -0.09, -1.01, -0.82, 0.16, -0.14, 0.20, -0.42, -…
## $ ul      &amp;lt;dbl&amp;gt; 0.28, 1.77, 0.76, 0.84, 1.03, 1.10, 0.53, 0.74, 0.70, 0.13, 2.…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In this paper, the effect size of interest is a &lt;em&gt;Cohen’s d&lt;/em&gt;, derived from the formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[d = \frac{\mu_\text{treatment} - \mu_\text{comparison}}{\sigma_{pooled}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;where&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[\sigma_{pooled} = \sqrt{\frac{((n_1 - 1) \sigma_1^2) + ((n_2 - 1) \sigma_2^2)}{n_1 + n_2 -2}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;To help make the equation for &lt;span class=&#34;math inline&#34;&gt;\(d\)&lt;/span&gt; clearer for our example, we might re-express it as&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[d = \frac{\mu_\text{spanked} - \mu_\text{not spanked}}{\sigma_{pooled}}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;McElreath didn’t really focus on effect sizes in his text. If you need a refresher, you might check out Kelley and Preacher’s &lt;a href=&#34;https://www.researchgate.net/profile/Ken_Kelley/publication/270757972_On_Effect_Size/links/0046351b0cd48217ce000000/On-Effect-Size.pdf&#34;&gt;&lt;em&gt;On effect size&lt;/em&gt;&lt;/a&gt;. But in words, &lt;em&gt;Cohen’s d&lt;/em&gt; is a standardized mean difference between two groups.&lt;/p&gt;
&lt;p&gt;So if you look back up at the results of &lt;code&gt;glimpse(spank)&lt;/code&gt;, you’ll notice the column &lt;code&gt;d&lt;/code&gt;, which is indeed a vector of &lt;em&gt;Cohen’s d&lt;/em&gt; effect sizes. The last two columns, &lt;code&gt;ll&lt;/code&gt; and &lt;code&gt;ul&lt;/code&gt; are the lower and upper limits of the associated 95% frequentist confidence intervals. But we don’t want confidence intervals for our &lt;code&gt;d&lt;/code&gt;-values; we want their standard errors. Fortunately, we can compute those with the following formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[SE = \frac{\text{upper limit } – \text{lower limit}}{3.92}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here it is in code.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spank &amp;lt;-
  spank %&amp;gt;% 
  mutate(se = (ul - ll) / 3.92)

glimpse(spank)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Rows: 111
## Columns: 9
## $ study   &amp;lt;chr&amp;gt; &amp;quot;Bean and Roberts (1981)&amp;quot;, &amp;quot;Day and Roberts (1983)&amp;quot;, &amp;quot;Minton, …
## $ year    &amp;lt;dbl&amp;gt; 1981, 1983, 1971, 1988, 1990, 1961, 1962, 1990, 2002, 2005, 19…
## $ outcome &amp;lt;chr&amp;gt; &amp;quot;Immediate defiance&amp;quot;, &amp;quot;Immediate defiance&amp;quot;, &amp;quot;Immediate defianc…
## $ between &amp;lt;dbl&amp;gt; 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,…
## $ within  &amp;lt;dbl&amp;gt; 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,…
## $ d       &amp;lt;dbl&amp;gt; -0.74, 0.36, 0.34, -0.08, 0.10, 0.63, 0.19, 0.47, 0.14, -0.18,…
## $ ll      &amp;lt;dbl&amp;gt; -1.76, -1.04, -0.09, -1.01, -0.82, 0.16, -0.14, 0.20, -0.42, -…
## $ ul      &amp;lt;dbl&amp;gt; 0.28, 1.77, 0.76, 0.84, 1.03, 1.10, 0.53, 0.74, 0.70, 0.13, 2.…
## $ se      &amp;lt;dbl&amp;gt; 0.52040816, 0.71683673, 0.21683673, 0.47193878, 0.47193878, 0.…&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now our data are ready, we can express our first Bayesian meta-analysis with the formula&lt;/p&gt;
&lt;p&gt;&lt;span class=&#34;math display&#34;&gt;\[
\begin{eqnarray}
\text{d}_i &amp;amp; \sim &amp;amp; \text{Normal}(\theta_i, \sigma_i = \text{se}_i) \\
\theta_i &amp;amp; \sim &amp;amp; \text{Normal} (\mu, \tau) \\
\mu &amp;amp; \sim &amp;amp; \text{Normal} (0, 1) \\
\tau &amp;amp; \sim &amp;amp; \text{HalfCauchy} (0, 1)
\end{eqnarray}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The last two lines, of course, spell out our priors. In psychology, it’s pretty rare to see &lt;em&gt;Cohen’s d&lt;/em&gt;-values greater than the absolute value of &lt;span class=&#34;math inline&#34;&gt;\(\pm 1\)&lt;/span&gt;. So in the absence of more specific domain knowledge–which I don’t have–, it seems like &lt;span class=&#34;math inline&#34;&gt;\(\text{Normal} (0, 1)\)&lt;/span&gt; is a reasonable place to start. And just like McElreath used &lt;span class=&#34;math inline&#34;&gt;\(\text{HalfCauchy} (0, 1)\)&lt;/span&gt; as the default prior for the group-level standard deviations, &lt;a href=&#34;https://psyarxiv.com/7tbrm/&#34;&gt;it makes sense to use it here&lt;/a&gt; for our meta-analytic &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; parameter.&lt;/p&gt;
&lt;p&gt;Let’s load brms.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(brms)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here’s the code for the first model.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b14.5 &amp;lt;- 
  brm(data = spank, family = gaussian,
      d | se(se) ~ 1 + (1 | study),
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(cauchy(0, 1), class = sd)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      seed = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;One thing you might notice is our &lt;code&gt;se(se)&lt;/code&gt; function excluded the &lt;code&gt;sigma&lt;/code&gt; argument. If you recall from section 14.1, we specified &lt;code&gt;sigma = T&lt;/code&gt; in our measurement-error models. The brms default is that within &lt;code&gt;se()&lt;/code&gt;, &lt;code&gt;sigma = FALSE&lt;/code&gt;. As such, we have no estimate for sigma the way we would if we were doing this analysis with the raw data from the studies. Hopefully this makes sense. The uncertainty around the &lt;code&gt;d&lt;/code&gt;-value for each study &lt;span class=&#34;math inline&#34;&gt;\(i\)&lt;/span&gt; has already been encoded in the data as &lt;code&gt;se&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;This brings us to another point. We typically perform meta-analyses on data summaries. In my field and perhaps in yours, this is due to the historical accident that it has not been the norm among researchers to make their data publicly available. So effect size summaries were the best we typically had. However, times are changing (e.g., &lt;a href=&#34;https://www.apa.org/monitor/2017/11/trends-open-science.aspx&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;https://www.blog.google/products/search/making-it-easier-discover-datasets/&#34;&gt;here&lt;/a&gt;). If the raw data from all the studies for your meta-analysis are available, you can just fit a multilevel model in which the data are nested in the studies. Heck, you could even allow the studies to vary by &lt;span class=&#34;math inline&#34;&gt;\(\sigma\)&lt;/span&gt; by taking the &lt;a href=&#34;https://cran.r-project.org/web/packages/brms/vignettes/brms_distreg.html#a-simple-distributional-model&#34;&gt;distributional modeling approach&lt;/a&gt; and specify something like &lt;code&gt;sigma ~ 0 + study&lt;/code&gt; or even &lt;code&gt;sigma ~ 1 + (1 | study)&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;But enough technical talk. Let’s look at the model results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(b14.5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: d | se(se) ~ 1 + (1 | study) 
##    Data: spank (Number of observations: 111) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~study (Number of levels: 76) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.26      0.03     0.21     0.33 1.01      754     1582
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.38      0.04     0.31     0.45 1.00      605     1021
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.00      0.00     0.00     0.00 1.00     4000     4000
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thus, in our simple Bayesian meta-analysis, we have a population &lt;em&gt;Cohen’s d&lt;/em&gt; of about 0.38. Our estimate for &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt;, 0.26, suggests we have quite a bit of between-study variability. One question you might ask is: &lt;em&gt;What exactly are these&lt;/em&gt; Cohen’s d&lt;em&gt;s measuring, anyways?&lt;/em&gt; We’ve encoded that in the &lt;code&gt;outcome&lt;/code&gt; vector of the &lt;code&gt;spank&lt;/code&gt; data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spank %&amp;gt;% 
  distinct(outcome) %&amp;gt;% 
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;outcome&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Immediate defiance&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Low moral internalization&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Child aggression&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Child antisocial behavior&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Child externalizing behavior problems&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Child internalizing behavior problems&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Child mental health problems&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Child alcohol or substance abuse&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Negative parent–child relationship&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Impaired cognitive ability&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Low self-esteem&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Low self-regulation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Victim of physical abuse&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Adult antisocial behavior&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Adult mental health problems&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Adult alcohol or substance abuse&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Adult support for physical punishment&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There are a few things to note. First, with the possible exception of &lt;code&gt;Adult support for physical punishment&lt;/code&gt;, all of the outcomes are negative. We prefer conditions associated with lower values for things like &lt;code&gt;Child aggression&lt;/code&gt; and &lt;code&gt;Adult mental health problems&lt;/code&gt;. Second, the way the data are coded, larger effect sizes are interpreted as more negative outcomes associated with children having been spanked. That is, our analysis suggests spanking children is associated with worse outcomes. What might not be immediately apparent is that even though there are 111 cases in the data, there are only 76 distinct studies.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spank %&amp;gt;% 
  distinct(study) %&amp;gt;% 
  count()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##       n
##   &amp;lt;int&amp;gt;
## 1    76&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In other words, some studies have multiple outcomes. In order to better accommodate the &lt;code&gt;study&lt;/code&gt;- and &lt;code&gt;outcome&lt;/code&gt;-level variances, let’s fit a cross-classified Bayesian meta-analysis reminiscent of the cross-classified chimp model from Chapter 13.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b14.6 &amp;lt;- 
  brm(data = spank, family = gaussian,
      d | se(se) ~ 1 + (1 | study) + (1 | outcome),
      prior = c(prior(normal(0, 1), class = Intercept),
                prior(cauchy(0, 1), class = sd)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      seed = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(b14.6)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: d | se(se) ~ 1 + (1 | study) + (1 | outcome) 
##    Data: spank (Number of observations: 111) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~outcome (Number of levels: 17) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.08      0.03     0.04     0.14 1.00     1018     1756
## 
## ~study (Number of levels: 76) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.25      0.03     0.20     0.31 1.00      827     1571
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## Intercept     0.36      0.04     0.28     0.43 1.01      664     1562
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.00      0.00     0.00     0.00 1.00     4000     4000
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we have two &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; parameters. We might plot them to get a sense of where the variance is at.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(b14.6) %&amp;gt;% 
  select(starts_with(&amp;quot;sd&amp;quot;)) %&amp;gt;% 
  gather(key, tau) %&amp;gt;% 
  mutate(key = str_remove(key, &amp;quot;sd_&amp;quot;) %&amp;gt;% str_remove(., &amp;quot;__Intercept&amp;quot;)) %&amp;gt;% 
  
  ggplot(aes(x = tau, fill = key)) +
  geom_density(color = &amp;quot;transparent&amp;quot;, alpha = 2/3) +
  scale_fill_viridis_d(NULL, end = .85) +
  scale_y_continuous(NULL, breaks = NULL) +
  xlab(expression(tau)) +
  theme(panel.grid = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-meta-analysis/index_files/figure-html/unnamed-chunk-8-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;So at this point, the big story is there’s more variability between the studies than there is the outcomes. But I still want to get a sense of the individual outcomes. Here we’ll use &lt;code&gt;tidybayes::stat_halfeye()&lt;/code&gt; to help us make our version of a &lt;a href=&#34;https://cran.r-project.org/web/packages/forestplot/vignettes/forestplot.html&#34;&gt;forest plot&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# load tidybayes
library(tidybayes)

b14.6 %&amp;gt;%
  spread_draws(b_Intercept, r_outcome[outcome,]) %&amp;gt;%
  # add the grand mean to the group-specific deviations
  mutate(mu = b_Intercept + r_outcome) %&amp;gt;%
  ungroup() %&amp;gt;%
  mutate(outcome = str_replace_all(outcome, &amp;quot;[.]&amp;quot;, &amp;quot; &amp;quot;)) %&amp;gt;% 

  # plot
  ggplot(aes(x = mu, y = reorder(outcome, mu))) +
  geom_vline(xintercept = fixef(b14.6)[1, 1], color = &amp;quot;white&amp;quot;, size = 1) +
  geom_vline(xintercept = fixef(b14.6)[1, 3:4], color = &amp;quot;white&amp;quot;, linetype = 2) +
  stat_halfeye(.width = .95, size = 2/3) +
  labs(x = expression(italic(&amp;quot;Cohen&amp;#39;s d&amp;quot;)),
       y = NULL) +
  theme(panel.grid   = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y  = element_text(hjust = 0))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-meta-analysis/index_files/figure-html/unnamed-chunk-9-1.png&#34; width=&#34;480&#34; /&gt;&lt;/p&gt;
&lt;p&gt;The solid and dashed vertical white lines in the background mark off the grand mean (i.e., the meta-analytic effect) and its 95% intervals. But anyway, there’s not a lot of variability across the outcomes. Let’s go one step further with the model. Doubling back to Gelman and colleagues, we read:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;When assuming exchangeability we assume there are no important covariates that might form the basis of a more complex model, and this assumption (perhaps misguidedly) is widely adopted in meta-analysis. What if other information (in addition to the data &lt;span class=&#34;math inline&#34;&gt;\((n, y)\)&lt;/span&gt;) is available to distinguish among the &lt;span class=&#34;math inline&#34;&gt;\(J\)&lt;/span&gt; studies in a meta-analysis, so that an exchangeable model is inappropriate? In this situation, we can expand the framework of the model to be exchangeable in the observed data and covariates, for example using a hierarchical regression model. (p. 126)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One important covariate Gershoff and Grogan-Kaylor addressed in their meta-analysis was the type of study. The 76 papers they based their meta-analysis on contained both between- and within-participants designs. In the &lt;code&gt;spank&lt;/code&gt; data, we’ve dummy coded that information with the &lt;code&gt;between&lt;/code&gt; and &lt;code&gt;within&lt;/code&gt; vectors. Both are dummy variables and &lt;code&gt;within&lt;/code&gt; = 1 - &lt;code&gt;between&lt;/code&gt;. Here are the counts.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;spank %&amp;gt;% 
  count(between)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 2 x 2
##   between     n
##     &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1       0    71
## 2       1    40&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When I use dummies in my models, I prefer to have the majority group stand as the reference category. As such, I typically name those variables by the minority group. In this case, most occasions are based on within-participant designs. Thus, we’ll go ahead and add the &lt;code&gt;between&lt;/code&gt; variable to the model. While we’re at it, we’ll practice using the &lt;code&gt;0 + intercept&lt;/code&gt; syntax.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;b14.7 &amp;lt;- 
  brm(data = spank, family = gaussian,
      d | se(se) ~ 0 + intercept + between + (1 | study) + (1 | outcome),
      prior = c(prior(normal(0, 1), class = b),
                prior(cauchy(0, 1), class = sd)),
      iter = 2000, warmup = 1000, cores = 4, chains = 4,
      seed = 14)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;print(b14.7)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: d | se(se) ~ 0 + intercept + between + (1 | study) + (1 | outcome) 
##    Data: spank (Number of observations: 111) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Group-Level Effects: 
## ~outcome (Number of levels: 17) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.08      0.03     0.04     0.14 1.00     1490     2304
## 
## ~study (Number of levels: 76) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sd(Intercept)     0.25      0.03     0.20     0.31 1.01      820     2203
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## intercept     0.38      0.05     0.29     0.48 1.01      925     1662
## between      -0.07      0.07    -0.21     0.07 1.00      891     1645
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
## sigma     0.00      0.00     0.00     0.00 1.00     4000     4000
## 
## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS
## and Tail_ESS are effective sample size measures, and Rhat is the potential
## scale reduction factor on split chains (at convergence, Rhat = 1).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s take a closer look at &lt;code&gt;b_between&lt;/code&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;posterior_samples(b14.7) %&amp;gt;% 
  
  ggplot(aes(x = b_between, y = 0)) +
  stat_halfeye(point_interval = median_qi, .width = c(.5, .95)) +
  labs(x = &amp;quot;Overall difference for between- vs within-participant designs&amp;quot;,
       y = NULL) +
  scale_y_continuous(NULL, breaks = NULL) +
  theme(panel.grid   = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/bayesian-meta-analysis/index_files/figure-html/unnamed-chunk-12-1.png&#34; width=&#34;432&#34; /&gt;&lt;/p&gt;
&lt;p&gt;That difference isn’t as large I’d expect it to be. But then again, I’m no spanking researcher. So what do I know?&lt;/p&gt;
&lt;p&gt;There are other things you might do with these data. For example, you might check for trends by year or, as the authors did in their manuscript, distinguish among different severities of corporal punishment. But I think we’ve gone far enough to get you started.&lt;/p&gt;
&lt;p&gt;If you’d like to learn more about these methods, do check out Vourre’s &lt;a href=&#34;https://mvuorre.github.io/blog/posts/2016-09-29-bayesian-meta-analysis/&#34;&gt;&lt;em&gt;Meta-analysis is a special case of Bayesian multilevel modeling&lt;/em&gt;&lt;/a&gt;. From his blog, you’ll learn additional tricks, like making a more traditional-looking forest plot with the &lt;code&gt;brmstools::forest()&lt;/code&gt; function and how our Bayesian brms method compares with frequentist meta-analyses via the &lt;a href=&#34;https://CRAN.R-project.org/package=metafor&#34;&gt;metafor package&lt;/a&gt;. You might also check out Williams, Rast, and Bürkner’s manuscript, &lt;a href=&#34;https://psyarxiv.com/7tbrm/&#34;&gt;&lt;em&gt;Bayesian Meta-Analysis with Weakly Informative Prior Distributions&lt;/em&gt;&lt;/a&gt; to give you an empirical justification for using a half-Cauchy prior for your meta-analysis &lt;span class=&#34;math inline&#34;&gt;\(\tau\)&lt;/span&gt; parameters.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;session-info&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Session info&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sessionInfo()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## R version 4.0.4 (2021-02-15)
## Platform: x86_64-apple-darwin17.0 (64-bit)
## Running under: macOS Catalina 10.15.7
## 
## Matrix products: default
## BLAS:   /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] tidybayes_2.3.1 brms_2.15.0     Rcpp_1.0.6      forcats_0.5.1  
##  [5] stringr_1.4.0   dplyr_1.0.5     purrr_0.3.4     readr_1.4.0    
##  [9] tidyr_1.1.3     tibble_3.1.0    ggplot2_3.3.3   tidyverse_1.3.0
## 
## loaded via a namespace (and not attached):
##   [1] readxl_1.3.1         backports_1.2.1      plyr_1.8.6          
##   [4] igraph_1.2.6         svUnit_1.0.3         splines_4.0.4       
##   [7] crosstalk_1.1.0.1    TH.data_1.0-10       rstantools_2.1.1    
##  [10] inline_0.3.17        digest_0.6.27        htmltools_0.5.1.1   
##  [13] rsconnect_0.8.16     fansi_0.4.2          magrittr_2.0.1      
##  [16] modelr_0.1.8         RcppParallel_5.0.2   matrixStats_0.57.0  
##  [19] xts_0.12.1           sandwich_3.0-0       prettyunits_1.1.1   
##  [22] colorspace_2.0-0     rvest_0.3.6          ggdist_2.4.0.9000   
##  [25] haven_2.3.1          xfun_0.22            callr_3.5.1         
##  [28] crayon_1.4.1         jsonlite_1.7.2       lme4_1.1-25         
##  [31] survival_3.2-10      zoo_1.8-8            glue_1.4.2          
##  [34] gtable_0.3.0         emmeans_1.5.2-1      V8_3.4.0            
##  [37] distributional_0.2.2 pkgbuild_1.2.0       rstan_2.21.2        
##  [40] abind_1.4-5          scales_1.1.1         mvtnorm_1.1-1       
##  [43] DBI_1.1.0            miniUI_0.1.1.1       viridisLite_0.3.0   
##  [46] xtable_1.8-4         stats4_4.0.4         StanHeaders_2.21.0-7
##  [49] DT_0.16              htmlwidgets_1.5.2    httr_1.4.2          
##  [52] threejs_0.3.3        arrayhelpers_1.1-0   ellipsis_0.3.1      
##  [55] farver_2.0.3         pkgconfig_2.0.3      loo_2.4.1           
##  [58] dbplyr_2.0.0         utf8_1.1.4           tidyselect_1.1.0    
##  [61] labeling_0.4.2       rlang_0.4.10         reshape2_1.4.4      
##  [64] later_1.1.0.1        munsell_0.5.0        cellranger_1.1.0    
##  [67] tools_4.0.4          cli_2.3.1            generics_0.1.0      
##  [70] broom_0.7.5          ggridges_0.5.2       evaluate_0.14       
##  [73] fastmap_1.0.1        yaml_2.2.1           processx_3.4.5      
##  [76] knitr_1.31           fs_1.5.0             nlme_3.1-152        
##  [79] mime_0.10            projpred_2.0.2       xml2_1.3.2          
##  [82] compiler_4.0.4       bayesplot_1.8.0      shinythemes_1.1.2   
##  [85] rstudioapi_0.13      gamm4_0.2-6          curl_4.3            
##  [88] reprex_0.3.0         statmod_1.4.35       stringi_1.5.3       
##  [91] highr_0.8            ps_1.6.0             blogdown_1.3        
##  [94] Brobdingnag_1.2-6    lattice_0.20-41      Matrix_1.3-2        
##  [97] nloptr_1.2.2.2       markdown_1.1         shinyjs_2.0.0       
## [100] vctrs_0.3.6          pillar_1.5.1         lifecycle_1.0.0     
## [103] bridgesampling_1.0-0 estimability_1.3     httpuv_1.5.4        
## [106] R6_2.5.0             bookdown_0.21        promises_1.1.1      
## [109] gridExtra_2.3        codetools_0.2-18     boot_1.3-26         
## [112] colourpicker_1.1.0   MASS_7.3-53          gtools_3.8.2        
## [115] assertthat_0.2.1     withr_2.4.1          shinystan_2.5.0     
## [118] multcomp_1.4-16      mgcv_1.8-33          parallel_4.0.4      
## [121] hms_0.5.3            grid_4.0.4           coda_0.19-4         
## [124] minqa_1.2.4          rmarkdown_2.7        shiny_1.5.0         
## [127] lubridate_1.7.9.2    base64enc_0.1-3      dygraphs_1.1.1.6&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div class=&#34;footnotes&#34;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&#34;fn1&#34;&gt;&lt;p&gt;At the time of this revision (2021-04-21), this ebook is now in &lt;a href=&#34;https://github.com/ASKurz/Statistical_Rethinking_with_brms_ggplot2_and_the_tidyverse/releases/tag/1.2.0&#34;&gt;version 1.2.0&lt;/a&gt;. The revision of this post includes fixes to a couple code breaks and a few updated hyperlinks. If you’d like to see the current version of this meta-analysis material, you can find it &lt;a href=&#34;https://bookdown.org/content/3890/missing-data-and-other-opportunities.html#summary-bonus-meta-analysis&#34;&gt;here&lt;/a&gt;.&lt;a href=&#34;#fnref1&#34; class=&#34;footnote-back&#34;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
