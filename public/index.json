[{"authors":null,"categories":null,"content":"I am an aspiring data analyst and experienced researcher with a Master of Arts in Economics. Apart from my formal education, I have been self-learning and teaching topics in statistics and research methods. I have several publications in the form of textbooks on Research Method; Applied Statistics for Policy Analysis; and Data Management, Analysis, and Visualization that are freely available to anyone who is interested in this field.\nI started this blog to share data analysis tips and tricks using R and Python.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/fahim-ahmad/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/fahim-ahmad/","section":"authors","summary":"I am an aspiring data analyst and experienced researcher with a Master of Arts in Economics. Apart from my formal education, I have been self-learning and teaching topics in statistics and research methods.","tags":null,"title":"Fahim Ahmad","type":"authors"},{"authors":null,"categories":["R"],"content":" In R working with survey weight is made possible using survey package. Let’s use below data frame as an exmaple here:\nset.seed(1000) age \u0026lt;- c(18:100) age \u0026lt;- sample(age, 100, replace = TRUE) gender \u0026lt;- c(\u0026quot;Male\u0026quot;, \u0026quot;Female\u0026quot;) gender \u0026lt;- sample(gender, 100, replace = TRUE) country \u0026lt;- c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;) country \u0026lt;- sample(country, 100, replace = TRUE) df \u0026lt;- data.frame(age, gender, country) df$weight[df$gender==\u0026quot;Female\u0026quot;] \u0026lt;-50/sum(df$gender==\u0026quot;Female\u0026quot;) df$weight[df$gender==\u0026quot;Male\u0026quot;] \u0026lt;-50/sum(df$gender==\u0026quot;Male\u0026quot;) # summary of data summary(df) ## age gender country weight ## Min. :18.00 Length:100 Length:100 Min. :0.8929 ## 1st Qu.:38.75 Class :character Class :character 1st Qu.:0.8929 ## Median :54.50 Mode :character Mode :character Median :0.8929 ## Mean :55.79 Mean :1.0000 ## 3rd Qu.:73.25 3rd Qu.:1.1364 ## Max. :97.00 Max. :1.1364 The most important variable here is the weight variable which is constructed to balance the sex ratio.\nInside the survey package, there is svydesign() function that can be used to link a data frame with a weight.\n# install.packages(\u0026quot;survey\u0026quot;) library(survey) df.w \u0026lt;- svydesign(ids = ~1, data = df, weights = ~weight) The resulting object is not a data frame anymore, but is a list of different objects that can be seen using attributes() function.\nattributes(df.w) ## $names ## [1] \u0026quot;cluster\u0026quot; \u0026quot;strata\u0026quot; \u0026quot;has.strata\u0026quot; \u0026quot;prob\u0026quot; \u0026quot;allprob\u0026quot; ## [6] \u0026quot;call\u0026quot; \u0026quot;variables\u0026quot; \u0026quot;fpc\u0026quot; \u0026quot;pps\u0026quot; ## ## $class ## [1] \u0026quot;survey.design2\u0026quot; \u0026quot;survey.design\u0026quot; Therefore, we need to use survey’s own analytical functions. For example, here is a comparison of unweighted and weighted sex ratio.\n# unweighted df %\u0026gt;% {table(.$gender)} %\u0026gt;% prop.table() ## ## Female Male ## 0.44 0.56 # weighted df.w %\u0026gt;% svytable(~gender, .) %\u0026gt;% prop.table() ## gender ## Female Male ## 0.5 0.5 svytable() can be used to create more than one-way frequency/percentage tables as well. For example, let’s create contingency table of gender and country\ndf.w %\u0026gt;% svytable(~gender+country, .) %\u0026gt;% prop.table(2) ## country ## gender A B ## Female 0.5600000 0.4329897 ## Male 0.4400000 0.5670103 Below are other useful functions of survey package:\n# to compute weighted mean svymean(~age, df.w) # to compute weighted quantiles svyquantile(~age, df.w, c(.25, .50, .75)) # to compute weigted variance svyvar(~age, df.w) # to perform t-test svyttest(age~gender, df.w) ","date":1652486400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1652486400,"objectID":"139270799ab66c89449eeb892bb332fd","permalink":"/post/using-survey-weight-in-r/","publishdate":"2022-05-14T00:00:00Z","relpermalink":"/post/using-survey-weight-in-r/","section":"post","summary":"In R working with survey weight is made possible using survey package. Let’s use below data frame as an exmaple here:\nset.seed(1000) age \u0026lt;- c(18:100) age \u0026lt;- sample(age, 100, replace = TRUE) gender \u0026lt;- c(\u0026quot;Male\u0026quot;, \u0026quot;Female\u0026quot;) gender \u0026lt;- sample(gender, 100, replace = TRUE) country \u0026lt;- c(\u0026quot;A\u0026quot;, \u0026quot;B\u0026quot;) country \u0026lt;- sample(country, 100, replace = TRUE) df \u0026lt;- data.","tags":["R"],"title":"Using Survey Weight","type":"post"},{"authors":null,"categories":["R"],"content":"  Introduction loading required packages creating example plots  Combining plots using the patchwork package Combining plots beside or on top of each other Controlling the legend Adding an empty area Combining plot and table Annotation Modifying the result of the patchwork   Introduction Data is just a collection of numbers until it is turned into a story. Sometimes, the combination of several plots is required for telling a great data-driven story.\nIt is a while that I am using R for data analysis and visualization and I have been using several packages for combining multiple plots. During this period, I found the patchwork package the most straightforward way of combining multiple ggplot plots which I will explore it in this post.\nloading required packages # install.packages(\u0026quot;patchwork\u0026quot;) library(patchwork) # install.packages(\u0026quot;gapminder\u0026quot;) library(gapminder) # install.packages(\u0026quot;dplyr\u0026quot;) library(dplyr) # install.packages() library(ggplot2)  creating example plots gdpPercap_lifeExpt \u0026lt;- gapminder %\u0026gt;% ggplot(aes(x=gdpPercap, y=lifeExp, col = continent)) + geom_point() + theme_bw() + labs(x = NULL, y = NULL) lifeExpt_densityPlot \u0026lt;- gapminder %\u0026gt;% ggplot(aes(x=lifeExp, fill=continent)) + geom_density(alpha=0.4) + theme_bw() + labs(x = NULL, y = NULL) lifeExpt_boxPlot \u0026lt;- gapminder %\u0026gt;% ggplot(aes(x=continent, y=lifeExp, col=continent)) + geom_boxplot() + geom_jitter(width=0.2, alpha=0.4) + theme_bw() + labs(x = NULL, y = NULL) gdpPercap_densityPlot \u0026lt;- gapminder %\u0026gt;% ggplot(aes(x = gdpPercap, fill = continent)) + geom_density(alpha = 0.4) + theme_bw() + labs(x = NULL, y = NULL) gdpPercap_boxPlot \u0026lt;- gapminder %\u0026gt;% ggplot(aes(x=continent, y=gdpPercap, col=continent)) + geom_boxplot() + geom_jitter(width=0.2, alpha=0.4) + theme_bw() + labs(x = NULL, y = NULL)   Combining plots using the patchwork package Them most simple and straightforward way to combine plots is to use the + operator.\nlifeExpt_densityPlot + lifeExpt_boxPlot + gdpPercap_densityPlot + gdpPercap_boxPlot  Combining plots beside or on top of each other The + operator combines plots without indicating anything about the desired layout. By default, the patchwork package keeps the grid square and fill the grid in row order. This can be controlled by plot_layout().\nlifeExpt_densityPlot + lifeExpt_boxPlot + gdpPercap_densityPlot + gdpPercap_boxPlot + plot_layout(nrow = 3, byrow = F)  By having a one-row layout plot_layout(nrow = 1) or one-column layout plotlayout(ncol = 1), plots can be placed on top of each other or beside each other.\n Likewise, patchwork provides two more operators. | and /\n| will place the plots beside each other, while / will stack them.\n(lifeExpt_densityPlot | lifeExpt_boxPlot) / gdpPercap_lifeExpt  Controlling the legend The plotlayout() function can also be used to place the legends in a common place instead of next to each plot.\nlifeExpt_densityPlot + lifeExpt_boxPlot + gdpPercap_densityPlot + gdpPercap_boxPlot + plot_layout(nrow = 3, byrow = F, guides = \u0026#39;collect\u0026#39;) gdpPercap_lifeExpt / ((lifeExpt_densityPlot / lifeExpt_boxPlot) | (gdpPercap_densityPlot / gdpPercap_boxPlot)) + plot_layout(guides = \u0026#39;collect\u0026#39;)  Adding an empty area It is also possible to add an empty area between the plots by creating an empty ggplot object using the plot_spacer() and adding it to the patchwork.\n(lifeExpt_densityPlot | lifeExpt_boxPlot) / plot_spacer() / gdpPercap_lifeExpt  Combining plot and table Sometimes you may want to combine a non-ggplot content with a ggplot plot. For instance, let’s combine the correlation table between life expectancy, GDP per capita, and population with the GDP per capita and life expectancy scatter plot.\n# install.packages(\u0026quot;gridExtra\u0026quot;) library(gridExtra) correlation \u0026lt;- cor(gapminder[,c(4:6)], method = \u0026#39;pearson\u0026#39;) %\u0026gt;% round(digits = 3) gdpPercap_lifeExpt / tableGrob(correlation)  Annotation The plot_annotation() function can be used to control different aspects of the annotation of the final plot such as title, subtitle, and caption.\n(lifeExpt_densityPlot | lifeExpt_boxPlot) / gdpPercap_lifeExpt + plot_layout(guides = \u0026#39;collect\u0026#39;) + plot_annotation(title = \u0026#39;THIS IS TITLE\u0026#39;, subtitle = \u0026#39;this is subtitle\u0026#39;) The plot_annotation() function also provide the tag_levels, tag_prefix, and tag_suffix arguments for auto-tagging to identify the subplots in text.\n tag_levels = A character vector defining the enumeration format to use at each level. Possible values are ‘a’ for lowercase letters, ‘A’ for uppercase letters, ‘1’ for numbers, ‘i’ for lowercase Roman numerals, and ‘I’ for uppercase Roman numerals.\n tag_prefix = String that should appear before the tag.\n tag_suffix = String that should appear after the tag.\n  (lifeExpt_densityPlot | lifeExpt_boxPlot) / gdpPercap_lifeExpt + plot_layout(guides = \u0026#39;collect\u0026#39;) + plot_annotation(tag_levels = \u0026quot;I\u0026quot;, tag_prefix = \u0026quot;Plot \u0026quot;, tag_suffix = \u0026quot; :\u0026quot;)  Modifying the result of the patchwork The resulting object of the patchwork is a ggplot object. Which means if you continue adding objects such as geoms, scales, etc. it will be referenced to the last added plot. For example, let’s italicize the x-axis text and set the angle to 45.\n(lifeExpt_densityPlot | lifeExpt_boxPlot) / gdpPercap_lifeExpt + plot_layout(guides = \u0026#39;collect\u0026#39;) + plot_annotation(tag_levels = \u0026quot;I\u0026quot;, tag_prefix = \u0026quot;Plot \u0026quot;, tag_suffix = \u0026quot; :\u0026quot;) + theme(axis.text.x = element_text(angle = -45, face = \u0026#39;italic\u0026#39;)) Often when it comes to modifying the plot it is more reasonable to modify everything at once. To do so, instead of the + operator, the \u0026amp; operator can be used.\n(lifeExpt_densityPlot | lifeExpt_boxPlot) / gdpPercap_lifeExpt + plot_layout(guides = \u0026#39;collect\u0026#39;) + plot_annotation(tag_levels = \u0026quot;I\u0026quot;, tag_prefix = \u0026quot;Plot \u0026quot;, tag_suffix = \u0026quot; :\u0026quot;) \u0026amp; theme(axis.text.x = element_text(angle = -45, face = \u0026#39;italic\u0026#39;))  ","date":1649635200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649635200,"objectID":"ddba152c703054d361462071b25c9a19","permalink":"/post/combining-multiple-plots-using-patchwork/","publishdate":"2022-04-11T00:00:00Z","relpermalink":"/post/combining-multiple-plots-using-patchwork/","section":"post","summary":"Introduction loading required packages creating example plots  Combining plots using the patchwork package Combining plots beside or on top of each other Controlling the legend Adding an empty area Combining plot and table Annotation Modifying the result of the patchwork   Introduction Data is just a collection of numbers until it is turned into a story.","tags":["ggplot","patchwork"],"title":"Combining Multiple Plots using Patchwork","type":"post"},{"authors":null,"categories":["R"],"content":" The geom_histogram() function from ggplot2 package is used to create a histogram plot. For example, let’s plot the distribution of Sepal.Length from iris data.\nlibrary(ggplot2) theme_set(theme_bw()) ggplot(iris, aes(Sepal.Length)) + geom_histogram(fill = \u0026quot;orange\u0026quot;) To add a vertical line to show the mean value of Sepal.Length, we can use geom_vline().\nlibrary(ggplot2) ggplot(iris, aes(Sepal.Length)) + geom_histogram(fill = \u0026quot;orange\u0026quot;) + geom_vline(data = iris, aes(xintercept = mean(Sepal.Length))) One of the most powerful aspects of ggplot2 is the ease with which you can create multiple sub-plots using facet_wrap(). For example, let’s plot the distribution of Sepal.Length by each group of Species from iris data.\nggplot(iris, aes(Sepal.Length)) + geom_histogram(fill = \u0026quot;orange\u0026quot;) + facet_wrap(~Species) + geom_vline(data = iris, aes(xintercept = mean(Sepal.Length))) While using facet_wrap() each plot shows a different subset of the data, however, the geom_vline() adds the vertical line on the same x-intercept in all plots. For instance, in the above histograms the vertical line shows the overall mean of Sepal.Length column instead of mean of each group.\nIt’s more practical to add a vertical line on each facet showing the mean for each group of data. To do so, a separate data frame containing the mean of each group should be created to use with geom_vline().\nlibrary(dplyr) vline \u0026lt;- summarise(group_by(iris,Species), mean = mean(Sepal.Length)) vline ## # A tibble: 3 × 2 ## Species mean ## \u0026lt;fct\u0026gt; \u0026lt;dbl\u0026gt; ## 1 setosa 5.01 ## 2 versicolor 5.94 ## 3 virginica 6.59 ggplot(iris, aes(Sepal.Length)) + geom_histogram(fill = \u0026quot;orange\u0026quot;) + facet_wrap(~Species) + geom_vline(data = vline, aes(xintercept = mean)) ","date":1648944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648944000,"objectID":"d661aa539482913fd5ff40d6c95c6fa4","permalink":"/post/ggplot2-facet-wrap-with-different-vertical-lines-on-each-facet/","publishdate":"2022-04-03T00:00:00Z","relpermalink":"/post/ggplot2-facet-wrap-with-different-vertical-lines-on-each-facet/","section":"post","summary":"The geom_histogram() function from ggplot2 package is used to create a histogram plot. For example, let’s plot the distribution of Sepal.Length from iris data.\nlibrary(ggplot2) theme_set(theme_bw()) ggplot(iris, aes(Sepal.Length)) + geom_histogram(fill = \u0026quot;orange\u0026quot;) To add a vertical line to show the mean value of Sepal.","tags":["ggplot","visualization"],"title":"ggplot2: geom_histogram \u0026 facet_wrap with different vertical lines on each facet","type":"post"},{"authors":null,"categories":["R"],"content":"        When to use scatterplot? Scatterplot using the base R functions Scatterplot using ggplot2 package   When to use scatterplot? When dealing with numerical data, the most common way to graphically explore the patterns and relationships between variables and draw a conclusion about how variables correlate to one another is by plotting the data points using a scatterplot. A scatterplot uses dots/markers to represent values for two numeric variables where the position of each dot indicates values for an individual data point in the (x,y) coordinates.\nScatterplots are used primarily to determine the strength and direction of the relationship between two numeric variables.\nThe direction of the relationship is determined by how y variable changes by an increase in x variable.\n When the y variable tends to increase by increasing the x variable, it shows the positive relationship between two variables. When the y variable tends to decrease by increasing the x variable, it shows the negative relationship between two variables. If it is impossible to establish either of the above criteria, there is not any meaningful relationship between the variables.  The strength of the relationship is determined by how spread the data points are in the (x,y) coordinates.\n When the data points lie exactly along a straight line, it shows the perfect relationship. When the data points are closed to one another and are concentrated near the straight line, it shows a strong relationship. If the data points appeared randomly scattered or equally distributed across the plot, it shows no relationship or a weak relationship.  \n Scatterplot using the base R functions The plot(x,y) function is used to create a scatterplot where x and y are columns to be plotted in the x-axis and y-axis, respectively. Each point’s horizontal position indicates the value of x (column that is plotted in the x-axis) and the vertical position of each point indicates the value of y (column that is plotted in the y-axis).\nFor example, you collect data from 30 individuals about their education level, age, and salary as well as the gender of each individual as below.\ndf \u0026lt;- data.frame( gender = c(\u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Male\u0026quot;), age = c(30, 25, 27, 28, 24, 29, 27, 24, 22, NA, NA, 21, 25, 27, 29, 24, 22, 18, NA, 25, 22, 23, 27, NA, 18, 23, 19, 26, 23, 22), salary = c(25000, 31000, 35000, 27000, 32000, 26000, 31000, 30000, 35000, 38000, 37000, 36000, 33000, 30000, 25000, 29000, 37000, 28000, 38000, 31000, 37000, 34000, 31000, 38000, 38000, 35000, 37000, 29000, 37000, 36000), education = c(9, 12, 16, 10, 14, 10, 11, 14, 16, 18, 18, NA, 14, 12, 9, 13, 15, 10, 18, 12, 17, 16, 13, 18, NA, 16, NA, 12, 18, 17) ) df ## gender age salary education ## 1 Male 30 25000 9 ## 2 Male 25 31000 12 ## 3 Male 27 35000 16 ## 4 Male 28 27000 10 ## 5 Male 24 32000 14 ## 6 Male 29 26000 10 ## 7 Male 27 31000 11 ## 8 Male 24 30000 14 ## 9 Male 22 35000 16 ## 10 Female NA 38000 18 ## 11 Female NA 37000 18 ## 12 Female 21 36000 NA ## 13 Female 25 33000 14 ## 14 Female 27 30000 12 ## 15 Female 29 25000 9 ## 16 Female 24 29000 13 ## 17 Female 22 37000 15 ## 18 Female 18 28000 10 ## 19 Female NA 38000 18 ## 20 Female 25 31000 12 ## 21 Male 22 37000 17 ## 22 Male 23 34000 16 ## 23 Male 27 31000 13 ## 24 Male NA 38000 18 ## 25 Female 18 38000 NA ## 26 Female 23 35000 16 ## 27 Female 19 37000 NA ## 28 Female 26 29000 12 ## 29 Female 23 37000 18 ## 30 Male 22 36000 17 By plotting the data points we can explore the relationship between age, education, and salary.\n# plot Age against Salary plot(df$age, df$salary, main = \u0026#39;Age vs. Salary\u0026#39;) # plot Education against Salary plot(df$education, df$salary, main = \u0026#39;Education vs. Salary\u0026#39;) The plot shown above reveals that those who are younger tend to have a higher salary. Moreover, a higher education level can predict a higher salary as well.\nLet’s plot age against education to explore the relationship between the two variables.\nplot(df$age, df$education, main = \u0026quot;Age vs. Education\u0026quot;) It is also possible to explore the relationship between age, salary, and education in one plot by creating a scatterplot matrix using pairs() function.\npairs(~salary+education+age, data = df, main = \u0026quot;Scatterplot Matrix\u0026quot;) The above plot confirms the same findings. It shows a positive correlation between education and salary, however, there is a negative correlation between age and salary. Furthermore, those who are younger tend to have a higher education level.\n Scatterplot using ggplot2 package As I mentioned in the previous posts, it is preferred to use the ggplot2 packages for visualization because the resulting plot is easy to modify and it is more popular among R users to use the ggplot2 package. The geom_point() function can be used from ggplot2 package to create scatterplots. For example, let’s plot age against salary.\nlibrary(ggplot2) ggplot(df, aes(x = age, y = salary)) + geom_point() + theme_bw() + labs(title = \u0026quot;Age vs. Salary\u0026quot;) The common issue with scatterplot is when we have lots of data, the points will overlap (known as overplotting). There are several ways to alleviate this issue. The most common way is to use geom_jitter() instead of geom_point().\nThe geom_jitter() adds a small amount of random noise to the location of each point to make the plot easier to read. For example, compare the below plot to the one above.\nggplot(df, aes(x = age, y = salary)) + geom_jitter() + theme_bw() + labs(title = \u0026quot;Age vs. Salary\u0026quot;) Scatterplots are very useful in identifying the relationship between two numerical variables among several groups as well by adding a third variable. When the third variable is categorical data, the most common way is by giving the dots a distinct hue to show the membership of each point to a respective group. For instance, let’s plot the relationship between age and salary among males and females.\nggplot(df, aes(x = age, y = salary, color = gender)) + geom_jitter() + theme_bw() + labs(title = \u0026quot;Age vs. Salary, by Gender\u0026quot;) To depict the third variable that has numeric values, the common way is to change the dots’ size based on the values of the third variable, where larger points indicate higher values and smaller points indicate lower values. Moreover, hue can also be used when the third variable has numeric values by using a sequence of colors rather than using distinct colors for points like in the categorical case.\nggplot(df, aes(x = age, y = salary, size = education)) + geom_jitter() + theme_bw() + labs(title = \u0026quot;Age vs. Salary\u0026quot;) ggplot(df, aes(x = age, y = salary, color = education)) + geom_jitter() + scale_fill_gradient(low = \u0026quot;orange\u0026quot;, high = \u0026quot;red\u0026quot;, na.value = \u0026quot;grey50\u0026quot;, aesthetics = \u0026quot;color\u0026quot;) + theme_bw() + labs(title = \u0026quot;Age vs. Salary\u0026quot;) Also, adding another dimension to create a 3D scatterplot can be used to depict the third variable that has numeric values as another alternative rather than changing the dots’ size. Since the ggplot2 package does not produce plots with three dimensions, I use the plotly package as an example here.\nlibrary(plotly) plot_ly(df, x = ~age, y = ~salary, z = ~education, type = \u0026quot;scatter3d\u0026quot;)  {\"x\":{\"visdat\":{\"de1a7254039c\":[\"function () \",\"plotlyVisDat\"]},\"cur_data\":\"de1a7254039c\",\"attrs\":{\"de1a7254039c\":{\"x\":{},\"y\":{},\"z\":{},\"alpha_stroke\":1,\"sizes\":[10,100],\"spans\":[1,20],\"type\":\"scatter3d\"}},\"layout\":{\"margin\":{\"b\":40,\"l\":60,\"t\":25,\"r\":10},\"scene\":{\"xaxis\":{\"title\":\"age\"},\"yaxis\":{\"title\":\"salary\"},\"zaxis\":{\"title\":\"education\"}},\"hovermode\":\"closest\",\"showlegend\":false},\"source\":\"A\",\"config\":{\"showSendToCloud\":false},\"data\":[{\"x\":[30,25,27,28,24,29,27,24,22,25,27,29,24,22,18,25,22,23,27,23,26,23,22],\"y\":[25000,31000,35000,27000,32000,26000,31000,30000,35000,33000,30000,25000,29000,37000,28000,31000,37000,34000,31000,35000,29000,37000,36000],\"z\":[9,12,16,10,14,10,11,14,16,14,12,9,13,15,10,12,17,16,13,16,12,18,17],\"type\":\"scatter3d\",\"mode\":\"markers\",\"marker\":{\"color\":\"rgba(31,119,180,1)\",\"line\":{\"color\":\"rgba(31,119,180,1)\"}},\"error_y\":{\"color\":\"rgba(31,119,180,1)\"},\"error_x\":{\"color\":\"rgba(31,119,180,1)\"},\"line\":{\"color\":\"rgba(31,119,180,1)\"},\"frame\":null}],\"highlight\":{\"on\":\"plotly_click\",\"persistent\":false,\"dynamic\":false,\"selectize\":false,\"opacityDim\":0.2,\"selected\":{\"opacity\":1},\"debounce\":0},\"shinyEvents\":[\"plotly_hover\",\"plotly_click\",\"plotly_selected\",\"plotly_relayout\",\"plotly_brushed\",\"plotly_brushing\",\"plotly_clickannotation\",\"plotly_doubleclick\",\"plotly_deselect\",\"plotly_afterplot\",\"plotly_sunburstclick\"],\"base_url\":\"https://plot.ly\"},\"evals\":[],\"jsHooks\":[]}  ","date":1628553600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628553600,"objectID":"dabf8b7176ced71e847701da8901ec38","permalink":"/post/exploring-relationship-between-variables-scatter-plot/","publishdate":"2021-08-10T00:00:00Z","relpermalink":"/post/exploring-relationship-between-variables-scatter-plot/","section":"post","summary":"When to use scatterplot? Scatterplot using the base R functions Scatterplot using ggplot2 package   When to use scatterplot? When dealing with numerical data, the most common way to graphically explore the patterns and relationships between variables and draw a conclusion about how variables correlate to one another is by plotting the data points using a scatterplot.","tags":["R","ggplot","visualization"],"title":"Exploring Relationship Between Variables | scatter-plot","type":"post"},{"authors":null,"categories":["R"],"content":"  Removing duplicates based on a single variable Removing duplicates based on the combination of multiple variables Conclusion   Sometimes you may encounter duplicated values in the data which might cause problems depending on how you plan to use the data. In this post, I provide an overview of duplicated() function from base R and the distinct() function from dplyr package to detect and remove duplicates.\nI will be using the following data frame as an example in this post.\nset.seed(1000) df \u0026lt;- data.frame( ID = sample(paste0(\u0026quot;ID-00\u0026quot;, 1:7), 10, replace = T), value_1 = sample(1:7, 10, replace = T), value_2 = sample(2:5, 10, replace = T) ) df ## ID value_1 value_2 ## 1 ID-004 5 2 ## 2 ID-003 6 5 ## 3 ID-006 1 3 ## 4 ID-003 1 4 ## 5 ID-005 5 5 ## 6 ID-003 2 3 ## 7 ID-005 2 2 ## 8 ID-002 4 3 ## 9 ID-006 7 2 ## 10 ID-006 2 3 Removing duplicates based on a single variable The duplicated() function returns a logical vector where TRUE specifies which rows of the data frame are duplicates.\nFor instance, duplicated(df[\u0026quot;ID\u0026quot;]) returns the following vector.\n## [1] FALSE FALSE FALSE TRUE FALSE TRUE TRUE FALSE TRUE TRUE  Note: the duplicated() function preserves the first occurrence in the process of identifying the duplicate values, if you want to consider the duplication from the reverse side, then set the fromLast argument to TRUE.\n Let’s use the above vector to exclude the duplicated values.\ndf[!duplicate_rows, ] ## ID value_1 value_2 ## 1 ID-004 5 2 ## 2 ID-003 6 5 ## 3 ID-006 1 3 ## 5 ID-005 5 5 ## 8 ID-002 4 3 An alternative way to select unique values is dplyr::distinct() function that yields a similar result as above.\ndplyr::distinct(df, ID, .keep_all = TRUE) ## ID value_1 value_2 ## 1 ID-004 5 2 ## 2 ID-003 6 5 ## 3 ID-006 1 3 ## 4 ID-005 5 5 ## 5 ID-002 4 3  Note: The .keep_all argument is used to retain all other columns in the output data frame.\n  Removing duplicates based on the combination of multiple variables The above chunks of codes remove the duplicated rows based on a single column. What if we want to remove duplicates based on more than a single column?\nOne way is to concatenate the columns in which you want to check the presence of duplicates. For example, let’s remove the rows where value_1 and value_2 are duplicated.\ndf \u0026lt;- dplyr::mutate(df, value_1_2 = paste(value_1, value_2)) df[!duplicated(df[c(\u0026quot;value_1_2\u0026quot;)]), ] ## ID value_1 value_2 value_1_2 ## 1 ID-004 5 2 5 2 ## 2 ID-003 6 5 6 5 ## 3 ID-006 1 3 1 3 ## 4 ID-003 1 4 1 4 ## 5 ID-005 5 5 5 5 ## 6 ID-003 2 3 2 3 ## 7 ID-005 2 2 2 2 ## 8 ID-002 4 3 4 3 ## 9 ID-006 7 2 7 2 Below is an efficient way of detecting duplicates based on the combination of multiple columns without concatenating the values of the columns in which we want to identify the duplicated values:\n# using duplicated() function df[!duplicated(df[c(\u0026quot;value_1\u0026quot;, \u0026quot;value_2\u0026quot;)]), ] # using distinct() function dplyr::distinct(df, value_1, value_2, .keep_all = TRUE) ## ID value_1 value_2 value_1_2 ## 1 ID-004 5 2 5 2 ## 2 ID-003 6 5 6 5 ## 3 ID-006 1 3 1 3 ## 4 ID-003 1 4 1 4 ## 5 ID-005 5 5 5 5 ## 6 ID-003 2 3 2 3 ## 7 ID-005 2 2 2 2 ## 8 ID-002 4 3 4 3 ## 9 ID-006 7 2 7 2  Conclusion It seems that both approaches work very well; however, the advantage of using duplicated() function from base R is it returns a logical vector identifying the duplicated rows that can be used to either drop the duplicated rows or keep only these rows for further investigation while the distinct() function directly removes the duplicated rows without specifying which row has duplicate values.\nFor instance, let’s keep the duplicated ID numbers only.\ndf[duplicated(df[\u0026quot;ID\u0026quot;], fromLast = F), ] ## ID value_1 value_2 value_1_2 ## 4 ID-003 1 4 1 4 ## 6 ID-003 2 3 2 3 ## 7 ID-005 2 2 2 2 ## 9 ID-006 7 2 7 2 ## 10 ID-006 2 3 2 3 As mentioned above, the duplicated() function does not assign the first occurrence in the process of identifying the duplicated values as duplicates. Thus, we need to count backward as well to consider the duplication from the reverse side. To do so, we need to set the fromLast argument to TRUE.\ndf[duplicated(df[\u0026quot;ID\u0026quot;], fromLast = F) | duplicated(df[\u0026quot;ID\u0026quot;], fromLast = T), ] ## ID value_1 value_2 value_1_2 ## 2 ID-003 6 5 6 5 ## 3 ID-006 1 3 1 3 ## 4 ID-003 1 4 1 4 ## 5 ID-005 5 5 5 5 ## 6 ID-003 2 3 2 3 ## 7 ID-005 2 2 2 2 ## 9 ID-006 7 2 7 2 ## 10 ID-006 2 3 2 3  ","date":1626998400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1626998400,"objectID":"d8d545a7db874b37d518a47c29924c06","permalink":"/post/detecting-duplicates/","publishdate":"2021-07-23T00:00:00Z","relpermalink":"/post/detecting-duplicates/","section":"post","summary":"Removing duplicates based on a single variable Removing duplicates based on the combination of multiple variables Conclusion   Sometimes you may encounter duplicated values in the data which might cause problems depending on how you plan to use the data.","tags":["R"],"title":"Detecting Duplicates (base R vs. dplyr)","type":"post"},{"authors":null,"categories":["R","Statistics"],"content":"  Introduction Dealing with the positive skewness Dealing with the negative skewness Conclusion   Introduction Before we get deep into transforming skewed data, let’s quickly talk around the normal distribution and skewness coefficient, or have a look at my previous post to have a detailed insight on different types of distribution of data here.\nThe normal distribution is a statistical concept that denotes the probability distribution of data which has a bell-shaped curve. That is, the normal distribution is symmetrical on both sides where mean, median, and mode are equal. The skewness coefficient of a normal distribution is 0 that can be used as a reference to measure the extent and direction of deviation of the distribution of a given data from the normal distribution.\nA positively skewed data has a skewness of greater than 0, whereas the negatively skewed data has a skewness of lower than 0. In other words, the data points tend to concentrate around the lower values in a positively skewed data and the mean is greater than the median, where the opposite is true in a negatively skewed data.\nOftentimes the real-life data do not follow the normal distribution which undermines the validity of the parametric statistical models and inferences. Thus, some sort of modification is needed. That is where the data transformation comes in to make the distribution of the data as normal as possible so that the statistical inferences drawn from the data become more valid by reducing the skewness of the original data.\nIn this post, I try to cover the most common methods of transforming a skewed distribution into a normal distribution, and the foundational step you must consider before deciding which method to apply.\nLoading required packages:\n library(data.table) # Enhanced data.frame library(dplyr) # Data manipulation library(tidyr) # Reshape the data between wide and long formats library(ggplot2) # Data visualization library(patchwork) # Re-arrange ggplot2 plots library(moments) # Calculating skewness coefficient library(gt) # Creating an object of class \u0026quot;gt\u0026quot; table  Dealing with the positive skewness The common methods for transforming positively skewed data to normal distribution are, but not limited to, square root transformation, cube root transformation, and log transformation.\nI use the GDP per capita as an example. You can download the data from here.\nhtml { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #toybytjxst .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #toybytjxst .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #toybytjxst .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #toybytjxst .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #toybytjxst .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #toybytjxst .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #toybytjxst .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #toybytjxst .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #toybytjxst .gt_column_spanner_outer:first-child { padding-left: 0; } #toybytjxst .gt_column_spanner_outer:last-child { padding-right: 0; } #toybytjxst .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #toybytjxst .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #toybytjxst .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #toybytjxst .gt_from_md  :first-child { margin-top: 0; } #toybytjxst .gt_from_md  :last-child { margin-bottom: 0; } #toybytjxst .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #toybytjxst .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #toybytjxst .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #toybytjxst .gt_row_group_first td { border-top-width: 2px; } #toybytjxst .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #toybytjxst .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #toybytjxst .gt_first_summary_row.thick { border-top-width: 2px; } #toybytjxst .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #toybytjxst .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #toybytjxst .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #toybytjxst .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #toybytjxst .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #toybytjxst .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #toybytjxst .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #toybytjxst .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #toybytjxst .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #toybytjxst .gt_left { text-align: left; } #toybytjxst .gt_center { text-align: center; } #toybytjxst .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #toybytjxst .gt_font_normal { font-weight: normal; } #toybytjxst .gt_font_bold { font-weight: bold; } #toybytjxst .gt_font_italic { font-style: italic; } #toybytjxst .gt_super { font-size: 65%; } #toybytjxst .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #toybytjxst .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #toybytjxst .gt_asterisk { font-size: 100%; vertical-align: 0; } #toybytjxst .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #toybytjxst .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #toybytjxst .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; }    Country Name Indicator Name value   1 Afghanistan GDP per capita (current US$) 502.1 2 Angola GDP per capita (current US$) 2,973.6 3 Albania GDP per capita (current US$) 5,352.9 4 Andorra GDP per capita (current US$) 40,886.4 5 Arab World GDP per capita (current US$) 6,580.1 6 United Arab Emirates GDP per capita (current US$) 43,103.3 7 Argentina GDP per capita (current US$) 10,006.1 8..214    215 Vietnam GDP per capita (current US$) 2,715.3 216 Vanuatu GDP per capita (current US$) 3,058.1 217 Samoa GDP per capita (current US$) 4,315.9 218 Kosovo GDP per capita (current US$) 4,417.5 219 South Africa GDP per capita (current US$) 6,001.4 220 Zambia GDP per capita (current US$) 1,291.3 221 Zimbabwe GDP per capita (current US$) 1,464.0   Source: The World Bank   Last update: 2020-07-01.     Let’s illustrate the distribution of the above data to see what we are dealing with.\ndf \u0026lt;- select(gdp_pc, gdp_pc = value) ggplot(df, aes(x = gdp_pc)) + geom_histogram(aes(y = ..density..), fill = \u0026quot;coral\u0026quot;, color = \u0026quot;gray\u0026quot;, alpha = 0.8) + geom_density() + theme_bw() + labs(x = NULL, title = \u0026#39;GDP Per Capita\u0026#39;) It certainly does not follow the normal distribution and is positively skewed and most of the data points tend to concentrate around the lower values. That is, most countries have a lower GDP per capita.\nThe extent of the skewness, however, is not known yet. To measure the skewness you can use skewness() function from the moments package.\nskewness(df$gdp_pc) ## [1] 2.096777 Since the skewness coefficient is greater than one, it denotes the data is highly skewed. Let’s transform the data into normal distribution using different methods.\n1) Square root transformation:  The square root transformation involves converting each value to its square root. That is, converting \\({(x)}\\) to \\({({x}^{1/2})}\\).\n2) Cube root transformation:  This method involves converting \\({(x)}\\) to \\({(x^{1/3})}\\).\n3) Log transformation:  Different types of logarithmic transformation can be applied, including \\(x\\) to \\({log_{10}x}\\); \\(x\\) to \\({log_{2}x}\\), \\(x\\) to \\({log_{e}x}\\) or \\({ln}\\ {x}\\).\ndf \u0026lt;- df %\u0026gt;% mutate(sqrt_gdp_pc = sqrt(gdp_pc), cbrt_gdp_pc = (gdp_pc)^(1/3), log_gdp_pc = log(gdp_pc) ) do.call(rbind, (lapply(df, skewness))) %\u0026gt;% data.table(keep.rownames = T) %\u0026gt;% mutate(Method = factor(case_when(rn %in% \u0026quot;gdp_pc\u0026quot; ~ 1, rn %in% \u0026quot;sqrt_gdp_pc\u0026quot; ~ 2, rn %in% \u0026quot;cbrt_gdp_pc\u0026quot; ~ 3, rn %in% \u0026quot;log_gdp_pc\u0026quot; ~ 4), labels = c(\u0026quot;Original data\u0026quot;, \u0026quot;Square Root Transformation\u0026quot;, \u0026quot;Cube Root Transformation\u0026quot;, \u0026quot;Log Transformation\u0026quot;), ordered = T)) %\u0026gt;% gt() %\u0026gt;% cols_hide(columns = vars(rn)) %\u0026gt;% cols_move_to_start(columns = vars(Method)) %\u0026gt;% # tab_row_group(group = \u0026quot;Methods to reduce skewness\u0026quot;, rows = 2:4) %\u0026gt;% # tab_row_group(group = \u0026quot;Original Dat\u0026quot;, rows = 1) %\u0026gt;% fmt_number(columns = vars(V1),decimals = 3) %\u0026gt;% cols_label(V1 = \u0026quot;Skewness Coefficient\u0026quot;) %\u0026gt;% tab_style(style = cell_fill(color = \u0026quot;maroon\u0026quot;, alpha = 1), locations = cells_body(columns = vars(V1), rows = V1 \u0026gt; 2)) %\u0026gt;% tab_style(style = cell_fill(color = \u0026quot;maroon\u0026quot;, alpha = 0.7), locations = cells_body(columns = vars(V1), rows = V1 \u0026gt; 1 \u0026amp; V1 \u0026lt; 2)) %\u0026gt;% tab_style(style = cell_fill(color = \u0026quot;maroon\u0026quot;, alpha = 0.5), locations = cells_body(columns = vars(V1), rows = V1 \u0026gt; 0.5 \u0026amp; V1 \u0026lt; 1)) %\u0026gt;% tab_style(style = cell_fill(color = \u0026quot;maroon\u0026quot;, alpha = 0.3), locations = cells_body(columns = vars(V1), rows = V1 \u0026lt; 0.5)) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #huvbobxmlt .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #huvbobxmlt .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #huvbobxmlt .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #huvbobxmlt .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #huvbobxmlt .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #huvbobxmlt .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #huvbobxmlt .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #huvbobxmlt .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #huvbobxmlt .gt_column_spanner_outer:first-child { padding-left: 0; } #huvbobxmlt .gt_column_spanner_outer:last-child { padding-right: 0; } #huvbobxmlt .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #huvbobxmlt .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #huvbobxmlt .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #huvbobxmlt .gt_from_md  :first-child { margin-top: 0; } #huvbobxmlt .gt_from_md  :last-child { margin-bottom: 0; } #huvbobxmlt .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #huvbobxmlt .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #huvbobxmlt .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #huvbobxmlt .gt_row_group_first td { border-top-width: 2px; } #huvbobxmlt .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #huvbobxmlt .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #huvbobxmlt .gt_first_summary_row.thick { border-top-width: 2px; } #huvbobxmlt .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #huvbobxmlt .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #huvbobxmlt .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #huvbobxmlt .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #huvbobxmlt .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #huvbobxmlt .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #huvbobxmlt .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #huvbobxmlt .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #huvbobxmlt .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #huvbobxmlt .gt_left { text-align: left; } #huvbobxmlt .gt_center { text-align: center; } #huvbobxmlt .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #huvbobxmlt .gt_font_normal { font-weight: normal; } #huvbobxmlt .gt_font_bold { font-weight: bold; } #huvbobxmlt .gt_font_italic { font-style: italic; } #huvbobxmlt .gt_super { font-size: 65%; } #huvbobxmlt .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #huvbobxmlt .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #huvbobxmlt .gt_asterisk { font-size: 100%; vertical-align: 0; } #huvbobxmlt .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #huvbobxmlt .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #huvbobxmlt .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; }   Method Skewness Coefficient   Original data 2.097 Square Root Transformation 1.092 Cube Root Transformation 0.737 Log Transformation \u0026minus;0.032    The square root transformation reduces the skewness coefficient remarkably from 2.1 to 1.09, however, it is still greater than 1. It is reduced to 0.74 by applying the cube root transformation, whereas the log transformation reduces the skewness to -0.032.\nLet’s explore more the variability of the data.\ndo.call(cbind, (lapply(df, summary))) %\u0026gt;% data.table(keep.rownames = T) %\u0026gt;% gt(rowname_col = \u0026quot;rn\u0026quot;) %\u0026gt;% tab_spanner(label = \u0026quot;Methods to Reduce Skewness\u0026quot;, columns = vars(\u0026quot;sqrt_gdp_pc\u0026quot;, \u0026quot;cbrt_gdp_pc\u0026quot;, \u0026quot;log_gdp_pc\u0026quot;)) %\u0026gt;% tab_spanner(label = \u0026quot;Original Data\u0026quot;, columns = vars(\u0026quot;gdp_pc\u0026quot;)) %\u0026gt;% fmt_number(columns = ends_with(\u0026quot;gdp_pc\u0026quot;), decimals = 3) %\u0026gt;% cols_label(gdp_pc = \u0026quot;GDP per capita\u0026quot;, sqrt_gdp_pc = \u0026quot;Square root transformation\u0026quot;, cbrt_gdp_pc = \u0026quot;Cube root transformaiton\u0026quot;, log_gdp_pc = \u0026quot;Log transformation\u0026quot;) %\u0026gt;% tab_style(style = cell_fill(color = \u0026quot;maroon\u0026quot;, alpha = 1), locations = cells_body(columns = vars(gdp_pc))) %\u0026gt;% tab_style(style = cell_fill(color = \u0026quot;maroon\u0026quot;, alpha = 0.7), locations = cells_body(columns = vars(sqrt_gdp_pc))) %\u0026gt;% tab_style(style = cell_fill(color = \u0026quot;maroon\u0026quot;, alpha = 0.5), locations = cells_body(columns = vars(cbrt_gdp_pc))) %\u0026gt;% tab_style(style = cell_fill(color = \u0026quot;maroon\u0026quot;, alpha = 0.3), locations = cells_body(columns = vars(log_gdp_pc))) ## Warning: `columns = vars(...)` has been deprecated in gt 0.3.0: ## * please use `columns = c(...)` instead ## Warning: `columns = vars(...)` has been deprecated in gt 0.3.0: ## * please use `columns = c(...)` instead ## Warning: `columns = vars(...)` has been deprecated in gt 0.3.0: ## * please use `columns = c(...)` instead ## Warning: `columns = vars(...)` has been deprecated in gt 0.3.0: ## * please use `columns = c(...)` instead ## Warning: `columns = vars(...)` has been deprecated in gt 0.3.0: ## * please use `columns = c(...)` instead ## Warning: `columns = vars(...)` has been deprecated in gt 0.3.0: ## * please use `columns = c(...)` instead html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #tfyuvvwwyq .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #tfyuvvwwyq .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #tfyuvvwwyq .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #tfyuvvwwyq .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #tfyuvvwwyq .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #tfyuvvwwyq .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #tfyuvvwwyq .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #tfyuvvwwyq .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #tfyuvvwwyq .gt_column_spanner_outer:first-child { padding-left: 0; } #tfyuvvwwyq .gt_column_spanner_outer:last-child { padding-right: 0; } #tfyuvvwwyq .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #tfyuvvwwyq .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #tfyuvvwwyq .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #tfyuvvwwyq .gt_from_md  :first-child { margin-top: 0; } #tfyuvvwwyq .gt_from_md  :last-child { margin-bottom: 0; } #tfyuvvwwyq .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #tfyuvvwwyq .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #tfyuvvwwyq .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #tfyuvvwwyq .gt_row_group_first td { border-top-width: 2px; } #tfyuvvwwyq .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #tfyuvvwwyq .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #tfyuvvwwyq .gt_first_summary_row.thick { border-top-width: 2px; } #tfyuvvwwyq .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #tfyuvvwwyq .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #tfyuvvwwyq .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #tfyuvvwwyq .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #tfyuvvwwyq .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #tfyuvvwwyq .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #tfyuvvwwyq .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #tfyuvvwwyq .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #tfyuvvwwyq .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #tfyuvvwwyq .gt_left { text-align: left; } #tfyuvvwwyq .gt_center { text-align: center; } #tfyuvvwwyq .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #tfyuvvwwyq .gt_font_normal { font-weight: normal; } #tfyuvvwwyq .gt_font_bold { font-weight: bold; } #tfyuvvwwyq .gt_font_italic { font-style: italic; } #tfyuvvwwyq .gt_super { font-size: 65%; } #tfyuvvwwyq .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #tfyuvvwwyq .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #tfyuvvwwyq .gt_asterisk { font-size: 100%; vertical-align: 0; } #tfyuvvwwyq .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #tfyuvvwwyq .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #tfyuvvwwyq .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; }    Original Data  Methods to Reduce Skewness    GDP per capita Square root transformation Cube root transformaiton Log transformation   Min. 261.247 16.163 6.393 5.565 1st Qu. 1,994.906 44.664 12.589 7.598 Median 6,564.920 81.024 18.724 8.789 Mean 14,536.951 99.495 20.439 8.738 3rd Qu. 17,401.722 131.916 25.914 9.764 Max. 114,704.594 338.681 48.588 11.650    In the original data, the distance between the 1st quartile and the minimum value is 1733.7 and the distance between the 3rd quartile and the maximum value is 97302.9 prior to any kind of transformations. Nevertheless, it decreases at different levels after applying various forms of transformation. For instance, the difference between the 3rd quartile and the maximum value is 206.8 after the square root transformation, it is 22.7 after the cube root transformation, and it is 1.9 after the log transformation.\nAnother point of consideration is the distance between the mean and the median. The mean is 7972.03 points away from the median in the original data, whereas it is 18.5 after the square root transformation, 1.71 after the cube root transformation, and -0.05 after the log transformation.\nLet’s make a quick visualization to better understand the shape of the distribution after applying each kind of above-mentioned methods.\ndf \u0026lt;- df %\u0026gt;% pivot_longer(cols = everything(), names_to = \u0026quot;method\u0026quot;, values_to = \u0026quot;values\u0026quot;) %\u0026gt;% mutate(method = factor(case_when(method == \u0026quot;gdp_pc\u0026quot; ~ 1, method == \u0026quot;sqrt_gdp_pc\u0026quot; ~ 2, method == \u0026quot;cbrt_gdp_pc\u0026quot; ~ 3, method == \u0026quot;log_gdp_pc\u0026quot; ~ 4), labels = c(\u0026quot;Original data\u0026quot;, \u0026quot;Square root transformation\u0026quot;, \u0026quot;Cube root transformation\u0026quot;, \u0026quot;Log transformation\u0026quot;))) vline \u0026lt;- summarise(group_by(df, method), mean = mean(values), median = median(values)) df %\u0026gt;% ggplot(aes(x = values)) + geom_histogram(aes(y = ..density..), fill = \u0026quot;coral\u0026quot;, alpha = 0.8, color = \u0026quot;gray\u0026quot;) + geom_density() + theme_bw() + facet_wrap(~method, nrow = 2, scales = \u0026quot;free\u0026quot;) + geom_vline(data = vline, aes(xintercept = mean), linetype = \u0026quot;dotted\u0026quot;) + geom_vline(data = vline, aes(xintercept = median), linetype = \u0026quot;dashed\u0026quot;) + labs(x = NULL, caption = \u0026quot;Mean = Dotted line\\nMedian = Dashed line\u0026quot;) + theme(strip.text = element_text(size = 15, face = \u0026quot;bold\u0026quot;)) As the above plots depict, the log transformation is pretty awesome. It reduces the skewness and improves the normality of the data more rapidly compared to the cube root or square root transformation.\n Dealing with the negative skewness The important caveat in applying the above methods to reduce the skewness is the data should be skewed to the right side, otherwise those methods do not transform the distribution of the data to normal.\nLet’s use the life expectancy data from the World Bank as an example. You can download the data from here.\nhtml { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #qzghdmrtjl .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #qzghdmrtjl .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qzghdmrtjl .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #qzghdmrtjl .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #qzghdmrtjl .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qzghdmrtjl .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #qzghdmrtjl .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #qzghdmrtjl .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #qzghdmrtjl .gt_column_spanner_outer:first-child { padding-left: 0; } #qzghdmrtjl .gt_column_spanner_outer:last-child { padding-right: 0; } #qzghdmrtjl .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #qzghdmrtjl .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #qzghdmrtjl .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #qzghdmrtjl .gt_from_md  :first-child { margin-top: 0; } #qzghdmrtjl .gt_from_md  :last-child { margin-bottom: 0; } #qzghdmrtjl .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #qzghdmrtjl .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #qzghdmrtjl .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #qzghdmrtjl .gt_row_group_first td { border-top-width: 2px; } #qzghdmrtjl .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qzghdmrtjl .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #qzghdmrtjl .gt_first_summary_row.thick { border-top-width: 2px; } #qzghdmrtjl .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qzghdmrtjl .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #qzghdmrtjl .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #qzghdmrtjl .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #qzghdmrtjl .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #qzghdmrtjl .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qzghdmrtjl .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #qzghdmrtjl .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #qzghdmrtjl .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #qzghdmrtjl .gt_left { text-align: left; } #qzghdmrtjl .gt_center { text-align: center; } #qzghdmrtjl .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #qzghdmrtjl .gt_font_normal { font-weight: normal; } #qzghdmrtjl .gt_font_bold { font-weight: bold; } #qzghdmrtjl .gt_font_italic { font-style: italic; } #qzghdmrtjl .gt_super { font-size: 65%; } #qzghdmrtjl .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #qzghdmrtjl .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #qzghdmrtjl .gt_asterisk { font-size: 100%; vertical-align: 0; } #qzghdmrtjl .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #qzghdmrtjl .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #qzghdmrtjl .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; }    Country Name Indicator Name value   1 Aruba Life expectancy at birth, total (years) 76.2 2 Afghanistan Life expectancy at birth, total (years) 64.5 3 Angola Life expectancy at birth, total (years) 60.8 4 Albania Life expectancy at birth, total (years) 78.5 5 Arab World Life expectancy at birth, total (years) 71.8 6 United Arab Emirates Life expectancy at birth, total (years) 77.8 7 Argentina Life expectancy at birth, total (years) 76.5 8..236    237 Vanuatu Life expectancy at birth, total (years) 70.3 238 Samoa Life expectancy at birth, total (years) 73.2 239 Kosovo Life expectancy at birth, total (years) 72.2 240 Yemen, Rep. Life expectancy at birth, total (years) 66.1 241 South Africa Life expectancy at birth, total (years) 63.9 242 Zambia Life expectancy at birth, total (years) 63.5 243 Zimbabwe Life expectancy at birth, total (years) 61.2   Source: The World Bank   Last update: 2020-07-01.     Below is the distribution of the above data which is moderately skewed to the left side with a skewness coefficient of -0.532.\ndf \u0026lt;- select(life_exp, life_exp = value) ggplot(df, aes(x = life_exp)) + geom_histogram(aes(y = ..density..), fill = \u0026quot;coral\u0026quot;, color = \u0026quot;gray\u0026quot;, alpha = 0.8) + geom_density() + theme_bw() + labs(x = NULL, title = \u0026#39;Life expectancy\u0026#39;) One solution when dealing with the negatively skewed data is to reflect the values and apply the methods that are used to reduce the positive skewness on the reflected values. That is, subtract each value from a constant which is larger than the maximum value prior to transformation. The highest value in the above data is 84.9. Thus, I subtract each value from 86.\nThe point to notice after reflecting the data is that the extent of the skewness remains the same and the distribution of the data is as skewed as it was, though in the opposite direction.\nLet’s apply the above methods to the reflected data.\ndf \u0026lt;- df %\u0026gt;% mutate(reflected_life_exp = 86-life_exp, sqrt_reflected_life_exp = sqrt(reflected_life_exp), cbrt_reflected_life_exp = (reflected_life_exp)^(1/3), log_reflected_life_exp = log(reflected_life_exp), life_exp = NULL) %\u0026gt;% pivot_longer(cols = everything(), names_to = \u0026quot;method\u0026quot;, values_to = \u0026quot;values\u0026quot;) %\u0026gt;% mutate(method = factor(case_when(method == \u0026quot;reflected_life_exp\u0026quot; ~ 1, method == \u0026quot;sqrt_reflected_life_exp\u0026quot; ~ 2, method == \u0026quot;cbrt_reflected_life_exp\u0026quot; ~ 3, method == \u0026quot;log_reflected_life_exp\u0026quot; ~ 4), labels = c(\u0026quot;Reflected data\u0026quot;, \u0026quot;Square root transformation\u0026quot;, \u0026quot;Cube root transformation\u0026quot;, \u0026quot;Log transformation\u0026quot;))) vline \u0026lt;- summarise(group_by(df, method), mean = mean(values), median = median(values)) df %\u0026gt;% ggplot(aes(x = values)) + geom_histogram(aes(y = ..density..), fill = \u0026quot;coral\u0026quot;, alpha = 0.8, color = \u0026quot;gray\u0026quot;) + geom_density() + theme_bw() + facet_wrap(~method, nrow = 2, scales = \u0026quot;free\u0026quot;) + geom_vline(data = vline, aes(xintercept = mean), linetype = \u0026quot;dotted\u0026quot;) + geom_vline(data = vline, aes(xintercept = median), linetype = \u0026quot;dashed\u0026quot;) + labs(x = NULL, caption = \u0026quot;Mean = Dotted line\\nMedian = Dashed line\u0026quot;) + theme(strip.text = element_text(size = 15, face = \u0026quot;bold\u0026quot;)) Surprisingly, the square root and cube root transformation convert the distribution of the above data closer to the normal distribution compare to log transformation.\n The important point to consider is that the values have been reflected. That is, the lower values represent high values and the higher values represent low values.\n Other approaches to dealing with the negative skewness can be the inverse of the transformations that are used to reduce the positive skewness. For example, instead of computing square root convert \\(x\\) to \\(x^2\\) and instead of cube root convert \\(x\\) to \\(x^{3}\\).\n Conclusion Different approaches reduce the extent of the skewness and boost the validity of the statistical inferences at different levels. Whatever method you use to transform the data into a normal distribution, the points you have to consider are a) never limit yourself to one standard method and examine several options before deciding which approach to use b) be cautious and always explore the math behind each approach. For example, let’s have a glance at the below graphs that illustrate the domain of log, square root, and cube root functions.\nplot \u0026lt;- ggplot(data.frame(x = c(-25,25)), aes(x = x)) + theme_bw() + geom_vline(xintercept = 0) + geom_hline(yintercept = 0) sqrt \u0026lt;- plot + stat_function(fun = function(x){sqrt(x)}, color = \u0026#39;maroon\u0026#39;) + labs(title = \u0026quot;Square root\u0026quot;) cbrt \u0026lt;- plot + stat_function(fun = function(x){sign(x) * abs((x))^(1/3)}, color = \u0026#39;maroon\u0026#39;) + labs(title = \u0026quot;Cube root\u0026quot;) + xlim(c(-50, 50)) log \u0026lt;- plot + stat_function(fun = function(x){log10(x)}, color = \u0026#39;maroon\u0026#39;) + labs(title = \u0026quot;Log\u0026quot;) (log | sqrt) / (cbrt) Since the domain for log is strictly greater than zero, it is reasonable to use log+1 instead of log transformation if the data have meaningful zero values. Furthermore, the square root is not defined for the negative numbers, thus you can consider adding a constant to convert the negative values to positive values prior to transformation or use cube root transformation instead of square root transformation. The kind of data you are working with, therefore, is literally foundational in deciding which method to use.\n ","date":1596153600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596153600,"objectID":"9065f9a5643d42df7935fd0740424b7a","permalink":"/post/methods-for-transforming-data-to-normal-distribution-in-r/","publishdate":"2020-07-31T00:00:00Z","relpermalink":"/post/methods-for-transforming-data-to-normal-distribution-in-r/","section":"post","summary":"Introduction Dealing with the positive skewness Dealing with the negative skewness Conclusion   Introduction Before we get deep into transforming skewed data, let’s quickly talk around the normal distribution and skewness coefficient, or have a look at my previous post to have a detailed insight on different types of distribution of data here.","tags":["R","Statistics"],"title":"Methods for Transforming Data to Normal Distribution","type":"post"},{"authors":null,"categories":["R","Statistics"],"content":"  What is Skewness? Calculating Skewness using R and by Hand Importance of Skewness in Data Science   What is Skewness? Skewness is an important statistical concept in the field of data analytics that every statistician and data scientist needs to know. As you are reading this post, I am sure you will understand the concept of skewness and why it is important in data analytics by the end of this post.\nSkewness is a measure of the asymmetry of the probability distribution. In other words, skewness is a measure to describe the deviation of the distribution of the data from a normal distribution. Have a glance at the below graphs for comparing normal distribution with the skewed distribution.\nAs the above plots depict, the normal distribution is symmetrical on both sides and the data points tend to fall at the center of the distribution. Whereas the positively skewed distribution has its long tail on the right side and most of the data points are concentrated around the lower values, and the distribution with its long tail on the left side is a negatively skewed distribution which most of its data points are concentrated around the higher values.\nAnother aspect of the normal distribution is that all measures of the central tendency (click here to read more about the measures of central tendency) are equal and lie in one point (mean = mode = median). While in the skewed distributions, the mean is pulled out toward the longer tail. Therefore, in the positively skewed distribution, the mean is larger than the median and mode (mean \u0026gt; median \u0026gt; mode) and the opposite is the case in a negatively skewed distribution (mean \u0026lt; median \u0026lt; mode).\n Calculating Skewness using R and by Hand Skewness can be quantified to represent the extent of variation of a distribution from the normal distribution. A normal distribution has a skew of zero and is used as a reference for determining the level of skewness. When the skewness is greater than zero it shows a positively skewed distribution, whereas a negatively skewed distribution has a skewness of lower than zero.\nWhen is the skewness too much? As a rule of thumb, the data with the skewness between -0.5 to 0.5 is assumed to be fairly symmetrical and if the skewness is greater than 1 or lower than -1, it denotes highly skewed distribution.\nSkewness is defined as:\n\\[{ Skewness = \\frac{∑_{i=1}^{n} \\ ((x_i - \\bar{x})^3/n)}{(∑_{i=1}^{n} \\ ((x_i - \\bar{x})^2/n))^{(3/2)}}}\\]\nWhere \\(X_i\\) is the \\(i^{th}\\) value of \\(X\\), \\(\\bar{X}\\) is the mean, and \\(n\\) is the sample size.\nIn R, the skewness() function from the moments package can be used to compute the skewness of a given data.\nFor example, let’s compute the skewness of below data using the skewness() function and the aforementioned formula to confirm the consistent results.\n(df \u0026lt;- data.frame(x = c(400, 300, 180, 360, 490, 400, 280, 290, 180, 110, 120, 270))) ## x ## 1 400 ## 2 300 ## 3 180 ## 4 360 ## 5 490 ## 6 400 ## 7 280 ## 8 290 ## 9 180 ## 10 110 ## 11 120 ## 12 270 library(tidyverse) library(moments) df %\u0026gt;% summarise(skewness_builtin = skewness(x), skewness_by_hand = sum((x - mean(x))^3/nrow(.))/sum((x - mean(x))^2/nrow(.))^(3/2) ) ## skewness_builtin skewness_by_hand ## 1 0.08316773 0.08316773  Importance of Skewness in Data Science Skewness is an important statistical concept for, at least, three reasons. a) Many statistical models and inferences require that the distribution of the data should be normal, while the real-world data rarely follow a normal distribution. Therefore, skewness as a measure of asymmetric is essential to know the shape of the distribution of the data; b) skewness tells us about the direction of outliers. The positive skewness is the sign of the presence of larger extreme values and the negative skewness indicates the presence lower extreme values; c) skewness shows the location of the data points. That is, it denotes where most of the values are concentrated.\nFor instance, below graph depicts the density plot of GDP per capita which is skewed on the right side and the mean is more than two times higher than the median.\nIn other words, most countries have a lower GDP per capita. That is, if you use this data to predict, for example, life expectancy, it can predict the life expectancy of those countries with the lower GDP per capita more accurately compare to predicting the life expectancy of the countries with the higher GDP per capita.\n ","date":1594944000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1594944000,"objectID":"e7bb61671f87d4c3c7a61bd497c78654","permalink":"/post/skewness-definition-and-its-importance-in-data-science/","publishdate":"2020-07-17T00:00:00Z","relpermalink":"/post/skewness-definition-and-its-importance-in-data-science/","section":"post","summary":"What is Skewness? Calculating Skewness using R and by Hand Importance of Skewness in Data Science   What is Skewness? Skewness is an important statistical concept in the field of data analytics that every statistician and data scientist needs to know.","tags":["R","Statistics"],"title":"Skewness | Definition and its Importance in Data Science","type":"post"},{"authors":null,"categories":["R","Statistics"],"content":"  Introduction Pearson Correlation Spearman Rank Correlation Interpreting the Correlation Coefficient Computing Correlation Coefficient in R   Introduction In recent posts, we discussed measures of central tendency and measures of dispersion. But hey, that is the start of a long journey. Finding relationships between variables is more interesting than describing the distribution of the data.\nWhile studying, for example, the relationship between GDP and life expectancy, you might be interested to know whether there exists any relationship between the two indicators? is it a positive relationship or a negative relationship? and how strong the association is?\nThe above questions can be answered by computing the correlation coefficient between the two indicators. Depending on the type of data, different methods of correlation exist. In this post, you will learn the Pearson correlation coefficient and the Spearman correlation coefficient.\n Pearson Correlation Pearson correlation is a parametric correlation test that measures the strength and direction of a linear relationship between two variables. This method is by far the most used and best method for calculating the association between variables that follow a normal distribution.\nIf the two variables are denoted by x and y, the Pearson correlation coefficient is defined as the ratio of covariance between x and y to the product of standard deviation of x and standard deviation of y.\n\\[r = (Covariance (x,y)) \\space/\\space (S.D.(x)×S.D.(y))\\] Where,\n\\[{Covariance(x,y) = \\frac{∑^n_{i=1}(x_i-\\bar{x})(y_i-\\bar{y})}{\\ {n-1}}}\\]\n\\[{S.D.(x) = \\sqrt\\frac{∑^n_{i=1}(x_i-\\bar{x})^2}{\\ {n-1}}}\\]\n\\[{S.D.(y) = \\sqrt\\frac{∑^n_{i=1}(y_i-\\bar{y})^2}{\\ {n-1}}}\\]\n Spearman Rank Correlation While the Pearson correlation is used to compute the degree of relationship between linearly related variables, the Spearman correlation indicates the monotonic relationship. The Pearson correlation is more appropriate for continuous data such as income, age, and height, while Spearman is more appropriate for ordinal data such as level of satisfaction, or level of happiness measured on a scale of 1 to 4.\nIn other words, the Pearson correlation is used to compute the extent of association when there is an equal interval between the adjacent units of the input variables. For instance, an increase in income from 100 to 101 is equal to the increase from 500 to 501 or an increase in age from 18 to 19 is same as an increase in 38 to 39, while the Spearman correlation is widely used with the ordinal data such that one level can be considered higher or lower than another level, but the magnitude of the difference is not necessarily known or the same. For instance, “Strong satisfaction” is higher than the “Somewhat satisfaction” and “Somewhat dissatisfaction” is higher than “Strong dissatisfaction”. However, it can not be quantified how much higher/lower is one level compared to the other level.\nMoreover, since the Spearman correlation is based on the ranked values rather than the raw data and does not carry any assumption about the distribution of the data points, it can be used to measure the association between two continuous variables as well when the data are not distributed normally.\nThe Spearman ranked correlation can be expressed as follow:\n\\[rho = (Covariance (x\u0026#39;,y\u0026#39;)) \\space/\\space (S.D.(x\u0026#39;)×S.D.(y\u0026#39;))\\]\nWhere \\(x\u0026#39;\\) is rank(x) and \\(y\u0026#39;\\) is rank(y).\n Interpreting the Correlation Coefficient The correlation coefficient always lies between -1 and +1 and can’t go outside of this range. Where the sign of the correlation coefficient denotes the direction of the relationship between two variables and the absolute value of the correlation coefficient indicates the strength of association between two variables. A + sign indicates the positive relationship and a - sign indicates the negative relationship. Furthermore, the closer the correlation coefficient to -1 or +1, the stronger the relationship, and as it goes toward 0 the relationship will be weaker.\nHow close is close enough to -1 or +1? I get too excited to see correlations beyond ±0.7. You can refer to below table while interpreting the correlation coefficient:\nhtml { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #afvpaeqnbm .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #afvpaeqnbm .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #afvpaeqnbm .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #afvpaeqnbm .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #afvpaeqnbm .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #afvpaeqnbm .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #afvpaeqnbm .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #afvpaeqnbm .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #afvpaeqnbm .gt_column_spanner_outer:first-child { padding-left: 0; } #afvpaeqnbm .gt_column_spanner_outer:last-child { padding-right: 0; } #afvpaeqnbm .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #afvpaeqnbm .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #afvpaeqnbm .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #afvpaeqnbm .gt_from_md  :first-child { margin-top: 0; } #afvpaeqnbm .gt_from_md  :last-child { margin-bottom: 0; } #afvpaeqnbm .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #afvpaeqnbm .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #afvpaeqnbm .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #afvpaeqnbm .gt_row_group_first td { border-top-width: 2px; } #afvpaeqnbm .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #afvpaeqnbm .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #afvpaeqnbm .gt_first_summary_row.thick { border-top-width: 2px; } #afvpaeqnbm .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #afvpaeqnbm .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #afvpaeqnbm .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #afvpaeqnbm .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #afvpaeqnbm .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #afvpaeqnbm .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #afvpaeqnbm .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #afvpaeqnbm .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #afvpaeqnbm .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #afvpaeqnbm .gt_left { text-align: left; } #afvpaeqnbm .gt_center { text-align: center; } #afvpaeqnbm .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #afvpaeqnbm .gt_font_normal { font-weight: normal; } #afvpaeqnbm .gt_font_bold { font-weight: bold; } #afvpaeqnbm .gt_font_italic { font-style: italic; } #afvpaeqnbm .gt_super { font-size: 65%; } #afvpaeqnbm .gt_two_val_uncert { display: inline-block; line-height: 1em; text-align: right; font-size: 60%; vertical-align: -0.25em; margin-left: 0.1em; } #afvpaeqnbm .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #afvpaeqnbm .gt_asterisk { font-size: 100%; vertical-align: 0; } #afvpaeqnbm .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #afvpaeqnbm .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #afvpaeqnbm .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; }   Interpreting the Correlation Coefficient    Correlation coefficient Meaning   -1.0 Perfect negative relationship -0.7 Strong negative relationship -0.5 Moderate negative relationship -0.3 Weak negative relationship 0.0 No relationship 0.3 Weak positive relationship 0.5 Moderate positive relationship 0.7 Strong positive relationship 1.0 Perfect positive relationship     Computing Correlation Coefficient in R In the example below, we have a table of time series data of global GDP per capita and life expectancy from 1960 to 2018. Let’s find if if a higher GDP per capita can predict a higher life expectancy, and to what extent both indicators are correlated to each other.\n  year life_exp gdp_pc    1960 52.57821 452.1089  1961 53.07938 464.0490  1962 53.49664 489.5471  1963 54.02187 516.6151  1964 54.69176 554.5533  1965 55.35094 591.7181  1966 56.08243 628.7388  1967 56.78712 655.8735  1968 57.38625 693.9011  1969 57.99542 749.7251  1970 58.58291 803.9466  1971 59.11015 870.4373  1972 59.59617 984.5294  1973 60.04475 1178.0889  1974 60.54026 1332.8028  1975 60.98629 1457.1544  1976 61.40832 1556.8154  1977 61.83214 1729.5263  1978 62.19287 2005.1087  1979 62.55490 2288.6660  1980 62.84117 2532.7632  1981 63.18203 2576.6880  1982 63.50846 2507.3214  1983 63.75660 2513.1282  1984 64.02116 2560.9983  1985 64.27871 2643.7584  1986 64.57943 3069.9131  1987 64.83061 3431.5807  1988 65.03467 3772.4014  1989 65.24723 3870.4130  1990 65.43349 4285.2353  1991 65.61949 4464.6543  1992 65.77051 4668.2405  1993 65.88757 4669.5816  1994 66.08953 4939.8349  1995 66.27814 5412.3441  1996 66.55982 5453.3128  1997 66.84463 5357.0692  1998 67.08683 5272.6333  1999 67.29315 5395.9428  2000 67.54925 5498.3297  2001 67.82180 5396.8919  2002 68.07043 5533.4253  2003 68.32699 6131.2232  2004 68.65235 6820.6152  2005 68.92032 7297.1534  2006 69.26243 7811.9362  2007 69.59208 8694.9003  2008 69.89930 9423.7573  2009 70.24658 8830.3069  2010 70.55621 9551.3357  2011 70.88413 10488.3340  2012 71.17172 10605.2083  2013 71.46224 10781.8553  2014 71.74238 10952.3444  2015 71.94752 10246.5074  2016 72.18048 10281.9088  2017 72.38530 10817.4819  2018 72.56006 11381.6806  2019 NA 11435.6099    First thing first, let’s plot the data points to explore if there exists any relationship between the two indicators or not, and if the data points vary together. This is done through a scatter-plot. Please read this post for more details: Exploring Relationship Between Variables | scatter-plot\nlibrary(ggplot2) df %\u0026gt;% ggplot(aes(x = gdp_pc, y = life_exp)) + geom_point() + theme_bw() + labs(title = \u0026quot;GDP per capita and life expectancy, 1960-2018\u0026quot;) ## Warning: Removed 1 rows containing missing values (geom_point). Since the points are moving from the lower-left corner to the upper-right corner. Thus, a positive relationship exists1. However, it does not indicate the extent of the relationship between the variables.\nNext, the normality test should be performed to check whether the data follow a normal distribution or not. This can be tested visually through qq-plot or histogram:\nqq1 \u0026lt;- df %\u0026gt;% ggplot(aes(sample = life_exp)) + geom_qq() + labs(y = \u0026quot;life expectancy\u0026quot;) qq2 \u0026lt;- df %\u0026gt;% ggplot(aes(sample = gdp_pc)) + geom_qq() + labs(y = \u0026quot;GDP per capita\u0026quot;) hist1 \u0026lt;- df %\u0026gt;% ggplot(aes(x = life_exp)) + geom_histogram(fill = \u0026quot;orange\u0026quot;, alpha = 0.5) + labs(x = \u0026quot;life expectancy\u0026quot;) hist2 \u0026lt;- df %\u0026gt;% ggplot(aes(x = gdp_pc)) + geom_histogram(fill = \u0026quot;orange\u0026quot;, alpha = 0.5) + labs(x = \u0026quot;GDP per capita\u0026quot;) library(patchwork) (qq1 | qq2) / (hist1 / hist2) \u0026amp; theme_bw() ## Warning: Removed 1 rows containing non-finite values (stat_qq). ## Warning: Removed 1 rows containing non-finite values (stat_bin). From the above plots it can easily be drawn that the data points do not follow a normal distribution, but the more precise way to check the normality of distribution is to use a statistical test. The shapiro.test() function performs the Shapiro-Wilk test of normality.\nshapiro.test(df$gdp_pc)  Shapiro-Wilk normality test data: df$gdp_pc W = 0.89361, p-value = 7.756e-05 shapiro.test(df$life_exp)  Shapiro-Wilk normality test data: df$life_exp W = 0.9538, p-value = 0.02537 The null hypothesis in the Shapiro-Wilk test is that the data are normally distributed. Therefore, a p-value of less than the significance level, or less than 0.05 indicates the data points are not normally distributed.\nAfter testing the assumptions, you can decide to choose either Pearson or Spearman correlation. The cor.test() function can be used for evaluating the association between variables.\ncor.test(df$gdp_pc, df$life_exp, method = \u0026quot;pearson\u0026quot;)   Pearson\u0026#39;s product-moment correlation data: df$gdp_pc and df$life_exp t = 18.088, df = 57, p-value \u0026lt; 2.2e-16 alternative hypothesis: true correlation is not equal to 0 95 percent confidence interval: 0.8730810 0.9535685 sample estimates: cor 0.9228352  cor.test(df$gdp_pc, df$life_exp, method = \u0026quot;spearman\u0026quot;)  Spearman\u0026#39;s rank correlation rho data: df$gdp_pc and df$life_exp S = 134, p-value \u0026lt; 2.2e-16 alternative hypothesis: true rho is not equal to 0 sample estimates: rho 0.9960842  As shown above, both Pearson and Spearman’s correlation coefficient is above 0.9 which indicates a strong correlation between the two indicators. In other words, as GDP per capita increases life expectancy increases as well.\n  If there exists a positive correlation, the points will be moving from the lower-left to the upper-right corner. Similarly, if there is a negative correlation, the points will be moving down from the upper-left corner to the lower right corner. In case the points are scattered and do not form any pattern, it depicts that no relationship exists between the variables.↩\n   ","date":1593129600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593129600,"objectID":"5e3f527aaa76d45b2879c20e9b543ea5","permalink":"/post/analysis-of-the-relationship-between-two-quantitative-variables-in-r-correlation/","publishdate":"2020-06-26T00:00:00Z","relpermalink":"/post/analysis-of-the-relationship-between-two-quantitative-variables-in-r-correlation/","section":"post","summary":"Introduction Pearson Correlation Spearman Rank Correlation Interpreting the Correlation Coefficient Computing Correlation Coefficient in R   Introduction In recent posts, we discussed measures of central tendency and measures of dispersion.","tags":["R","Statistics"],"title":"Analysis of the Relationship Between Two Quantitative Variables | Correlation","type":"post"},{"authors":null,"categories":["R","Statistics"],"content":"  Introduction Absolute measures of dispersion Relative measures of dispersion   Introduction In the previous post I described the measures of central tendency. But the central tendency is not the only thing you can tell interesting facts about the data and is not the only way by which you can get to know about the concentration of the data. In this post, you will learn about the measures of dispersion as part of the descriptive statistics.\nAs the name suggests, the measures of dispersion show the extent of variability and the scattering of the data points. The main idea of the measures of dispersion is to get to know how the data are spread and how much the data points vary from the average value.\nTwo distinct sets of data may have the same central value, but a completely different level of variation. Therefore, an adequate description of the data should include both of these characteristics. In other words, the combination of measures of the central tendency and measures of dispersion help to understand the distribution of the data.\nA measure of dispersion is zero if all the data points are the same and increases as the data become more diverse. There are mainly two types of measures of dispersion.\n Absolute measures of dispersion Relative measures of dispersion   Absolute measures of dispersion Absolute measures of dispersion express the scattering of the data points in terms of distance such as range or in terms of deviation from the central value such as variance and standard deviation.\nRange: Range is defined as the difference between the smallest and the largest value in a set of data. The range is easy to compute; however, it is influenced by extreme values. Therefore, it is not a reliable measure of dispersion.\n\\[Range = X_{max} - X_{min}\\]\nQuartile deviation: Quartile deviation is defined as half of the distance between the first and third quartile1. Quartile deviation is not influenced by extreme values. However, its demerit is that it ignores 50% of the data. Therefore, variance and standard deviation are suggested as the most reliable measures of dispersion.\n\\[Quartile \\space deviation = \\frac{Q_{3}-Q_{1}}{\\ 2}\\]\nVariance and Standard Deviation2: These measures of dispersion tell you how much spread out the data points are from the mean. To find out the variance, deduct each value from the mean, square it, sum each square, and divide it by the total number of values.\n\\[Variance = \\frac{∑(x-\\bar{x})^2}{\\ {n-1}}\\]\nStandard deviation is the square root of the variance. In the asymmetrical distribution, 68.25% of data points fall between mean ± 1s.d; 95.45% of data points fall between mean ± 2s.d; 99.73% of the data points fall between mean ± 3s.d.\nMathematically, the standard deviation can be expressed as below:\n\\[{Standard \\space deviation} = {\\sqrt\\frac{∑(x-\\bar{x})^2}{\\ {n-1}}}\\]\nNo panic! In R, you can easily compute the range, quartile deviation, variance, and standard deviation. Suppose you have the weekly expenditures of two projects over 10 weeks.\n## Projects Expenditures ## 1 project1 10000 ## 2 project1 15400 ## 3 project1 14250 ## 4 project1 13000 ## 5 project1 11250 ## 6 project1 10450 ## 7 project1 9035 ## 8 project1 12500 ## 9 project1 14125 ## 10 project1 11240 ## 11 project2 10500 ## 12 project2 15000 ## 13 project2 14300 ## 14 project2 12500 ## 15 project2 11300 ## 16 project2 10500 ## 17 project2 8530 ## 18 project2 12500 ## 19 project2 14120 ## 20 project2 11320 The below functions can be used to compute the measures of dispersion.\nlibrary(tidyverse) df %\u0026gt;% group_by(Projects) %\u0026gt;% summarise(Range = max(Expenditures) - min(Expenditures), \u0026#39;Quartile Deviation\u0026#39; = IQR(Expenditures)/2, Variance = var(Expenditures), \u0026#39;Standard Deviation\u0026#39; = sd(Expenditures)) %\u0026gt;% kable()   Projects Range Quartile Deviation Variance Standard Deviation    project1 6365 1598.125 4285078 2070.043  project2 6470 1507.500 4082801 2020.594    As the above table shows, based on Range as a measure of dispersion that includes only minimum and maximum values, the data points in the second group (project2) are more scattered while based on the Standard deviation the data points in that group are less scattered3.\n Relative measures of dispersion For comparing data among two or more than two groups that differ significantly in their averages, and for unit free comparison the relative measures of dispersion are used which is known as the coefficient of dispersion (C.D).\nCoefficient of dispersion in terms of range: C.D in terms of range is the distance between the minimum value and maximum value divided by sum of the minimum and maximum values.\n\\[{C.D\\space in\\space terms\\space of\\space range} = {\\frac{X_{max} - X_{min}}{\\ X_{max} + X_{min}}}\\]\nCoefficient of dispersion in terms of quartile deviation: C.D in terms of quartile deviation is the distance between first quartile and third quartile divided by the sum of the first and third quartiles.\n\\[{C.D\\space in\\space terms\\space of\\space quartile \\space deviation} = {\\frac{Q_{3} - Q_{1}}{\\ Q_{3} + Q_{1}}}\\]\nCoefficient of dispersion in terms of standard deviation: C.D in terms of standard deviation is defined as the standard deviation divided by the mean.\n\\[{C.D\\space in\\space terms\\space of\\space S.D} = {\\frac{S.D}{\\bar{X}}}\\]\nCoefficient of Variation (C.V): 100 times the coefficient of dispersion based on the standard deviation is the coefficient of variation.\n\\[C.V = 100 * \\frac{S.D}{\\bar{X}}\\]\nLet’s find the relative measures of dispersion for the above data.\nlibrary(raster) df %\u0026gt;% group_by(Projects) %\u0026gt;% summarise(\u0026#39;C.D in terms of range\u0026#39; = (max(Expenditures)-min(Expenditures)/max(Expenditures)+min(Expenditures)), \u0026#39;C.D in terms of standard deviation\u0026#39; = sd(Expenditures)/mean(Expenditures), # \u0026#39;Coefficient of Variation\u0026#39; = 100 * sd(Expenditures)/mean(Expenditures), \u0026#39;Coefficient of Variation\u0026#39; = cv(Expenditures)) %\u0026gt;% kable()     Projects C.D in terms of range C.D in terms of standard deviation Coefficient of Variation    project1 24434.41 0.1707252 17.07252  project2 23529.43 0.1675868 16.75868      Quartiles are values that divide the data into quarters. The first quartile (Q1) is the middle number between the smallest number and the median of the data. The second quartile, (Q2) is the median of the data set. The third quartile (Q3) is the middle number between the median and the largest number.↩\n In R, the var() and sd() functions compute the sample variance and sample standard deviation. Therefore, the n-1 is used in the denominator.↩\n Standard deviation as measure of dispersion to compare variability among two groups should be used only when both groups have the same central value. When the central value of both groups differ widely, the coefficient of dispersion in terms of standard deviation or coefficient of variance should be used.↩\n   ","date":1590019200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590019200,"objectID":"68c3f7ed1051ac55257635e3c3cb539a","permalink":"/post/measures-of-dispersion-using-r/","publishdate":"2020-05-21T00:00:00Z","relpermalink":"/post/measures-of-dispersion-using-r/","section":"post","summary":"Introduction Absolute measures of dispersion Relative measures of dispersion   Introduction In the previous post I described the measures of central tendency. But the central tendency is not the only thing you can tell interesting facts about the data and is not the only way by which you can get to know about the concentration of the data.","tags":["R","Statistics"],"title":"Measures of Dispersion","type":"post"},{"authors":null,"categories":["R","Statistics"],"content":" Before going directly to measures of central tendency, I want you to look at the data below. This is a table of weekly expenditures of two projects over the course of 10 weeks. Now tell me which one is cost-efficient than the other, or both are the same?\n  project1 project2    10000 10500  15400 15000  14250 14300  13000 12500  11250 11300  10450 10500  9035 9030  12500 12500  14125 14120  11240 11320    What if I show you this?\n  projects average    project1 12125  project2 12107    Using the average, it is easy to compare the expenditures of both projects. This is one of the primary purposes of the measures of central tendency to summarize the data into a single number that represents the center point of the data.\nMeasures of central tendency show the point where most values of a the data fall and represent the tendency of the data to cluster around a middle value using different approaches. Selecting the appropriate method, however, depends on the type of data you are dealing with. In this post, you will learn when to use a particular measure of central tendency and how to calculate it using R.\n Mean: Mean is the measure of central tendency that you are most familiar with. Its use is most often with continuous data. You just add up all of the values and divide by the number of observations in the data. The mean locates the center accurately when the data is normally distributed. In fact, in any symmetrical distribution the mean, median and mode are equal. You can, therefore, use any of the measures of the central tendency to locate the center of the data. However, the presence of extreme values pulls the mean away from the center while the median is less affected by outliers.  As mean is susceptible to the presence of outliers1, it loses its ability to provide the best central location when the data is skewed. As the above figures show that mean is dragged in the direction of the skew. Thus, using only the mean to approximate the center of the data can often be misleading.\nIn R, the mean() function can be used to calculate the arithmetic mean. It takes a vector of values as input and returns the average.\n# use (na.rm = TRUE) if there is any missing value in the list of values mean(c(10000, 15400, 14250, 13000, 11250, 10450, 9035, 12500, 14125, 11240), na.rm = FALSE) ## [1] 12125  Median: Median is the middle point of the data that is arranged in ascending or descending order. If a dataset contains an even number of values, the median is the mean of the two middle values. In other words, the median is the middle of an ordered list of values. Median is less likely to be influenced by the presence of outliers. Therefore, it is the most preferred measure of central tendency when the distribution of the data is skewed. Moreover, the median is used when there is an open-ended distribution. For example, if you have data that measures numbers of employees and the options are 1, 2, 3, 4, “5 or more”. The “5 or more” option is open-ended and the exact value is unknown. Thus, it makes calculating the mean impossible.  The median() function can be used to compute the median. It takes a vector of values as input and returns the value that is occurred most frequently.\n# use (na.rm = TRUE) if there is any missing value in the list of values median(c(10000, 15400, 14250, 13000, 11250, 10450, 9035, 12500, 14125, 11240), na.rm = FALSE) ## [1] 11875  Mode: Mode is preferred when you have a categorical data. It is not often used with the continuous data because there are an infinite number of values between two values and it is very unlikely that two or more values will be exactly equal. Mode represents the most common value -the value that occurs most frequently- in the data. In some cases, a dataset may contain multiple modes while some datasets may not have any mode at all  To the best of my knowledge, there is not any built-in function in R to find out mode in a vector of values. Therefore, below two steps must be followed:\ncount the frequency of each value using table() function. use the result of the first step as an input into the which.max() function to find the mode.  Also, you can use below code to program a new function called Mode to find the mode in a given vector of values.\nMode \u0026lt;- function(x) { as.character( pull( filter( data.frame( table(x) ), Freq == max(Freq)), x) ) } Mode(c(2, 4, 7, 2, 3, 2, 5, 7, 9)) ## [1] \u0026quot;2\u0026quot; The following table shows what the best measure of central tendency is with respect to different types of variables.\n  Types of the variable The best measure of central tendency    Nominal Mode  Ordinal Median / Mode  Continuous (not skewed) Mean  Continuous (skewed) Median    \n Outliers are values that are notably different from the rest of the data. Usually, any value larger than 1.5IQR above the third quartile or lower than 1.5IQR below the first quartile is considered as outlier.↩\n   ","date":1587168000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587168000,"objectID":"1d7204a616e3197f25169a278f48b616","permalink":"/post/measures-of-central-tendency-using-r/","publishdate":"2020-04-18T00:00:00Z","relpermalink":"/post/measures-of-central-tendency-using-r/","section":"post","summary":"Before going directly to measures of central tendency, I want you to look at the data below. This is a table of weekly expenditures of two projects over the course of 10 weeks.","tags":["R","Statistics"],"title":"What is Central Tendency?","type":"post"},{"authors":null,"categories":["R"],"content":"  Why box-plot? Box-plot using the base R function Box-plot using the ggplot2 package   Why box-plot? Box-plot is one of the effective ways to visually represent the distribution of data and it gives you an overall idea about how the data looks. Also, it is one of the best tools to identify the outliers to check if an association you find in your analysis can be explained by the presence of potential unusual observations.\nThe graph shown below is an example of box-plot where the box shows the interquartile range (IQR), the horizontal line inside the box presents the median (50th percentile), and the whiskers (lines extending from the box) represent maximum value that is not an outlier (1.5 IQR above the third quartile) and minimum value that is not an outlier (1.5 IQR below the first quartile). All individual points outside the whiskers are considered as outliers.\n First quartile (Q1 / 25th Percentile) also knows as lower quartile is the center of the lower half of the data. Median (Q2 / 50th Percentile) is the middle value of the data. Third quartile (Q3 / 75th Percentile) also known as upper quartile is center of the upper half of the data. Interquartile range (IQR) shows the middle half of the data. (distance between first and third quartile)  Box-plots are usually a useful way to compare the distribution of data among two or more groups, or to compare the distribution of data among one or more than one group across time.\n Box-plot using the base R function Let’s use the below data as an example. The first column shows the gender of each observation, the values in the second column are pre-test scores and the values in the third column are post-test scores.\ndf \u0026lt;- data.frame( gender = c(\u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Male\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;, \u0026quot;Female\u0026quot;), pre_test = c(30, 26, 24, 19, 27, 21, 31, 16, 16, 26, 28, 29, 36, 25, 27, 24, 32, 30, 33, 26), post_test = c(35, 31, 29, 24, 32, 26, 36, 21, 21, 31, 33, 34, 41, 30, 32, 29, 37, 35, 38, 31) ) df ## gender pre_test post_test ## 1 Male 30 35 ## 2 Male 26 31 ## 3 Male 24 29 ## 4 Male 19 24 ## 5 Male 27 32 ## 6 Male 21 26 ## 7 Male 31 36 ## 8 Male 16 21 ## 9 Male 16 21 ## 10 Female 26 31 ## 11 Female 28 33 ## 12 Female 29 34 ## 13 Female 36 41 ## 14 Female 25 30 ## 15 Female 27 32 ## 16 Female 24 29 ## 17 Female 32 37 ## 18 Female 30 35 ## 19 Female 33 38 ## 20 Female 26 31 The base R function to build a boxplot is boxplot().\nboxplot(df$pre_test, main=\u0026quot;Pre-test\u0026quot;) Let’s combine both plots for better comparison.\nboxplot(df[,c(\u0026quot;pre_test\u0026quot;, \u0026quot;post_test\u0026quot;)], main = \u0026quot;Pre-test vs Post test\u0026quot;)  Box-plot using the ggplot2 package I prefer the ggplot2 plots because the output is nicer and importantly it can be easily modified compared to base R graphs, moreover, it is more popular among R users.\nThe geom_box() function from the ggplot2 package can be used to create a box-plot.\n# install.packages(\u0026quot;ggplot2\u0026quot;) library(ggplot2) ggplot(df) + geom_boxplot(aes(y = pre_test, x = \u0026quot;1: Pre-test\u0026quot;)) + geom_boxplot(aes(y = post_test, x = \u0026quot;2: Post-test\u0026quot;)) + theme_bw() + labs(title = \u0026quot;Pre-test vs. Post-test scores\u0026quot;, x = NULL, y = NULL) The plot on the left side shows the distribution of pre-test scores and the one on the right side shows the distribution of post-test scores. The above plot shows that average post-test score (31.5) is higher compare to the pre-test (26.5).\nIt is also possible to use box-plot to visualize the distribution of data by categories of another variable as well, see below example for instance.\nggplot(df) + geom_boxplot(aes(y = pre_test, x = \u0026quot;1: Pre-test\u0026quot;, fill = gender), alpha = 0.25) + geom_boxplot(aes(y = post_test, x = \u0026quot;2: Post-test\u0026quot;, fill = gender), alpha = 0.25) + theme_bw() + labs(title = \u0026quot;Pre-test vs. Post-test scores, by gender\u0026quot;, x = NULL, y = NULL) The above plot shows that on average females have higher score (boxes in red color) compare to those of males (boxes in blue color) in both pre-test and post-test.\n ","date":1586390400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1586390400,"objectID":"eaf5c05d697872bb9b1b81d5251645c8","permalink":"/post/visualizing-distribution-of-data-in-r-box-plot/","publishdate":"2020-04-09T00:00:00Z","relpermalink":"/post/visualizing-distribution-of-data-in-r-box-plot/","section":"post","summary":"Why box-plot? Box-plot using the base R function Box-plot using the ggplot2 package   Why box-plot? Box-plot is one of the effective ways to visually represent the distribution of data and it gives you an overall idea about how the data looks.","tags":["ggplot","R","visualization"],"title":"Visualizing Distribution of Data | box-plot","type":"post"},{"authors":null,"categories":null,"content":"  body { text-align: justify}  Calculating the average of percentages is NOT similar to calculating the average of numbers.\nI am conducting data analysis trainings once every two months and at the end of each class I ask students if they want to join the advanced data analysis class that I organize once each year. Below data frame contains part of the actual data which I collected from those who have participated in my classes in the past few months which basically has three variables as following:\n class: either a trainee is from class 1 or class 2. education: highest education level of trainees advanced_class: a dummy variable where TRUE indicates a trainee is eager to participate in the advanced class and FALAE indicates a trainee doesn’t want to attend in the advanced class.  df \u0026lt;- data.frame( class = c(\u0026quot;class 1\u0026quot;,\u0026quot;class 2\u0026quot;,\u0026quot;class 1\u0026quot;,\u0026quot;class 1\u0026quot;,\u0026quot;class 2\u0026quot;,\u0026quot;class 2\u0026quot;,\u0026quot;class 1\u0026quot;,\u0026quot;class 1\u0026quot;,\u0026quot;class 1\u0026quot;,\u0026quot;class 2\u0026quot;,\u0026quot;class 1\u0026quot;,\u0026quot;class 1\u0026quot;,\u0026quot;class 2\u0026quot;,\u0026quot;class 2\u0026quot;,\u0026quot;class 2\u0026quot;,\u0026quot;class 1\u0026quot;,\u0026quot;class 1\u0026quot;,\u0026quot;class 1\u0026quot;,\u0026quot;class 1\u0026quot;,\u0026quot;class 2\u0026quot;,\u0026quot;class 1\u0026quot;,\u0026quot;class 1\u0026quot;, \u0026quot;class 1\u0026quot;,\u0026quot;class 2\u0026quot;,\u0026quot;class 1\u0026quot;, \u0026quot;class 1\u0026quot;, \u0026quot;class 1\u0026quot;,\u0026quot;class 2\u0026quot;), education = c(\u0026quot;BA\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;BA\u0026quot;,\u0026quot;BA\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;BA\u0026quot;,\u0026quot;BA\u0026quot;,\u0026quot;BA\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;BA\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;BA\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;BA\u0026quot;,\u0026quot;BA\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;BA\u0026quot;,\u0026quot;BA\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;BA\u0026quot;,\u0026quot;MA\u0026quot;,\u0026quot;BA\u0026quot;,\u0026quot;MA\u0026quot;), advanced_class = c(TRUE,TRUE,FALSE,TRUE,FALSE,TRUE,TRUE,FALSE,TRUE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,TRUE,TRUE,TRUE,FALSE,FALSE,FALSE,FALSE,TRUE,TRUE,FALSE,TRUE) ) ## class education advanced_class ## 1 class 1 BA TRUE ## 2 class 2 MA TRUE ## 3 class 1 BA FALSE ## 4 class 1 BA TRUE ## 5 class 2 MA FALSE ## 6 class 2 MA TRUE ## 7 class 1 BA TRUE ## 8 class 1 BA FALSE ## 9 class 1 BA TRUE ## 10 class 2 MA TRUE ## 11 class 1 MA FALSE ## 12 class 1 MA TRUE ## 13 class 2 BA FALSE ## 14 class 2 MA TRUE ## 15 class 2 BA FALSE ## 16 class 1 MA FALSE ## 17 class 1 BA FALSE ## 18 class 1 BA TRUE ## 19 class 1 MA TRUE ## 20 class 2 MA TRUE ## 21 class 1 BA FALSE ## 22 class 1 BA FALSE ## 23 class 1 MA FALSE ## 24 class 2 MA FALSE ## 25 class 1 BA TRUE ## 26 class 1 MA TRUE ## 27 class 1 BA FALSE ## 28 class 2 MA TRUE Let’s find the percentage of each group who are eager to participate in the advanced class.\nlibrary(dplyr) df %\u0026gt;% {round(prop.table(table(.$class, .$advanced_class),1)*100,2)} ## ## FALSE TRUE ## class 1 50 50 ## class 2 40 60 Above table shows that 60% of trainees from class 2 and 50% of trainees from class 1 want to join the advanced class. Does this mean that (60%+50%)/2=55% of all trainees are intended to join the advanced class?\nlibrary(ggplot2) theme_set(theme_bw()) round(prop.table(table(df$class, df$advanced_class),1)*100,1) %\u0026gt;% data.frame() %\u0026gt;% rename(class = Var1, advanced_class=Var2, percentage = Freq) %\u0026gt;% filter(advanced_class!=FALSE) %\u0026gt;% # mutate(average = sum(percentage)/2) %\u0026gt;% ggplot(aes(x=class, y=percentage, fill = class)) + geom_col() + geom_text(aes(label = percentage), nudge_x=0, nudge_y = 2) + geom_hline(yintercept = (50+60)/2, linetype = \u0026quot;dashed\u0026quot;, color = \u0026quot;red\u0026quot;, size = 1) The answer is No. Because each group does not represent equal numbers of trainees.\ndf %\u0026gt;% {table(.$class)} ## ## class 1 class 2 ## 18 10 As shown above, there are 18 trainees from class 1 and 10 trainees from class 2. It means that 60% of those form the second class represents only 6 trainees and 50% of those from the first class represents 9 trainees.\n class 1: (50 / 100) x 18 = 9 class 2: (60 / 100) x 10 = 6  From the above result we can say that 9+6=15 out of all 18+10=28 trainees in both classes said they would like to join the advanced class. Therefore we can say that (15/28)*100=53.57% of all trainees want to join the advanced class.\ndf %\u0026gt;% {round(prop.table(table(.$advanced_class))*100,2)} ## ## FALSE TRUE ## 46.43 53.57 It can be observed that there is an inconsistency between (6+9/28)*100 =53.57% and (60%+50%)/2=55%. Hence, the temptation of averaging percentages can lead to an inaccurate result.\nWhen sample size in both groups is equal, however, the average of percentages agrees with the accurate percentage calculation.\nFor example, the above data shows that 64.29% of trainees with a master degree would like to join the advanced data analysis class and this proportion is 42.86% among those with a bachelor degree.\ndf %\u0026gt;% {round(prop.table(table(.$education, .$advanced_class),1)*100,2)} ## ## FALSE TRUE ## BA 57.14 42.86 ## MA 35.71 64.29 Here the average of both percentages is (64.29%+42.86)/2=53.57% which is equal to accurate calculation of the percentage of trainees who are intended to join the advanced data analysis training.\nround(prop.table(table(df$education, df$advanced_class),1)*100,1) %\u0026gt;% data.frame() %\u0026gt;% rename(education = Var1, advanced_class=Var2, percentage = Freq) %\u0026gt;% filter(advanced_class!=FALSE) %\u0026gt;% ggplot(aes(x=education, y=percentage, fill = education)) + geom_col()+ geom_text(aes(label=percentage), nudge_y = 2) + geom_hline(yintercept = (42.9+64.3)/2, linetype = \u0026quot;dashed\u0026quot;, color = \u0026quot;red\u0026quot;, size = 2 ) The reason is that there is an equal number of trainees with master and bachelor degrees.\ndf %\u0026gt;% {table(.$education)} ## ## BA MA ## 14 14 Summary Average of percentages would lead you to an inaccurate result unless all groups represent the equal sample size. The reason is simple, when two groups are different in size then the same percentage in both groups will give you two different numbers. For example, 10% of a group of 100 individuals is 10 while 10% of a group of 150 individuals is 15.\n ","date":1562284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562284800,"objectID":"cd42a9db67b5f1101147a1ef7c63c8c2","permalink":"/post/calculating-averag-of-percentages/","publishdate":"2019-07-05T00:00:00Z","relpermalink":"/post/calculating-averag-of-percentages/","section":"post","summary":"body { text-align: justify}  Calculating the average of percentages is NOT similar to calculating the average of numbers.\nI am conducting data analysis trainings once every two months and at the end of each class I ask students if they want to join the advanced data analysis class that I organize once each year.","tags":null,"title":"Calculating Average of Percentages","type":"post"},{"authors":null,"categories":["R"],"content":"  Rename column names with R base functions Rename column names with dplyr Rename column names with data.table   There are several ways of renaming variables in R. In this post you will learn how to change a column name using base R function, the dplyr way and using data.table package.\nI will use the R built-in iris data frame.\nhead(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Rename column names with R base functions Let’s change Sepal.Length to S.P. The procedure is simple; get column names using names() or colnames, extract the specific column name, and assign a new name.\ncolnames(iris)[colnames(iris)==\u0026quot;Sepal.Length\u0026quot;] \u0026lt;- \u0026quot;S.P\u0026quot; head(iris) ## S.P Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa The code does the following:\ncolnames(iris) looks into all the names in the iris. names(iris) == \u0026quot;Sepal.Length\u0026quot; returns a vector with true and false values to extract the variable name you want to change. \u0026lt;- \u0026quot;S.P\u0026quot; assigns the new name.  You can also rename a variable by its index as well. For example, let’s change Sepal.Width [the second column] to S.W.\ncolnames(iris)[2] \u0026lt;- \u0026quot;S.W\u0026quot; head(iris) ## S.P S.W Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa  Rename column names with dplyr You can use rename() function to change column names as following. For instance, let’s change Petal.Length to P.L and Petal.Width to P.W.\n# install.packages(\u0026quot;dplyr\u0026quot;) library(dplyr) iris %\u0026gt;% rename( P.L = Petal.Length, P.W = Petal.Width ) %\u0026gt;% head() ## S.P S.W P.L P.W Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa  Rename column names with data.table setnames() function from data.table package can be used to rename a variable. The syntax is setnames(df, \u0026quot;old_name\u0026quot;, \u0026quot;new_name\u0026quot;). As an example, let’s change Species to SPECIES.\n# install.packages(\u0026quot;data.table\u0026quot;) library(data.table) setnames(iris, \u0026quot;Species\u0026quot;, \u0026quot;SPECIES\u0026quot;) colnames(iris) ## [1] \u0026quot;Sepal.Length\u0026quot; \u0026quot;Sepal.Width\u0026quot; \u0026quot;Petal.Length\u0026quot; \u0026quot;Petal.Width\u0026quot; \u0026quot;SPECIES\u0026quot;  ","date":1560902400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1560902400,"objectID":"fe901af0fd88869a873d98d83f8bdea9","permalink":"/post/rename-data-frame-columns/","publishdate":"2019-06-19T00:00:00Z","relpermalink":"/post/rename-data-frame-columns/","section":"post","summary":"Rename column names with R base functions Rename column names with dplyr Rename column names with data.table   There are several ways of renaming variables in R. In this post you will learn how to change a column name using base R function, the dplyr way and using data.","tags":["R"],"title":"Rename Data Frame Columns","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]